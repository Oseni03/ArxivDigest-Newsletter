{"main_page": "https://arxiv.org/abs/2404.00017", "pdf": "https://arxiv.org/pdf/2404.00017", "title": "Psittacines of Innovation? Assessing the True Novelty of AI Creations", "authors": "Anirban Mukherjee", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "abstract": "We examine whether Artificial Intelligence (AI) systems generate truly novel ideas rather than merely regurgitating patterns learned during training. Utilizing a novel experimental design, we task an AI with generating project titles for hypothetical crowdfunding campaigns. We compare within AI-generated project titles, measuring repetition and complexity. We compare between the AI-generated titles and actual observed field data using an extension of maximum mean discrepancy--a metric derived from the application of kernel mean embeddings of statistical distributions to high-dimensional machine learning (large language) embedding vectors--yielding a structured analysis of AI output novelty. Results suggest that (1) the AI generates unique content even under increasing task complexity, and at the limits of its computational capabilities, (2) the generated content has face validity, being consistent with both inputs to other generative AI and in qualitative comparison to field data, and (3) exhibits divergence from field data, mitigating concerns relating to intellectual property rights. We discuss implications for copyright and trademark law."}
{"main_page": "https://arxiv.org/abs/2404.00051", "pdf": "https://arxiv.org/pdf/2404.00051", "title": "Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal  Knowledge Graph Reasoning", "authors": "Miao Peng, Ben Liu, Wenjie Xu, Zihao Jiang, Jiahui Zhu, Min Peng", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the task of inferring missing facts for incomplete TKGs in complex scenarios (e.g., transductive and inductive settings), which has been gaining increasing attention. Recently, to mitigate dependence on structured connections in TKGs, text-based methods have been developed to utilize rich linguistic information from entity descriptions. However, suffering from the enormous parameters and inflexibility of pre-trained language models, existing text-based methods struggle to balance the textual knowledge and temporal information with computationally expensive purpose-built training strategies. To tap the potential of text-based models for TKGR in various complex scenarios, we propose ChapTER, a Contrastive historical modeling framework with prefix-tuning for TEmporal Reasoning. ChapTER feeds history-contextualized text into the pseudo-Siamese encoders to strike a textual-temporal balance via contrastive estimation between queries and candidates. By introducing virtual time prefix tokens, it applies a prefix-based tuning method to facilitate the frozen PLM capable for TKGR tasks under different settings. We evaluate ChapTER on four transductive and three few-shot inductive TKGR benchmarks, and experimental results demonstrate that ChapTER achieves superior performance compared to competitive baselines with only 0.17% tuned parameters. We conduct thorough analysis to verify the effectiveness, flexibility and efficiency of ChapTER."}
{"main_page": "https://arxiv.org/abs/2404.00099", "pdf": "https://arxiv.org/pdf/2404.00099", "title": "Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision  Processes", "authors": "Andrew Bennett, Nathan Kallus, Miruna Oprescu, Wen Sun, Kaiwen Wang", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "abstract": "We study evaluating a policy under best- and worst-case perturbations to a Markov decision process (MDP), given transition observations from the original MDP, whether under the same or different policy. This is an important problem when there is the possibility of a shift between historical and future environments, due to e.g. unmeasured confounding, distributional shift, or an adversarial environment. We propose a perturbation model that can modify transition kernel densities up to a given multiplicative factor or its reciprocal, which extends the classic marginal sensitivity model (MSM) for single time step decision making to infinite-horizon RL. We characterize the sharp bounds on policy value under this model, that is, the tightest possible bounds given by the transition observations from the original MDP, and we study the estimation of these bounds from such transition observations. We develop an estimator with several appealing guarantees: it is semiparametrically efficient, and remains so even when certain necessary nuisance functions such as worst-case Q-functions are estimated at slow nonparametric rates. It is also asymptotically normal, enabling easy statistical inference using Wald confidence intervals. In addition, when certain nuisances are estimated inconsistently we still estimate a valid, albeit possibly not sharp bounds on the policy value. We validate these properties in numeric simulations. The combination of accounting for environment shifts from train to test (robustness), being insensitive to nuisance-function estimation (orthogonality), and accounting for having only finite samples to learn from (inference) together leads to credible and reliable policy evaluation."}
{"main_page": "https://arxiv.org/abs/2404.00140", "pdf": "https://arxiv.org/pdf/2404.00140", "title": "Does Faithfulness Conflict with Plausibility? An Empirical Study in  Explainable AI across NLP Tasks", "authors": "Xiaolei Lu, Jianghong Ma", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Explainability algorithms aimed at interpreting decision-making AI systems usually consider balancing two critical dimensions: 1) \\textit{faithfulness}, where explanations accurately reflect the model's inference process. 2) \\textit{plausibility}, where explanations are consistent with domain experts. However, the question arises: do faithfulness and plausibility inherently conflict? In this study, through a comprehensive quantitative comparison between the explanations from the selected explainability methods and expert-level interpretations across three NLP tasks: sentiment analysis, intent detection, and topic labeling, we demonstrate that traditional perturbation-based methods Shapley value and LIME could attain greater faithfulness and plausibility. Our findings suggest that rather than optimizing for one dimension at the expense of the other, we could seek to optimize explainability algorithms with dual objectives to achieve high levels of accuracy and user accessibility in their explanations."}
{"main_page": "https://arxiv.org/abs/2404.00276", "pdf": "https://arxiv.org/pdf/2404.00276", "title": "Instruction-Driven Game Engines on Large Language Models", "authors": "Hongqiu Wu, Yan Wang, Xingyuan Liu, Hai Zhao, Min Zhang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "The Instruction-Driven Game Engine (IDGE) project aims to democratize game development by enabling a large language model (LLM) to follow free-form game rules and autonomously generate game-play processes. The IDGE allows users to create games by issuing simple natural language instructions, which significantly lowers the barrier for game development. We approach the learning process for IDGEs as a Next State Prediction task, wherein the model autoregressively predicts in-game states given player actions. It is a challenging task because the computation of in-game states must be precise; otherwise, slight errors could disrupt the game-play. To address this, we train the IDGE in a curriculum manner that progressively increases the model's exposure to complex scenarios. Our initial progress lies in developing an IDGE for Poker, a universally cherished card game. The engine we've designed not only supports a wide range of poker variants but also allows for high customization of rules through natural language inputs. Furthermore, it also favors rapid prototyping of new games from minimal samples, proposing an innovative paradigm in game development that relies on minimal prompt and data engineering. This work lays the groundwork for future advancements in instruction-driven game creation, potentially transforming how games are designed and played."}
{"main_page": "https://arxiv.org/abs/2404.00320", "pdf": "https://arxiv.org/pdf/2404.00320", "title": "Advancing Multimodal Data Fusion in Pain Recognition: A Strategy  Leveraging Statistical Correlation and Human-Centered Perspectives", "authors": "Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "This research tackles the challenge of integrating heterogeneous data for specific behavior recognition within the domain of Pain Recognition, presenting a novel methodology that harmonizes statistical correlations with a human-centered approach. By leveraging a diverse range of deep learning architectures, we highlight the adaptability and efficacy of our approach in improving model performance across various complex scenarios. The novelty of our methodology is the strategic incorporation of statistical relevance weights and the segmentation of modalities from a human-centric perspective, enhancing model precision and providing a explainable analysis of multimodal data. This study surpasses traditional modality fusion techniques by underscoring the role of data diversity and customized modality segmentation in enhancing pain behavior analysis. Introducing a framework that matches each modality with an suited classifier, based on the statistical significance, signals a move towards customized and accurate multimodal fusion strategies. Our contributions extend beyond the field of Pain Recognition by delivering new insights into modality fusion and human-centered computing applications, contributing towards explainable AI and bolstering patient-centric healthcare interventions. Thus, we bridge a significant void in the effective and interpretable fusion of multimodal data, establishing a novel standard for forthcoming inquiries in pain behavior recognition and allied fields."}
{"main_page": "https://arxiv.org/abs/2404.00341", "pdf": "https://arxiv.org/pdf/2404.00341", "title": "Ontology in Holonic Cooperative Manufacturing: A Solution to Share and  Exchange the Knowledge", "authors": "Ahmed R.Sadik, Bodo Urban", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Cooperative manufacturing is a new trend in industry, which depends on the existence of a collaborative robot. A collaborative robot is usually a light-weight robot which is capable of operating safely with a human co-worker in a shared work environment. During this cooperation, a vast amount of information is exchanged between the collaborative robot and the worker. This information constructs the cooperative manufacturing knowledge, which describes the production components and environment. In this research, we propose a holonic control solution, which uses the ontology concept to represent the cooperative manufacturing knowledge. The holonic control solution is implemented as an autonomous multi-agent system that exchanges the manufacturing knowledge based on an ontology model. Ultimately, the research illustrates and implements the proposed solution over a cooperative assembly scenario, which involves two workers and one collaborative robot, whom cooperate together to assemble a customized product."}
{"main_page": "https://arxiv.org/abs/2404.00560", "pdf": "https://arxiv.org/pdf/2404.00560", "title": "A Theory for Length Generalization in Learning to Reason", "authors": "Changnan Xiao, Bing Liu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Length generalization (LG) is a challenging problem in learning to reason. It refers to the phenomenon that when trained on reasoning problems of smaller lengths or sizes, the resulting model struggles with problems of larger sizes or lengths. Although LG has been studied by many researchers, the challenge remains. This paper proposes a theoretical study of LG for problems whose reasoning processes can be modeled as DAGs (directed acyclic graphs). The paper first identifies and proves the conditions under which LG can be achieved in learning to reason. It then designs problem representations based on the theory to learn to solve challenging reasoning problems like parity, addition, and multiplication, using a Transformer to achieve perfect LG."}
{"main_page": "https://arxiv.org/abs/2404.00586", "pdf": "https://arxiv.org/pdf/2404.00586", "title": "RLGNet: Repeating-Local-Global History Network for Temporal Knowledge  Graph Reasoning", "authors": "Ao Lv, Yongzhong Huang, Guige Ouyang, Yue Chen, Haoran Xie", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Temporal Knowledge Graph (TKG) reasoning is based on historical information to predict the future. Therefore, parsing and mining historical information is key to predicting the future. Most existing methods fail to concurrently address and comprehend historical information from both global and local perspectives. Neglecting the global view might result in overlooking macroscopic trends and patterns, while ignoring the local view can lead to missing critical detailed information. Additionally, some methods do not focus on learning from high-frequency repeating events, which means they may not fully grasp frequently occurring historical events. To this end, we propose the \\textbf{R}epetitive-\\textbf{L}ocal-\\textbf{G}lobal History \\textbf{Net}work(RLGNet). We utilize a global history encoder to capture the overarching nature of historical information. Subsequently, the local history encoder provides information related to the query timestamp. Finally, we employ the repeating history encoder to identify and learn from frequently occurring historical events. In the evaluation on six benchmark datasets, our approach generally outperforms existing TKG reasoning models in multi-step and single-step reasoning tasks."}
{"main_page": "https://arxiv.org/abs/2404.00756", "pdf": "https://arxiv.org/pdf/2404.00756", "title": "Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery", "authors": "Cristina Cornelio, Mohammed Diab", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO); Robotics (cs.RO)", "abstract": "Recognizing failures during task execution and implementing recovery procedures is challenging in robotics. Traditional approaches rely on the availability of extensive data or a tight set of constraints, while more recent approaches leverage large language models (LLMs) to verify task steps and replan accordingly. However, these methods often operate offline, necessitating scene resets and incurring in high costs. This paper introduces Recover, a neuro-symbolic framework for online failure identification and recovery. By integrating ontologies, logical rules, and LLM-based planners, Recover exploits symbolic information to enhance the ability of LLMs to generate recovery plans and also to decrease the associated costs. In order to demonstrate the capabilities of our method in a simulated kitchen environment, we introduce OntoThor, an ontology describing the AI2Thor simulator setting. Empirical evaluation shows that OntoThor's logical rules accurately detect all failures in the analyzed tasks, and that Recover considerably outperforms, for both failure detection and recovery, a baseline method reliant solely on LLMs."}
{"main_page": "https://arxiv.org/abs/2404.00886", "pdf": "https://arxiv.org/pdf/2404.00886", "title": "MTLight: Efficient Multi-Task Reinforcement Learning for Traffic Signal  Control", "authors": "Liwen Zhu, Peixi Peng, Zongqing Lu, Yonghong Tian", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Traffic signal control has a great impact on alleviating traffic congestion in modern cities. Deep reinforcement learning (RL) has been widely used for this task in recent years, demonstrating promising performance but also facing many challenges such as limited performances and sample inefficiency. To handle these challenges, MTLight is proposed to enhance the agent observation with a latent state, which is learned from numerous traffic indicators. Meanwhile, multiple auxiliary and supervisory tasks are constructed to learn the latent state, and two types of embedding latent features, the task-specific feature and task-shared feature, are used to make the latent state more abundant. Extensive experiments conducted on CityFlow demonstrate that MTLight has leading convergence speed and asymptotic performance. We further simulate under peak-hour pattern in all scenarios with increasing control difficulty and the results indicate that MTLight is highly adaptable."}
{"main_page": "https://arxiv.org/abs/2404.01266", "pdf": "https://arxiv.org/pdf/2404.01266", "title": "IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic  Representations", "authors": "Deqing Fu, Ghazal Khalighinejad, Ollie Liu, Bhuwan Dhingra, Dani Yogatama, Robin Jia, Willie Neiswanger", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Current foundation models exhibit impressive capabilities when prompted either with text only or with both image and text inputs. But do their capabilities change depending on the input modality? In this work, we propose $\\textbf{IsoBench}$, a benchmark dataset containing problems from four major areas: math, science, algorithms, and games. Each example is presented with multiple $\\textbf{isomorphic representations}$ of inputs, such as visual, textual, and mathematical presentations. IsoBench provides fine-grained feedback to diagnose performance gaps caused by the form of the representation. Across various foundation models, we observe that on the same problem, models have a consistent preference towards textual representations. Most prominently, when evaluated on all IsoBench problems, Claude-3 Opus performs 28.7 points worse when provided with images instead of text; similarly, GPT-4 Turbo is 18.7 points worse and Gemini Pro is 14.9 points worse. Finally, we present two prompting techniques, $\\textit{IsoCombination}$ and $\\textit{IsoScratchPad}$, which improve model performance by considering combinations of, and translations between, different input representations."}
