{"main_page": "https://arxiv.org/abs/2404.00024", "pdf": "https://arxiv.org/pdf/2404.00024", "title": "Hey, Teacher, (Don't) Leave Those Kids Alone: Standardizing HRI  Education", "authors": "Alexis E. Block", "subjects": "Robotics (cs.RO); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "abstract": "Creating a standardized introduction course becomes more critical as the field of human-robot interaction (HRI) becomes more established. This paper outlines the key components necessary to provide an undergraduate with a sufficient foundational understanding of the interdisciplinary nature of this field and provides proposed course content. It emphasizes the importance of creating a course with theoretical and experimental components to accommodate all different learning preferences. This manuscript also advocates creating or adopting a universal platform to standardize the hands-on component of introductory HRI courses, regardless of university funding or size. Next, it recommends formal training in how to read scientific articles and staying up-to-date with the latest relevant papers. Finally, it provides detailed lecture content and project milestones for a 15-week semester. By creating a standardized course, researchers can ensure consistency and quality are maintained across institutions, which will help students as well as industrial and academic employers understand what foundational knowledge is expected."}
{"main_page": "https://arxiv.org/abs/2404.00123", "pdf": "https://arxiv.org/pdf/2404.00123", "title": "SURESTEP: An Uncertainty-Aware Trajectory Optimization Framework to  Enhance Visual Tool Tracking for Robust Surgical Automation", "authors": "Nikhil U. Shinde, Zih-Yun Chiu, Florian Richter, Jason Lim, Yuheng Zhi, Sylvia Herbert, Michael C. Yip", "subjects": "Robotics (cs.RO)", "abstract": "Inaccurate tool localization is one of the main reasons for failures in automating surgical tasks. Imprecise robot kinematics and noisy observations caused by the poor visual acuity of an endoscopic camera make tool tracking challenging. Previous works in surgical automation adopt environment-specific setups or hard-coded strategies instead of explicitly considering motion and observation uncertainty of tool tracking in their policies. In this work, we present SURESTEP, an uncertainty-aware trajectory optimization framework for robust surgical automation. We model the uncertainty of tool tracking with the components motivated by the sources of noise in typical surgical scenes. Using a Gaussian assumption to propagate our uncertainty models through a given tool trajectory, SURESTEP provides a general framework that minimizes the upper bound on the entropy of the final estimated tool distribution. We compare SURESTEP with a baseline method on a real-world suture needle regrasping task under challenging environmental conditions, such as poor lighting and a moving endoscopic camera. The results over 60 regrasps on the da Vinci Research Kit (dVRK) demonstrate that our optimized trajectories significantly outperform the un-optimized baseline."}
{"main_page": "https://arxiv.org/abs/2404.00133", "pdf": "https://arxiv.org/pdf/2404.00133", "title": "An Optimization-Based Planner with B-spline Parameterized  Continuous-Time Reference Signals", "authors": "Chuyuan Tao, Sheng Cheng, Yang Zhao, Fanxin Wang, Naira Hovakimyan", "subjects": "Robotics (cs.RO)", "abstract": "For the cascaded planning and control modules implemented for robot navigation, the frequency gap between the planner and controller has received limited attention. In this study, we introduce a novel B-spline parameterized optimization-based planner (BSPOP) designed to address the frequency gap challenge with limited onboard computational power in robots. The proposed planner generates continuous-time control inputs for low-level controllers running at arbitrary frequencies to track. Furthermore, when considering the convex control action sets, BSPOP uses the convex hull property to automatically constrain the continuous-time control inputs within the convex set. Consequently, compared with the discrete-time optimization-based planners, BSPOP reduces the number of decision variables and inequality constraints, which improves computational efficiency as a byproduct. Simulation results demonstrate that our approach can achieve a comparable planning performance to the high-frequency baseline optimization-based planners while demanding less computational power. Both simulation and experiment results show that the proposed method performs better in planning compared with baseline planners in the same frequency."}
{"main_page": "https://arxiv.org/abs/2404.00143", "pdf": "https://arxiv.org/pdf/2404.00143", "title": "Accelerating Search-Based Planning for Multi-Robot Manipulation by  Leveraging Online-Generated Experiences", "authors": "Yorai Shaoul, Itamar Mishani, Maxim Likhachev, Jiaoyang Li", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "abstract": "An exciting frontier in robotic manipulation is the use of multiple arms at once. However, planning concurrent motions is a challenging task using current methods. The high-dimensional composite state space renders many well-known motion planning algorithms intractable. Recently, Multi-Agent Path-Finding (MAPF) algorithms have shown promise in discrete 2D domains, providing rigorous guarantees. However, widely used conflict-based methods in MAPF assume an efficient single-agent motion planner. This poses challenges in adapting them to manipulation cases where this assumption does not hold, due to the high dimensionality of configuration spaces and the computational bottlenecks associated with collision checking. To this end, we propose an approach for accelerating conflict-based search algorithms by leveraging their repetitive and incremental nature -- making them tractable for use in complex scenarios involving multi-arm coordination in obstacle-laden environments. We show that our method preserves completeness and bounded sub-optimality guarantees, and demonstrate its practical efficacy through a set of experiments with up to 10 robotic arms."}
{"main_page": "https://arxiv.org/abs/2404.00186", "pdf": "https://arxiv.org/pdf/2404.00186", "title": "A Sequential Quadratic Programming Approach to the Solution of Open-Loop  Generalized Nash Equilibria for Autonomous Racing", "authors": "Edward L. Zhu, Francesco Borrelli", "subjects": "Robotics (cs.RO)", "abstract": "Dynamic games can be an effective approach for modeling interactive behavior between multiple competitive agents in autonomous racing and they provide a theoretical framework for simultaneous prediction and control in such scenarios. In this work, we propose DG-SQP, a numerical method for the solution of local generalized Nash equilibria (GNE) for open-loop general-sum dynamic games for agents with nonlinear dynamics and constraints. In particular, we formulate a sequential quadratic programming (SQP) approach which requires only the solution of a single convex quadratic program at each iteration. The three key elements of the method are a non-monotonic line search for solving the associated KKT equations, a merit function to handle zero sum costs, and a decaying regularization scheme for SQP step selection. We show that our method achieves linear convergence in the neighborhood of local GNE and demonstrate the effectiveness of the approach in the context of head-to-head car racing, where we show significant improvement in solver success rate when comparing against the state-of-the-art PATH solver for dynamic games. An implementation of our solver can be found at https://github.com/zhu-edward/DGSQP."}
{"main_page": "https://arxiv.org/abs/2404.00204", "pdf": "https://arxiv.org/pdf/2404.00204", "title": "A PPO-based DRL Auto-Tuning Nonlinear PID Drone Controller for Robust  Autonomous Flights", "authors": "Junyang Zhang, Cristian Emanuel Ocampo Rivera, Kyle Tyni, Steven Nguyen", "subjects": "Robotics (cs.RO); Machine Learning (cs.LG); Systems and Control (eess.SY)", "abstract": "This project aims to revolutionize drone flight control by implementing a nonlinear Deep Reinforcement Learning (DRL) agent as a replacement for traditional linear Proportional Integral Derivative (PID) controllers. The primary objective is to seamlessly transition drones between manual and autonomous modes, enhancing responsiveness and stability. We utilize the Proximal Policy Optimization (PPO) reinforcement learning strategy within the Gazebo simulator to train the DRL agent. Adding a $20,000 indoor Vicon tracking system offers <1mm positioning accuracy, which significantly improves autonomous flight precision. To navigate the drone in the shortest collision-free trajectory, we also build a 3 dimensional A* path planner and implement it into the real flight successfully."}
{"main_page": "https://arxiv.org/abs/2404.00210", "pdf": "https://arxiv.org/pdf/2404.00210", "title": "Socially Aware Robot Navigation through Scoring Using Vision-Language  Models", "authors": "Daeun Song, Jing Liang, Amirreza Payandeh, Xuesu Xiao, Dinesh Manocha", "subjects": "Robotics (cs.RO)", "abstract": "We propose VLM-Social-Nav, a novel Vision-Language Model (VLM) based navigation approach to compute a robot's trajectory in human-centered environments. Our goal is to make real-time decisions on robot actions that are socially compliant with human expectations. We utilize a perception model to detect important social entities and prompt a VLM to generate guidance for socially compliant robot behavior. VLM-Social-Nav uses a VLM-based scoring module that computes a cost term that ensures socially appropriate and effective robot actions generated by the underlying planner. Our overall approach reduces reliance on large datasets (for training) and enhances adaptability in decision-making. In practice, it results in improved socially compliant navigation in human-shared environments. We demonstrate and evaluate our system in four different real-world social navigation scenarios with a Turtlebot robot. We observe at least 36.37% improvement in average success rate and 20.00% improvement in average collision rate in the four social navigation scenarios. The user study score shows that VLM-Social-Nav generates the most socially compliant navigation behavior."}
{"main_page": "https://arxiv.org/abs/2404.00232", "pdf": "https://arxiv.org/pdf/2404.00232", "title": "Efficient Automatic Tuning for Data-driven Model Predictive Control via  Meta-Learning", "authors": "Baoyu Li, William Edwards, Kris Hauser", "subjects": "Robotics (cs.RO); Machine Learning (cs.LG)", "abstract": "AutoMPC is a Python package that automates and optimizes data-driven model predictive control. However, it can be computationally expensive and unstable when exploring large search spaces using pure Bayesian Optimization (BO). To address these issues, this paper proposes to employ a meta-learning approach called Portfolio that improves AutoMPC's efficiency and stability by warmstarting BO. Portfolio optimizes initial designs for BO using a diverse set of configurations from previous tasks and stabilizes the tuning process by fixing initial configurations instead of selecting them randomly. Experimental results demonstrate that Portfolio outperforms the pure BO in finding desirable solutions for AutoMPC within limited computational resources on 11 nonlinear control simulation benchmarks and 1 physical underwater soft robot dataset."}
{"main_page": "https://arxiv.org/abs/2404.00237", "pdf": "https://arxiv.org/pdf/2404.00237", "title": "Joint Pedestrian Trajectory Prediction through Posterior Sampling", "authors": "Haotian Lin, Yixiao Wang, Mingxiao Huo, Chensheng Peng, Zhiyuan Liu, Masayoshi Tomizuka", "subjects": "Robotics (cs.RO)", "abstract": "Joint pedestrian trajectory prediction has long grappled with the inherent unpredictability of human behaviors. Recent investigations employing variants of conditional diffusion models in trajectory prediction have exhibited notable success. Nevertheless, the heavy dependence on accurate historical data results in their vulnerability to noise disturbances and data incompleteness. To improve the robustness and reliability, we introduce the Guided Full Trajectory Diffuser (GFTD), a novel diffusion model framework that captures the joint full (historical and future) trajectory distribution. By learning from the full trajectory, GFTD can recover the noisy and missing data, hence improving the robustness. In addition, GFTD can adapt to data imperfections without additional training requirements, leveraging posterior sampling for reliable prediction and controllable generation. Our approach not only simplifies the prediction process but also enhances generalizability in scenarios with noise and incomplete inputs. Through rigorous experimental evaluation, GFTD exhibits superior performance in both trajectory prediction and controllable generation."}
{"main_page": "https://arxiv.org/abs/2404.00318", "pdf": "https://arxiv.org/pdf/2404.00318", "title": "Exploring Unseen Environments with Robots using Large Language and  Vision Models through a Procedurally Generated 3D Scene Representation", "authors": "Arjun P S, Andrew Melnik, Gora Chand Nandi", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advancements in Generative Artificial Intelligence, particularly in the realm of Large Language Models (LLMs) and Large Vision Language Models (LVLMs), have enabled the prospect of leveraging cognitive planners within robotic systems. This work focuses on solving the object goal navigation problem by mimicking human cognition to attend, perceive and store task specific information and generate plans with the same. We introduce a comprehensive framework capable of exploring an unfamiliar environment in search of an object by leveraging the capabilities of Large Language Models(LLMs) and Large Vision Language Models (LVLMs) in understanding the underlying semantics of our world. A challenging task in using LLMs to generate high level sub-goals is to efficiently represent the environment around the robot. We propose to use a 3D scene modular representation, with semantically rich descriptions of the object, to provide the LLM with task relevant information. But providing the LLM with a mass of contextual information (rich 3D scene semantic representation), can lead to redundant and inefficient plans. We propose to use an LLM based pruner that leverages the capabilities of in-context learning to prune out irrelevant goal specific information."}
{"main_page": "https://arxiv.org/abs/2404.00340", "pdf": "https://arxiv.org/pdf/2404.00340", "title": "Deep Reinforcement Learning in Autonomous Car Path Planning and Control:  A Survey", "authors": "Yiyang Chen, Chao Ji, Yunrui Cai, Tong Yan, Bo Su", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "Combining data-driven applications with control systems plays a key role in recent Autonomous Car research. This thesis offers a structured review of the latest literature on Deep Reinforcement Learning (DRL) within the realm of autonomous vehicle Path Planning and Control. It collects a series of DRL methodologies and algorithms and their applications in the field, focusing notably on their roles in trajectory planning and dynamic control. In this review, we delve into the application outcomes of DRL technologies in this domain. By summarizing these literatures, we highlight potential challenges, aiming to offer insights that might aid researchers engaged in related fields."}
{"main_page": "https://arxiv.org/abs/2404.00343", "pdf": "https://arxiv.org/pdf/2404.00343", "title": "Commonsense Scene Graph-based Target Localization for Object Search", "authors": "Wenqi Ge, Chao Tang, Hong Zhang", "subjects": "Robotics (cs.RO)", "abstract": "Object search is a fundamental skill for household robots, yet the core problem lies in the robot's ability to locate the target object accurately. The dynamic nature of household environments, characterized by the arbitrary placement of daily objects by users, makes it challenging to perform target localization. To efficiently locate the target object, the robot needs to be equipped with knowledge at both the object and room level. However, existing approaches rely solely on one type of knowledge, leading to unsatisfactory object localization performance and, consequently, inefficient object search processes. To address this problem, we propose a commonsense scene graph-based target localization, CSG-TL, to enhance target object search in the household environment. Given the pre-built map with stationary items, the robot models the room-level knowledge with object-level commonsense knowledge generated by a large language model (LLM) to a commonsense scene graph (CSG), supporting both types of knowledge for CSG-TL. To demonstrate the superiority of CSG-TL on target localization, extensive experiments are performed on the real-world ScanNet dataset and the AI2THOR simulator. Moreover, we have extended CSG-TL to an object search framework, CSG-OS, validated in both simulated and real-world environments. Code and videos are available at https://sites.google.com/view/csg-os."}
{"main_page": "https://arxiv.org/abs/2404.00353", "pdf": "https://arxiv.org/pdf/2404.00353", "title": "CBF-Based STL Motion Planning for Social Navigation in Crowded  Environment", "authors": "Andrea Ruo, Lorenzo Sabattini, Valeria Villani", "subjects": "Robotics (cs.RO)", "abstract": "A motion planning methodology based on the combination of Control Barrier Functions (CBF) and Signal Temporal Logic (STL) is employed in this paper. This methodology allows task completion at any point within a specified time interval, considering a dynamic system subject to velocity constraints. In this work, we apply this approach into the context of Socially Responsible Navigation (SRN), introducing a rotation constraint. This constraint is designed to maintain the user within the robot's field of view (FOV), enhancing human-robot interaction with the concept of side-by-side human-robot companion. This angular constraint offers the possibility to customize social navigation to specific needs, thereby enabling safe SRN. Its validation is carried out through simulations demonstrating the system's effectiveness in adhering to spatio-temporal constraints, including those related to robot velocity, rotation, and the presence of static and dynamic obstacles."}
{"main_page": "https://arxiv.org/abs/2404.00354", "pdf": "https://arxiv.org/pdf/2404.00354", "title": "Follow me: an architecture for user identification and social navigation  with a mobile robot", "authors": "Andrea Ruo, Lorenzo Sabattini, Valeria Villani", "subjects": "Robotics (cs.RO)", "abstract": "Over the past decade, a multitude of service robots have been developed to fulfill a wide range of practical purposes. Notably, roles such as reception and robotic guidance have garnered extensive popularity. In these positions, robots are progressively assuming the responsibilities traditionally held by human staff in assisting customers. Ensuring the safe and socially acceptable operation of robots in such environments poses a fundamental challenge within the context of Socially Responsible Navigation (SRN). This article presents an architecture for user identification and social navigation with a mobile robot that employs computer vision, machine learning, and artificial intelligence algorithms to identify and guide users in a social navigation context, thereby providing an intuitive and user-friendly experience with the robot."}
{"main_page": "https://arxiv.org/abs/2404.00356", "pdf": "https://arxiv.org/pdf/2404.00356", "title": "CBF-Based Motion Planning for Socially Responsible Robot Navigation  Guaranteeing STL Specification", "authors": "Andrea Ruo, Lorenzo Sabattini, Valeria Villani", "subjects": "Robotics (cs.RO)", "abstract": "In the field of control engineering, the connection between Signal Temporal Logic (STL) and time-varying Control Barrier Functions (CBF) has attracted considerable attention. CBFs have demonstrated notable success in ensuring the safety of critical applications by imposing constraints on system states, while STL allows for precisely specifying spatio-temporal constraints on the behavior of robotic systems. Leveraging these methodologies, this paper addresses the safety-critical navigation problem, in Socially Responsible Navigation (SRN) context, presenting a CBF-based STL motion planning methodology. This methodology enables task completion at any time within a specified time interval considering a dynamic system subject to velocity constraints. The proposed approach involves real-time computation of a smooth CBF, with the computation of a dynamically adjusted parameter based on the available path space and the maximum allowable velocity. A simulation study is conducted to validate the methodology, ensuring safety in the presence of static and dynamic obstacles and demonstrating its compliance with spatio-temporal constraints under non-linear velocity constraints."}
{"main_page": "https://arxiv.org/abs/2404.00364", "pdf": "https://arxiv.org/pdf/2404.00364", "title": "Accurate Cutting-point Estimation for Robotic Lychee Harvesting through  Geometry-aware Learning", "authors": "Gengming Zhang, Hao Cao, Kewei Hu, Yaoqiang Pan, Yuqin Deng, Hongjun Wang, Hanwen Kang", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "abstract": "Accurately identifying lychee-picking points in unstructured orchard environments and obtaining their coordinate locations is critical to the success of lychee-picking robots. However, traditional two-dimensional (2D) image-based object detection methods often struggle due to the complex geometric structures of branches, leaves and fruits, leading to incorrect determination of lychee picking points. In this study, we propose a Fcaf3d-lychee network model specifically designed for the accurate localisation of lychee picking points. Point cloud data of lychee picking points in natural environments are acquired using Microsoft's Azure Kinect DK time-of-flight (TOF) camera through multi-view stitching. We augment the Fully Convolutional Anchor-Free 3D Object Detection (Fcaf3d) model with a squeeze-and-excitation(SE) module, which exploits human visual attention mechanisms for improved feature extraction of lychee picking points. The trained network model is evaluated on a test set of lychee-picking locations and achieves an impressive F1 score of 88.57%, significantly outperforming existing models. Subsequent three-dimensional (3D) position detection of picking points in real lychee orchard environments yields high accuracy, even under varying degrees of occlusion. Localisation errors of lychee picking points are within 1.5 cm in all directions, demonstrating the robustness and generality of the model."}
{"main_page": "https://arxiv.org/abs/2404.00369", "pdf": "https://arxiv.org/pdf/2404.00369", "title": "Worker Robot Cooperation and Integration into the Manufacturing Workcell  via the Holonic Control Architecture", "authors": "Ahmed R. Sadik, Bodo Urban, Omar Adel", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Systems and Control (eess.SY)", "abstract": "Worker-Robot Cooperation is a new industrial trend, which aims to sum the advantages of both the human and the industrial robot to afford a new intelligent manufacturing techniques. The cooperative manufacturing between the worker and the robot contains other elements such as the product parts and the manufacturing tools. All these production elements must cooperate in one manufacturing workcell to fulfill the production requirements. The manufacturing control system is the mean to connect all these cooperative elements together in one body. This manufacturing control system is distributed and autonomous due to the nature of the cooperative workcell. Accordingly, this article proposes the holonic control architecture as the manufacturing concept of the cooperative workcell. Furthermore, the article focuses on the feasibility of this manufacturing concept, by applying it over a case study that involves the cooperation between a dual-arm robot and a worker. During this case study, the worker uses a variety of hand gestures to cooperate with the robot to achieve the highest production flexibility"}
{"main_page": "https://arxiv.org/abs/2404.00426", "pdf": "https://arxiv.org/pdf/2404.00426", "title": "Self-Corrective Sensor Fusion for Drone Positioning in Indoor Facilities", "authors": "Francisco Javier Gonz\u00e1lez-Casta\u00f1o, Felipe Gil-Casti\u00f1eira, David Rodr\u00edguez-Pereira, Jos\u00e9 \u00c1ngel Regueiro-Janeiro, Silvia Garc\u00eda-M\u00e9ndez, David Candal-Ventureira", "subjects": "Robotics (cs.RO); Signal Processing (eess.SP)", "abstract": "Drones may be more advantageous than fixed cameras for quality control applications in industrial facilities, since they can be redeployed dynamically and adjusted to production planning. The practical scenario that has motivated this paper, image acquisition with drones in a car manufacturing plant, requires drone positioning accuracy in the order of 5 cm. During repetitive manufacturing processes, it is assumed that quality control imaging drones will follow highly deterministic periodic paths, stop at predefined points to take images and send them to image recognition servers. Therefore, by relying on prior knowledge about production chain schedules, it is possible to optimize the positioning technologies for the drones to stay at all times within the boundaries of their flight plans, which will be composed of stopping points and the paths in between. This involves mitigating issues such as temporary blocking of line-of-sight between the drone and any existing radio beacons; sensor data noise; and the loss of visual references. We present a self-corrective solution for this purpose. It corrects visual odometer readings based on filtered and clustered Ultra-Wide Band (UWB) data, as an alternative to direct Kalman fusion. The approach combines the advantages of these technologies when at least one of them works properly at any measurement spot. It has three method components: independent Kalman filtering, data association by means of stream clustering and mutual correction of sensor readings based on the generation of cumulative correction vectors. The approach is inspired by the observation that UWB positioning works reasonably well at static spots whereas visual odometer measurements reflect straight displacements correctly but can underestimate their length. Our experimental results demonstrate the advantages of the approach in the application scenario over Kalman fusion."}
{"main_page": "https://arxiv.org/abs/2404.00442", "pdf": "https://arxiv.org/pdf/2404.00442", "title": "Interactive Multi-Robot Flocking with Gesture Responsiveness and Musical  Accompaniment", "authors": "Catie Cuan, Kyle Jeffrey, Kim Kleiven, Adrian Li, Emre Fisher, Matt Harrison, Benjie Holson, Allison Okamura, Matt Bennice", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "abstract": "For decades, robotics researchers have pursued various tasks for multi-robot systems, from cooperative manipulation to search and rescue. These tasks are multi-robot extensions of classical robotic tasks and often optimized on dimensions such as speed or efficiency. As robots transition from commercial and research settings into everyday environments, social task aims such as engagement or entertainment become increasingly relevant. This work presents a compelling multi-robot task, in which the main aim is to enthrall and interest. In this task, the goal is for a human to be drawn to move alongside and participate in a dynamic, expressive robot flock. Towards this aim, the research team created algorithms for robot movements and engaging interaction modes such as gestures and sound. The contributions are as follows: (1) a novel group navigation algorithm involving human and robot agents, (2) a gesture responsive algorithm for real-time, human-robot flocking interaction, (3) a weight mode characterization system for modifying flocking behavior, and (4) a method of encoding a choreographer's preferences inside a dynamic, adaptive, learned system. An experiment was performed to understand individual human behavior while interacting with the flock under three conditions: weight modes selected by a human choreographer, a learned model, or subset list. Results from the experiment showed that the perception of the experience was not influenced by the weight mode selection. This work elucidates how differing task aims such as engagement manifest in multi-robot system design and execution, and broadens the domain of multi-robot tasks."}
{"main_page": "https://arxiv.org/abs/2404.00443", "pdf": "https://arxiv.org/pdf/2404.00443", "title": "UDE-based Dynamic Motion Force Control of Mobile Manipulators", "authors": "Songqun Gao, Wendi Ding, Qinyuan Ren, Ben M. Chen", "subjects": "Robotics (cs.RO)", "abstract": "Mobile manipulators are known for their superior mobility over manipulators on fixed bases, offering promising applications in smart industry and housekeeping scenarios. However, the dynamic coupling nature between the mobile base and the manipulator presents challenges for the physical interactive tasks of the mobile manipulator. Current methods suffer from complex modeling processes and poor transferability. To address this, this article presents a novel dynamic model of the manipulator on the mobile base that requires only the manipulator dynamics and the kinematic information of the mobile base. In addition, embedding the dynamic model, an uncertainty and disturbance estimator-based (UDE-based) dynamic motion/force control scheme is proposed for the mobile manipulator, which compensates for the dynamic coupling and other unmodeled uncertainties. Passivity and stability analyses justify the proposed control law. Simulation and experimental results on our mobile manipulator platform demonstrate the feasibility and effectiveness of our proposed methodology."}
{"main_page": "https://arxiv.org/abs/2404.00447", "pdf": "https://arxiv.org/pdf/2404.00447", "title": "Synthetic Dataset Generation and Learning From Demonstration Applied to  Industrial Manipulation", "authors": "Alireza Barekatain, Hamed Rahimi Nohooji, Holger Voos", "subjects": "Robotics (cs.RO)", "abstract": "The aim of this study is to investigate an automated industrial manipulation pipeline, where assembly tasks can be flexibly adapted to production without the need for a robotic expert, both for the vision system and the robot program. The objective of this study is first, to develop a synthetic-dataset-generation pipeline with a special focus on industrial parts, and second, to use Learning-from-Demonstration (LfD) methods to replace manual robot programming, so that a non-robotic expert/process engineer can introduce a new manipulation task by teaching it to the robot."}
{"main_page": "https://arxiv.org/abs/2404.00451", "pdf": "https://arxiv.org/pdf/2404.00451", "title": "Thin-Shell Object Manipulations With Differentiable Physics Simulations", "authors": "Yian Wang, Juntian Zheng, Zhehuan Chen, Zhou Xian, Gu Zhang, Chao Liu, Chuang Gan", "subjects": "Robotics (cs.RO)", "abstract": "In this work, we aim to teach robots to manipulate various thin-shell materials. Prior works studying thin-shell object manipulation mostly rely on heuristic policies or learn policies from real-world video demonstrations, and only focus on limited material types and tasks (e.g., cloth unfolding). However, these approaches face significant challenges when extended to a wider variety of thin-shell materials and a diverse range of tasks. While virtual simulations are shown to be effective in diverse robot skill learning and evaluation, prior thin-shell simulation environments only support a subset of thin-shell materials, which also limits their supported range of tasks. We introduce ThinShellLab - a fully differentiable simulation platform tailored for robotic interactions with diverse thin-shell materials possessing varying material properties, enabling flexible thin-shell manipulation skill learning and evaluation. Our experiments suggest that manipulating thin-shell objects presents several unique challenges: 1) thin-shell manipulation relies heavily on frictional forces due to the objects' co-dimensional nature, 2) the materials being manipulated are highly sensitive to minimal variations in interaction actions, and 3) the constant and frequent alteration in contact pairs makes trajectory optimization methods susceptible to local optima, and neither standard reinforcement learning algorithms nor trajectory optimization methods (either gradient-based or gradient-free) are able to solve the tasks alone. To overcome these challenges, we present an optimization scheme that couples sampling-based trajectory optimization and gradient-based optimization, boosting both learning efficiency and converged performance across various proposed tasks. In addition, the differentiable nature of our platform facilitates a smooth sim-to-real transition."}
{"main_page": "https://arxiv.org/abs/2404.00494", "pdf": "https://arxiv.org/pdf/2404.00494", "title": "Designing Robot Identity: The Role of Voice, Clothing, and Task on Robot  Gender Perception", "authors": "Nathaniel S. Dennler, Mina Kian, Stefanos Nikolaidis, Maja Matari\u0107", "subjects": "Robotics (cs.RO)", "abstract": "Perceptions of gender are a significant aspect of human-human interaction, and gender has wide-reaching social implications for robots deployed in contexts where they are expected to interact with humans. This work explored two flexible modalities for communicating gender in robots--voice and appearance--and we studied their individual and combined influences on a robot's perceived gender. We evaluated the perception of a robot's gender through three video-based studies. First, we conducted a study (n=65) on the gender perception of robot voices by varying speaker identity and pitch. Second, we conducted a study (n=93) on the gender perception of robot clothing designed for two different tasks. Finally, building on the results of the first two studies, we completed a large integrative video-based study (n=273) involving two human-robot interaction tasks. We found that voice and clothing can be used to reliably establish a robot's perceived gender, and that combining these two modalities can have different effects on the robot's perceived gender. Taken together, these results inform the design of robot voices and clothing as individual and interacting components in the perceptions of robot gender."}
{"main_page": "https://arxiv.org/abs/2404.00514", "pdf": "https://arxiv.org/pdf/2404.00514", "title": "Human-Robot Co-Transportation with Human Uncertainty-Aware MPC and Pose  Optimization", "authors": "Al Jaber Mahmud, Amir Hossain Raj, Duc M. Nguyen, Xuesu Xiao, Xuan Wang", "subjects": "Robotics (cs.RO)", "abstract": "This paper proposes a new control algorithm for human-robot co-transportation based on a robot manipulator equipped with a mobile base and a robotic arm. The primary focus is to adapt to human uncertainties through the robot's whole-body dynamics and pose optimization. We introduce an augmented Model Predictive Control (MPC) formulation that explicitly models human uncertainties and contains extra variables than regular MPC to optimize the pose of the robotic arm. The core of our methodology involves a two-step iterative design: At each planning horizon, we select the best pose of the robotic arm (joint angle combination) from a candidate set, aiming to achieve the lowest estimated control cost. This selection is based on solving an uncertainty-aware Discrete Algebraic Ricatti Equation (DARE), which also informs the optimal control inputs for both the mobile base and the robotic arm. To validate the effectiveness of the proposed approach, we provide theoretical derivation for the uncertainty-aware DARE and perform simulated and proof-of-concept hardware experiments using a Fetch robot under varying conditions, including different nominal trajectories and noise levels. The results reveal that our proposed approach outperforms baseline algorithms, maintaining similar execution time with that do not consider human uncertainty or do not perform pose optimization."}
{"main_page": "https://arxiv.org/abs/2404.00520", "pdf": "https://arxiv.org/pdf/2404.00520", "title": "Competition-Aware Decision-Making Approach for Mobile Robots in Racing  Scenarios", "authors": "Kyoungtae Ji, Sangjae Bae, Nan Li, Kyoungseok Han", "subjects": "Robotics (cs.RO); Optimization and Control (math.OC)", "abstract": "This paper presents a game-theoretic strategy for racing, where the autonomous ego agent seeks to block a racing opponent that aims to overtake the ego agent. After a library of trajectory candidates and an associated reward matrix are constructed, the optimal trajectory in terms of maximizing the cumulative reward over the planning horizon is determined based on the level-K reasoning framework. In particular, the level of the opponent is estimated online according to its behavior over a past window and is then used to determine the trajectory for the ego agent. Taking into account that the opponent may change its level and strategy during the decision process of the ego agent, we introduce a trajectory mixing strategy that blends the level-K optimal trajectory with a fail-safe trajectory. The overall algorithm was tested and evaluated in various simulated racing scenarios, which also includes human-in-the-loop experiments. Comparative analysis against the conventional level-K framework demonstrates the superiority of our proposed approach in terms of overtake-blocking success rates."}
{"main_page": "https://arxiv.org/abs/2404.00591", "pdf": "https://arxiv.org/pdf/2404.00591", "title": "Task-Space Riccati Feedback based Whole Body Control for Underactuated  Legged Locomotion", "authors": "Shunpeng Yang, Zejun Hong, Sen Li, Patrick Wensing, Wei Zhang, Hua Chen", "subjects": "Robotics (cs.RO)", "abstract": "This manuscript primarily aims to enhance the performance of whole-body controllers(WBC) for underactuated legged locomotion. We introduce a systematic parameter design mechanism for the floating-base feedback control within the WBC. The proposed approach involves utilizing the linearized model of unactuated dynamics to formulate a Linear Quadratic Regulator(LQR) and solving a Riccati gain while accounting for potential physical constraints through a second-order approximation of the log-barrier function. And then the user-tuned feedback gain for the floating base task is replaced by a new one constructed from the solved Riccati gain. Extensive simulations conducted in MuJoCo with a point bipedal robot, as well as real-world experiments performed on a quadruped robot, demonstrate the effectiveness of the proposed method. In the different bipedal locomotion tasks, compared with the user-tuned method, the proposed approach is at least 12% better and up to 50% better at linear velocity tracking, and at least 7% better and up to 47% better at angular velocity tracking. In the quadruped experiment, linear velocity tracking is improved by at least 3% and angular velocity tracking is improved by at least 23% using the proposed method."}
{"main_page": "https://arxiv.org/abs/2404.00691", "pdf": "https://arxiv.org/pdf/2404.00691", "title": "Graph-Based vs. Error State Kalman Filter-Based Fusion Of 5G And  Inertial Data For MAV Indoor Pose Estimation", "authors": "Meisam Kabiri, Claudio Cimarelli, Hriday Bavle, Jose Luis Sanchez-Lopez, Holger Voos", "subjects": "Robotics (cs.RO)", "abstract": "5G New Radio Time of Arrival (ToA) data has the potential to revolutionize indoor localization for micro aerial vehicles (MAVs). However, its performance under varying network setups, especially when combined with IMU data for real-time localization, has not been fully explored so far. In this study, we develop an error state Kalman filter (ESKF) and a pose graph optimization (PGO) approach to address this gap. We systematically evaluate the performance of the derived approaches for real-time MAV localization in realistic scenarios with 5G base stations in Line-Of-Sight (LOS), demonstrating the potential of 5G technologies in this domain. In order to experimentally test and compare our localization approaches, we augment the EuRoC MAV benchmark dataset for visual-inertial odometry with simulated yet highly realistic 5G ToA measurements. Our experimental results comprehensively assess the impact of varying network setups, including varying base station numbers and network configurations, on ToA-based MAV localization performance. The findings show promising results for seamless and robust localization using 5G ToA measurements, achieving an accuracy of 15 cm throughout the entire trajectory within a graph-based framework with five 5G base stations, and an accuracy of up to 34 cm in the case of ESKF-based localization. Additionally, we measure the run time of both algorithms and show that they are both fast enough for real-time implementation."}
{"main_page": "https://arxiv.org/abs/2404.00717", "pdf": "https://arxiv.org/pdf/2404.00717", "title": "End-to-End Autonomous Driving through V2X Cooperation", "authors": "Haibao Yu, Wenxian Yang, Jiaru Zhong, Zhenwei Yang, Siqi Fan, Ping Luo, Zaiqing Nie", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "abstract": "Cooperatively utilizing both ego-vehicle and infrastructure sensor data via V2X communication has emerged as a promising approach for advanced autonomous driving. However, current research mainly focuses on improving individual modules, rather than taking end-to-end learning to optimize final planning performance, resulting in underutilized data potential. In this paper, we introduce UniV2X, a pioneering cooperative autonomous driving framework that seamlessly integrates all key driving modules across diverse views into a unified network. We propose a sparse-dense hybrid data transmission and fusion mechanism for effective vehicle-infrastructure cooperation, offering three advantages: 1) Effective for simultaneously enhancing agent perception, online mapping, and occupancy prediction, ultimately improving planning performance. 2) Transmission-friendly for practical and limited communication conditions. 3) Reliable data fusion with interpretability of this hybrid data. We implement UniV2X, as well as reproducing several benchmark methods, on the challenging DAIR-V2X, the real-world cooperative driving dataset. Experimental results demonstrate the effectiveness of UniV2X in significantly enhancing planning performance, as well as all intermediate output performance. Code is at https://github.com/AIR-THU/UniV2X."}
{"main_page": "https://arxiv.org/abs/2404.00769", "pdf": "https://arxiv.org/pdf/2404.00769", "title": "An Active Perception Game for Robust Autonomous Exploration", "authors": "Siming He, Yuezhan Tao, Igor Spasojevic, Vijay Kumar, Pratik Chaudhari", "subjects": "Robotics (cs.RO)", "abstract": "We formulate active perception for an autonomous agent that explores an unknown environment as a two-player zero-sum game: the agent aims to maximize information gained from the environment while the environment aims to minimize the information gained by the agent. In each episode, the environment reveals a set of actions with their potentially erroneous information gain. In order to select the best action, the robot needs to recover the true information gain from the erroneous one. The robot does so by minimizing the discrepancy between its estimate of information gain and the true information gain it observes after taking the action. We propose an online convex optimization algorithm that achieves sub-linear expected regret $O(T^{3/4})$ for estimating the information gain. We also provide a bound on the regret of active perception performed by any (near-)optimal prediction and trajectory selection algorithms. We evaluate this approach using semantic neural radiance fields (NeRFs) in simulated realistic 3D environments to show that the robot can discover up to 12% more objects using the improved estimate of the information gain. On the M3ED dataset, the proposed algorithm reduced the error of information gain prediction in occupancy map by over 67%. In real-world experiments using occupancy maps on a Jackal ground robot, we show that this approach can calculate complicated trajectories that efficiently explore all occluded regions."}
{"main_page": "https://arxiv.org/abs/2404.00783", "pdf": "https://arxiv.org/pdf/2404.00783", "title": "Potentials of the Metaverse for Robotized Applications in Industry 4.0  and Industry 5.0", "authors": "Eric Guiffo Kaigom", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "As a digital environment of interconnected virtual ecosystems driven by measured and synthesized data, the Metaverse has so far been mostly considered from its gaming perspective that closely aligns with online edutainment. Although it is still in its infancy and more research as well as standardization efforts remain to be done, the Metaverse could provide considerable advantages for smart robotized applications in the industry.Workflow efficiency, collective decision enrichment even for executives, as well as a natural, resilient, and sustainable robotized assistance for the workforce are potential advantages. Hence, the Metaverse could consolidate the connection between Industry 4.0 and Industry 5.0. This paper identifies and puts forward potential advantages of the Metaverse for robotized applications and highlights how these advantages support goals pursued by the Industry 4.0 and Industry 5.0 visions."}
{"main_page": "https://arxiv.org/abs/2404.00796", "pdf": "https://arxiv.org/pdf/2404.00796", "title": "CARL: Congestion-Aware Reinforcement Learning for Imitation-based  Perturbations in Mixed Traffic Control", "authors": "Bibek Poudel, Weizi Li", "subjects": "Robotics (cs.RO)", "abstract": "Human-driven vehicles (HVs) exhibit complex and diverse behaviors. Accurately modeling such behavior is crucial for validating Robot Vehicles (RVs) in simulation and realizing the potential of mixed traffic control. However, existing approaches like parameterized models and data-driven techniques struggle to capture the full complexity and diversity. To address this, in this work, we introduce CARL, a hybrid technique combining imitation learning for close proximity car-following and probabilistic sampling for larger headways. We also propose two classes of RL-based RVs: a safety RV focused on maximizing safety and an efficiency RV focused on maximizing efficiency. Our experiments show that the safety RV increases Time-to-Collision above the critical 4 second threshold and reduces Deceleration Rate to Avoid a Crash by up to 80%, while the efficiency RV achieves improvements in throughput of up to 49%. These results demonstrate the effectiveness of CARL in enhancing both safety and efficiency in mixed traffic."}
{"main_page": "https://arxiv.org/abs/2404.00797", "pdf": "https://arxiv.org/pdf/2404.00797", "title": "Metarobotics for Industry and Society: Vision, Technologies, and  Opportunities", "authors": "Eric Guiffo Kaigom", "subjects": "Robotics (cs.RO); Computers and Society (cs.CY); Machine Learning (cs.LG); Systems and Control (eess.SY)", "abstract": "Metarobotics aims to combine next generation wireless communication, multi-sense immersion, and collective intelligence to provide a pervasive, itinerant, and non-invasive access and interaction with distant robotized applications. Industry and society are expected to benefit from these functionalities. For instance, robot programmers will no longer travel worldwide to plan and test robot motions, even collaboratively. Instead, they will have a personalized access to robots and their environments from anywhere, thus spending more time with family and friends. Students enrolled in robotics courses will be taught under authentic industrial conditions in real-time. This paper describes objectives of Metarobotics in society, industry, and in-between. It identifies and surveys technologies likely to enable their completion and provides an architecture to put forward the interplay of key components of Metarobotics. Potentials for self-determination, self-efficacy, and work-life-flexibility in robotics-related applications in Society 5.0, Industry 4.0, and Industry 5.0 are outlined."}
{"main_page": "https://arxiv.org/abs/2404.00808", "pdf": "https://arxiv.org/pdf/2404.00808", "title": "Using Explainable AI and Hierarchical Planning for Outreach with Robots", "authors": "Daksh Dobhal, Jayesh Nagpal, Rushang Karia, Pulkit Verma, Rashmeet Kaur Nayyar, Naman Shah, Siddharth Srivastava", "subjects": "Robotics (cs.RO)", "abstract": "Understanding how robots plan and execute tasks is crucial in today's world, where they are becoming more prevalent in our daily lives. However, teaching non-experts the complexities of robot planning can be challenging. This work presents an open-source platform that simplifies the process using a visual interface that completely abstracts the complex internals of hierarchical planning that robots use for performing task and motion planning. Using the principles developed in the field of explainable AI, this intuitive platform enables users to create plans for robots to complete tasks, and provides helpful hints and natural language explanations for errors. The platform also has a built-in simulator to demonstrate how robots execute submitted plans. This platform's efficacy was tested in a user study on university students with little to no computer science background. Our results show that this platform is highly effective in teaching novice users the intuitions of robot task planning."}
{"main_page": "https://arxiv.org/abs/2404.00814", "pdf": "https://arxiv.org/pdf/2404.00814", "title": "Imposing Exact Safety Specifications in Neural Reachable Tubes", "authors": "Aditya Singh, Zeyuan Feng, Somil Bansal", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "Hamilton-Jacobi (HJ) reachability analysis is a verification tool that provides safety and performance guarantees for autonomous systems. It is widely adopted because of its ability to handle nonlinear dynamical systems with bounded adversarial disturbances and constraints on states and inputs. However, it involves solving a PDE to compute a safety value function, whose computational and memory complexity scales exponentially with the state dimension, making its direct usage in large-scale systems intractable. Recently, a learning-based approach called DeepReach, has been proposed to approximate high-dimensional reachable tubes using neural networks. While DeepReach has been shown to be effective, the accuracy of the learned solution decreases with the increase in system complexity. One of the reasons for this degradation is the inexact imposition of safety constraints during the learning process, which corresponds to the PDE's boundary conditions. Specifically, DeepReach imposes boundary conditions as soft constraints in the loss function, which leaves room for error during the value function learning. Moreover, one needs to carefully adjust the relative contributions from the imposition of boundary conditions and the imposition of the PDE in the loss function. This, in turn, induces errors in the overall learned solution. In this work, we propose a variant of DeepReach that exactly imposes safety constraints during the learning process by restructuring the overall value function as a weighted sum of the boundary condition and neural network output. This eliminates the need for a boundary loss during training, thus bypassing the need for loss adjustment. We demonstrate the efficacy of the proposed approach in significantly improving the accuracy of learned solutions for challenging high-dimensional reachability tasks, such as rocket-landing and multivehicle collision-avoidance problems."}
{"main_page": "https://arxiv.org/abs/2404.00830", "pdf": "https://arxiv.org/pdf/2404.00830", "title": "2D Ego-Motion with Yaw Estimation using Only mmWave Radars via Two-Way  weighted ICP", "authors": "Hojune Kim, Hyesu Jang, Ayoung Kim", "subjects": "Robotics (cs.RO)", "abstract": "The interest in single-chip mmWave Radar is driven by their compact form factor, cost-effectiveness, and robustness under harsh environmental conditions. Despite its promising attributes, the principal limitation of mmWave radar lies in its capacity for autonomous yaw rate estimation. Conventional solutions have often resorted to integrating inertial measurement unit (IMU) or deploying multiple radar units to circumvent this shortcoming. This paper introduces an innovative methodology for two-dimensional ego-motion estimation, focusing on yaw rate deduction, utilizing solely mmWave radar sensors. By applying a weighted Iterated Closest Point (ICP) algorithm to register processed points derived from heatmap data, our method facilitates 2D ego-motion estimation devoid of prior information. Through experimental validation, we verified the effectiveness and promise of our technique for ego-motion estimation using exclusively radar data."}
{"main_page": "https://arxiv.org/abs/2404.00890", "pdf": "https://arxiv.org/pdf/2404.00890", "title": "Development of Musculoskeletal Legs with Planar Interskeletal Structures  to Realize Human Comparable Moving Function", "authors": "Moritaka Onitsuka, Manabu Nishiura, Kento Kawaharazuka, Kei Tsuzuki, Yasunori Toshimitsu, Yusuke Omura, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba", "subjects": "Robotics (cs.RO)", "abstract": "Musculoskeletal humanoids have been developed by imitating humans and expected to perform natural and dynamic motions as well as humans. To achieve desired motions stably in current musculoskeletal humanoids is not easy because they cannot maintain the sufficient moment arm of muscles in various postures. In this research, we discuss planar structures that spread across joint structures such as ligament and planar muscles and the application of planar interskeletal structures to humanoid robots. Next, we develop MusashiOLegs, a musculoskeletal legs which has planar interskeletal structures and conducts several experiments to verify the importance of planar interskeletal structures."}
{"main_page": "https://arxiv.org/abs/2404.00892", "pdf": "https://arxiv.org/pdf/2404.00892", "title": "Realization of Seated Walk by a Musculoskeletal Humanoid with  Buttock-Contact Sensors From Human Constrained Teaching", "authors": "Kento Kawaharazuka, Kei Okada, Masayuki Inaba", "subjects": "Robotics (cs.RO)", "abstract": "In this study, seated walk, a movement of walking while sitting on a chair with casters, is realized on a musculoskeletal humanoid from human teaching. The body is balanced by using buttock-contact sensors implemented on the planar interskeletal structure of the human mimetic musculoskeletal robot. Also, we develop a constrained teaching method in which one-dimensional control command, its transition, and a transition condition are described for each state in advance, and a threshold value for each transition condition such as joint angles and foot contact sensor values is determined based on human teaching. Complex behaviors can be easily generated from simple inputs. In the musculoskeletal humanoid MusashiOLegs, forward, backward, and rotational movements of seated walk are realized."}
{"main_page": "https://arxiv.org/abs/2404.00893", "pdf": "https://arxiv.org/pdf/2404.00893", "title": "An Integrating Comprehensive Trajectory Prediction with Risk Potential  Field Method for Autonomous Driving", "authors": "Kailu Wu, Xing Liu, Feiyu Bian, Yizhai Zhang, Panfeng Huang", "subjects": "Robotics (cs.RO)", "abstract": "Due to the uncertainty of traffic participants' intentions, generating safe but not overly cautious behavior in interactive driving scenarios remains a formidable challenge for autonomous driving. In this paper, we address this issue by combining a deep learning-based trajectory prediction model with risk potential field-based motion planning. In order to comprehensively predict the possible future trajectories of other vehicles, we propose a target-region based trajectory prediction model(TRTP) which considers every region a vehicle may arrive in the future. After that, we construct a risk potential field at each future time step based on the prediction results of TRTP, and integrate risk value to the objective function of Model Predictive Contouring Control(MPCC). This enables the uncertainty of other vehicles to be taken into account during the planning process. Balancing between risk and progress along the reference path can achieve both driving safety and efficiency at the same time. We also demonstrate the security and effectiveness performance of our method in the CARLA simulator."}
{"main_page": "https://arxiv.org/abs/2404.01081", "pdf": "https://arxiv.org/pdf/2404.01081", "title": "PhysReaction: Physically Plausible Real-Time Humanoid Reaction Synthesis  via Forward Dynamics Guided 4D Imitation", "authors": "Yunze Liu, Changxi Chen, Chenjing Ding, Li Yi", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Humanoid Reaction Synthesis is pivotal for creating highly interactive and empathetic robots that can seamlessly integrate into human environments, enhancing the way we live, work, and communicate. However, it is difficult to learn the diverse interaction patterns of multiple humans and generate physically plausible reactions. The kinematics-based approaches face challenges, including issues like floating feet, sliding, penetration, and other problems that defy physical plausibility. The existing physics-based method often relies on kinematics-based methods to generate reference states, which struggle with the challenges posed by kinematic noise during action execution. Constrained by their reliance on diffusion models, these methods are unable to achieve real-time inference. In this work, we propose a Forward Dynamics Guided 4D Imitation method to generate physically plausible human-like reactions. The learned policy is capable of generating physically plausible and human-like reactions in real-time, significantly improving the speed(x33) and quality of reactions compared with the existing method. Our experiments on the InterHuman and Chi3D datasets, along with ablation studies, demonstrate the effectiveness of our approach."}
{"main_page": "https://arxiv.org/abs/2404.01110", "pdf": "https://arxiv.org/pdf/2404.01110", "title": "A Center-of-Mass Shifting Aerial Manipulation Platform for Heavy-Tool  Handling on Non-Horizontal Surfaces", "authors": "Tong Hui, Stefan Rucareanu, Haotian Liu, Matteo Fumagalli", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "Aerial vehicles equipped with manipulators can serve contact-based industrial applications, where fundamental tasks like drilling and grinding often necessitate aerial platforms to handle heavy tools. Industrial environments often involve non-horizontal surfaces. Existing aerial manipulation platforms based on multirotors typically feature a fixed CoM (Center of Mass) within the rotor-defined area, leading to a considerable moment arm between the EE (End-Effector) tip and the CoM for operations on such surfaces. Carrying heavy tools at the EE tip of the manipulator with an extended moment arm can lead to system instability and potential damage to the servo actuators used in the manipulator. To tackle this issue, we present a novel aerial vehicle tailored for handling heavy tools on non-horizontal surfaces. In this work, we provide the platform's system design, modeling, and control strategies. This platform can carry heavy manipulators within the rotor-defined area during free flight. During interactions, the manipulator can shift towards the work surface outside the rotor-defined area, resulting in a displaced CoM location with a significantly shorter moment arm. Furthermore, we propose a method for automatically determining the manipulator's position to reach the maximum CoM displacement towards the work surface. Our proposed concepts are validated through simulations that closely capture the developed physical prototype of the platform."}
{"main_page": "https://arxiv.org/abs/2404.01116", "pdf": "https://arxiv.org/pdf/2404.01116", "title": "Intelligent Robotic Control System Based on Computer Vision Technology", "authors": "Chang Che, Haotian Zheng, Zengyi Huang, Wei Jiang, Bo Liu", "subjects": "Robotics (cs.RO)", "abstract": "The article explores the intersection of computer vision technology and robotic control, highlighting its importance in various fields such as industrial automation, healthcare, and environmental protection. Computer vision technology, which simulates human visual observation, plays a crucial role in enabling robots to perceive and understand their surroundings, leading to advancements in tasks like autonomous navigation, object recognition, and waste management. By integrating computer vision with robot control, robots gain the ability to interact intelligently with their environment, improving efficiency."}
{"main_page": "https://arxiv.org/abs/2404.01150", "pdf": "https://arxiv.org/pdf/2404.01150", "title": "Visual-inertial state estimation based on Chebyshev polynomial  optimization", "authors": "Hongyu Zhang, Maoran Zhu, Qi Cai, Yuanxin Wu", "subjects": "Robotics (cs.RO)", "abstract": "This paper proposes an innovative state estimation method for visual-inertial fusion based on Chebyshev polynomial optimization. Specifically, the pose is modeled as a Chebyshev polynomial of a certain order, and its time derivatives are used to calculate linear acceleration and angular velocity, which, along with inertial measurements, constitute dynamic constraints. This is coupled with a visual measurement model to construct a visual-inertial bundle adjustment formulation. Simulation and public dataset experiments show that the proposed method has better accuracy than the discrete-form preintegration method."}
{"main_page": "https://arxiv.org/abs/2404.01166", "pdf": "https://arxiv.org/pdf/2404.01166", "title": "Scalable Radar-based ITS: Self-localization and Occupancy Heat Map for  Traffic Analysis", "authors": "Longfei Han, Klaus Kefferp\u00fctz, Qiuyu Xu, Ying Lu, Gordon Elger, J\u00fcrgen Beyerer", "subjects": "Robotics (cs.RO)", "abstract": "4D mmWave radar sensors are well suited for city scale Intelligent Transportation Systems (ITS) given their long sensing range, weatherproof functionality, simple mechanical design, and low manufacturing cost. In this paper, we investigate radar-based ITS for scalable traffic analysis. Localization of these radar sensors in a city scale range is a fundamental task in ITS. For mobile ITS setups it requires more endeavor. To address this task, we propose a self-localization approach that matches two descriptions of \"road\": the one from the geometry of the motion trajectories of cumulatively observed vehicles, and the other one from the aerial laser scan. An ICP (iterative closest point) algorithm is used to register the motion trajectory into the road section of the laser scan to estimate the sensor pose. We evaluates the results and show that it outperforms other map-based radar localization methods, especially for the orientation estimation. Beyond the localization result, we project radar sensor data onto city scale laser scan and generate an scalable occupancy heat map as a traffic analysis tool. This is demonstrated using two radar sensors monitoring an urban area in the real world."}
{"main_page": "https://arxiv.org/abs/2404.01170", "pdf": "https://arxiv.org/pdf/2404.01170", "title": "Force-EvT: A Closer Look at Robotic Gripper Force Measurement with  Event-based Vision Transformer", "authors": "Qianyu Guo, Ziqing Yu, Jiaming Fu, Yawen Lu, Yahya Zweiri, Dongming Gan", "subjects": "Robotics (cs.RO); Image and Video Processing (eess.IV)", "abstract": "Robotic grippers are receiving increasing attention in various industries as essential components of robots for interacting and manipulating objects. While significant progress has been made in the past, conventional rigid grippers still have limitations in handling irregular objects and can damage fragile objects. We have shown that soft grippers offer deformability to adapt to a variety of object shapes and maximize object protection. At the same time, dynamic vision sensors (e.g., event-based cameras) are capable of capturing small changes in brightness and streaming them asynchronously as events, unlike RGB cameras, which do not perform well in low-light and fast-moving environments. In this paper, a dynamic-vision-based algorithm is proposed to measure the force applied to the gripper. In particular, we first set up a DVXplorer Lite series event camera to capture twenty-five sets of event data. Second, motivated by the impressive performance of the Vision Transformer (ViT) algorithm in dense image prediction tasks, we propose a new approach that demonstrates the potential for real-time force estimation and meets the requirements of real-world scenarios. We extensively evaluate the proposed algorithm on a wide range of scenarios and settings, and show that it consistently outperforms recent approaches."}
{"main_page": "https://arxiv.org/abs/2404.01184", "pdf": "https://arxiv.org/pdf/2404.01184", "title": "Efficient Motion Planning for Manipulators with Control Barrier  Function-Induced Neural Controller", "authors": "Mingxin Yu, Chenning Yu, M-Mahdi Naddaf-Sh, Devesh Upadhyay, Sicun Gao, Chuchu Fan", "subjects": "Robotics (cs.RO); Machine Learning (cs.LG)", "abstract": "Sampling-based motion planning methods for manipulators in crowded environments often suffer from expensive collision checking and high sampling complexity, which make them difficult to use in real time. To address this issue, we propose a new generalizable control barrier function (CBF)-based steering controller to reduce the number of samples needed in a sampling-based motion planner RRT. Our method combines the strength of CBF for real-time collision-avoidance control and RRT for long-horizon motion planning, by using CBF-induced neural controller (CBF-INC) to generate control signals that steer the system towards sampled configurations by RRT. CBF-INC is learned as Neural Networks and has two variants handling different inputs, respectively: state (signed distance) input and point-cloud input from LiDAR. In the latter case, we also study two different settings: fully and partially observed environmental information. Compared to manually crafted CBF which suffers from over-approximating robot geometry, CBF-INC can balance safety and goal-reaching better without being over-conservative. Given state-based input, our neural CBF-induced neural controller-enhanced RRT (CBF-INC-RRT) can increase the success rate by 14% while reducing the number of nodes explored by 30%, compared with vanilla RRT on hard test cases. Given LiDAR input where vanilla RRT is not directly applicable, we demonstrate that our CBF-INC-RRT can improve the success rate by 10%, compared with planning with other steering controllers. Our project page with supplementary material is at https://mit-realm.github.io/CBF-INC-RRT-website/."}
{"main_page": "https://arxiv.org/abs/2404.01219", "pdf": "https://arxiv.org/pdf/2404.01219", "title": "LTL-D*: Incrementally Optimal Replanning for Feasible and Infeasible  Tasks in Linear Temporal Logic Specifications", "authors": "Jiming Ren, Haris Miller, Karen M. Feigh, Samuel Coogan, Ye Zhao", "subjects": "Robotics (cs.RO); Formal Languages and Automata Theory (cs.FL)", "abstract": "This paper presents an incremental replanning algorithm, dubbed LTL-D*, for temporal-logic-based task planning in a dynamically changing environment. Unexpected changes in the environment may lead to failures in satisfying a task specification in the form of a Linear Temporal Logic (LTL). In this study, the considered failures are categorized into two classes: (i) the desired LTL specification can be satisfied via replanning, and (ii) the desired LTL specification is infeasible to meet strictly and can only be satisfied in a \"relaxed\" fashion. To address these failures, the proposed algorithm finds an optimal replanning solution that minimally violates desired task specifications. In particular, our approach leverages the D* Lite algorithm and employs a distance metric within the synthesized automaton to quantify the degree of the task violation and then replan incrementally. This ensures plan optimality and reduces planning time, especially when frequent replanning is required. Our approach is implemented in a robot navigation simulation to demonstrate a significant improvement in the computational efficiency for replanning by two orders of magnitude."}
{"main_page": "https://arxiv.org/abs/2404.01220", "pdf": "https://arxiv.org/pdf/2404.01220", "title": "Entity-Centric Reinforcement Learning for Object Manipulation from  Pixels", "authors": "Dan Haramati, Tal Daniel, Aviv Tamar", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Manipulating objects is a hallmark of human intelligence, and an important task in domains such as robotics. In principle, Reinforcement Learning (RL) offers a general approach to learn object manipulation. In practice, however, domains with more than a few objects are difficult for RL agents due to the curse of dimensionality, especially when learning from raw image observations. In this work we propose a structured approach for visual RL that is suitable for representing multiple objects and their interaction, and use it to learn goal-conditioned manipulation of several objects. Key to our method is the ability to handle goals with dependencies between the objects (e.g., moving objects in a certain order). We further relate our architecture to the generalization capability of the trained agent, based on a theoretical result for compositional generalization, and demonstrate agents that learn with 3 objects but generalize to similar tasks with over 10 objects. Videos and code are available on the project website: https://sites.google.com/view/entity-centric-rl"}
{"main_page": "https://arxiv.org/abs/2404.01237", "pdf": "https://arxiv.org/pdf/2404.01237", "title": "FPGA-Accelerated Correspondence-free Point Cloud Registration with  PointNet Features", "authors": "Keisuke Sugiura, Hiroki Matsutani", "subjects": "Robotics (cs.RO); Hardware Architecture (cs.AR)", "abstract": "Point cloud registration serves as a basis for vision and robotic applications including 3D reconstruction and mapping. Despite significant improvements on the quality of results, recent deep learning approaches are computationally expensive and power-hungry, making them difficult to deploy on resource-constrained edge devices. To tackle this problem, in this paper, we propose a fast, accurate, and robust registration for low-cost embedded FPGAs. Based on a parallel and pipelined PointNet feature extractor, we develop custom accelerator cores namely PointLKCore and ReAgentCore, for two different learning-based methods. They are both correspondence-free and computationally efficient as they avoid the costly feature matching step involving nearest-neighbor search. The proposed cores are implemented on the Xilinx ZCU104 board and evaluated using both synthetic and real-world datasets, showing the substantial improvements in the trade-offs between runtime and registration quality. They run 44.08-45.75x faster than ARM Cortex-A53 CPU and offer 1.98-11.13x speedups over Intel Xeon CPU and Nvidia Jetson boards, while consuming less than 1W and achieving 163.11-213.58x energy-efficiency compared to Nvidia GeForce GPU. The proposed cores are more robust to noise and large initial misalignments than the classical methods and quickly find reasonable solutions in less than 15ms, demonstrating the real-time performance."}
