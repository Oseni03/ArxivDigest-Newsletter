{"main_page": "https://arxiv.org/abs/2404.00113", "pdf": "https://arxiv.org/pdf/2404.00113", "title": "Experi\u00eancias, Resultados e Reflex\u00f5es a partir do Gerenciamento de  experimentos no Mundo Real com FANETs e VANTs -- Vers\u00e3o Estendida", "authors": "Bruno Jos\u00e9 Olivieri de Souza, markus Endler", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "In the research on FANETs (Flying Ad-Hoc Networks) and distributed coordination of UAVs (Unmanned Aerial Vehicles), also known as drones, there are many studies that validate their proposals through simulations. Simulations are important, but beyond them, there is also a need for real-world tests to validate the proposals and enhance results. However, field experiments involving drones and FANETs are not trivial, and this work aims to share experiences and results obtained during the construction of a testbed actively used in comparing simulations and field tests."}
{"main_page": "https://arxiv.org/abs/2404.00270", "pdf": "https://arxiv.org/pdf/2404.00270", "title": "Engineering A Workload-balanced Push-Relabel Algorithm for Massive  Graphs on GPUs", "authors": "Chou-Ying Hsieh, Po-Chieh Lin, Sy-Yen Kuo", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS)", "abstract": "The push-relabel algorithm is an efficient algorithm that solves the maximum flow/ minimum cut problems of its affinity to parallelization. As the size of graphs grows exponentially, researchers have used Graphics Processing Units (GPUs) to accelerate the computation of the push-relabel algorithm further. However, prior works need to handle the significant memory consumption to represent a massive residual graph. In addition, the nature of their algorithms has inherently imbalanced workload distribution on GPUs. This paper first identifies the two challenges with the memory and computational models. Based on the analysis of these models, we propose a workload-balanced push-relabel algorithm (WBPR) with two enhanced compressed sparse representations (CSR) and a vertex-centric approach. The enhanced CSR significantly reduces memory consumption, while the vertex-centric approach alleviates the workload imbalance and improves the utilization of the GPU. In the experiment, our approach reduces the memory consumption from O(V^2) to O(V + E). Moreover, we can achieve up to 7.31x and 2.29x runtime speedup compared to the state-of-the-art on real-world graphs in maximum flow and bipartite matching tasks, respectively. Our code will be open-sourced for further research on accelerating the push-relabel algorithm."}
{"main_page": "https://arxiv.org/abs/2404.00438", "pdf": "https://arxiv.org/pdf/2404.00438", "title": "Communication Efficient Distributed Training with Distributed Lion", "authors": "Bo Liu, Lemeng Wu, Lizhang Chen, Kaizhao Liang, Jiaxu Zhu, Chen Liang, Raghuraman Krishnamoorthi, Qiang Liu", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)", "abstract": "The Lion optimizer has been a promising competitor with the AdamW for training large AI models, with advantages on memory, computation, and sample efficiency. In this paper, we introduce Distributed Lion, an innovative adaptation of Lion for distributed training environments. Leveraging the sign operator in Lion, our Distributed Lion only requires communicating binary or lower-precision vectors between workers to the center server, significantly reducing the communication cost. Our theoretical analysis confirms Distributed Lion's convergence properties. Empirical results demonstrate its robustness across a range of tasks, worker counts, and batch sizes, on both vision and language problems. Notably, Distributed Lion attains comparable performance to standard Lion or AdamW optimizers applied on aggregated gradients, but with significantly reduced communication bandwidth. This feature is particularly advantageous for training large models. In addition, we also demonstrate that Distributed Lion presents a more favorable performance-bandwidth balance compared to existing efficient distributed methods such as deep gradient compression and ternary gradients."}
{"main_page": "https://arxiv.org/abs/2404.00704", "pdf": "https://arxiv.org/pdf/2404.00704", "title": "Sponge: Inference Serving with Dynamic SLOs Using In-Place Vertical  Scaling", "authors": "Kamran Razavi, Saeid Ghafouri, Max M\u00fchlh\u00e4user, Pooyan Jamshidi, Lin Wang", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Mobile and IoT applications increasingly adopt deep learning inference to provide intelligence. Inference requests are typically sent to a cloud infrastructure over a wireless network that is highly variable, leading to the challenge of dynamic Service Level Objectives (SLOs) at the request level. This paper presents Sponge, a novel deep learning inference serving system that maximizes resource efficiency while guaranteeing dynamic SLOs. Sponge achieves its goal by applying in-place vertical scaling, dynamic batching, and request reordering. Specifically, we introduce an Integer Programming formulation to capture the resource allocation problem, providing a mathematical model of the relationship between latency, batch size, and resources. We demonstrate the potential of Sponge through a prototype implementation and preliminary experiments and discuss future works."}
