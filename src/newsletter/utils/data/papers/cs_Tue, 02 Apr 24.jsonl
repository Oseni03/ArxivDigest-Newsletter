{"main_page": "https://arxiv.org/abs/2404.00006", "pdf": "https://arxiv.org/pdf/2404.00006", "title": "A Critique of Chen's \"The 2-MAXSAT Problem Can Be Solved in Polynomial  Time\"", "authors": "Tran Duy Anh Le, Michael P. Reidy, Eliot J. Smith", "subjects": "Computational Complexity (cs.CC)", "abstract": "In this paper, we examine Yangjun Chen's technical report titled ``The 2-MAXSAT Problem Can Be Solved in Polynomial Time'' [Che23], which revises and expands upon their conference paper of the same name [Che22]. Chen's paper purports to build a polynomial-time algorithm for the ${\\rm NP}$-complete problem 2-MAXSAT by converting a 2-CNF formula into a graph that is then searched. We show through multiple counterexamples that Chen's proposed algorithms contain flaws, and we find that the structures they create lack properly formalized definitions. Furthermore, we elaborate on how the author fails to prove the correctness of their algorithms and how they make overgeneralizations in their time analysis of their proposed solution. Due to these issues, we conclude that Chen's technical report [Che23] and conference paper [Che22] both fail to provide a proof that ${\\rm P}={\\rm NP}$."}
{"main_page": "https://arxiv.org/abs/2404.00007", "pdf": "https://arxiv.org/pdf/2404.00007", "title": "A Comprehensive Tutorial on over 100 Years of Diagrammatic  Representations of Logical Statements and Relational Queries", "authors": "Wolfgang Gatterbauer", "subjects": "Databases (cs.DB); Logic in Computer Science (cs.LO)", "abstract": "Query formulation is increasingly performed by systems that need to guess a user's intent (e.g. via spoken word interfaces). But how can a user know that the computational agent is returning answers to the \"right\" query? More generally, given that relational queries can become pretty complicated, how can we help users understand relational queries, whether human-generated or automatically generated? Now seems the right moment to revisit a topic that predates the birth of the relational model: developing visual metaphors that help users understand relational queries. This lecture-style tutorial surveys the key visual metaphors developed for diagrammatic representations of logical statements and relational expressions, across both the relational database and the much older diagrammatic reasoning communities. We survey the history and state-of-the-art of relationally-complete diagrammatic representations of relational queries, discuss the key visual metaphors developed in over a century of investigations into diagrammatic languages, and organize the landscape by mapping the visual alphabets of diagrammatic representation systems to the syntax and semantics of Relational Algebra (RA) and Relational Calculus (RC). Tutorial website: https://northeastern-datalab.github.io/diagrammatic-representation-tutorial/"}
{"main_page": "https://arxiv.org/abs/2404.00011", "pdf": "https://arxiv.org/pdf/2404.00011", "title": "A novel interface for adversarial trivia question-writing", "authors": "Jason Liu", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "abstract": "A critical component when developing question-answering AIs is an adversarial dataset that challenges models to adapt to the complex syntax and reasoning underlying our natural language. Present techniques for procedurally generating adversarial texts are not robust enough for training on complex tasks such as answering multi-sentence trivia questions. We instead turn to human-generated data by introducing an interface for collecting adversarial human-written trivia questions. Our interface is aimed towards question writers and players of Quiz Bowl, a buzzer-based trivia competition where paragraph-long questions consist of a sequence of clues of decreasing difficulty. To incentivize usage, a suite of machine learning-based tools in our interface assist humans in writing questions that are more challenging to answer for Quiz Bowl players and computers alike. Not only does our interface gather training data for the groundbreaking Quiz Bowl AI project QANTA, but it is also a proof-of-concept of future adversarial data collection for question-answering systems. The results of performance-testing our interface with ten originally-composed questions indicate that, despite some flaws, our interface's novel question-writing features as well as its real-time exposure of useful responses from our machine models could facilitate and enhance the collection of adversarial questions."}
{"main_page": "https://arxiv.org/abs/2404.00013", "pdf": "https://arxiv.org/pdf/2404.00013", "title": "Missing Data Imputation With Granular Semantics and AI-driven Pipeline  for Bankruptcy Prediction", "authors": "Debarati Chakraborty, Ravi Ranjan", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Statistical Finance (q-fin.ST); Applications (stat.AP)", "abstract": "This work focuses on designing a pipeline for the prediction of bankruptcy. The presence of missing values, high dimensional data, and highly class-imbalance databases are the major challenges in the said task. A new method for missing data imputation with granular semantics has been introduced here. The merits of granular computing have been explored here to define this method. The missing values have been predicted using the feature semantics and reliable observations in a low-dimensional space, in the granular space. The granules are formed around every missing entry, considering a few of the highly correlated features and most reliable closest observations to preserve the relevance and reliability, the context, of the database against the missing entries. An intergranular prediction is then carried out for the imputation within those contextual granules. That is, the contextual granules enable a small relevant fraction of the huge database to be used for imputation and overcome the need to access the entire database repetitively for each missing value. This method is then implemented and tested for the prediction of bankruptcy with the Polish Bankruptcy dataset. It provides an efficient solution for big and high-dimensional datasets even with large imputation rates. Then an AI-driven pipeline for bankruptcy prediction has been designed using the proposed granular semantic-based data filling method followed by the solutions to the issues like high dimensional dataset and high class-imbalance in the dataset. The rest of the pipeline consists of feature selection with the random forest for reducing dimensionality, data balancing with SMOTE, and prediction with six different popular classifiers including deep NN. All methods defined here have been experimentally verified with suitable comparative studies and proven to be effective on all the data sets captured over the five years."}
{"main_page": "https://arxiv.org/abs/2404.00016", "pdf": "https://arxiv.org/pdf/2404.00016", "title": "SOMson -- Sonification of Multidimensional Data in Kohonen Maps", "authors": "Simon Linke, Tim Ziemer", "subjects": "Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "abstract": "Kohonen Maps, aka. Self-organizing maps (SOMs) are neural networks that visualize a high-dimensional feature space on a low-dimensional map. While SOMs are an excellent tool for data examination and exploration, they inherently cause a loss of detail. Visualizations of the underlying data do not integrate well and, therefore, fail to provide an overall picture. Consequently, we suggest SOMson, an interactive sonification of the underlying data, as a data augmentation technique. The sonification increases the amount of information provided simultaneously by the SOM. Instead of a user study, we present an interactive online example, so readers can explore SOMson themselves. Its strengths, weaknesses, and prospects are discussed."}
{"main_page": "https://arxiv.org/abs/2404.00017", "pdf": "https://arxiv.org/pdf/2404.00017", "title": "Psittacines of Innovation? Assessing the True Novelty of AI Creations", "authors": "Anirban Mukherjee", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "abstract": "We examine whether Artificial Intelligence (AI) systems generate truly novel ideas rather than merely regurgitating patterns learned during training. Utilizing a novel experimental design, we task an AI with generating project titles for hypothetical crowdfunding campaigns. We compare within AI-generated project titles, measuring repetition and complexity. We compare between the AI-generated titles and actual observed field data using an extension of maximum mean discrepancy--a metric derived from the application of kernel mean embeddings of statistical distributions to high-dimensional machine learning (large language) embedding vectors--yielding a structured analysis of AI output novelty. Results suggest that (1) the AI generates unique content even under increasing task complexity, and at the limits of its computational capabilities, (2) the generated content has face validity, being consistent with both inputs to other generative AI and in qualitative comparison to field data, and (3) exhibits divergence from field data, mitigating concerns relating to intellectual property rights. We discuss implications for copyright and trademark law."}
{"main_page": "https://arxiv.org/abs/2404.00018", "pdf": "https://arxiv.org/pdf/2404.00018", "title": "Can AI Outperform Human Experts in Creating Social Media Creatives?", "authors": "Eunkyung Park, Raymond K. Wong, Junbum Kwon", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)", "abstract": "Artificial Intelligence has outperformed human experts in functional tasks such as chess and baduk. How about creative tasks? This paper evaluates AI's capability in the creative domain compared to human experts, which little research has been conducted so far. We propose a novel Prompt-for-Prompt to generate social media creatives via prompt augmentation by Large Language Models. We take the most popular Instagram posts (with the biggest number of like clicks) in top brands' Instagram accounts to create social media creatives. We give GPT 4 several prompt instructions with text descriptions to generate the most effective prompts for cutting-edge text-to-image generators: Midjourney, DALL E 3, and Stable Diffusion. LLM-augmented prompts can boost AI's abilities by adding objectives, engagement strategy, lighting and brand consistency for social media image creation. We conduct an extensive human evaluation experiment, and find that AI excels human experts, and Midjourney is better than the other text-to-image generators. Surprisingly, unlike conventional wisdom in the social media industry, prompt instruction including eye-catching shows much poorer performance than those including natural. Regarding the type of creatives, AI improves creatives with animals or products but less with real people. Also, AI improves creatives with short text descriptions more than with long text descriptions, because there is more room for AI to augment prompts with shorter descriptions."}
{"main_page": "https://arxiv.org/abs/2404.00019", "pdf": "https://arxiv.org/pdf/2404.00019", "title": "Advancing Explainable Autonomous Vehicle Systems: A Comprehensive Review  and Research Roadmap", "authors": "Sule Tekkesinoglu, Azra Habibovic, Lars Kunze", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)", "abstract": "Given the uncertainty surrounding how existing explainability methods for autonomous vehicles (AVs) meet the diverse needs of stakeholders, a thorough investigation is imperative to determine the contexts requiring explanations and suitable interaction strategies. A comprehensive review becomes crucial to assess the alignment of current approaches with the varied interests and expectations within the AV ecosystem. This study presents a review to discuss the complexities associated with explanation generation and presentation to facilitate the development of more effective and inclusive explainable AV systems. Our investigation led to categorising existing literature into three primary topics: explanatory tasks, explanatory information, and explanatory information communication. Drawing upon our insights, we have proposed a comprehensive roadmap for future research centred on (i) knowing the interlocutor, (ii) generating timely explanations, (ii) communicating human-friendly explanations, and (iv) continuous learning. Our roadmap is underpinned by principles of responsible research and innovation, emphasising the significance of diverse explanation requirements. To effectively tackle the challenges associated with implementing explainable AV systems, we have delineated various research directions, including the development of privacy-preserving data integration, ethical frameworks, real-time analytics, human-centric interaction design, and enhanced cross-disciplinary collaborations. By exploring these research directions, the study aims to guide the development and deployment of explainable AVs, informed by a holistic understanding of user needs, technological advancements, regulatory compliance, and ethical considerations, thereby ensuring safer and more trustworthy autonomous driving experiences."}
{"main_page": "https://arxiv.org/abs/2404.00021", "pdf": "https://arxiv.org/pdf/2404.00021", "title": "Evaluatology: The Science and Engineering of Evaluation", "authors": "Jianfeng Zhan, Lei Wang, Wanling Gao, Hongxiao Li, Chenxi Wang, Yunyou Huang, Yatao Li, Zhengxin Yang, Guoxin Kang, Chunjie Luo, Hainan Ye, Shaopeng Dai, Zhifei Zhang", "subjects": "Human-Computer Interaction (cs.HC); Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY); Performance (cs.PF)", "abstract": "Evaluation is a crucial aspect of human existence and plays a vital role in various fields. However, it is often approached in an empirical and ad-hoc manner, lacking consensus on universal concepts, terminologies, theories, and methodologies. This lack of agreement has significant repercussions. This article aims to formally introduce the discipline of evaluatology, which encompasses the science and engineering of evaluation. We propose a universal framework for evaluation, encompassing concepts, terminologies, theories, and methodologies that can be applied across various disciplines. Our research reveals that the essence of evaluation lies in conducting experiments that intentionally apply a well-defined evaluation condition to diverse subjects and infer the impact of different subjects by measuring and/or testing. Derived from the essence of evaluation, we propose five axioms focusing on key aspects of evaluation outcomes as the foundational evaluation theory. These axioms serve as the bedrock upon which we build universal evaluation theories and methodologies. When evaluating a single subject, it is crucial to create evaluation conditions with different levels of equivalency. By applying these conditions to diverse subjects, we can establish reference evaluation models. These models allow us to alter a single independent variable at a time while keeping all other variables as controls. When evaluating complex scenarios, the key lies in establishing a series of evaluation models that maintain transitivity. Building upon the science of evaluation, we propose a formal definition of a benchmark as a simplified and sampled evaluation condition that guarantees different levels of equivalency. This concept serves as the cornerstone for a universal benchmark-based engineering approach to evaluation across various disciplines, which we refer to as benchmarkology."}
{"main_page": "https://arxiv.org/abs/2404.00022", "pdf": "https://arxiv.org/pdf/2404.00022", "title": "Analysing and Organising Human Communications for AI Fairness-Related  Decisions: Use Cases from the Public Sector", "authors": "Mirthe Dankloff, Vanja Skoric, Giovanni Sileno, Sennay Ghebreab, Jacco Van Ossenbruggen, Emma Beauxis-Aussalet", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "abstract": "AI algorithms used in the public sector, e.g., for allocating social benefits or predicting fraud, often involve multiple public and private stakeholders at various phases of the algorithm's life-cycle. Communication issues between these diverse stakeholders can lead to misinterpretation and misuse of algorithms. We investigate the communication processes for AI fairness-related decisions by conducting interviews with practitioners working on algorithmic systems in the public sector. By applying qualitative coding analysis, we identify key elements of communication processes that underlie fairness-related human decisions. We analyze the division of roles, tasks, skills, and challenges perceived by stakeholders. We formalize the underlying communication issues within a conceptual framework that i. represents the communication patterns ii. outlines missing elements, such as actors who miss skills for their tasks. The framework is used for describing and analyzing key organizational issues for fairness-related decisions. Three general patterns emerge from the analysis: 1. Policy-makers, civil servants, and domain experts are less involved compared to developers throughout a system's life-cycle. This leads to developers taking on extra roles such as advisor, while they potentially miss the required skills and guidance from domain experts. 2. End-users and policy-makers often lack the technical skills to interpret a system's limitations, and rely on developer roles for making decisions concerning fairness issues. 3. Citizens are structurally absent throughout a system's life-cycle, which may lead to decisions that do not include relevant considerations from impacted stakeholders."}
{"main_page": "https://arxiv.org/abs/2404.00024", "pdf": "https://arxiv.org/pdf/2404.00024", "title": "Hey, Teacher, (Don't) Leave Those Kids Alone: Standardizing HRI  Education", "authors": "Alexis E. Block", "subjects": "Robotics (cs.RO); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "abstract": "Creating a standardized introduction course becomes more critical as the field of human-robot interaction (HRI) becomes more established. This paper outlines the key components necessary to provide an undergraduate with a sufficient foundational understanding of the interdisciplinary nature of this field and provides proposed course content. It emphasizes the importance of creating a course with theoretical and experimental components to accommodate all different learning preferences. This manuscript also advocates creating or adopting a universal platform to standardize the hands-on component of introductory HRI courses, regardless of university funding or size. Next, it recommends formal training in how to read scientific articles and staying up-to-date with the latest relevant papers. Finally, it provides detailed lecture content and project milestones for a 15-week semester. By creating a standardized course, researchers can ensure consistency and quality are maintained across institutions, which will help students as well as industrial and academic employers understand what foundational knowledge is expected."}
{"main_page": "https://arxiv.org/abs/2404.00025", "pdf": "https://arxiv.org/pdf/2404.00025", "title": "Understanding Physical Breakdowns in Virtual Reality", "authors": "Wen-Jie Tseng", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Virtual Reality (VR) moves away from well-controlled laboratory environments into public and personal spaces. As users are visually disconnected from the physical environment, interacting in an uncontrolled space frequently leads to collisions and raises safety concerns. In my thesis, I investigate this phenomenon which I define as the physical breakdown in VR. The goal is to understand the reasons for physical breakdowns, provide solutions, and explore future mechanisms that could perpetuate safety risks. First, I explored the reasons for physical breakdowns by investigating how people interact with the current VR safety mechanism (e.g., Oculus Guardian). Results show one reason for breaking out of the safety boundary is when interacting with large motions (e.g., swinging arms), the user does not have enough time to react although they see the safety boundary. I proposed a solution, FingerMapper, that maps small-scale finger motions onto virtual arms and hands to enable whole-body virtual arm motions in VR to avoid physical breakdowns. To demonstrate future safety risks, I explored the malicious use of perceptual manipulations (e.g., redirection techniques) in VR, which could deliberately create physical breakdowns without users noticing. Results indicate further open challenges about the cognitive process of how users comprehend their physical environment when they are blindfolded in VR."}
{"main_page": "https://arxiv.org/abs/2404.00026", "pdf": "https://arxiv.org/pdf/2404.00026", "title": "Ink and Individuality: Crafting a Personalised Narrative in the Age of  LLMs", "authors": "Azmine Toushik Wasi, Raima Islam, Rafia Islam", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "abstract": "Individuality and personalization comprise the distinctive characteristics that make each writer unique and influence their words in order to effectively engage readers while conveying authenticity. However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time. We often overlook the negative impacts of this trend on our creativity and uniqueness, despite the possible consequences. This study investigates these concerns by performing a brief survey to explore different perspectives and concepts, as well as trying to understand people's viewpoints, in conjunction with past studies in the area. Addressing these issues is essential for improving human-computer interaction systems and enhancing writing assistants for personalization and individuality."}
{"main_page": "https://arxiv.org/abs/2404.00027", "pdf": "https://arxiv.org/pdf/2404.00027", "title": "LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership  and Reasoning", "authors": "Azmine Toushik Wasi, Rafia Islam, Raima Islam", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems."}
{"main_page": "https://arxiv.org/abs/2404.00029", "pdf": "https://arxiv.org/pdf/2404.00029", "title": "Complementarity in Human-AI Collaboration: Concept, Sources, and  Evidence", "authors": "Patrick Hemmer, Max Schemmer, Niklas K\u00fchl, Michael V\u00f6ssing, Gerhard Satzger", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "abstract": "Artificial intelligence (AI) can improve human decision-making in various application areas. Ideally, collaboration between humans and AI should lead to complementary team performance (CTP) -- a level of performance that neither of them can attain individually. So far, however, CTP has rarely been observed, suggesting an insufficient understanding of the complementary constituents in human-AI collaboration that can contribute to CTP in decision-making. This work establishes a holistic theoretical foundation for understanding and developing human-AI complementarity. We conceptualize complementarity by introducing and formalizing the notion of complementarity potential and its realization. Moreover, we identify and outline sources that explain CTP. We illustrate our conceptualization by applying it in two empirical studies exploring two different sources of complementarity potential. In the first study, we focus on information asymmetry as a source and, in a real estate appraisal use case, demonstrate that humans can leverage unique contextual information to achieve CTP. In the second study, we focus on capability asymmetry as an alternative source, demonstrating how heterogeneous capabilities can help achieve CTP. Our work provides researchers with a theoretical foundation of complementarity in human-AI decision-making and demonstrates that leveraging sources of complementarity potential constitutes a viable pathway toward effective human-AI collaboration."}
{"main_page": "https://arxiv.org/abs/2404.00030", "pdf": "https://arxiv.org/pdf/2404.00030", "title": "Visualization of Unstructured Sports Data -- An Example of Cricket Short  Text Commentary", "authors": "Swarup Ranjan Behera, Vijaya V Saradhi", "subjects": "Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "abstract": "Sports visualization focuses on the use of structured data, such as box-score data and tracking data. Unstructured data sources pertaining to sports are available in various places such as blogs, social media posts, and online news articles. Sports visualization methods either not fully exploited the information present in these sources or the proposed visualizations through the use of these sources did not augment to the body of sports visualization methods. We propose the use of unstructured data, namely cricket short text commentary for visualization. The short text commentary data is used for constructing individual player's strength rules and weakness rules. A computationally feasible definition for player's strength rule and weakness rule is proposed. A visualization method for the constructed rules is presented. In addition, players having similar strength rules or weakness rules is computed and visualized. We demonstrate the usefulness of short text commentary in visualization by analyzing the strengths and weaknesses of cricket players using more than one million text commentaries. We validate the constructed rules through two validation methods. The collected data, source code, and obtained results on more than 500 players are made publicly available."}
{"main_page": "https://arxiv.org/abs/2404.00031", "pdf": "https://arxiv.org/pdf/2404.00031", "title": "Towards gaze-independent c-VEP BCI: A pilot study", "authors": "S. Narayanan, S. Ahmadi, P. Desain, J. Thielen", "subjects": "Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "abstract": "A limitation of brain-computer interface (BCI) spellers is that they require the user to be able to move the eyes to fixate on targets. This poses an issue for users who cannot voluntarily control their eye movements, for instance, people living with late-stage amyotrophic lateral sclerosis (ALS). This pilot study makes the first step towards a gaze-independent speller based on the code-modulated visual evoked potential (c-VEP). Participants were presented with two bi-laterally located stimuli, one of which was flashing, and were tasked to attend to one of these stimuli either by directly looking at the stimuli (overt condition) or by using spatial attention, eliminating the need for eye movement (covert condition). The attended stimuli were decoded from electroencephalography (EEG) and classification accuracies of 88% and 100% were obtained for the covert and overt conditions, respectively. These fundamental insights show the promising feasibility of utilizing the c-VEP protocol for gaze-independent BCIs that use covert spatial attention when both stimuli flash simultaneously."}
{"main_page": "https://arxiv.org/abs/2404.00032", "pdf": "https://arxiv.org/pdf/2404.00032", "title": "Deployment of Deep Learning Model in Real World Clinical Setting: A Case  Study in Obstetric Ultrasound", "authors": "Chun Kit Wong, Mary Ngo, Manxi Lin, Zahra Bashir, Amihai Heen, Morten Bo S\u00f8ndergaard Svendsen, Martin Gr\u00f8nneb\u00e6k Tolsgaard, Anders Nymark Christensen, Aasa Feragen", "subjects": "Human-Computer Interaction (cs.HC); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Despite the rapid development of AI models in medical image analysis, their validation in real-world clinical settings remains limited. To address this, we introduce a generic framework designed for deploying image-based AI models in such settings. Using this framework, we deployed a trained model for fetal ultrasound standard plane detection, and evaluated it in real-time sessions with both novice and expert users. Feedback from these sessions revealed that while the model offers potential benefits to medical practitioners, the need for navigational guidance was identified as a key area for improvement. These findings underscore the importance of early deployment of AI models in real-world settings, leading to insights that can guide the refinement of the model and system based on actual user feedback."}
{"main_page": "https://arxiv.org/abs/2404.00033", "pdf": "https://arxiv.org/pdf/2404.00033", "title": "The Hall of Singularity: VR Experience of Prophecy by AI", "authors": "Jisu Kim, Kirak Kim", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "\"The Hall of Singularity\" is an immersive art that creates personalized experiences of receiving prophecies from an AI deity through an integration of Artificial Intelligence (AI) and Virtual Reality (VR). As a metaphor for the mythologizing of AI in our society, \"The Hall of Singularity\" offers an immersive quasi-religious experience where individuals can encounter an AI that has the power to make prophecies. This journey enables users to experience and imagine a world with an omnipotent AI deity."}
{"main_page": "https://arxiv.org/abs/2404.00036", "pdf": "https://arxiv.org/pdf/2404.00036", "title": "A Fast Convergence Algorithm for Iterative Adaptation of Feedforward  Controller Parameters", "authors": "Eloy Serrano-Seco (1), Eduardo Moya-Lasheras (1), Edgar Ramirez-Laboreo (1) ((1) Universidad de Zaragoza)", "subjects": "Systems and Control (eess.SY)", "abstract": "Feedforward control is a viable option for enhancing the response time and control accuracy of a wide variety of systems. Nevertheless, it is not able to compensate for the effects produced by modeling errors or disturbances. A solution to improve the feedforward performance is the use of an adaptation law that modifies the parameters of the feedforward control. In the case where real-time feedback is not possible, a solution is a run-to-run numerical optimization method that is fed with a cost based on a measured signal. Although the effectiveness of this approach has been demonstrated, its performance is hindered by slow convergence. In this paper, we present an algorithm based on Pattern Search and Adaptive Coordinate Descent methods that makes use of the sensitivity of the feedforward controller to its parameters so that the convergence speed improves significantly. Like many algorithms, this is a local strategy so the algorithm might converge to a local minimum. Therefore, we present two versions, one without a learning rate and one with it. To compare them and to demonstrate the effectiveness of the algorithm, simulated results are shown on a well-known control problem in electromechanics: the soft-landing control of electromechanical switching devices."}
{"main_page": "https://arxiv.org/abs/2404.00039", "pdf": "https://arxiv.org/pdf/2404.00039", "title": "MicroHD: An Accuracy-Driven Optimization of Hyperdimensional Computing  Algorithms for TinyML systems", "authors": "Flavio Ponzina, Tajana Rosing", "subjects": "Performance (cs.PF); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)", "abstract": "Hyperdimensional computing (HDC) is emerging as a promising AI approach that can effectively target TinyML applications thanks to its lightweight computing and memory requirements. Previous works on HDC showed that limiting the standard 10k dimensions of the hyperdimensional space to much lower values is possible, reducing even more HDC resource requirements. Similarly, other studies demonstrated that binary values can be used as elements of the generated hypervectors, leading to significant efficiency gains at the cost of some degree of accuracy degradation. Nevertheless, current optimization attempts do not concurrently co-optimize HDC hyper-parameters, and accuracy degradation is not directly controlled, resulting in sub-optimal HDC models providing several applications with unacceptable output qualities. In this work, we propose MicroHD, a novel accuracy-driven HDC optimization approach that iteratively tunes HDC hyper-parameters, reducing memory and computing requirements while ensuring user-defined accuracy levels. The proposed method can be applied to HDC implementations using different encoding functions, demonstrates good scalability for larger HDC workloads, and achieves compression and efficiency gains up to 200x when compared to baseline implementations for accuracy degradations lower than 1%."}
{"main_page": "https://arxiv.org/abs/2404.00040", "pdf": "https://arxiv.org/pdf/2404.00040", "title": "Stationary and Dynamic Reference Frame Comparison Based Microgrid  Application", "authors": "Ilyas Bennia, Yacine Daili, Abdelghani Harrag, Walid Issa", "subjects": "Systems and Control (eess.SY)", "abstract": "This paper presents a brief comparison for voltage and current controllers implementation in both stationary and dynamic reference frame for a microgrid (MG) application. Diagrams of implementations are reviewed and the simulation results are presented to show the performance of each topology"}
{"main_page": "https://arxiv.org/abs/2404.00041", "pdf": "https://arxiv.org/pdf/2404.00041", "title": "On contention resolution for the hypergraph matching, knapsack, and  $k$-column sparse packing problems", "authors": "Ivan Sergeev", "subjects": "Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)", "abstract": "The contention resolution framework is a versatile rounding technique used as a part of the relaxation and rounding approach for solving constrained submodular function maximization problems. We apply this framework to the hypergraph matching, knapsack, and $k$-column sparse packing problems. In the hypergraph matching setting, we adapt the technique of Guruganesh, Lee (2018) to non-constructively prove that the correlation gap is at least $\\frac{1-e^{-k}}{k}$ and provide a monotone $\\left(b,\\frac{1-e^{-bk}}{bk}\\right)$-balanced contention resolution scheme, generalizing the results of Bruggmann, Zenklusen (2019). For the knapsack problem, we prove that the correlation gap of instances where exactly $k$ copies of each item fit into the knapsack is at least $\\frac{1-e^{-2}}{2}$ and provide several monotone contention resolution schemes: a $\\frac{1-e^{-2}}{2}$-balanced scheme for instances where all item sizes are strictly bigger than $\\frac{1}{2}$, a $\\frac{4}{9}$-balanced scheme for instances where all item sizes are at most $\\frac{1}{2}$, and a $0.279$-balanced scheme for instances with arbitrary item sizes. For $k$-column sparse packing integer programs, we slightly modify the $\\left(2k+o\\left(k\\right)\\right)$-approximation algorithm for $k$-CS-PIP based on the strengthened LP relaxation presented in Brubach et al. (2019) to obtain a $\\frac{1}{4k+o\\left(k\\right)}$-balanced contention resolution scheme and hence a $\\left(4k+o\\left(k\\right)\\right)$-approximation algorithm for $k$-CS-PIP based on the natural LP relaxation."}
{"main_page": "https://arxiv.org/abs/2404.00043", "pdf": "https://arxiv.org/pdf/2404.00043", "title": "Improve accessibility for Low Vision and Blind people using Machine  Learning and Computer Vision", "authors": "Jasur Shukurov", "subjects": "Human-Computer Interaction (cs.HC); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "With the ever-growing expansion of mobile technology worldwide, there is an increasing need for accommodation for those who are disabled. This project explores how machine learning and computer vision could be utilized to improve accessibility for people with visual impairments. There have been many attempts to develop various software that would improve accessibility in the day-to-day lives of blind people. However, applications on the market have low accuracy and only provide audio feedback. This project will concentrate on building a mobile application that helps blind people to orient in space by receiving audio and haptic feedback, e.g. vibrations, about their surroundings in real-time. The mobile application will have 3 main features. The initial feature is scanning text from the camera and reading it to a user. This feature can be used on paper with text, in the environment, and on road signs. The second feature is detecting objects around the user, and providing audio feedback about those objects. It also includes providing the description of the objects and their location, and giving haptic feedback if the user is too close to an object. The last feature is currency detection which provides a total amount of currency value to the user via the camera."}
{"main_page": "https://arxiv.org/abs/2404.00045", "pdf": "https://arxiv.org/pdf/2404.00045", "title": "Policy Optimization finds Nash Equilibrium in Regularized General-Sum LQ  Games", "authors": "Muhammad Aneeq uz Zaman, Shubham Aggarwal, Melih Bastopcu, Tamer Ba\u015far", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "abstract": "In this paper, we investigate the impact of introducing relative entropy regularization on the Nash Equilibria (NE) of General-Sum $N$-agent games, revealing the fact that the NE of such games conform to linear Gaussian policies. Moreover, it delineates sufficient conditions, contingent upon the adequacy of entropy regularization, for the uniqueness of the NE within the game. As Policy Optimization serves as a foundational approach for Reinforcement Learning (RL) techniques aimed at finding the NE, in this work we prove the linear convergence of a policy optimization algorithm which (subject to the adequacy of entropy regularization) is capable of provably attaining the NE. Furthermore, in scenarios where the entropy regularization proves insufficient, we present a $\\delta$-augmentation technique, which facilitates the achievement of an $\\epsilon$-NE within the game."}
{"main_page": "https://arxiv.org/abs/2404.00047", "pdf": "https://arxiv.org/pdf/2404.00047", "title": "Guidelines for Public and Patient Involvement in Neurotechnology in the  United Kingdom", "authors": "Amparo Guemes Gonzalez, Tiago da Silva Costa, Tamar Makin", "subjects": "Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)", "abstract": "Neurotechnologies are increasingly becoming integrated in our everyday lives, our bodies and minds. As the popularity and impact of neurotech grows, so does our responsibility to ensure we understand its particular ethical and societal implications. Enabling end-users and other stakeholders to participate in the development of neurotechnology, even at its earliest stages of conception, will help us better navigate our design around these serious considerations, and deliver more impactful technologies. There are many different terms and frameworks to articulate the concept of involving end users in the technology development lifecycle: 'Public and Patient Involvement and Engagement' (PPIE), 'lived experience', 'co-design', 'co-production'. What is lacking are clear guidelines for implementing a robust PPIE process in neurotechnology. While general advice is available online, it is down to individuals (and their funders) to carve up their own approach to meaningful involvement. Here we present guidance for UK-based researchers and engineers to conduct PPI for neurotechnology. The overall aim is the establishment of gold-standard PPIE methodologies in the neurotechnology space that bring patient and public insights at the forefront of our scientific inquiry and product development."}
{"main_page": "https://arxiv.org/abs/2404.00048", "pdf": "https://arxiv.org/pdf/2404.00048", "title": "SLIMBRAIN: Augmented Reality Real-Time Acquisition and Processing System  For Hyperspectral Classification Mapping with Depth Information for In-Vivo  Surgical Procedures", "authors": "Jaime Sancho, Manuel Villa, Miguel Chavarr\u00edas, Eduardo Juarez, Alfonso Lagares, C\u00e9sar Sanz", "subjects": "Human-Computer Interaction (cs.HC); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Over the last two decades, augmented reality (AR) has led to the rapid development of new interfaces in various fields of social and technological application domains. One such domain is medicine, and to a higher extent surgery, where these visualization techniques help to improve the effectiveness of preoperative and intraoperative procedures. Following this trend, this paper presents SLIMBRAIN, a real-time acquisition and processing AR system suitable to classify and display brain tumor tissue from hyperspectral (HS) information. This system captures and processes HS images at 14 frames per second (FPS) during the course of a tumor resection operation to detect and delimit cancer tissue at the same time the neurosurgeon operates. The result is represented in an AR visualization where the classification results are overlapped with the RGB point cloud captured by a LiDAR camera. This representation allows natural navigation of the scene at the same time it is captured and processed, improving the visualization and hence effectiveness of the HS technology to delimit tumors. The whole system has been verified in real brain tumor resection operations."}
{"main_page": "https://arxiv.org/abs/2404.00049", "pdf": "https://arxiv.org/pdf/2404.00049", "title": "Web-based Interactive Narratives to Present Business Processes Models", "authors": "M\u00e1rcio Rocha Ferreira, Tadeu Moreira de Classe, Sean Wolfgand Matsui Siqueira", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Interactive narratives offer a novel approach to presenting business process models, making them more accessible and collaborative. These narratives create a hyper-textual environment that facilitates knowledge exchange and comprehension for ordinary individuals. However, designing such narratives is complex, as business process modelers must accurately identify and translate the graphic elements of a process model into dynamic narrative elements. This research paper introduces the Scripting Your Process (SYP) method, which provides a systematic approach to designing interactive narratives based on business process models. Following the principles of Design Science Research (DSR), a quasi-experimental study demonstrates and evaluates the SYP method. The results show that the SYP method successfully achieves its objective, contributing to the systematic design of interactive narratives derived from business process models. Consequently, individuals who are not experts in business process management can understand these processes in an engaging and gameful manner."}
{"main_page": "https://arxiv.org/abs/2404.00051", "pdf": "https://arxiv.org/pdf/2404.00051", "title": "Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal  Knowledge Graph Reasoning", "authors": "Miao Peng, Ben Liu, Wenjie Xu, Zihao Jiang, Jiahui Zhu, Min Peng", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the task of inferring missing facts for incomplete TKGs in complex scenarios (e.g., transductive and inductive settings), which has been gaining increasing attention. Recently, to mitigate dependence on structured connections in TKGs, text-based methods have been developed to utilize rich linguistic information from entity descriptions. However, suffering from the enormous parameters and inflexibility of pre-trained language models, existing text-based methods struggle to balance the textual knowledge and temporal information with computationally expensive purpose-built training strategies. To tap the potential of text-based models for TKGR in various complex scenarios, we propose ChapTER, a Contrastive historical modeling framework with prefix-tuning for TEmporal Reasoning. ChapTER feeds history-contextualized text into the pseudo-Siamese encoders to strike a textual-temporal balance via contrastive estimation between queries and candidates. By introducing virtual time prefix tokens, it applies a prefix-based tuning method to facilitate the frozen PLM capable for TKGR tasks under different settings. We evaluate ChapTER on four transductive and three few-shot inductive TKGR benchmarks, and experimental results demonstrate that ChapTER achieves superior performance compared to competitive baselines with only 0.17% tuned parameters. We conduct thorough analysis to verify the effectiveness, flexibility and efficiency of ChapTER."}
{"main_page": "https://arxiv.org/abs/2404.00054", "pdf": "https://arxiv.org/pdf/2404.00054", "title": "Choreographing the Digital Canvas: A Machine Learning Approach to  Artistic Performance", "authors": "Siyuan Peng, Kate Ladenheim, Snehesh Shrestha, Cornelia Ferm\u00fcller", "subjects": "Human-Computer Interaction (cs.HC); Graphics (cs.GR); Machine Learning (cs.LG)", "abstract": "This paper introduces the concept of a design tool for artistic performances based on attribute descriptions. To do so, we used a specific performance of falling actions. The platform integrates a novel machine-learning (ML) model with an interactive interface to generate and visualize artistic movements. Our approach's core is a cyclic Attribute-Conditioned Variational Autoencoder (AC-VAE) model developed to address the challenge of capturing and generating realistic 3D human body motions from motion capture (MoCap) data. We created a unique dataset focused on the dynamics of falling movements, characterized by a new ontology that divides motion into three distinct phases: Impact, Glitch, and Fall. The ML model's innovation lies in its ability to learn these phases separately. It is achieved by applying comprehensive data augmentation techniques and an initial pose loss function to generate natural and plausible motion. Our web-based interface provides an intuitive platform for artists to engage with this technology, offering fine-grained control over motion attributes and interactive visualization tools, including a 360-degree view and a dynamic timeline for playback manipulation. Our research paves the way for a future where technology amplifies the creative potential of human expression, making sophisticated motion generation accessible to a wider artistic community."}
{"main_page": "https://arxiv.org/abs/2404.00056", "pdf": "https://arxiv.org/pdf/2404.00056", "title": "Fingerprinting web servers through Transformer-encoded HTTP response  headers", "authors": "Patrick Darwinkel", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)", "abstract": "We explored leveraging state-of-the-art deep learning, big data, and natural language processing to enhance the detection of vulnerable web server versions. Focusing on improving accuracy and specificity over rule-based systems, we conducted experiments by sending various ambiguous and non-standard HTTP requests to 4.77 million domains and capturing HTTP response status lines. We represented these status lines through training a BPE tokenizer and RoBERTa encoder for unsupervised masked language modeling. We then dimensionality reduced and concatenated encoded response lines to represent each domain's web server. A Random Forest and multilayer perceptron (MLP) classified these web servers, and achieved 0.94 and 0.96 macro F1-score, respectively, on detecting the five most popular origin web servers. The MLP achieved a weighted F1-score of 0.55 on classifying 347 major type and minor version pairs. Analysis indicates that our test cases are meaningful discriminants of web server types. Our approach demonstrates promise as a powerful and flexible alternative to rule-based systems."}
{"main_page": "https://arxiv.org/abs/2404.00057", "pdf": "https://arxiv.org/pdf/2404.00057", "title": "PerOS: Personalized Self-Adapting Operating Systems in the Cloud", "authors": "Hongyu H\u00e8", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Operating Systems (cs.OS)", "abstract": "Operating systems (OSes) are foundational to computer systems, managing hardware resources and ensuring secure environments for diverse applications. However, despite their enduring importance, the fundamental design objectives of OSes have seen minimal evolution over decades. Traditionally prioritizing aspects like speed, memory efficiency, security, and scalability, these objectives often overlook the crucial aspect of intelligence as well as personalized user experience. The lack of intelligence becomes increasingly critical amid technological revolutions, such as the remarkable advancements in machine learning (ML). Today's personal devices, evolving into intimate companions for users, pose unique challenges for traditional OSes like Linux and iOS, especially with the emergence of specialized hardware featuring heterogeneous components. Furthermore, the rise of large language models (LLMs) in ML has introduced transformative capabilities, reshaping user interactions and software development paradigms. While existing literature predominantly focuses on leveraging ML methods for system optimization or accelerating ML workloads, there is a significant gap in addressing personalized user experiences at the OS level. To tackle this challenge, this work proposes PerOS, a personalized OS ingrained with LLM capabilities. PerOS aims to provide tailored user experiences while safeguarding privacy and personal data through declarative interfaces, self-adaptive kernels, and secure data management in a scalable cloud-centric architecture; therein lies the main research question of this work: How can we develop intelligent, secure, and scalable OSes that deliver personalized experiences to thousands of users?"}
{"main_page": "https://arxiv.org/abs/2404.00061", "pdf": "https://arxiv.org/pdf/2404.00061", "title": "ERIOS: Co-construction of a Dynamic Temporal Visualization Tool in the  Electronic Health Record", "authors": "Louise Robert, Quentin Luzurier, Ana\u00efs Velcker, Emma Mathieu, Loic Fontaine, David Morquin", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "ERIOS, is a collaborative project between Dedalus, a health software company, Montpellier University Hospital Center (CHU), and the University of Montpellier. This initiative aims to incorporate research and development (R\\&D) directly within the hospital, focusing on co-creating components of the Electronic Health Record (EHR) alongside end-users. The project was initiated with two initial use cases, which led to the development of components for dynamic temporal visualization, now integrated into specific dashboards. The application of academic recommendations regarding user engagement methodology and human-computer interactions significantly enhanced our ability to meet user needs."}
{"main_page": "https://arxiv.org/abs/2404.00062", "pdf": "https://arxiv.org/pdf/2404.00062", "title": "Modelling the Impact of Quantum Circuit Imperfections on Networks and  Computer Applications", "authors": "Savo Glisic", "subjects": "Cryptography and Security (cs.CR); Quantum Physics (quant-ph)", "abstract": "Post Quantum and Quantum Cryptography schemes are feasible quantum computer applications for 7G networks. These schemes could possibly replace existing schemes. These algorithms have been compromised by advances in quantum search algorithms run on quantum computers like Shor algorithm. Shor algorithm is a quantum algorithm for finding the prime factors of an integer which is the basis of existing algorithm. This has become an available quantum computer application putting the use of ESA algorithm at risk. Our recent paper provides a detailed survey of the work on post quantum and quantum cryptography algorithms with focus on their applicability in 7G networks. Since the paper focuses on the cryptography algorithms as a follow up, in this paper, we provide a new framework for quantum network optimization and survey in detail the work on enabling technologies (quantum hardware) for the practical implementation of these algorithms including the most important segments of quantum hardware in 7G. As always in engineering practice practical solutions are a compromise between the performance and complexity of the implementation. For this reason, as the main contribution, the paper presents a network and computer applications optimization framework that includes implementation imperfections. The tools should be useful in optimizing future generation practical computer system design. After that a comprehensive survey of the existing work on quantum hardware is presented pointing out the sources of these imperfections. This enables us to make a fair assessment of how much investment into quantum hardware improvements contributes to the performance enhancement of the overall system. In this way a decision can be made on proper partitioning between the investment in hardware and system level complexity."}
{"main_page": "https://arxiv.org/abs/2404.00065", "pdf": "https://arxiv.org/pdf/2404.00065", "title": "Towards a Theoretical Foundation of Process Science", "authors": "Peter Fettke, Wolfgang Reisig", "subjects": "Databases (cs.DB); Computers and Society (cs.CY); Physics and Society (physics.soc-ph)", "abstract": "Process science is a highly interdisciplinary field of research. Despite numerous proposals, process science lacks an adequate understanding of the core concepts of the field, including notions such as process, event, and system. A more systematic framework to cope with process science is mandatory. We suggest such a framework using an example. The framework itself addresses three aspects: architecture, statics, and dynamics. Corresponding formal concepts, based on established scientific theories, together provide an integrated framework for understanding processes in the world. We argue that our foundations have positive implications not only for theoretical research, but also for empirical research, e.g., because hypothesized relationships can be explicitly tested. It is now time to start a discussion about the foundations of our field."}
{"main_page": "https://arxiv.org/abs/2404.00066", "pdf": "https://arxiv.org/pdf/2404.00066", "title": "Local Observability of VINS and LINS", "authors": "Xinran Li", "subjects": "Systems and Control (eess.SY); Robotics (cs.RO)", "abstract": "This work analyzes unobservable directions of Vision-aided Inertial Navigation System (VINS) and Lidar-aided Inertial Navigation System (LINS) nonlinear model. Under the assumption that there exist two features observed by the camera without occlusion, the unobservable directions of VINS are uniformly globally translation and global rotations about the gravity vector. The unobservable directions of LINS are same as VINS, while only one feature need to be observed."}
{"main_page": "https://arxiv.org/abs/2404.00068", "pdf": "https://arxiv.org/pdf/2404.00068", "title": "A Data-Driven Predictive Analysis on Cyber Security Threats with Key  Risk Factors", "authors": "Fatama Tuz Johora (1), Md Shahedul Islam Khan (2), Esrath Kanon (1), Mohammad Abu Tareq Rony (3), Md Zubair (4),  (5)Iqbal H. Sarker ((1) Department of Computer Science and Engineering, University of Chittagong, Chattogram, Bangladesh, (2) Department of School of Electronics and Information, Northwestern Polytechnical University, Xi'an, Shaanxi, China (3) Department of Statistics, Noakhali Science and Technology University, Noakhali, Bangladesh (4) Department of Computer Science and Engineering, Chittagong University of Engineering & Technology, Chattogram, Bangladesh (5) Centre for Securing Digital Futures, Edith Cowan University, Perth, WA, Australia)", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "Cyber risk refers to the risk of defacing reputation, monetary losses, or disruption of an organization or individuals, and this situation usually occurs by the unconscious use of cyber systems. The cyber risk is unhurriedly increasing day by day and it is right now a global threat. Developing countries like Bangladesh face major cyber risk challenges. The growing cyber threat worldwide focuses on the need for effective modeling to predict and manage the associated risk. This paper exhibits a Machine Learning(ML) based model for predicting individuals who may be victims of cyber attacks by analyzing socioeconomic factors. We collected the dataset from victims and non-victims of cyberattacks based on socio-demographic features. The study involved the development of a questionnaire to gather data, which was then used to measure the significance of features. Through data augmentation, the dataset was expanded to encompass 3286 entries, setting the stage for our investigation and modeling. Among several ML models with 19, 20, 21, and 26 features, we proposed a novel Pertinent Features Random Forest (RF) model, which achieved maximum accuracy with 20 features (95.95\\%) and also demonstrated the association among the selected features using the Apriori algorithm with Confidence (above 80\\%) according to the victim. We generated 10 important association rules and presented the framework that is rigorously evaluated on real-world datasets, demonstrating its potential to predict cyberattacks and associated risk factors effectively. Looking ahead, future efforts will be directed toward refining the predictive model's precision and delving into additional risk factors, to fortify the proposed framework's efficacy in navigating the complex terrain of cybersecurity threats."}
{"main_page": "https://arxiv.org/abs/2404.00069", "pdf": "https://arxiv.org/pdf/2404.00069", "title": "A Two-Phase Recall-and-Select Framework for Fast Model Selection", "authors": "Jianwei Cui, Wenhang Shi, Honglin Tao, Wei Lu, Xiaoyong Du", "subjects": "Machine Learning (cs.LG)", "abstract": "As the ubiquity of deep learning in various machine learning applications has amplified, a proliferation of neural network models has been trained and shared on public model repositories. In the context of a targeted machine learning assignment, utilizing an apt source model as a starting point typically outperforms the strategy of training from scratch, particularly with limited training data. Despite the investigation and development of numerous model selection strategies in prior work, the process remains time-consuming, especially given the ever-increasing scale of model repositories. In this paper, we propose a two-phase (coarse-recall and fine-selection) model selection framework, aiming to enhance the efficiency of selecting a robust model by leveraging the models' training performances on benchmark datasets. Specifically, the coarse-recall phase clusters models showcasing similar training performances on benchmark datasets in an offline manner. A light-weight proxy score is subsequently computed between this model cluster and the target dataset, which serves to recall a significantly smaller subset of potential candidate models in a swift manner. In the following fine-selection phase, the final model is chosen by fine-tuning the recalled models on the target dataset with successive halving. To accelerate the process, the final fine-tuning performance of each potential model is predicted by mining the model's convergence trend on the benchmark datasets, which aids in filtering lower performance models more earlier during fine-tuning. Through extensive experimentation on tasks covering natural language processing and computer vision, it has been demonstrated that the proposed methodology facilitates the selection of a high-performing model at a rate about 3x times faster than conventional baseline methods. Our code is available at https://github.com/plasware/two-phase-selection."}
{"main_page": "https://arxiv.org/abs/2404.00074", "pdf": "https://arxiv.org/pdf/2404.00074", "title": "A finite operator learning technique for mapping the elastic properties  of microstructures to their mechanical deformations", "authors": "Shahed Rezaei, Shirko Faroughi, Mahdi Asgharzadeh, Ali Harandi, Gottfried Laschet, Stefanie Reese, Markus Apel", "subjects": "Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)", "abstract": "To develop faster solvers for governing physical equations in solid mechanics, we introduce a method that parametrically learns the solution to mechanical equilibrium. The introduced method outperforms traditional ones in terms of computational cost while acceptably maintaining accuracy. Moreover, it generalizes and enhances the standard physics-informed neural networks to learn a parametric solution with rather sharp discontinuities. We focus on micromechanics as an example, where the knowledge of the micro-mechanical solution, i.e., deformation and stress fields for a given heterogeneous microstructure, is crucial. The parameter under investigation is the Young modulus distribution within the heterogeneous solid system. Our method, inspired by operator learning and the finite element method, demonstrates the ability to train without relying on data from other numerical solvers. Instead, we leverage ideas from the finite element approach to efficiently set up loss functions algebraically, particularly based on the discretized weak form of the governing equations. Notably, our investigations reveal that physics-based training yields higher accuracy compared to purely data-driven approaches for unseen microstructures. In essence, this method achieves independence from data and enhances accuracy for predictions beyond the training range. The aforementioned observations apply here to heterogeneous elastic microstructures. Comparisons are also made with other well-known operator learning algorithms, such as DeepOnet, to further emphasize the advantages of the newly proposed architecture."}
{"main_page": "https://arxiv.org/abs/2404.00075", "pdf": "https://arxiv.org/pdf/2404.00075", "title": "BEACON: Bayesian Experimental design Acceleration with Conditional  Normalizing flows $-$ a case study in optimal monitor well placement for  CO$_2$ sequestration", "authors": "Rafael Orozco, Abhinav Gahlot, Felix J. Herrmann", "subjects": "Machine Learning (cs.LG); Mathematical Physics (math-ph)", "abstract": "CO$_2$ sequestration is a crucial engineering solution for mitigating climate change. However, the uncertain nature of reservoir properties, necessitates rigorous monitoring of CO$_2$ plumes to prevent risks such as leakage, induced seismicity, or breaching licensed boundaries. To address this, project managers use borehole wells for direct CO$_2$ and pressure monitoring at specific locations. Given the high costs associated with drilling, it is crucial to strategically place a limited number of wells to ensure maximally effective monitoring within budgetary constraints. Our approach for selecting well locations integrates fluid-flow solvers for forecasting plume trajectories with generative neural networks for plume inference uncertainty. Our methodology is extensible to three-dimensional domains and is developed within a Bayesian framework for optimal experimental design, ensuring scalability and mathematical optimality. We use a realistic case study to verify these claims by demonstrating our method's application in a large scale domain and optimal performance as compared to baseline well placement."}
{"main_page": "https://arxiv.org/abs/2404.00076", "pdf": "https://arxiv.org/pdf/2404.00076", "title": "A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping  Attacks", "authors": "Orson Mengara", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Signal Processing (eess.SP)", "abstract": "Audio-based machine learning systems frequently use public or third-party data, which might be inaccurate. This exposes deep neural network (DNN) models trained on such data to potential data poisoning attacks. In this type of assault, attackers can train the DNN model using poisoned data, potentially degrading its performance. Another type of data poisoning attack that is extremely relevant to our investigation is label flipping, in which the attacker manipulates the labels for a subset of data. It has been demonstrated that these assaults may drastically reduce system performance, even for attackers with minimal abilities. In this study, we propose a backdoor attack named 'DirtyFlipping', which uses dirty label techniques, \"label-on-label\", to input triggers (clapping) in the selected data patterns associated with the target class, thereby enabling a stealthy backdoor."}
{"main_page": "https://arxiv.org/abs/2404.00085", "pdf": "https://arxiv.org/pdf/2404.00085", "title": "Bayesian Nonparametrics: An Alternative to Deep Learning", "authors": "Bahman Moraffah", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Bayesian nonparametric models offer a flexible and powerful framework for statistical model selection, enabling the adaptation of model complexity to the intricacies of diverse datasets. This survey intends to delve into the significance of Bayesian nonparametrics, particularly in addressing complex challenges across various domains such as statistics, computer science, and electrical engineering. By elucidating the basic properties and theoretical foundations of these nonparametric models, this survey aims to provide a comprehensive understanding of Bayesian nonparametrics and their relevance in addressing complex problems, particularly in the domain of multi-object tracking. Through this exploration, we uncover the versatility and efficacy of Bayesian nonparametric methodologies, paving the way for innovative solutions to intricate challenges across diverse disciplines."}
{"main_page": "https://arxiv.org/abs/2404.00086", "pdf": "https://arxiv.org/pdf/2404.00086", "title": "DVIS-DAQ: Improving Video Segmentation via Dynamic Anchor Queries", "authors": "Yikang Zhou, Tao Zhang, Shunping JI, Shuicheng Yan, Xiangtai Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Modern video segmentation methods adopt object queries to perform inter-frame association and demonstrate satisfactory performance in tracking continuously appearing objects despite large-scale motion and transient occlusion. However, they all underperform on newly emerging and disappearing objects that are common in the real world because they attempt to model object emergence and disappearance through feature transitions between background and foreground queries that have significant feature gaps. We introduce Dynamic Anchor Queries (DAQ) to shorten the transition gap between the anchor and target queries by dynamically generating anchor queries based on the features of potential candidates. Furthermore, we introduce a query-level object Emergence and Disappearance Simulation (EDS) strategy, which unleashes DAQ's potential without any additional cost. Finally, we combine our proposed DAQ and EDS with DVIS~\\cite{zhang2023dvis} to obtain DVIS-DAQ. Extensive experiments demonstrate that DVIS-DAQ achieves a new state-of-the-art (SOTA) performance on five mainstream video segmentation benchmarks. Code and models are available at \\url{https://github.com/SkyworkAI/DAQ-VS}."}
{"main_page": "https://arxiv.org/abs/2404.00095", "pdf": "https://arxiv.org/pdf/2404.00095", "title": "GDA: Generalized Diffusion for Robust Test-time Adaptation", "authors": "Yun-Yun Tsai, Fu-Chen Chen, Albert Y. C. Chen, Junfeng Yang, Che-Chun Su, Min Sun, Cheng-Hao Kuo", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Machine learning models struggle with generalization when encountering out-of-distribution (OOD) samples with unexpected distribution shifts. For vision tasks, recent studies have shown that test-time adaptation employing diffusion models can achieve state-of-the-art accuracy improvements on OOD samples by generating new samples that align with the model's domain without the need to modify the model's weights. Unfortunately, those studies have primarily focused on pixel-level corruptions, thereby lacking the generalization to adapt to a broader range of OOD types. We introduce Generalized Diffusion Adaptation (GDA), a novel diffusion-based test-time adaptation method robust against diverse OOD types. Specifically, GDA iteratively guides the diffusion by applying a marginal entropy loss derived from the model, in conjunction with style and content preservation losses during the reverse sampling process. In other words, GDA considers the model's output behavior with the semantic information of the samples as a whole, which can reduce ambiguity in downstream tasks during the generation process. Evaluation across various popular model architectures and OOD benchmarks shows that GDA consistently outperforms prior work on diffusion-driven adaptation. Notably, it achieves the highest classification accuracy improvements, ranging from 4.4\\% to 5.02\\% on ImageNet-C and 2.5\\% to 7.4\\% on Rendition, Sketch, and Stylized benchmarks. This performance highlights GDA's generalization to a broader range of OOD benchmarks."}
{"main_page": "https://arxiv.org/abs/2404.00098", "pdf": "https://arxiv.org/pdf/2404.00098", "title": "Sparse Views, Near Light: A Practical Paradigm for Uncalibrated  Point-light Photometric Stereo", "authors": "Mohammed Brahimi, Bjoern Haefner, Zhenzhang Ye, Bastian Goldluecke, Daniel Cremers", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Neural approaches have shown a significant progress on camera-based reconstruction. But they require either a fairly dense sampling of the viewing sphere, or pre-training on an existing dataset, thereby limiting their generalizability. In contrast, photometric stereo (PS) approaches have shown great potential for achieving high-quality reconstruction under sparse viewpoints. Yet, they are impractical because they typically require tedious laboratory conditions, are restricted to dark rooms, and often multi-staged, making them subject to accumulated errors. To address these shortcomings, we propose an end-to-end uncalibrated multi-view PS framework for reconstructing high-resolution shapes acquired from sparse viewpoints in a real-world environment. We relax the dark room assumption, and allow a combination of static ambient lighting and dynamic near LED lighting, thereby enabling easy data capture outside the lab. Experimental validation confirms that it outperforms existing baseline approaches in the regime of sparse viewpoints by a large margin. This allows to bring high-accuracy 3D reconstruction from the dark room to the real world, while maintaining a reasonable data capture complexity."}
{"main_page": "https://arxiv.org/abs/2404.00099", "pdf": "https://arxiv.org/pdf/2404.00099", "title": "Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision  Processes", "authors": "Andrew Bennett, Nathan Kallus, Miruna Oprescu, Wen Sun, Kaiwen Wang", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "abstract": "We study evaluating a policy under best- and worst-case perturbations to a Markov decision process (MDP), given transition observations from the original MDP, whether under the same or different policy. This is an important problem when there is the possibility of a shift between historical and future environments, due to e.g. unmeasured confounding, distributional shift, or an adversarial environment. We propose a perturbation model that can modify transition kernel densities up to a given multiplicative factor or its reciprocal, which extends the classic marginal sensitivity model (MSM) for single time step decision making to infinite-horizon RL. We characterize the sharp bounds on policy value under this model, that is, the tightest possible bounds given by the transition observations from the original MDP, and we study the estimation of these bounds from such transition observations. We develop an estimator with several appealing guarantees: it is semiparametrically efficient, and remains so even when certain necessary nuisance functions such as worst-case Q-functions are estimated at slow nonparametric rates. It is also asymptotically normal, enabling easy statistical inference using Wald confidence intervals. In addition, when certain nuisances are estimated inconsistently we still estimate a valid, albeit possibly not sharp bounds on the policy value. We validate these properties in numeric simulations. The combination of accounting for environment shifts from train to test (robustness), being insensitive to nuisance-function estimation (orthogonality), and accounting for having only finite samples to learn from (inference) together leads to credible and reliable policy evaluation."}
{"main_page": "https://arxiv.org/abs/2404.00103", "pdf": "https://arxiv.org/pdf/2404.00103", "title": "PikeLPN: Mitigating Overlooked Inefficiencies of Low-Precision Neural  Networks", "authors": "Marina Neseem, Conor McCullough, Randy Hsin, Chas Leichner, Shan Li, In Suk Chong, Andrew G. Howard, Lukasz Lew, Sherief Reda, Ville-Mikko Rautio, Daniele Moro", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Low-precision quantization is recognized for its efficacy in neural network optimization. Our analysis reveals that non-quantized elementwise operations which are prevalent in layers such as parameterized activation functions, batch normalization, and quantization scaling dominate the inference cost of low-precision models. These non-quantized elementwise operations are commonly overlooked in SOTA efficiency metrics such as Arithmetic Computation Effort (ACE). In this paper, we propose ACEv2 - an extended version of ACE which offers a better alignment with the inference cost of quantized models and their energy consumption on ML hardware. Moreover, we introduce PikeLPN, a model that addresses these efficiency issues by applying quantization to both elementwise operations and multiply-accumulate operations. In particular, we present a novel quantization technique for batch normalization layers named QuantNorm which allows for quantizing the batch normalization parameters without compromising the model performance. Additionally, we propose applying Double Quantization where the quantization scaling parameters are quantized. Furthermore, we recognize and resolve the issue of distribution mismatch in Separable Convolution layers by introducing Distribution-Heterogeneous Quantization which enables quantizing them to low-precision. PikeLPN achieves Pareto-optimality in efficiency-accuracy trade-off with up to 3X efficiency improvement compared to SOTA low-precision models."}
{"main_page": "https://arxiv.org/abs/2404.00107", "pdf": "https://arxiv.org/pdf/2404.00107", "title": "Robust Ensemble Person Re-Identification via Orthogonal Fusion with  Occlusion Handling", "authors": "Syeda Nyma Ferdous, Xin Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Occlusion remains one of the major challenges in person reidentification (ReID) as a result of the diversity of poses and the variation of appearances. Developing novel architectures to improve the robustness of occlusion-aware person Re-ID requires new insights, especially on low-resolution edge cameras. We propose a deep ensemble model that harnesses both CNN and Transformer architectures to generate robust feature representations. To achieve robust Re-ID without the need to manually label occluded regions, we propose to take an ensemble learning-based approach derived from the analogy between arbitrarily shaped occluded regions and robust feature representation. Using the orthogonality principle, our developed deep CNN model makes use of masked autoencoder (MAE) and global-local feature fusion for robust person identification. Furthermore, we present a part occlusion-aware transformer capable of learning feature space that is robust to occluded regions. Experimental results are reported on several Re-ID datasets to show the effectiveness of our developed ensemble model named orthogonal fusion with occlusion handling (OFOH). Compared to competing methods, the proposed OFOH approach has achieved competent rank-1 and mAP performance."}
{"main_page": "https://arxiv.org/abs/2404.00108", "pdf": "https://arxiv.org/pdf/2404.00108", "title": "Efficient Data-Free Model Stealing with Label Diversity", "authors": "Yiyong Liu, Rui Wen, Michael Backes, Yang Zhang", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Machine learning as a Service (MLaaS) allows users to query the machine learning model in an API manner, which provides an opportunity for users to enjoy the benefits brought by the high-performance model trained on valuable data. This interface boosts the proliferation of machine learning based applications, while on the other hand, it introduces the attack surface for model stealing attacks. Existing model stealing attacks have relaxed their attack assumptions to the data-free setting, while keeping the effectiveness. However, these methods are complex and consist of several components, which obscure the core on which the attack really depends. In this paper, we revisit the model stealing problem from a diversity perspective and demonstrate that keeping the generated data samples more diverse across all the classes is the critical point for improving the attack performance. Based on this conjecture, we provide a simplified attack framework. We empirically signify our conjecture by evaluating the effectiveness of our attack, and experimental results show that our approach is able to achieve comparable or even better performance compared with the state-of-the-art method. Furthermore, benefiting from the absence of redundant components, our method demonstrates its advantages in attack efficiency and query budget."}
{"main_page": "https://arxiv.org/abs/2404.00113", "pdf": "https://arxiv.org/pdf/2404.00113", "title": "Experi\u00eancias, Resultados e Reflex\u00f5es a partir do Gerenciamento de  experimentos no Mundo Real com FANETs e VANTs -- Vers\u00e3o Estendida", "authors": "Bruno Jos\u00e9 Olivieri de Souza, markus Endler", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "In the research on FANETs (Flying Ad-Hoc Networks) and distributed coordination of UAVs (Unmanned Aerial Vehicles), also known as drones, there are many studies that validate their proposals through simulations. Simulations are important, but beyond them, there is also a need for real-world tests to validate the proposals and enhance results. However, field experiments involving drones and FANETs are not trivial, and this work aims to share experiences and results obtained during the construction of a testbed actively used in comparing simulations and field tests."}
{"main_page": "https://arxiv.org/abs/2404.00114", "pdf": "https://arxiv.org/pdf/2404.00114", "title": "Deepfake Sentry: Harnessing Ensemble Intelligence for Resilient  Detection and Generalisation", "authors": "Liviu-Daniel \u015etefan (1), Dan-Cristian Stanciu (1), Mihai Dogariu (1), Mihai Gabriel Constantin (1), Andrei Cosmin Jitaru (1), Bogdan Ionescu (1) ((1) University \"Politehnica\" of Bucharest, Romania)", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advancements in Generative Adversarial Networks (GANs) have enabled photorealistic image generation with high quality. However, the malicious use of such generated media has raised concerns regarding visual misinformation. Although deepfake detection research has demonstrated high accuracy, it is vulnerable to advances in generation techniques and adversarial iterations on detection countermeasures. To address this, we propose a proactive and sustainable deepfake training augmentation solution that introduces artificial fingerprints into models. We achieve this by employing an ensemble learning approach that incorporates a pool of autoencoders that mimic the effect of the artefacts introduced by the deepfake generator models. Experiments on three datasets reveal that our proposed ensemble autoencoder-based data augmentation learning approach offers improvements in terms of generalisation, resistance against basic data perturbations such as noise, blurring, sharpness enhancement, and affine transforms, resilience to commonly used lossy compression algorithms such as JPEG, and enhanced resistance against adversarial attacks."}
{"main_page": "https://arxiv.org/abs/2404.00122", "pdf": "https://arxiv.org/pdf/2404.00122", "title": "AgileFormer: Spatially Agile Transformer UNet for Medical Image  Segmentation", "authors": "Peijie Qiu, Jin Yang, Sayantan Kumar, Soumyendu Sekhar Ghosh, Aristeidis Sotiras", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "In the past decades, deep neural networks, particularly convolutional neural networks, have achieved state-of-the-art performance in a variety of medical image segmentation tasks. Recently, the introduction of the vision transformer (ViT) has significantly altered the landscape of deep segmentation models. There has been a growing focus on ViTs, driven by their excellent performance and scalability. However, we argue that the current design of the vision transformer-based UNet (ViT-UNet) segmentation models may not effectively handle the heterogeneous appearance (e.g., varying shapes and sizes) of objects of interest in medical image segmentation tasks. To tackle this challenge, we present a structured approach to introduce spatially dynamic components to the ViT-UNet. This adaptation enables the model to effectively capture features of target objects with diverse appearances. This is achieved by three main components: \\textbf{(i)} deformable patch embedding; \\textbf{(ii)} spatially dynamic multi-head attention; \\textbf{(iii)} deformable positional encoding. These components were integrated into a novel architecture, termed AgileFormer. AgileFormer is a spatially agile ViT-UNet designed for medical image segmentation. Experiments in three segmentation tasks using publicly available datasets demonstrated the effectiveness of the proposed method. The code is available at \\href{https://github.com/sotiraslab/AgileFormer}{https://github.com/sotiraslab/AgileFormer}."}
{"main_page": "https://arxiv.org/abs/2404.00123", "pdf": "https://arxiv.org/pdf/2404.00123", "title": "SURESTEP: An Uncertainty-Aware Trajectory Optimization Framework to  Enhance Visual Tool Tracking for Robust Surgical Automation", "authors": "Nikhil U. Shinde, Zih-Yun Chiu, Florian Richter, Jason Lim, Yuheng Zhi, Sylvia Herbert, Michael C. Yip", "subjects": "Robotics (cs.RO)", "abstract": "Inaccurate tool localization is one of the main reasons for failures in automating surgical tasks. Imprecise robot kinematics and noisy observations caused by the poor visual acuity of an endoscopic camera make tool tracking challenging. Previous works in surgical automation adopt environment-specific setups or hard-coded strategies instead of explicitly considering motion and observation uncertainty of tool tracking in their policies. In this work, we present SURESTEP, an uncertainty-aware trajectory optimization framework for robust surgical automation. We model the uncertainty of tool tracking with the components motivated by the sources of noise in typical surgical scenes. Using a Gaussian assumption to propagate our uncertainty models through a given tool trajectory, SURESTEP provides a general framework that minimizes the upper bound on the entropy of the final estimated tool distribution. We compare SURESTEP with a baseline method on a real-world suture needle regrasping task under challenging environmental conditions, such as poor lighting and a moving endoscopic camera. The results over 60 regrasps on the da Vinci Research Kit (dVRK) demonstrate that our optimized trajectories significantly outperform the un-optimized baseline."}
{"main_page": "https://arxiv.org/abs/2404.00124", "pdf": "https://arxiv.org/pdf/2404.00124", "title": "Where Are You From? Let Me Guess! Subdialect Recognition of Speeches in  Sorani Kurdish", "authors": "Sana Isam, Hossein Hassani", "subjects": "Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "Classifying Sorani Kurdish subdialects poses a challenge due to the need for publicly available datasets or reliable resources like social media or websites for data collection. We conducted field visits to various cities and villages to address this issue, connecting with native speakers from different age groups, genders, academic backgrounds, and professions. We recorded their voices while engaging in conversations covering diverse topics such as lifestyle, background history, hobbies, interests, vacations, and life lessons. The target area of the research was the Kurdistan Region of Iraq. As a result, we accumulated 29 hours, 16 minutes, and 40 seconds of audio recordings from 107 interviews, constituting an unbalanced dataset encompassing six subdialects. Subsequently, we adapted three deep learning models: ANN, CNN, and RNN-LSTM. We explored various configurations, including different track durations, dataset splitting, and imbalanced dataset handling techniques such as oversampling and undersampling. Two hundred and twenty-five(225) experiments were conducted, and the outcomes were evaluated. The results indicated that the RNN-LSTM outperforms the other methods by achieving an accuracy of 96%. CNN achieved an accuracy of 93%, and ANN 75%. All three models demonstrated improved performance when applied to balanced datasets, primarily when we followed the oversampling approach. Future studies can explore additional future research directions to include other Kurdish dialects."}
{"main_page": "https://arxiv.org/abs/2404.00125", "pdf": "https://arxiv.org/pdf/2404.00125", "title": "Memristor-Based Lightweight Encryption", "authors": "Muhammad Ali Siddiqi, Jan Andr\u00e9s Galvan Hern\u00e1ndez, Anteneh Gebregiorgis, Rajendra Bishnoi, Christos Strydis, Said Hamdioui, Mottaqiallah Taouil", "subjects": "Cryptography and Security (cs.CR); Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)", "abstract": "Next-generation personalized healthcare devices are undergoing extreme miniaturization in order to improve user acceptability. However, such developments make it difficult to incorporate cryptographic primitives using available target technologies since these algorithms are notorious for their energy consumption. Besides, strengthening these schemes against side-channel attacks further adds to the device overheads. Therefore, viable alternatives among emerging technologies are being sought. In this work, we investigate the possibility of using memristors for implementing lightweight encryption. We propose a 40-nm RRAM-based GIFT-cipher implementation using a 1T1R configuration with promising results; it exhibits roughly half the energy consumption of a CMOS-only implementation. More importantly, its non-volatile and reconfigurable substitution boxes offer an energy-efficient protection mechanism against side-channel attacks. The complete cipher takes 0.0034 mm$^2$ of area, and encrypting a 128-bit block consumes a mere 242 pJ."}
{"main_page": "https://arxiv.org/abs/2404.00130", "pdf": "https://arxiv.org/pdf/2404.00130", "title": "FISBe: A real-world benchmark dataset for instance segmentation of  long-range thin filamentous structures", "authors": "Lisa Mais, Peter Hirsch, Claire Managan, Ramya Kandarpa, Josef Lorenz Rumberger, Annika Reinke, Lena Maier-Hein, Gudrun Ihrke, Dagmar Kainmueller", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Instance segmentation of neurons in volumetric light microscopy images of nervous systems enables groundbreaking research in neuroscience by facilitating joint functional and morphological analyses of neural circuits at cellular resolution. Yet said multi-neuron light microscopy data exhibits extremely challenging properties for the task of instance segmentation: Individual neurons have long-ranging, thin filamentous and widely branching morphologies, multiple neurons are tightly inter-weaved, and partial volume effects, uneven illumination and noise inherent to light microscopy severely impede local disentangling as well as long-range tracing of individual neurons. These properties reflect a current key challenge in machine learning research, namely to effectively capture long-range dependencies in the data. While respective methodological research is buzzing, to date methods are typically benchmarked on synthetic datasets. To address this gap, we release the FlyLight Instance Segmentation Benchmark (FISBe) dataset, the first publicly available multi-neuron light microscopy dataset with pixel-wise annotations. In addition, we define a set of instance segmentation metrics for benchmarking that we designed to be meaningful with regard to downstream analyses. Lastly, we provide three baselines to kick off a competition that we envision to both advance the field of machine learning regarding methodology for capturing long-range data dependencies, and facilitate scientific discovery in basic neuroscience."}
{"main_page": "https://arxiv.org/abs/2404.00131", "pdf": "https://arxiv.org/pdf/2404.00131", "title": "Give Text A Chance: Advocating for Equal Consideration for Language and  Visualization", "authors": "Chase Stokes, Marti A. Hearst", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Visualization research tends to de-emphasize consideration of the textual context in which its images are placed. We argue that visualization research should consider textual representations as a primary alternative to visual options when assessing designs, and when assessing designs, equal attention should be given to the construction of the language as to the visualizations. We also call for a consideration of readability when integrating visualizations with written text. In highlighting these points, visualization research would be elevated in efficacy and demonstrate thorough accounting for viewers' needs and responses."}
{"main_page": "https://arxiv.org/abs/2404.00133", "pdf": "https://arxiv.org/pdf/2404.00133", "title": "An Optimization-Based Planner with B-spline Parameterized  Continuous-Time Reference Signals", "authors": "Chuyuan Tao, Sheng Cheng, Yang Zhao, Fanxin Wang, Naira Hovakimyan", "subjects": "Robotics (cs.RO)", "abstract": "For the cascaded planning and control modules implemented for robot navigation, the frequency gap between the planner and controller has received limited attention. In this study, we introduce a novel B-spline parameterized optimization-based planner (BSPOP) designed to address the frequency gap challenge with limited onboard computational power in robots. The proposed planner generates continuous-time control inputs for low-level controllers running at arbitrary frequencies to track. Furthermore, when considering the convex control action sets, BSPOP uses the convex hull property to automatically constrain the continuous-time control inputs within the convex set. Consequently, compared with the discrete-time optimization-based planners, BSPOP reduces the number of decision variables and inequality constraints, which improves computational efficiency as a byproduct. Simulation results demonstrate that our approach can achieve a comparable planning performance to the high-frequency baseline optimization-based planners while demanding less computational power. Both simulation and experiment results show that the proposed method performs better in planning compared with baseline planners in the same frequency."}
{"main_page": "https://arxiv.org/abs/2404.00137", "pdf": "https://arxiv.org/pdf/2404.00137", "title": "Budget-aware Query Tuning: An AutoML Perspective", "authors": "Wentao Wu, Chi Wang", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Modern database systems rely on cost-based query optimizers to come up with good execution plans for input queries. Such query optimizers rely on cost models to estimate the costs of candidate query execution plans. A cost model represents a function from a set of cost units to query execution cost, where each cost unit specifies the unit cost of executing a certain type of query processing operation (such as table scan or join). These cost units are traditionally viewed as constants, whose values only depend on the platform configuration where the database system runs on top of but are invariant for queries processed by the database system. In this paper, we challenge this classic view by thinking of these cost units as variables instead. We show that, by varying the cost-unit values one can obtain query plans that significantly outperform the default query plans returned by the query optimizer when viewing the cost units as constants. We term this cost-unit tuning process \"query tuning\" (QT) and show that it is similar to the well-known hyper-parameter optimization (HPO) problem in AutoML. As a result, any state-of-the-art HPO technologies can be applied to QT. We study the QT problem in the context of anytime tuning, which is desirable in practice by constraining the total time spent on QT within a given budget -- we call this problem budget-aware query tuning. We further extend our study from tuning a single query to tuning a workload with multiple queries, and we call this generalized problem budget-aware workload tuning (WT), which aims for minimizing the execution time of the entire workload. WT is more challenging as one needs to further prioritize individual query tuning within the given time budget. We propose solutions to both QT and WT and experimental evaluation using both benchmark and real workloads demonstrates the efficacy of our proposed solutions."}
{"main_page": "https://arxiv.org/abs/2404.00139", "pdf": "https://arxiv.org/pdf/2404.00139", "title": "Security Risks Concerns of Generative AI in the IoT", "authors": "Honghui Xu, Yingshu Li, Olusesi Balogun, Shaoen Wu, Yue Wang, Zhipeng Cai", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "In an era where the Internet of Things (IoT) intersects increasingly with generative Artificial Intelligence (AI), this article scrutinizes the emergent security risks inherent in this integration. We explore how generative AI drives innovation in IoT and we analyze the potential for data breaches when using generative AI and the misuse of generative AI technologies in IoT ecosystems. These risks not only threaten the privacy and efficiency of IoT systems but also pose broader implications for trust and safety in AI-driven environments. The discussion in this article extends to strategic approaches for mitigating these risks, including the development of robust security protocols, the multi-layered security approaches, and the adoption of AI technological solutions. Through a comprehensive analysis, this article aims to shed light on the critical balance between embracing AI advancements and ensuring stringent security in IoT, providing insights into the future direction of these intertwined technologies."}
{"main_page": "https://arxiv.org/abs/2404.00140", "pdf": "https://arxiv.org/pdf/2404.00140", "title": "Does Faithfulness Conflict with Plausibility? An Empirical Study in  Explainable AI across NLP Tasks", "authors": "Xiaolei Lu, Jianghong Ma", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Explainability algorithms aimed at interpreting decision-making AI systems usually consider balancing two critical dimensions: 1) \\textit{faithfulness}, where explanations accurately reflect the model's inference process. 2) \\textit{plausibility}, where explanations are consistent with domain experts. However, the question arises: do faithfulness and plausibility inherently conflict? In this study, through a comprehensive quantitative comparison between the explanations from the selected explainability methods and expert-level interpretations across three NLP tasks: sentiment analysis, intent detection, and topic labeling, we demonstrate that traditional perturbation-based methods Shapley value and LIME could attain greater faithfulness and plausibility. Our findings suggest that rather than optimizing for one dimension at the expense of the other, we could seek to optimize explainability algorithms with dual objectives to achieve high levels of accuracy and user accessibility in their explanations."}
{"main_page": "https://arxiv.org/abs/2404.00141", "pdf": "https://arxiv.org/pdf/2404.00141", "title": "Classifying Conspiratorial Narratives At Scale: False Alarms and  Erroneous Connections", "authors": "Ahmad Diab, Rr. Nefriana, Yu-Ru Lin", "subjects": "Computation and Language (cs.CL); Social and Information Networks (cs.SI)", "abstract": "Online discussions frequently involve conspiracy theories, which can contribute to the proliferation of belief in them. However, not all discussions surrounding conspiracy theories promote them, as some are intended to debunk them. Existing research has relied on simple proxies or focused on a constrained set of signals to identify conspiracy theories, which limits our understanding of conspiratorial discussions across different topics and online communities. This work establishes a general scheme for classifying discussions related to conspiracy theories based on authors' perspectives on the conspiracy belief, which can be expressed explicitly through narrative elements, such as the agent, action, or objective, or implicitly through references to known theories, such as chemtrails or the New World Order. We leverage human-labeled ground truth to train a BERT-based model for classifying online CTs, which we then compared to the Generative Pre-trained Transformer machine (GPT) for detecting online conspiratorial content. Despite GPT's known strengths in its expressiveness and contextual understanding, our study revealed significant flaws in its logical reasoning, while also demonstrating comparable strengths from our classifiers. We present the first large-scale classification study using posts from the most active conspiracy-related Reddit forums and find that only one-third of the posts are classified as positive. This research sheds light on the potential applications of large language models in tasks demanding nuanced contextual comprehension."}
{"main_page": "https://arxiv.org/abs/2404.00143", "pdf": "https://arxiv.org/pdf/2404.00143", "title": "Accelerating Search-Based Planning for Multi-Robot Manipulation by  Leveraging Online-Generated Experiences", "authors": "Yorai Shaoul, Itamar Mishani, Maxim Likhachev, Jiaoyang Li", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "abstract": "An exciting frontier in robotic manipulation is the use of multiple arms at once. However, planning concurrent motions is a challenging task using current methods. The high-dimensional composite state space renders many well-known motion planning algorithms intractable. Recently, Multi-Agent Path-Finding (MAPF) algorithms have shown promise in discrete 2D domains, providing rigorous guarantees. However, widely used conflict-based methods in MAPF assume an efficient single-agent motion planner. This poses challenges in adapting them to manipulation cases where this assumption does not hold, due to the high dimensionality of configuration spaces and the computational bottlenecks associated with collision checking. To this end, we propose an approach for accelerating conflict-based search algorithms by leveraging their repetitive and incremental nature -- making them tractable for use in complex scenarios involving multi-arm coordination in obstacle-laden environments. We show that our method preserves completeness and bounded sub-optimality guarantees, and demonstrate its practical efficacy through a set of experiments with up to 10 robotic arms."}
{"main_page": "https://arxiv.org/abs/2404.00146", "pdf": "https://arxiv.org/pdf/2404.00146", "title": "Fast OMP for Exact Recovery and Sparse Approximation", "authors": "Huiyuan Yu, Jia He, Maggie Cheng", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)", "abstract": "Orthogonal Matching Pursuit (OMP) has been a powerful method in sparse signal recovery and approximation. However OMP suffers computational issue when the signal has large number of non-zeros. This paper advances OMP in two fronts: it offers a fast algorithm for the orthogonal projection of the input signal at each iteration, and a new selection criterion for making the greedy choice, which reduces the number of iterations it takes to recover the signal. The proposed modifications to OMP directly reduce the computational complexity. Experiment results show significant improvement over the classical OMP in computation time. The paper also provided a sufficient condition for exact recovery under the new greedy choice criterion. For general signals that may not have sparse representations, the paper provides a bound for the approximation error. The approximation error is at the same order as OMP but is obtained within fewer iterations and less time."}
{"main_page": "https://arxiv.org/abs/2404.00149", "pdf": "https://arxiv.org/pdf/2404.00149", "title": "VSRD: Instance-Aware Volumetric Silhouette Rendering for Weakly  Supervised 3D Object Detection", "authors": "Zihua Liu, Hiroki Sakuma, Masatoshi Okutomi", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Monocular 3D object detection poses a significant challenge in 3D scene understanding due to its inherently ill-posed nature in monocular depth estimation. Existing methods heavily rely on supervised learning using abundant 3D labels, typically obtained through expensive and labor-intensive annotation on LiDAR point clouds. To tackle this problem, we propose a novel weakly supervised 3D object detection framework named VSRD (Volumetric Silhouette Rendering for Detection) to train 3D object detectors without any 3D supervision but only weak 2D supervision. VSRD consists of multi-view 3D auto-labeling and subsequent training of monocular 3D object detectors using the pseudo labels generated in the auto-labeling stage. In the auto-labeling stage, we represent the surface of each instance as a signed distance field (SDF) and render its silhouette as an instance mask through our proposed instance-aware volumetric silhouette rendering. To directly optimize the 3D bounding boxes through rendering, we decompose the SDF of each instance into the SDF of a cuboid and the residual distance field (RDF) that represents the residual from the cuboid. This mechanism enables us to optimize the 3D bounding boxes in an end-to-end manner by comparing the rendered instance masks with the ground truth instance masks. The optimized 3D bounding boxes serve as effective training data for 3D object detection. We conduct extensive experiments on the KITTI-360 dataset, demonstrating that our method outperforms the existing weakly supervised 3D object detection methods. The code is available at https://github.com/skmhrk1209/VSRD."}
{"main_page": "https://arxiv.org/abs/2404.00150", "pdf": "https://arxiv.org/pdf/2404.00150", "title": "Winning Without Observing Payoffs: Exploiting Behavioral Biases to Win  Nearly Every Round", "authors": "Avrim Blum, Melissa Dutz", "subjects": "Computer Science and Game Theory (cs.GT)", "abstract": "Gameplay under various forms of uncertainty has been widely studied. Feldman et al. (2010) studied a particularly low-information setting in which one observes the opponent's actions but no payoffs, not even one's own, and introduced an algorithm which guarantees one's payoff nonetheless approaches the minimax optimal value (i.e., zero) in a symmetric zero-sum game. Against an opponent playing a minimax-optimal strategy, approaching the value of the game is the best one can hope to guarantee. However, a wealth of research in behavioral economics shows that people often do not make perfectly rational, optimal decisions. Here we consider whether it is possible to actually win in this setting if the opponent is behaviorally biased. We model several deterministic, biased opponents and show that even without knowing the game matrix in advance or observing any payoffs, it is possible to take advantage of each bias in order to win nearly every round (so long as the game has the property that each action beats and is beaten by at least one other action). We also provide a partial characterization of the kinds of biased strategies that can be exploited to win nearly every round, and provide algorithms for beating some kinds of biased strategies even when we don't know which strategy the opponent uses."}
{"main_page": "https://arxiv.org/abs/2404.00152", "pdf": "https://arxiv.org/pdf/2404.00152", "title": "On-the-fly Definition Augmentation of LLMs for Biomedical NER", "authors": "Monica Munnangi, Sergey Feldman, Byron C Wallace, Silvio Amir, Tom Hope, Aakanksha Naik", "subjects": "Computation and Language (cs.CL)", "abstract": "Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15\\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM performance, allowing them to outperform fine-tuned language models in few-shot settings. To facilitate future research in this direction, we release our code at https://github.com/allenai/beacon."}
{"main_page": "https://arxiv.org/abs/2404.00153", "pdf": "https://arxiv.org/pdf/2404.00153", "title": "Precision game engineering through reshaping strategic payoffs", "authors": "Elie Eshoa (1, 2, 3 and 4), Ali R. Zomorrodi (3 and 4) ((1) Computer Science Department, Harvard John A. Paulson School of Engineering and Applied Sciences, Boston, MA, USA, (2) Harvard Kenneth C. Griffin Graduate School of Arts and Sciences, Cambridge, MA, USA, (3) Mucosal Immunology and Biology Research Center, Pediatrics Department, Massachusetts General Hospital, Boston, MA, USA, (4) Harvard Medical School, Boston, MA, USA)", "subjects": "Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)", "abstract": "Nash equilibrium is a key concept in game theory fundamental for elucidating the equilibrium state of strategic interactions, finding applications in diverse fields such as economics, political science, and biology. However, the Nash equilibrium may not always align with the optimal or desired outcomes within a system. This article introduces a novel game engineering framework that tweaks strategic payoffs within a game to achieve a desired Nash equilibrium while averting undesired ones. Leveraging mixed-integer linear programming, this framework identifies intricate combinations of players and strategies and optimal perturbations to their payoffs that enable the shift from undesirable Nash equilibria to more favorable ones. We demonstrate the effectiveness and scalability of our approach on games of varying complexity, ranging from simple prototype games such as the Prisoner's Dilemma and Snowdrift games with two or more players to complex game configurations with as high as $10^6$ entries in the payoff matrix. These studies showcase the capability of this framework in efficiently identifying the alternative ways of reshaping strategic payoffs to secure desired Nash equilibria and preclude the undesired equilibrium states. Our game engineering framework offers a versatile toolkit for precision strategic decision-making with far-reaching implications across diverse domains."}
{"main_page": "https://arxiv.org/abs/2404.00154", "pdf": "https://arxiv.org/pdf/2404.00154", "title": "Sampling error mitigation through spectrum smoothing in ensemble data  assimilation", "authors": "Bosu Choi, Yoonsang Lee", "subjects": "Numerical Analysis (math.NA)", "abstract": "In data assimilation, an ensemble provides a nonintrusive way to evolve a probability density described by a nonlinear prediction model. Although a large ensemble size is required for statistical accuracy, the ensemble size is typically limited to a small number due to the computational cost of running the prediction model, which leads to a sampling error. Several methods, such as localization, exist to mitigate the sampling error, often requiring problem-dependent fine-tuning and design. This work introduces another sampling error mitigation method using a smoothness constraint in the Fourier space. In particular, this work smoothes out the spectrum of the system to increase the stability and accuracy even under a small ensemble size. The efficacy of the new idea is validated through a suite of stringent test problems, including Lorenz 96 and Kuramoto-Sivashinsky turbulence models."}
{"main_page": "https://arxiv.org/abs/2404.00161", "pdf": "https://arxiv.org/pdf/2404.00161", "title": "Circle Back Next Week: The Effect of Meeting-Free Weeks on Distributed  Workers' Unstructured Time and Attention Negotiation", "authors": "Sharon Ferguson, Michael Massimi", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "While distributed workers rely on scheduled meetings for coordination and collaboration, these meetings can also challenge their ability to focus. Protecting worker focus has been addressed from a technical perspective, but companies are now attempting organizational interventions, such as meeting-free weeks. Recognizing distributed collaboration as a sociotechnical challenge, we first present an interview study with distributed workers participating in meeting-free weeks at an enterprise software company. We identify three orientations workers exhibit during these weeks: Focus, Collaborative, and Time-Bound, each with varying levels and use of unstructured time. These different orientations result in challenges in attention negotiation, which may be suited for technical interventions. This motivated a follow-up study investigating attention negotiation and the compensating mechanisms workers developed during meeting-free weeks. Our framework identified tensions between the attention-getting and attention-delegation strategies. We extend past work to show how workers adapt their virtual collaboration mechanisms in response to organizational interventions"}
{"main_page": "https://arxiv.org/abs/2404.00162", "pdf": "https://arxiv.org/pdf/2404.00162", "title": "Modeling Large-Scale Walking and Cycling Networks: A Machine Learning  Approach Using Mobile Phone and Crowdsourced Data", "authors": "Meead Saberi, Tanapon Lilasathapornkit", "subjects": "Machine Learning (cs.LG); Numerical Analysis (math.NA)", "abstract": "Walking and cycling are known to bring substantial health, environmental, and economic advantages. However, the development of evidence-based active transportation planning and policies has been impeded by significant data limitations, such as biases in crowdsourced data and representativeness issues of mobile phone data. In this study, we develop and apply a machine learning based modeling approach for estimating daily walking and cycling volumes across a large-scale regional network in New South Wales, Australia that includes 188,999 walking links and 114,885 cycling links. The modeling methodology leverages crowdsourced and mobile phone data as well as a range of other datasets on population, land use, topography, climate, etc. The study discusses the unique challenges and limitations related to all three aspects of model training, testing, and inference given the large geographical extent of the modeled networks and relative scarcity of observed walking and cycling count data. The study also proposes a new technique to identify model estimate outliers and to mitigate their impact. Overall, the study provides a valuable resource for transportation modelers, policymakers and urban planners seeking to enhance active transportation infrastructure planning and policies with advanced emerging data-driven modeling methodologies."}
{"main_page": "https://arxiv.org/abs/2404.00163", "pdf": "https://arxiv.org/pdf/2404.00163", "title": "CT respiratory motion synthesis using joint supervised and adversarial  learning", "authors": "Yi-Heng Cao, Vincent Bourbonne, Fran\u00e7ois Lucia, Ulrike Schick, Julien Bert, Vincent Jaouen, Dimitris Visvikis", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Objective: Four-dimensional computed tomography (4DCT) imaging consists in reconstructing a CT acquisition into multiple phases to track internal organ and tumor motion. It is commonly used in radiotherapy treatment planning to establish planning target volumes. However, 4DCT increases protocol complexity, may not align with patient breathing during treatment, and lead to higher radiation delivery. Approach: In this study, we propose a deep synthesis method to generate pseudo respiratory CT phases from static images for motion-aware treatment planning. The model produces patient-specific deformation vector fields (DVFs) by conditioning synthesis on external patient surface-based estimation, mimicking respiratory monitoring devices. A key methodological contribution is to encourage DVF realism through supervised DVF training while using an adversarial term jointly not only on the warped image but also on the magnitude of the DVF itself. This way, we avoid excessive smoothness typically obtained through deep unsupervised learning, and encourage correlations with the respiratory amplitude. Main results: Performance is evaluated using real 4DCT acquisitions with smaller tumor volumes than previously reported. Results demonstrate for the first time that the generated pseudo-respiratory CT phases can capture organ and tumor motion with similar accuracy to repeated 4DCT scans of the same patient. Mean inter-scans tumor center-of-mass distances and Dice similarity coefficients were $1.97$mm and $0.63$, respectively, for real 4DCT phases and $2.35$mm and $0.71$ for synthetic phases, and compares favorably to a state-of-the-art technique (RMSim)."}
{"main_page": "https://arxiv.org/abs/2404.00165", "pdf": "https://arxiv.org/pdf/2404.00165", "title": "Individual Text Corpora Predict Openness, Interests, Knowledge and Level  of Education", "authors": "Markus J. Hofmann, Markus T. Jansen, Christoph Wigbels, Benny Briesemeister, Arthur M. Jacobs", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Here we examine whether the personality dimension of openness to experience can be predicted from the individual google search history. By web scraping, individual text corpora (ICs) were generated from 214 participants with a mean number of 5 million word tokens. We trained word2vec models and used the similarities of each IC to label words, which were derived from a lexical approach of personality. These IC-label-word similarities were utilized as predictive features in neural models. For training and validation, we relied on 179 participants and held out a test sample of 35 participants. A grid search with varying number of predictive features, hidden units and boost factor was performed. As model selection criterion, we used R2 in the validation samples penalized by the absolute R2 difference between training and validation. The selected neural model explained 35% of the openness variance in the test sample, while an ensemble model with the same architecture often provided slightly more stable predictions for intellectual interests, knowledge in humanities and level of education. Finally, a learning curve analysis suggested that around 500 training participants are required for generalizable predictions. We discuss ICs as a complement or replacement of survey-based psychodiagnostics."}
{"main_page": "https://arxiv.org/abs/2404.00166", "pdf": "https://arxiv.org/pdf/2404.00166", "title": "Uncovering Bias in Large Vision-Language Models with Counterfactuals", "authors": "Phillip Howard, Anahita Bhiwandiwalla, Kathleen C. Fraser, Svetlana Kiritchenko", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "With the advent of Large Language Models (LLMs) possessing increasingly impressive capabilities, a number of Large Vision-Language Models (LVLMs) have been proposed to augment LLMs with visual inputs. Such models condition generated text on both an input image and a text prompt, enabling a variety of use cases such as visual question answering and multimodal chat. While prior studies have examined the social biases contained in text generated by LLMs, this topic has been relatively unexplored in LVLMs. Examining social biases in LVLMs is particularly challenging due to the confounding contributions of bias induced by information contained across the text and visual modalities. To address this challenging problem, we conduct a large-scale study of text generated by different LVLMs under counterfactual changes to input images. Specifically, we present LVLMs with identical open-ended text prompts while conditioning on images from different counterfactual sets, where each set contains images which are largely identical in their depiction of a common subject (e.g., a doctor), but vary only in terms of intersectional social attributes (e.g., race and gender). We comprehensively evaluate the text produced by different LVLMs under this counterfactual generation setting and find that social attributes such as race, gender, and physical characteristics depicted in input images can significantly influence toxicity and the generation of competency-associated words."}
{"main_page": "https://arxiv.org/abs/2404.00168", "pdf": "https://arxiv.org/pdf/2404.00168", "title": "Multi-Level Neural Scene Graphs for Dynamic Urban Environments", "authors": "Tobias Fischer, Lorenzo Porzi, Samuel Rota Bul\u00f2, Marc Pollefeys, Peter Kontschieder", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We estimate the radiance field of large-scale dynamic areas from multiple vehicle captures under varying environmental conditions. Previous works in this domain are either restricted to static environments, do not scale to more than a single short video, or struggle to separately represent dynamic object instances. To this end, we present a novel, decomposable radiance field approach for dynamic urban environments. We propose a multi-level neural scene graph representation that scales to thousands of images from dozens of sequences with hundreds of fast-moving objects. To enable efficient training and rendering of our representation, we develop a fast composite ray sampling and rendering scheme. To test our approach in urban driving scenarios, we introduce a new, novel view synthesis benchmark. We show that our approach outperforms prior art by a significant margin on both established and our proposed benchmark while being faster in training and rendering."}
{"main_page": "https://arxiv.org/abs/2404.00171", "pdf": "https://arxiv.org/pdf/2404.00171", "title": "No Risk, No Reward: Towards An Automated Measure of Psychological Safety  from Online Communication", "authors": "Sharon Ferguson, Georgia Van de Zande, Alison Olechowski", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "The data created from virtual communication platforms presents the opportunity to explore automated measures for monitoring team performance. In this work, we explore one important characteristic of successful teams - Psychological Safety - or the belief that a team is safe for interpersonal risk-taking. To move towards an automated measure of this phenomenon, we derive virtual communication characteristics and message keywords related to elements of Psychological Safety from the literature. Using a mixed methods approach, we investigate whether these characteristics are present in the Slack messages from two design teams - one high in Psychological Safety, and one low. We find that some usage characteristics, such as replies, reactions, and user mentions, might be promising metrics to indicate higher levels of Psychological Safety, while simple keyword searches may not be nuanced enough. We present the first step towards the automated detection of this important, yet complex, team characteristic."}
{"main_page": "https://arxiv.org/abs/2404.00172", "pdf": "https://arxiv.org/pdf/2404.00172", "title": "Universal Bovine Identification via Depth Data and Deep Metric Learning", "authors": "Asheesh Sharma, Lucy Randewich, William Andrew, Sion Hannuna, Neill Campbell, Siobhan Mullan, Andrew W. Dowsey, Melvyn Smith, Mark Hansen, Tilo Burghardt", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "This paper proposes and evaluates, for the first time, a top-down (dorsal view), depth-only deep learning system for accurately identifying individual cattle and provides associated code, datasets, and training weights for immediate reproducibility. An increase in herd size skews the cow-to-human ratio at the farm and makes the manual monitoring of individuals more challenging. Therefore, real-time cattle identification is essential for the farms and a crucial step towards precision livestock farming. Underpinned by our previous work, this paper introduces a deep-metric learning method for cattle identification using depth data from an off-the-shelf 3D camera. The method relies on CNN and MLP backbones that learn well-generalised embedding spaces from the body shape to differentiate individuals -- requiring neither species-specific coat patterns nor close-up muzzle prints for operation. The network embeddings are clustered using a simple algorithm such as $k$-NN for highly accurate identification, thus eliminating the need to retrain the network for enrolling new individuals. We evaluate two backbone architectures, ResNet, as previously used to identify Holstein Friesians using RGB images, and PointNet, which is specialised to operate on 3D point clouds. We also present CowDepth2023, a new dataset containing 21,490 synchronised colour-depth image pairs of 99 cows, to evaluate the backbones. Both ResNet and PointNet architectures, which consume depth maps and point clouds, respectively, led to high accuracy that is on par with the coat pattern-based backbone."}
{"main_page": "https://arxiv.org/abs/2404.00173", "pdf": "https://arxiv.org/pdf/2404.00173", "title": "Comparing Hyper-optimized Machine Learning Models for Predicting  Efficiency Degradation in Organic Solar Cells", "authors": "David Valientea, Fernando Rodr\u00edguez-Mas, Juan V. Alegre-Requena, David Dalmau, Juan C. Ferrer", "subjects": "Machine Learning (cs.LG)", "abstract": "This work presents a set of optimal machine learning (ML) models to represent the temporal degradation suffered by the power conversion efficiency (PCE) of polymeric organic solar cells (OSCs) with a multilayer structure ITO/PEDOT:PSS/P3HT:PCBM/Al. To that aim, we generated a database with 996 entries, which includes up to 7 variables regarding both the manufacturing process and environmental conditions for more than 180 days. Then, we relied on a software framework that brings together a conglomeration of automated ML protocols that execute sequentially against our database by simply command-line interface. This easily permits hyper-optimizing and randomizing seeds of the ML models through exhaustive benchmarking so that optimal models are obtained. The accuracy achieved reaches values of the coefficient determination (R2) widely exceeding 0.90, whereas the root mean squared error (RMSE), sum of squared error (SSE), and mean absolute error (MAE)>1% of the target value, the PCE. Additionally, we contribute with validated models able to screen the behavior of OSCs never seen in the database. In that case, R2~0.96-0.97 and RMSE~1%, thus confirming the reliability of the proposal to predict. For comparative purposes, classical Bayesian regression fitting based on non-linear mean squares (LMS) are also presented, which only perform sufficiently for univariate cases of single OSCs. Hence they fail to outperform the breadth of the capabilities shown by the ML models. Finally, thanks to the standardized results offered by the ML framework, we study the dependencies between the variables of the dataset and their implications for the optimal performance and stability of the OSCs. Reproducibility is ensured by a standardized report altogether with the dataset, which are publicly available at Github."}
{"main_page": "https://arxiv.org/abs/2404.00176", "pdf": "https://arxiv.org/pdf/2404.00176", "title": "The LSCD Benchmark: a Testbed for Diachronic Word Meaning Tasks", "authors": "Dominik Schlechtweg, Shafqat Mumtaz Virk, Nikolay Arefyev", "subjects": "Computation and Language (cs.CL)", "abstract": "Lexical Semantic Change Detection (LSCD) is a complex, lemma-level task, which is usually operationalized based on two subsequently applied usage-level tasks: First, Word-in-Context (WiC) labels are derived for pairs of usages. Then, these labels are represented in a graph on which Word Sense Induction (WSI) is applied to derive sense clusters. Finally, LSCD labels are derived by comparing sense clusters over time. This modularity is reflected in most LSCD datasets and models. It also leads to a large heterogeneity in modeling options and task definitions, which is exacerbated by a variety of dataset versions, preprocessing options and evaluation metrics. This heterogeneity makes it difficult to evaluate models under comparable conditions, to choose optimal model combinations or to reproduce results. Hence, we provide a benchmark repository standardizing LSCD evaluation. Through transparent implementation results become easily reproducible and by standardization different components can be freely combined. The repository reflects the task's modularity by allowing model evaluation for WiC, WSI and LSCD. This allows for careful evaluation of increasingly complex model components providing new ways of model optimization."}
{"main_page": "https://arxiv.org/abs/2404.00179", "pdf": "https://arxiv.org/pdf/2404.00179", "title": "Multi-Region Transfer Learning for Segmentation of Crop Field Boundaries  in Satellite Images with Limited Labels", "authors": "Hannah Kerner, Saketh Sundar, Mathan Satish", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "The goal of field boundary delineation is to predict the polygonal boundaries and interiors of individual crop fields in overhead remotely sensed images (e.g., from satellites or drones). Automatic delineation of field boundaries is a necessary task for many real-world use cases in agriculture, such as estimating cultivated area in a region or predicting end-of-season yield in a field. Field boundary delineation can be framed as an instance segmentation problem, but presents unique research challenges compared to traditional computer vision datasets used for instance segmentation. The practical applicability of previous work is also limited by the assumption that a sufficiently-large labeled dataset is available where field boundary delineation models will be applied, which is not the reality for most regions (especially under-resourced regions such as Sub-Saharan Africa). We present an approach for segmentation of crop field boundaries in satellite images in regions lacking labeled data that uses multi-region transfer learning to adapt model weights for the target region. We show that our approach outperforms existing methods and that multi-region transfer learning substantially boosts performance for multiple model architectures. Our implementation and datasets are publicly available to enable use of the approach by end-users and serve as a benchmark for future work."}
{"main_page": "https://arxiv.org/abs/2404.00184", "pdf": "https://arxiv.org/pdf/2404.00184", "title": "Word Ladders: A Mobile Application for Semantic Data Collection", "authors": "Marianna Marcella Bolognesi, Claudia Collacciani, Andrea Ferrari, Francesca Genovese, Tommaso Lamarra, Adele Loia, Giulia Rambelli, Andrea Amelio Ravelli, Caterina Villani", "subjects": "Computation and Language (cs.CL)", "abstract": "Word Ladders is a free mobile application for Android and iOS, developed for collecting linguistic data, specifically lists of words related to each other through semantic relations of categorical inclusion, within the Abstraction project (ERC-2021-STG-101039777). We hereby provide an overview of Word Ladders, explaining its game logic, motivation and expected results and applications to nlp tasks as well as to the investigation of cognitive scientific open questions"}
{"main_page": "https://arxiv.org/abs/2404.00185", "pdf": "https://arxiv.org/pdf/2404.00185", "title": "On Inherent Adversarial Robustness of Active Vision Systems", "authors": "Amitangshu Mukherjee, Timur Ibrayev, Kaushik Roy", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Current Deep Neural Networks are vulnerable to adversarial examples, which alter their predictions by adding carefully crafted noise. Since human eyes are robust to such inputs, it is possible that the vulnerability stems from the standard way of processing inputs in one shot by processing every pixel with the same importance. In contrast, neuroscience suggests that the human vision system can differentiate salient features by (1) switching between multiple fixation points (saccades) and (2) processing the surrounding with a non-uniform external resolution (foveation). In this work, we advocate that the integration of such active vision mechanisms into current deep learning systems can offer robustness benefits. Specifically, we empirically demonstrate the inherent robustness of two active vision methods - GFNet and FALcon - under a black box threat model. By learning and inferencing based on downsampled glimpses obtained from multiple distinct fixation points within an input, we show that these active methods achieve (2-3) times greater robustness compared to a standard passive convolutional network under state-of-the-art adversarial attacks. More importantly, we provide illustrative and interpretable visualization analysis that demonstrates how performing inference from distinct fixation points makes active vision methods less vulnerable to malicious inputs."}
{"main_page": "https://arxiv.org/abs/2404.00186", "pdf": "https://arxiv.org/pdf/2404.00186", "title": "A Sequential Quadratic Programming Approach to the Solution of Open-Loop  Generalized Nash Equilibria for Autonomous Racing", "authors": "Edward L. Zhu, Francesco Borrelli", "subjects": "Robotics (cs.RO)", "abstract": "Dynamic games can be an effective approach for modeling interactive behavior between multiple competitive agents in autonomous racing and they provide a theoretical framework for simultaneous prediction and control in such scenarios. In this work, we propose DG-SQP, a numerical method for the solution of local generalized Nash equilibria (GNE) for open-loop general-sum dynamic games for agents with nonlinear dynamics and constraints. In particular, we formulate a sequential quadratic programming (SQP) approach which requires only the solution of a single convex quadratic program at each iteration. The three key elements of the method are a non-monotonic line search for solving the associated KKT equations, a merit function to handle zero sum costs, and a decaying regularization scheme for SQP step selection. We show that our method achieves linear convergence in the neighborhood of local GNE and demonstrate the effectiveness of the approach in the context of head-to-head car racing, where we show significant improvement in solver success rate when comparing against the state-of-the-art PATH solver for dynamic games. An implementation of our solver can be found at https://github.com/zhu-edward/DGSQP."}
{"main_page": "https://arxiv.org/abs/2404.00188", "pdf": "https://arxiv.org/pdf/2404.00188", "title": "DataAgent: Evaluating Large Language Models' Ability to Answer  Zero-Shot, Natural Language Queries", "authors": "Manit Mishra, Abderrahman Braham, Charles Marsom, Bryan Chung, Gavin Griffin, Dakshesh Sidnerlikar, Chatanya Sarin, Arjun Rajaram", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Conventional processes for analyzing datasets and extracting meaningful information are often time-consuming and laborious. Previous work has identified manual, repetitive coding and data collection as major obstacles that hinder data scientists from undertaking more nuanced labor and high-level projects. To combat this, we evaluated OpenAI's GPT-3.5 as a \"Language Data Scientist\" (LDS) that can extrapolate key findings, including correlations and basic information, from a given dataset. The model was tested on a diverse set of benchmark datasets to evaluate its performance across multiple standards, including data science code-generation based tasks involving libraries such as NumPy, Pandas, Scikit-Learn, and TensorFlow, and was broadly successful in correctly answering a given data science query related to the benchmark dataset. The LDS used various novel prompt engineering techniques to effectively answer a given question, including Chain-of-Thought reinforcement and SayCan prompt engineering. Our findings demonstrate great potential for leveraging Large Language Models for low-level, zero-shot data analysis."}
{"main_page": "https://arxiv.org/abs/2404.00189", "pdf": "https://arxiv.org/pdf/2404.00189", "title": "GPTA: Generative Prompt Tuning Assistant for Synergistic Downstream  Neural Network Enhancement with LLMs", "authors": "Xiao Liu, Jiawei Zhang", "subjects": "Computation and Language (cs.CL)", "abstract": "This study introduces GPTA, a Large Language Model assistance training framework, that enhances the training of downstream task models via prefix prompt. By minimizing data exposure to LLM, the framework addresses the security and legal challenges of applying LLM in downstream task model training. GPTA utilizes a new synergistic training approach, optimizing the downstream models with parameter gradients and LLMs with the novel ``dialogue gradient''. The framework not only demonstrates significant improvements in model performance across six NLP benchmark datasets, but also reduces overfitting in low-resource scenarios effectively. The detailed analyses further validate that our pioneer framework provides a cost-efficient and adaptive method for downstream task model training with LLM support."}
{"main_page": "https://arxiv.org/abs/2404.00190", "pdf": "https://arxiv.org/pdf/2404.00190", "title": "GuaranTEE: Towards Attestable and Private ML with CCA", "authors": "Sandra Siby, Sina Abdollahi, Mohammad Maheri, Marios Kogias, Hamed Haddadi", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Machine-learning (ML) models are increasingly being deployed on edge devices to provide a variety of services. However, their deployment is accompanied by challenges in model privacy and auditability. Model providers want to ensure that (i) their proprietary models are not exposed to third parties; and (ii) be able to get attestations that their genuine models are operating on edge devices in accordance with the service agreement with the user. Existing measures to address these challenges have been hindered by issues such as high overheads and limited capability (processing/secure memory) on edge devices. In this work, we propose GuaranTEE, a framework to provide attestable private machine learning on the edge. GuaranTEE uses Confidential Computing Architecture (CCA), Arm's latest architectural extension that allows for the creation and deployment of dynamic Trusted Execution Environments (TEEs) within which models can be executed. We evaluate CCA's feasibility to deploy ML models by developing, evaluating, and openly releasing a prototype. We also suggest improvements to CCA to facilitate its use in protecting the entire ML deployment pipeline on edge devices."}
{"main_page": "https://arxiv.org/abs/2404.00191", "pdf": "https://arxiv.org/pdf/2404.00191", "title": "Optimal Blackjack Strategy Recommender: A Comprehensive Study on  Computer Vision Integration for Enhanced Gameplay", "authors": "Krishnanshu Gupta, Devon Bolt, Ben Hinchliff", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This research project investigates the application of several computer vision techniques for playing card detection and recognition in the context of the popular casino game, blackjack. The primary objective is to develop a robust system that is capable of detecting and accurately classifying playing cards in real-time, and displaying the optimal move recommendation based on the given image of the current game. The proposed methodology involves using K-Means for image segmentation, card reprojection and feature extraction, training of the KNN classifier using a labeled dataset, and integration of the detection system into a Blackjack Basic Strategy recommendation algorithm. Further, the study aims to observe the effectiveness of this approach in detecting various card designs under different lighting conditions and occlusions. Overall, the project examines the potential benefits of incorporating computer vision techniques, with a specific focus on card detection, into commonly played games aiming to enhance player decision-making and optimize strategic outcomes. The results obtained from our experimental evaluations with models developed under considerable time constraints, highlight the potential for practical implementation in real-world casino environments and across other similarly structured games."}
{"main_page": "https://arxiv.org/abs/2404.00192", "pdf": "https://arxiv.org/pdf/2404.00192", "title": "Tools and Tasks in Sensemaking: A Visual Accessibility Perspective", "authors": "Yichun Zhao, Miguel A. Nacenta", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Our previous interview study explores the needs and uses of diagrammatic information by the Blind and Low Vision (BLV) community, resulting in a framework called the Ladder of Diagram Access. The framework outlines five levels of information access when interacting with a diagram. In this paper, we connect this framework to include the global activity of sensemaking and discuss its (in)accessibility to the BLV demographic. We also discuss the integration of this framework into the sensemaking process and explore the current sensemaking practices and strategies employed by the BLV community, the challenges they face at different levels of the ladder, and potential solutions to enhance inclusivity towards a data-driven workforce."}
{"main_page": "https://arxiv.org/abs/2404.00195", "pdf": "https://arxiv.org/pdf/2404.00195", "title": "Multiple-policy Evaluation via Density Estimation", "authors": "Yilei Chen, Aldo Pacchiano, Ioannis Ch. Paschalidis", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "In this work, we focus on the multiple-policy evaluation problem where we are given a set of $K$ target policies and the goal is to evaluate their performance (the expected total rewards) to an accuracy $\\epsilon$ with probability at least $1-\\delta$. We propose an algorithm named $\\mathrm{CAESAR}$ to address this problem. Our approach is based on computing an approximate optimal offline sampling distribution and using the data sampled from it to perform the simultaneous estimation of the policy values. $\\mathrm{CAESAR}$ consists of two phases. In the first one we produce coarse estimates of the vistation distributions of the target policies at a low order sample complexity rate that scales with $\\tilde{O}(\\frac{1}{\\epsilon})$. In the second phase, we approximate the optimal offline sampling distribution and compute the importance weighting ratios for all target policies by minimizing a step-wise quadratic loss function inspired by the objective in DualDICE. Up to low order and logarithm terms $\\mathrm{CAESAR}$ achieves a sample complexity $\\tilde{O}\\left(\\frac{H^4}{\\epsilon^2}\\sum_{h=1}^H\\max_{k\\in[K]}\\sum_{s,a}\\frac{(d_h^{\\pi^k}(s,a))^2}{\\mu^*_h(s,a)}\\right)$, where $d^{\\pi}$ is the visitation distribution of policy $\\pi$ and $\\mu^*$ is the optimal sampling distribution."}
{"main_page": "https://arxiv.org/abs/2404.00196", "pdf": "https://arxiv.org/pdf/2404.00196", "title": "Combined Static Analysis and Machine Learning Prediction for Application  Debloating", "authors": "Chris Porter, Sharjeel Khan, Kangqi Ni, Santosh Pande", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Software debloating can effectively thwart certain code reuse attacks by reducing attack surfaces to break gadget chains. Approaches based on static analysis enable a reduced set of functions reachable at a callsite for execution by leveraging static properties of the callgraph. This achieves low runtime overhead, but the function set is conservatively computed, negatively affecting reduction. In contrast, approaches based on machine learning (ML) have much better precision and can sharply reduce function sets, leading to significant improvement in attack surface. Nevertheless, mispredictions occur in ML-based approaches. These cause overheads, and worse, there is no clear way to distinguish between mispredictions and actual attacks. In this work, we contend that a software debloating approach that incorporates ML-based predictions at runtime is realistic in a whole application setting, and that it can achieve significant attack surface reductions beyond the state of the art. We develop a framework, Predictive Debloat with Static Guarantees (PDSG). PDSG is fully sound and works on application source code. At runtime it predicts the dynamic callee set emanating from a callsite, and to resolve mispredictions, it employs a lightweight audit based on static invariants of call chains. We deduce the invariants offline and assert that they hold at runtime when there is a misprediction. To the best of our knowledge, it achieves the highest gadget reductions among similar techniques on SPEC CPU 2017, reducing 82.5% of the total gadgets on average. It triggers misprediction checks on only 3.8% of the total predictions invoked at runtime, and it leverages Datalog to verify dynamic call sequences conform to the static call relations. It has an overhead of 8.9%, which makes the scheme attractive for practical deployments."}
{"main_page": "https://arxiv.org/abs/2404.00200", "pdf": "https://arxiv.org/pdf/2404.00200", "title": "Managing power balance and reserve feasibility in the AC unit commitment  problem", "authors": "Robert Parker, Carleton Coffrin", "subjects": "Systems and Control (eess.SY); Optimization and Control (math.OC)", "abstract": "Incorporating the AC power flow equations into unit commitment models has the potential to avoid costly corrective actions required by less accurate power flow approximations. However, research on unit commitment with AC power flow constraints has been limited to a few relatively small test networks. This work investigates large-scale AC unit commitment problems for the day-ahead market and develops decomposition algorithms capable of obtaining high-quality solutions at industry-relevant scales. The results illustrate that a simple algorithm that only seeks to satisfy unit commitment, reserve, and AC power balance constraints can obtain surprisingly high-quality solutions to this AC unit commitment problem. However, a naive strategy that prioritizes reserve feasibility leads to AC infeasibility, motivating the need to design heuristics that can effectively balance reserve and AC feasibility. Finally, this work explores a parallel decomposition strategy that allows the proposed algorithm to obtain feasible solutions on large cases within the two hour time limit required by typical day-ahead market operations."}
{"main_page": "https://arxiv.org/abs/2404.00203", "pdf": "https://arxiv.org/pdf/2404.00203", "title": "A Stackelberg Regret Minimizing Framework for Online Learning in  Newsvendor Pricing Games", "authors": "Larkin Liu, Yuming Rong", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Multiagent Systems (cs.MA)", "abstract": "We introduce the application of online learning in a Stackelberg game pertaining to a system with two learning agents in a dyadic exchange network, consisting of a supplier and retailer, specifically where the parameters of the demand function are unknown. In this game, the supplier is the first-moving leader, and must determine the optimal wholesale price of the product. Subsequently, the retailer who is the follower, must determine both the optimal procurement amount and selling price of the product. In the perfect information setting, this is known as the classical price-setting Newsvendor problem, and we prove the existence of a unique Stackelberg equilibrium when extending this to a two-player pricing game. In the framework of online learning, the parameters of the reward function for both the follower and leader must be learned, under the assumption that the follower will best respond with optimism under uncertainty. A novel algorithm based on contextual linear bandits with a measurable uncertainty set is used to provide a confidence bound on the parameters of the stochastic demand. Consequently, optimal finite time regret bounds on the Stackelberg regret, along with convergence guarantees to an approximate Stackelberg equilibrium, are provided."}
{"main_page": "https://arxiv.org/abs/2404.00204", "pdf": "https://arxiv.org/pdf/2404.00204", "title": "A PPO-based DRL Auto-Tuning Nonlinear PID Drone Controller for Robust  Autonomous Flights", "authors": "Junyang Zhang, Cristian Emanuel Ocampo Rivera, Kyle Tyni, Steven Nguyen", "subjects": "Robotics (cs.RO); Machine Learning (cs.LG); Systems and Control (eess.SY)", "abstract": "This project aims to revolutionize drone flight control by implementing a nonlinear Deep Reinforcement Learning (DRL) agent as a replacement for traditional linear Proportional Integral Derivative (PID) controllers. The primary objective is to seamlessly transition drones between manual and autonomous modes, enhancing responsiveness and stability. We utilize the Proximal Policy Optimization (PPO) reinforcement learning strategy within the Gazebo simulator to train the DRL agent. Adding a $20,000 indoor Vicon tracking system offers <1mm positioning accuracy, which significantly improves autonomous flight precision. To navigate the drone in the shortest collision-free trajectory, we also build a 3 dimensional A* path planner and implement it into the real flight successfully."}
{"main_page": "https://arxiv.org/abs/2404.00205", "pdf": "https://arxiv.org/pdf/2404.00205", "title": "Conceptual and Unbiased Reasoning in Language Models", "authors": "Ben Zhou, Hongming Zhang, Sihao Chen, Dian Yu, Hongwei Wang, Baolin Peng, Dan Roth, Dong Yu", "subjects": "Computation and Language (cs.CL)", "abstract": "Conceptual reasoning, the ability to reason in abstract and high-level perspectives, is key to generalization in human cognition. However, limited study has been done on large language models' capability to perform conceptual reasoning. In this work, we bridge this gap and propose a novel conceptualization framework that forces models to perform conceptual reasoning on abstract questions and generate solutions in a verifiable symbolic space. Using this framework as an analytical tool, we show that existing large language models fall short on conceptual reasoning, dropping 9% to 28% on various benchmarks compared to direct inference methods. We then discuss how models can improve since high-level abstract reasoning is key to unbiased and generalizable decision-making. We propose two techniques to add trustworthy induction signals by generating familiar questions with similar underlying reasoning paths and asking models to perform self-refinement. Experiments show that our proposed techniques improve models' conceptual reasoning performance by 8% to 11%, achieving a more robust reasoning system that relies less on inductive biases."}
{"main_page": "https://arxiv.org/abs/2404.00206", "pdf": "https://arxiv.org/pdf/2404.00206", "title": "Random Reed-Solomon Codes are List Recoverable with Optimal List Size", "authors": "Dean Doron, S. Venkitesh", "subjects": "Information Theory (cs.IT); Computational Complexity (cs.CC); Combinatorics (math.CO)", "abstract": "We prove that Reed-Solomon (RS) codes with random evaluation points are list recoverable up to capacity with optimal output list size, for any input list size. Namely, given an input list size $\\ell$, a designated rate $R$, and any $\\varepsilon > 0$, we show that a random RS code is list recoverable from $1-R-\\varepsilon$ fraction of errors with output list size $L = O(\\ell/\\varepsilon)$, for field size $q=\\exp(\\ell,1/\\varepsilon) \\cdot n^2$. In particular, this shows that random RS codes are list recoverable beyond the ``list recovery Johnson bound''. Such a result was not even known for arbitrary random linear codes. Our technique follows and extends the recent line of work on list decoding of random RS codes, specifically the works of Brakensiek, Gopi, and Makam (STOC 2023), and of Guo and Zhang (FOCS 2023)."}
{"main_page": "https://arxiv.org/abs/2404.00207", "pdf": "https://arxiv.org/pdf/2404.00207", "title": "Causal Inference for Human-Language Model Collaboration", "authors": "Bohan Zhang, Yixin Wang, Paramveer S. Dhillon", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "In this paper, we examine the collaborative dynamics between humans and language models (LMs), where the interactions typically involve LMs proposing text segments and humans editing or responding to these proposals. Productive engagement with LMs in such scenarios necessitates that humans discern effective text-based interaction strategies, such as editing and response styles, from historical human-LM interactions. This objective is inherently causal, driven by the counterfactual `what-if' question: how would the outcome of collaboration change if humans employed a different text editing/refinement strategy? A key challenge in answering this causal inference question is formulating an appropriate causal estimand: the conventional average treatment effect (ATE) estimand is inapplicable to text-based treatments due to their high dimensionality. To address this concern, we introduce a new causal estimand -- Incremental Stylistic Effect (ISE) -- which characterizes the average impact of infinitesimally shifting a text towards a specific style, such as increasing formality. We establish the conditions for the non-parametric identification of ISE. Building on this, we develop CausalCollab, an algorithm designed to estimate the ISE of various interaction strategies in dynamic human-LM collaborations. Our empirical investigations across three distinct human-LM collaboration scenarios reveal that CausalCollab effectively reduces confounding and significantly improves counterfactual estimation over a set of competitive baselines."}
{"main_page": "https://arxiv.org/abs/2404.00208", "pdf": "https://arxiv.org/pdf/2404.00208", "title": "Discrete Natural Evolution Strategies", "authors": "Ahmad Ayaz Amin", "subjects": "Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)", "abstract": "Natural evolution strategies are a class of approximate-gradient black-box optimizers that have been successfully used for continuous parameter spaces. In this paper, we derive NES algorithms for discrete parameter spaces and demonstrate their effectiveness in tasks involving discrete parameters."}
{"main_page": "https://arxiv.org/abs/2404.00209", "pdf": "https://arxiv.org/pdf/2404.00209", "title": "EventGround: Narrative Reasoning by Grounding to Eventuality-centric  Knowledge Graphs", "authors": "Cheng Jiayang, Lin Qiu, Chunkit Chan, Xin Liu, Yangqiu Song, Zheng Zhang", "subjects": "Computation and Language (cs.CL)", "abstract": "Narrative reasoning relies on the understanding of eventualities in story contexts, which requires a wealth of background world knowledge. To help machines leverage such knowledge, existing solutions can be categorized into two groups. Some focus on implicitly modeling eventuality knowledge by pretraining language models (LMs) with eventuality-aware objectives. However, this approach breaks down knowledge structures and lacks interpretability. Others explicitly collect world knowledge of eventualities into structured eventuality-centric knowledge graphs (KGs). However, existing research on leveraging these knowledge sources for free-texts is limited. In this work, we propose an initial comprehensive framework called EventGround, which aims to tackle the problem of grounding free-texts to eventuality-centric KGs for contextualized narrative reasoning. We identify two critical problems in this direction: the event representation and sparsity problems. We provide simple yet effective parsing and partial information extraction methods to tackle these problems. Experimental results demonstrate that our approach consistently outperforms baseline models when combined with graph neural network (GNN) or large language model (LLM) based graph reasoning models. Our framework, incorporating grounded knowledge, achieves state-of-the-art performance while providing interpretable evidence."}
{"main_page": "https://arxiv.org/abs/2404.00210", "pdf": "https://arxiv.org/pdf/2404.00210", "title": "Socially Aware Robot Navigation through Scoring Using Vision-Language  Models", "authors": "Daeun Song, Jing Liang, Amirreza Payandeh, Xuesu Xiao, Dinesh Manocha", "subjects": "Robotics (cs.RO)", "abstract": "We propose VLM-Social-Nav, a novel Vision-Language Model (VLM) based navigation approach to compute a robot's trajectory in human-centered environments. Our goal is to make real-time decisions on robot actions that are socially compliant with human expectations. We utilize a perception model to detect important social entities and prompt a VLM to generate guidance for socially compliant robot behavior. VLM-Social-Nav uses a VLM-based scoring module that computes a cost term that ensures socially appropriate and effective robot actions generated by the underlying planner. Our overall approach reduces reliance on large datasets (for training) and enhances adaptability in decision-making. In practice, it results in improved socially compliant navigation in human-shared environments. We demonstrate and evaluate our system in four different real-world social navigation scenarios with a Turtlebot robot. We observe at least 36.37% improvement in average success rate and 20.00% improvement in average collision rate in the four social navigation scenarios. The user study score shows that VLM-Social-Nav generates the most socially compliant navigation behavior."}
{"main_page": "https://arxiv.org/abs/2404.00211", "pdf": "https://arxiv.org/pdf/2404.00211", "title": "Multi-Conditional Ranking with Large Language Models", "authors": "Pouya Pezeshkpour, Estevam Hruschka", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Utilizing large language models (LLMs) to rank a set of items has become a common approach in recommendation and retrieval systems. Typically, these systems focus on ordering a substantial number of documents in a monotonic order based on a given query. However, real-world scenarios often present a different challenge: ranking a comparatively smaller set of items, but according to a variety of diverse and occasionally conflicting conditions. In this paper, we define and explore the task of multi-conditional ranking by introducing MCRank, a benchmark tailored for assessing multi-conditional ranking across various item types and conditions. Our analysis of LLMs using MCRank indicates a significant decrease in performance as the number and complexity of items and conditions grow. To overcome this limitation, we propose a novel decomposed reasoning method, consisting of EXtracting and Sorting the conditions, and then Iterativly Ranking the items (EXSIR). Our extensive experiments show that this decomposed reasoning method enhances LLMs' performance significantly, achieving up to a 12% improvement over existing LLMs. We also provide a detailed analysis of LLMs performance across various condition categories, and examine the effectiveness of decomposition step. Furthermore, we compare our method with existing approaches such as Chain-of-Thought and an encoder-type ranking model, demonstrating the superiority of our approach and complexity of MCR task. We released our dataset and code."}
{"main_page": "https://arxiv.org/abs/2404.00212", "pdf": "https://arxiv.org/pdf/2404.00212", "title": "Cost-sensitive computational adequacy of higher-order recursion in  synthetic domain theory", "authors": "Yue Niu, Jonathan Sterling, Robert Harper", "subjects": "Programming Languages (cs.PL)", "abstract": "We study a cost-aware programming language for higher-order recursion dubbed $\\textbf{PCF}_\\mathsf{cost}$ in the setting of synthetic domain theory (SDT). Our main contribution relates the denotational cost semantics of $\\textbf{PCF}_\\mathsf{cost}$ to its computational cost semantics, a new kind of dynamic semantics for program execution that serves as a mathematically natural alternative to operational semantics in SDT. In particular we prove an internal, cost-sensitive version of Plotkin's computational adequacy theorem, giving a precise correspondence between the denotational and computational semantics for complete programs at base type. The constructions and proofs of this paper take place in the internal dependent type theory of an SDT topos extended by a phase distinction in the sense of Sterling and Harper. By controlling the interpretation of cost structure via the phase distinction in the denotational semantics, we show that $\\textbf{PCF}_\\mathsf{cost}$ programs also evince a noninterference property of cost and behavior. We verify the axioms of the type theory by means of a model construction based on relative sheaf models of SDT."}
{"main_page": "https://arxiv.org/abs/2404.00213", "pdf": "https://arxiv.org/pdf/2404.00213", "title": "Injecting New Knowledge into Large Language Models via Supervised  Fine-Tuning", "authors": "Nick Mecklenburg, Yiyou Lin, Xiaoxiao Li, Daniel Holstein, Leonardo Nunes, Sara Malvar, Bruno Silva, Ranveer Chandra, Vijay Aski, Pavan Kumar Reddy Yannam, Tolga Aktas", "subjects": "Computation and Language (cs.CL)", "abstract": "In recent years, Large Language Models (LLMs) have shown remarkable performance in generating human-like text, proving to be a valuable asset across various applications. However, adapting these models to incorporate new, out-of-domain knowledge remains a challenge, particularly for facts and events that occur after the model's knowledge cutoff date. This paper investigates the effectiveness of Supervised Fine-Tuning (SFT) as a method for knowledge injection in LLMs, specifically focusing on the domain of recent sporting events. We compare different dataset generation strategies -- token-based and fact-based scaling -- to create training data that helps the model learn new information. Our experiments on GPT-4 demonstrate that while token-based scaling can lead to improvements in Q&A accuracy, it may not provide uniform coverage of new knowledge. Fact-based scaling, on the other hand, offers a more systematic approach to ensure even coverage across all facts. We present a novel dataset generation process that leads to more effective knowledge ingestion through SFT, and our results show considerable performance improvements in Q&A tasks related to out-of-domain knowledge. This study contributes to the understanding of domain adaptation for LLMs and highlights the potential of SFT in enhancing the factuality of LLM responses in specific knowledge domains."}
{"main_page": "https://arxiv.org/abs/2404.00216", "pdf": "https://arxiv.org/pdf/2404.00216", "title": "Is Factuality Decoding a Free Lunch for LLMs? Evaluation on Knowledge  Editing Benchmark", "authors": "Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Xueqi Cheng", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "The rapid development of large language models (LLMs) enables them to convey factual knowledge in a more human-like fashion. Extensive efforts have been made to reduce factual hallucinations by modifying LLMs with factuality decoding. However, they also pose risks of hindering knowledge updates, as they make models overly confident in known facts. In this work, we first revisite the current factuality decoding methods and verified their effectiveness in enhancing factual accuracy. Subsequently, we conduct further evaluation of several strong factuality decoding methods on the knowledge editing benchmark. All these decoding methods significantly diminish the performance of llama2 models compared to their original decoding, with the largest decrease being a staggering 81.3\\%. This further indicates that the current existing decoding methods still cannot perfectly address the factual hallucinations, as they overlook the importance of preserving the flexibility for knowledge editing. Therefore, our work suggests that research into factual alignment should simultaneously focus on the effectiveness of knowledge editing."}
{"main_page": "https://arxiv.org/abs/2404.00217", "pdf": "https://arxiv.org/pdf/2404.00217", "title": "Rationale-based Opinion Summarization", "authors": "Haoyuan Li, Snigdha Chaturvedi", "subjects": "Computation and Language (cs.CL)", "abstract": "Opinion summarization aims to generate concise summaries that present popular opinions of a large group of reviews. However, these summaries can be too generic and lack supporting details. To address these issues, we propose a new paradigm for summarizing reviews, rationale-based opinion summarization. Rationale-based opinion summaries output the representative opinions as well as one or more corresponding rationales. To extract good rationales, we define four desirable properties: relatedness, specificity, popularity, and diversity and present a Gibbs-sampling-based method to extract rationales. Overall, we propose RATION, an unsupervised extractive system that has two components: an Opinion Extractor (to extract representative opinions) and Rationales Extractor (to extract corresponding rationales). We conduct automatic and human evaluations to show that rationales extracted by RATION have the proposed properties and its summaries are more useful than conventional summaries. The implementation of our work is available at https://github.com/leehaoyuan/RATION."}
{"main_page": "https://arxiv.org/abs/2404.00224", "pdf": "https://arxiv.org/pdf/2404.00224", "title": "Classification and Clustering of Sentence-Level Embeddings of Scientific  Articles Generated by Contrastive Learning", "authors": "Gustavo Bartz Guedes, Ana Estela Antunes da Silva", "subjects": "Computation and Language (cs.CL)", "abstract": "Scientific articles are long text documents organized into sections, each describing aspects of the research. Analyzing scientific production has become progressively challenging due to the increase in the number of available articles. Within this scenario, our approach consisted of fine-tuning transformer language models to generate sentence-level embeddings from scientific articles, considering the following labels: background, objective, methods, results, and conclusion. We trained our models on three datasets with contrastive learning. Two datasets are from the article's abstracts in the computer science and medical domains. Also, we introduce PMC-Sents-FULL, a novel dataset of sentences extracted from the full texts of medical articles. We compare the fine-tuned and baseline models in clustering and classification tasks to evaluate our approach. On average, clustering agreement measures values were five times higher. For the classification measures, in the best-case scenario, we had an average improvement in F1-micro of 30.73\\%. Results show that fine-tuning sentence transformers with contrastive learning and using the generated embeddings in downstream tasks is a feasible approach to sentence classification in scientific articles. Our experiment codes are available on GitHub."}
{"main_page": "https://arxiv.org/abs/2404.00225", "pdf": "https://arxiv.org/pdf/2404.00225", "title": "Heterogeneous Contrastive Learning for Foundation Models and Beyond", "authors": "Lecheng Zheng, Baoyu Jing, Zihao Li, Hanghang Tong, Jingrui He", "subjects": "Machine Learning (cs.LG)", "abstract": "In the era of big data and Artificial Intelligence, an emerging paradigm is to utilize contrastive self-supervised learning to model large-scale heterogeneous data. Many existing foundation models benefit from the generalization capability of contrastive self-supervised learning by learning compact and high-quality representations without relying on any label information. Amidst the explosive advancements in foundation models across multiple domains, including natural language processing and computer vision, a thorough survey on heterogeneous contrastive learning for the foundation model is urgently needed. In response, this survey critically evaluates the current landscape of heterogeneous contrastive learning for foundation models, highlighting the open challenges and future trends of contrastive learning. In particular, we first present how the recent advanced contrastive learning-based methods deal with view heterogeneity and how contrastive learning is applied to train and fine-tune the multi-view foundation models. Then, we move to contrastive learning methods for task heterogeneity, including pretraining tasks and downstream tasks, and show how different tasks are combined with contrastive learning loss for different purposes. Finally, we conclude this survey by discussing the open challenges and shedding light on the future directions of contrastive learning."}
{"main_page": "https://arxiv.org/abs/2404.00226", "pdf": "https://arxiv.org/pdf/2404.00226", "title": "Design as Desired: Utilizing Visual Question Answering for Multimodal  Pre-training", "authors": "Tongkun Su, Jun Li, Xi Zhang, Haibo Jin, Hao Chen, Qiong Wang, Faqin Lv, Baoliang Zhao, Yin Hu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Multimodal pre-training demonstrates its potential in the medical domain, which learns medical visual representations from paired medical reports. However, many pre-training tasks require extra annotations from clinicians, and most of them fail to explicitly guide the model to learn the desired features of different pathologies. To the best of our knowledge, we are the first to utilize Visual Question Answering (VQA) for multimodal pre-training to guide the framework focusing on targeted pathological features. In this work, we leverage descriptions in medical reports to design multi-granular question-answer pairs associated with different diseases, which assist the framework in pre-training without requiring extra annotations from experts. We also propose a novel pre-training framework with a quasi-textual feature transformer, a module designed to transform visual features into a quasi-textual space closer to the textual domain via a contrastive learning strategy. This narrows the vision-language gap and facilitates modality alignment. Our framework is applied to four downstream tasks: report generation, classification, segmentation, and detection across five datasets. Extensive experiments demonstrate the superiority of our framework compared to other state-of-the-art methods. Our code will be released upon acceptance."}
{"main_page": "https://arxiv.org/abs/2404.00227", "pdf": "https://arxiv.org/pdf/2404.00227", "title": "A Survey of using Large Language Models for Generating Infrastructure as  Code", "authors": "Kalahasti Ganesh Srivatsa, Sabyasachi Mukhopadhyay, Ganesh Katrapati, Manish Shrivastava", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL)", "abstract": "Infrastructure as Code (IaC) is a revolutionary approach which has gained significant prominence in the Industry. IaC manages and provisions IT infrastructure using machine-readable code by enabling automation, consistency across the environments, reproducibility, version control, error reduction and enhancement in scalability. However, IaC orchestration is often a painstaking effort which requires specialised skills as well as a lot of manual effort. Automation of IaC is a necessity in the present conditions of the Industry and in this survey, we study the feasibility of applying Large Language Models (LLM) to address this problem. LLMs are large neural network-based models which have demonstrated significant language processing abilities and shown to be capable of following a range of instructions within a broad scope. Recently, they have also been adapted for code understanding and generation tasks successfully, which makes them a promising choice for the automatic generation of IaC configurations. In this survey, we delve into the details of IaC, usage of IaC in different platforms, their challenges, LLMs in terms of code-generation aspects and the importance of LLMs in IaC along with our own experiments. Finally, we conclude by presenting the challenges in this area and highlighting the scope for future research."}
{"main_page": "https://arxiv.org/abs/2404.00228", "pdf": "https://arxiv.org/pdf/2404.00228", "title": "InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning", "authors": "Yan-Shuo Liang, Wu-Jun Li", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Continual learning requires the model to learn multiple tasks sequentially. In continual learning, the model should possess the ability to maintain its performance on old tasks (stability) and the ability to adapt to new tasks continuously (plasticity). Recently, parameter-efficient fine-tuning (PEFT), which involves freezing a pre-trained model and injecting a small number of learnable parameters to adapt to downstream tasks, has gained increasing popularity in continual learning. Although existing continual learning methods based on PEFT have demonstrated superior performance compared to those not based on PEFT, most of them do not consider how to eliminate the interference of the new task on the old tasks, which inhibits the model from making a good trade-off between stability and plasticity. In this work, we propose a new PEFT method, called interference-free low-rank adaptation (InfLoRA), for continual learning. InfLoRA injects a small number of parameters to reparameterize the pre-trained weights and shows that fine-tuning these injected parameters is equivalent to fine-tuning the pre-trained weights within a subspace. Furthermore, InfLoRA designs this subspace to eliminate the interference of the new task on the old tasks, making a good trade-off between stability and plasticity. Experimental results show that InfLoRA outperforms existing state-of-the-art continual learning methods on multiple datasets."}
{"main_page": "https://arxiv.org/abs/2404.00230", "pdf": "https://arxiv.org/pdf/2404.00230", "title": "Latent Watermark: Inject and Detect Watermarks in Latent Diffusion Space", "authors": "Zheling Meng, Bo Peng, Jing Dong", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Watermarking is a tool for actively identifying and attributing the images generated by latent diffusion models. Existing methods face the dilemma of watermark robustness and image quality. The reason for this dilemma is that watermark detection is performed in pixel space, implying an intrinsic link between image quality and watermark robustness. In this paper, we highlight that an effective solution to the problem is to both inject and detect watermarks in latent space, and propose Latent Watermark (LW) with a progressive training strategy. Experiments show that compared to the recently proposed methods such as StegaStamp, StableSignature, RoSteALS and TreeRing, LW not only surpasses them in terms of robustness but also offers superior image quality. When we inject 64-bit messages, LW can achieve an identification performance close to 100% and an attribution performance above 97% under 9 single-attack scenarios and one all-attack scenario. Our code will be available on GitHub."}
{"main_page": "https://arxiv.org/abs/2404.00231", "pdf": "https://arxiv.org/pdf/2404.00231", "title": "Attention-based Shape-Deformation Networks for Artifact-Free Geometry  Reconstruction of Lumbar Spine from MR Images", "authors": "Linchen Qian, Jiasong Chen, Linhai Ma, Timur Urakov, Weiyong Gu, Liang Liang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Lumbar disc degeneration, a progressive structural wear and tear of lumbar intervertebral disc, is regarded as an essential role on low back pain, a significant global health concern. Automated lumbar spine geometry reconstruction from MR images will enable fast measurement of medical parameters to evaluate the lumbar status, in order to determine a suitable treatment. Existing image segmentation-based techniques often generate erroneous segments or unstructured point clouds, unsuitable for medical parameter measurement. In this work, we present TransDeformer: a novel attention-based deep learning approach that reconstructs the contours of the lumbar spine with high spatial accuracy and mesh correspondence across patients, and we also present a variant of TransDeformer for error estimation. Specially, we devise new attention modules with a new attention formula, which integrates image features and tokenized contour features to predict the displacements of the points on a shape template without the need for image segmentation. The deformed template reveals the lumbar spine geometry in the input image. We develop a multi-stage training strategy to enhance model robustness with respect to template initialization. Experiment results show that our TransDeformer generates artifact-free geometry outputs, and its variant predicts the error of a reconstructed geometry. Our code is available at https://github.com/linchenq/TransDeformer-Mesh."}
{"main_page": "https://arxiv.org/abs/2404.00232", "pdf": "https://arxiv.org/pdf/2404.00232", "title": "Efficient Automatic Tuning for Data-driven Model Predictive Control via  Meta-Learning", "authors": "Baoyu Li, William Edwards, Kris Hauser", "subjects": "Robotics (cs.RO); Machine Learning (cs.LG)", "abstract": "AutoMPC is a Python package that automates and optimizes data-driven model predictive control. However, it can be computationally expensive and unstable when exploring large search spaces using pure Bayesian Optimization (BO). To address these issues, this paper proposes to employ a meta-learning approach called Portfolio that improves AutoMPC's efficiency and stability by warmstarting BO. Portfolio optimizes initial designs for BO using a diverse set of configurations from previous tasks and stabilizes the tuning process by fixing initial configurations instead of selecting them randomly. Experimental results demonstrate that Portfolio outperforms the pure BO in finding desirable solutions for AutoMPC within limited computational resources on 11 nonlinear control simulation benchmarks and 1 physical underwater soft robot dataset."}
{"main_page": "https://arxiv.org/abs/2404.00234", "pdf": "https://arxiv.org/pdf/2404.00234", "title": "Grid Diffusion Models for Text-to-Video Generation", "authors": "Taegyeong Lee, Soyeong Kwon, Taehwan Kim", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advances in the diffusion models have significantly improved text-to-image generation. However, generating videos from text is a more challenging task than generating images from text, due to the much larger dataset and higher computational cost required. Most existing video generation methods use either a 3D U-Net architecture that considers the temporal dimension or autoregressive generation. These methods require large datasets and are limited in terms of computational costs compared to text-to-image generation. To tackle these challenges, we propose a simple but effective novel grid diffusion for text-to-video generation without temporal dimension in architecture and a large text-video paired dataset. We can generate a high-quality video using a fixed amount of GPU memory regardless of the number of frames by representing the video as a grid image. Additionally, since our method reduces the dimensions of the video to the dimensions of the image, various image-based methods can be applied to videos, such as text-guided video manipulation from image manipulation. Our proposed method outperforms the existing methods in both quantitative and qualitative evaluations, demonstrating the suitability of our model for real-world video generation."}
{"main_page": "https://arxiv.org/abs/2404.00235", "pdf": "https://arxiv.org/pdf/2404.00235", "title": "Information Security and Privacy in the Digital World: Some Selected  Topics", "authors": "Jaydip Sen, Joceli Mayer, Subhasis Dasgupta, Subrata Nandi, Srinivasan Krishnaswamy, Pinaki Mitra, Mahendra Pratap Singh, Naga Prasanthi Kundeti, Chandra Sekhara Rao MVP, Sudha Sree Chekuri, Seshu Babu Pallapothu, Preethi Nanjundan, Jossy P. George, Abdelhadi El Allahi, Ilham Morino, Salma AIT Oussous, Siham Beloualid, Ahmed Tamtaoui, Abderrahim Bajit", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "In the era of generative artificial intelligence and the Internet of Things, while there is explosive growth in the volume of data and the associated need for processing, analysis, and storage, several new challenges are faced in identifying spurious and fake information and protecting the privacy of sensitive data. This has led to an increasing demand for more robust and resilient schemes for authentication, integrity protection, encryption, non-repudiation, and privacy-preservation of data. The chapters in this book present some of the state-of-the-art research works in the field of cryptography and security in computing and communications."}
{"main_page": "https://arxiv.org/abs/2404.00236", "pdf": "https://arxiv.org/pdf/2404.00236", "title": "Enhancing Content-based Recommendation via Large Language Model", "authors": "Wentao Xu, Qianqian Xie, Shuo Yang, Jiangxia Cao, Shuchao Pang", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "abstract": "In real-world applications, users express different behaviors when they interact with different items, including implicit click/like interactions, and explicit comments/reviews interactions. Nevertheless, almost all recommender works are focused on how to describe user preferences by the implicit click/like interactions, to find the synergy of people. For the content-based explicit comments/reviews interactions, some works attempt to utilize them to mine the semantic knowledge to enhance recommender models. However, they still neglect the following two points: (1) The content semantic is a universal world knowledge; how do we extract the multi-aspect semantic information to empower different domains? (2) The user/item ID feature is a fundamental element for recommender models; how do we align the ID and content semantic feature space? In this paper, we propose a `plugin' semantic knowledge transferring method \\textbf{LoID}, which includes two major components: (1) LoRA-based large language model pretraining to extract multi-aspect semantic information; (2) ID-based contrastive objective to align their feature spaces. We conduct extensive experiments with SOTA baselines on real-world datasets, the detailed results demonstrating significant improvements of our method LoID."}
{"main_page": "https://arxiv.org/abs/2404.00237", "pdf": "https://arxiv.org/pdf/2404.00237", "title": "Joint Pedestrian Trajectory Prediction through Posterior Sampling", "authors": "Haotian Lin, Yixiao Wang, Mingxiao Huo, Chensheng Peng, Zhiyuan Liu, Masayoshi Tomizuka", "subjects": "Robotics (cs.RO)", "abstract": "Joint pedestrian trajectory prediction has long grappled with the inherent unpredictability of human behaviors. Recent investigations employing variants of conditional diffusion models in trajectory prediction have exhibited notable success. Nevertheless, the heavy dependence on accurate historical data results in their vulnerability to noise disturbances and data incompleteness. To improve the robustness and reliability, we introduce the Guided Full Trajectory Diffuser (GFTD), a novel diffusion model framework that captures the joint full (historical and future) trajectory distribution. By learning from the full trajectory, GFTD can recover the noisy and missing data, hence improving the robustness. In addition, GFTD can adapt to data imperfections without additional training requirements, leveraging posterior sampling for reliable prediction and controllable generation. Our approach not only simplifies the prediction process but also enhances generalizability in scenarios with noise and incomplete inputs. Through rigorous experimental evaluation, GFTD exhibits superior performance in both trajectory prediction and controllable generation."}
{"main_page": "https://arxiv.org/abs/2404.00242", "pdf": "https://arxiv.org/pdf/2404.00242", "title": "DeFT: Flash Tree-attention with IO-Awareness for Efficient  Tree-search-based LLM Inference", "authors": "Jinwei Yao, Kaiqi Chen, Kexun Zhang, Jiaxuan You, Binhang Yuan, Zeke Wang, Tao Lin", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Decoding using tree search can greatly enhance the inference quality for transformer-based Large Language Models (LLMs). Depending on the guidance signal, it searches for the best path from root to leaf in the tree by forming LLM outputs to improve controllability, reasoning ability, alignment, et cetera. However, current tree decoding strategies and their inference systems do not suit each other well due to redundancy in computation, memory footprints, and memory access, resulting in inefficient inference. To address this issue, we propose DeFT, an IO-aware tree attention algorithm that maintains memory-efficient attention calculation with low memory footprints in two stages: (1) QKV Preparation: we propose a KV-Guided Tree Split strategy to group QKV wisely for high utilization of GPUs and reduction of memory reads/writes for the KV cache between GPU global memory and on-chip shared memory as much as possible; (2) Attention Calculation: we calculate partial attention of each QKV groups in a fused kernel then apply a Tree-topology-aware Global Reduction strategy to get final attention. Thanks to a reduction in KV cache IO by 3.6-4.5$\\times$, along with an additional reduction in IO for $\\mathbf{Q} \\mathbf{K}^\\top$ and Softmax equivalent to 25% of the total KV cache IO, DeFT can achieve a speedup of 1.7-2.4$\\times$ in end-to-end latency across two practical reasoning tasks over the SOTA attention algorithms."}
{"main_page": "https://arxiv.org/abs/2404.00243", "pdf": "https://arxiv.org/pdf/2404.00243", "title": "DSFNet: Learning Disentangled Scenario Factorization for Multi-Scenario  Route Ranking", "authors": "Jiahao Yu, Yihai Duan, Longfei Xu, Chao Chen, Shuliang Liu, Li Chen, Kaikui Liu, Fan Yang, Ning Guo", "subjects": "Information Retrieval (cs.IR)", "abstract": "Multi-scenario route ranking (MSRR) is crucial in many industrial mapping systems. However, the industrial community mainly adopts interactive interfaces to encourage users to select pre-defined scenarios, which may hinder the downstream ranking performance. In addition, in the academic community, the multi-scenario ranking works only come from other fields, and there are no works specifically focusing on route data due to lacking a publicly available MSRR dataset. Moreover, all the existing multi-scenario works still fail to address the three specific challenges of MSRR simultaneously, i.e. explosion of scenario number, high entanglement, and high-capacity demand. Different from the prior, to address MSRR, our key idea is to factorize the complicated scenario in route ranking into several disentangled factor scenario patterns. Accordingly, we propose a novel method, Disentangled Scenario Factorization Network (DSFNet), which flexibly composes scenario-dependent parameters based on a high-capacity multi-factor-scenario-branch structure. Then, a novel regularization is proposed to induce the disentanglement of factor scenarios. Furthermore, two extra novel techniques, i.e. scenario-aware batch normalization and scenario-aware feature filtering, are developed to improve the network awareness of scenario representation. Additionally, to facilitate MSRR research in the academic community, we propose MSDR, the first large-scale publicly available annotated industrial Multi-Scenario Driving Route dataset. Comprehensive experimental results demonstrate the superiority of our DSFNet, which has been successfully deployed in AMap to serve the major online traffic."}
{"main_page": "https://arxiv.org/abs/2404.00245", "pdf": "https://arxiv.org/pdf/2404.00245", "title": "Aligning Large Language Models with Recommendation Knowledge", "authors": "Yuwei Cao, Nikhil Mehta, Xinyang Yi, Raghunandan Keshavan, Lukasz Heldt, Lichan Hong, Ed H. Chi, Maheswaran Sathiamoorthy", "subjects": "Information Retrieval (cs.IR)", "abstract": "Large language models (LLMs) have recently been used as backbones for recommender systems. However, their performance often lags behind conventional methods in standard tasks like retrieval. We attribute this to a mismatch between LLMs' knowledge and the knowledge crucial for effective recommendations. While LLMs excel at natural language reasoning, they cannot model complex user-item interactions inherent in recommendation tasks. We propose bridging the knowledge gap and equipping LLMs with recommendation-specific knowledge to address this. Operations such as Masked Item Modeling (MIM) and Bayesian Personalized Ranking (BPR) have found success in conventional recommender systems. Inspired by this, we simulate these operations through natural language to generate auxiliary-task data samples that encode item correlations and user preferences. Fine-tuning LLMs on such auxiliary-task data samples and incorporating more informative recommendation-task data samples facilitates the injection of recommendation-specific knowledge into LLMs. Extensive experiments across retrieval, ranking, and rating prediction tasks on LLMs such as FLAN-T5-Base and FLAN-T5-XL show the effectiveness of our technique in domains such as Amazon Toys & Games, Beauty, and Sports & Outdoors. Notably, our method outperforms conventional and LLM-based baselines, including the current SOTA, by significant margins in retrieval, showcasing its potential for enhancing recommendation quality."}
{"main_page": "https://arxiv.org/abs/2404.00246", "pdf": "https://arxiv.org/pdf/2404.00246", "title": "Your Co-Workers Matter: Evaluating Collaborative Capabilities of  Language Models in Blocks World", "authors": "Guande Wu, Chen Zhao, Claudio Silva, He He", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "abstract": "Language agents that interact with the world on their own have great potential for automating digital tasks. While large language model (LLM) agents have made progress in understanding and executing tasks such as textual games and webpage control, many real-world tasks also require collaboration with humans or other LLMs in equal roles, which involves intent understanding, task coordination, and communication. To test LLM's ability to collaborate, we design a blocks-world environment, where two agents, each having unique goals and skills, build a target structure together. To complete the goals, they can act in the world and communicate in natural language. Under this environment, we design increasingly challenging settings to evaluate different collaboration perspectives, from independent to more complex, dependent tasks. We further adopt chain-of-thought prompts that include intermediate reasoning steps to model the partner's state and identify and correct execution errors. Both human-machine and machine-machine experiments show that LLM agents have strong grounding capacities, and our approach significantly improves the evaluation metric."}
{"main_page": "https://arxiv.org/abs/2404.00247", "pdf": "https://arxiv.org/pdf/2404.00247", "title": "Facilitating Reinforcement Learning for Process Control Using Transfer  Learning: Perspectives", "authors": "Runze Lin, Junghui Chen, Lei Xie, Hongye Su, Biao Huang", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "This paper provides insights into deep reinforcement learning (DRL) for process control from the perspective of transfer learning. We analyze the challenges of applying DRL in the field of process industries and the necessity of introducing transfer learning. Furthermore, recommendations and prospects are provided for future research directions on how transfer learning can be integrated with DRL to empower process control."}
{"main_page": "https://arxiv.org/abs/2404.00248", "pdf": "https://arxiv.org/pdf/2404.00248", "title": "Numerical Simulations for Fractional Differential Equations of Higher  Order and a Wright-Type Transformation", "authors": "M. Nacianceno, T. Oraby, H. Rodrigo, Y. Sepulveda, J. Sifuentes, E. Suazo, T. Stuck, J. Williams", "subjects": "Numerical Analysis (math.NA); Mathematical Physics (math-ph)", "abstract": "In this work, a new relationship is established between the solutions of higher fractional differential equations and a Wright-type transformation. Solutions could be interpreted as expected values of functions in a random time process. As applications, we solve the fractional beam equation, fractional electric circuits with special functions as external sources, and derive dAlemberts formula for the fractional wave equation. Due to this relationship, we present two methods for simulating solutions of fractional differential equations. The two approaches use the interpretation of the Caputo derivative of a function as a Wright-type transformation of the higher derivative of the function. In the first approach, we use the Runge-Kutta method of hybrid orders 4 and 5 to solve ordinary differential equations combined with the Monte Carlo integration to conduct the Wrighttype transformation. The second method uses a feedforward neural network to simulate the fractional differential equation."}
{"main_page": "https://arxiv.org/abs/2404.00251", "pdf": "https://arxiv.org/pdf/2404.00251", "title": "Approximation of a Pareto Set Segment Using a Linear Model with Sharing  Variables", "authors": "Ping Guo, Qingfu Zhang, Xi Lin", "subjects": "Neural and Evolutionary Computing (cs.NE)", "abstract": "In many real-world applications, the Pareto Set (PS) of a continuous multiobjective optimization problem can be a piecewise continuous manifold. A decision maker may want to find a solution set that approximates a small part of the PS and requires the solutions in this set share some similarities. This paper makes a first attempt to address this issue. We first develop a performance metric that considers both optimality and variable sharing. Then we design an algorithm for finding the model that minimizes the metric to meet the user's requirements. Experimental results illustrate that we can obtain a linear model that approximates the mapping from the preference vectors to solutions in a local area well."}
{"main_page": "https://arxiv.org/abs/2404.00254", "pdf": "https://arxiv.org/pdf/2404.00254", "title": "Clustering for Protein Representation Learning", "authors": "Ruijie Quan, Wenguan Wang, Fan Ma, Hehe Fan, Yi Yang", "subjects": "Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE); Biomolecules (q-bio.BM); Quantitative Methods (q-bio.QM)", "abstract": "Protein representation learning is a challenging task that aims to capture the structure and function of proteins from their amino acid sequences. Previous methods largely ignored the fact that not all amino acids are equally important for protein folding and activity. In this article, we propose a neural clustering framework that can automatically discover the critical components of a protein by considering both its primary and tertiary structure information. Our framework treats a protein as a graph, where each node represents an amino acid and each edge represents a spatial or sequential connection between amino acids. We then apply an iterative clustering strategy to group the nodes into clusters based on their 1D and 3D positions and assign scores to each cluster. We select the highest-scoring clusters and use their medoid nodes for the next iteration of clustering, until we obtain a hierarchical and informative representation of the protein. We evaluate on four protein-related tasks: protein fold classification, enzyme reaction classification, gene ontology term prediction, and enzyme commission number prediction. Experimental results demonstrate that our method achieves state-of-the-art performance."}
{"main_page": "https://arxiv.org/abs/2404.00255", "pdf": "https://arxiv.org/pdf/2404.00255", "title": "Geometric mean for T-positive definite tensors and associated Riemannian  geometry", "authors": "Jeong-Hoon Ju, Taehyeong Kim, Yeongrak Kim, Hayoung Choi", "subjects": "Numerical Analysis (math.NA); Differential Geometry (math.DG); Functional Analysis (math.FA)", "abstract": "In this paper, we generalize the geometric mean of two positive definite matrices to that of third-order tensors using the notion of T-product. Specifically, we define the geometric mean of two T-positive definite tensors and verify several properties that \"mean\" should satisfy including the idempotence and the commutative property, and so on. Moreover, it is shown that the geometric mean is a unique T-positive definite solution of an algebraic Riccati tensor equation and can be expressed as solutions of algebraic Riccati matrix equations. In addition, we investigate the Riemannian manifold associated with the geometric mean for T-positive definite tensors, considering it as a totally geodesic embedded submanifold of the Riemannian manifold associated with the case of matrices. It is particularly shown that the geometric mean of two T-positive definite tensors is the midpoint of a unique geodesic joining the tensors, and the manifold is a Cartan-Hadamard-Riemannian manifold."}
{"main_page": "https://arxiv.org/abs/2404.00257", "pdf": "https://arxiv.org/pdf/2404.00257", "title": "YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel  Class Discovery", "authors": "Qian Wan, Xiang Xiang, Qinhao Zhou", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)", "abstract": "Because of its use in practice, open-world object detection (OWOD) has gotten a lot of attention recently. The challenge is how can a model detect novel classes and then incrementally learn them without forgetting previously known classes. Previous approaches hinge on strongly-supervised or weakly-supervised novel-class data for novel-class detection, which may not apply to real applications. We construct a new benchmark that novel classes are only encountered at the inference stage. And we propose a new OWOD detector YOLOOC, based on the YOLO architecture yet for the Open-Class setup. We introduce label smoothing to prevent the detector from over-confidently mapping novel classes to known classes and to discover novel classes. Extensive experiments conducted on our more realistic setup demonstrate the effectiveness of our method for discovering novel classes in our new benchmark."}
{"main_page": "https://arxiv.org/abs/2404.00260", "pdf": "https://arxiv.org/pdf/2404.00260", "title": "Exploiting Self-Supervised Constraints in Image Super-Resolution", "authors": "Gang Wu, Junjun Jiang, Kui Jiang, Xianming Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Recent advances in self-supervised learning, predominantly studied in high-level visual tasks, have been explored in low-level image processing. This paper introduces a novel self-supervised constraint for single image super-resolution, termed SSC-SR. SSC-SR uniquely addresses the divergence in image complexity by employing a dual asymmetric paradigm and a target model updated via exponential moving average to enhance stability. The proposed SSC-SR framework works as a plug-and-play paradigm and can be easily applied to existing SR models. Empirical evaluations reveal that our SSC-SR framework delivers substantial enhancements on a variety of benchmark datasets, achieving an average increase of 0.1 dB over EDSR and 0.06 dB over SwinIR. In addition, extensive ablation studies corroborate the effectiveness of each constituent in our SSC-SR framework. Codes are available at https://github.com/Aitical/SSCSR."}
{"main_page": "https://arxiv.org/abs/2404.00261", "pdf": "https://arxiv.org/pdf/2404.00261", "title": "A Simple Yet Effective Approach for Diversified Session-Based  Recommendation", "authors": "Qing Yin, Hui Fang, Zhu Sun, Yew-Soon Ong", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "abstract": "Session-based recommender systems (SBRSs) have become extremely popular in view of the core capability of capturing short-term and dynamic user preferences. However, most SBRSs primarily maximize recommendation accuracy but ignore user minor preferences, thus leading to filter bubbles in the long run. Only a handful of works, being devoted to improving diversity, depend on unique model designs and calibrated loss functions, which cannot be easily adapted to existing accuracy-oriented SBRSs. It is thus worthwhile to come up with a simple yet effective design that can be used as a plugin to facilitate existing SBRSs on generating a more diversified list in the meantime preserving the recommendation accuracy. In this case, we propose an end-to-end framework applied for every existing representative (accuracy-oriented) SBRS, called diversified category-aware attentive SBRS (DCA-SBRS), to boost the performance on recommendation diversity. It consists of two novel designs: a model-agnostic diversity-oriented loss function, and a non-invasive category-aware attention mechanism. Extensive experiments on three datasets showcase that our framework helps existing SBRSs achieve extraordinary performance in terms of recommendation diversity and comprehensive performance, without significantly deteriorating recommendation accuracy compared to state-of-the-art accuracy-oriented SBRSs."}
{"main_page": "https://arxiv.org/abs/2404.00262", "pdf": "https://arxiv.org/pdf/2404.00262", "title": "Image-to-Image Matching via Foundation Models: A New Perspective for  Open-Vocabulary Semantic Segmentation", "authors": "Yuan Wang, Rui Sun, Naisong Luo, Yuwen Pan, Tianzhu Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Open-vocabulary semantic segmentation (OVS) aims to segment images of arbitrary categories specified by class labels or captions. However, most previous best-performing methods, whether pixel grouping methods or region recognition methods, suffer from false matches between image features and category labels. We attribute this to the natural gap between the textual features and visual features. In this work, we rethink how to mitigate false matches from the perspective of image-to-image matching and propose a novel relation-aware intra-modal matching (RIM) framework for OVS based on visual foundation models. RIM achieves robust region classification by firstly constructing diverse image-modal reference features and then matching them with region features based on relation-aware ranking distribution. The proposed RIM enjoys several merits. First, the intra-modal reference features are better aligned, circumventing potential ambiguities that may arise in cross-modal matching. Second, the ranking-based matching process harnesses the structure information implicit in the inter-class relationships, making it more robust than comparing individually. Extensive experiments on three benchmarks demonstrate that RIM outperforms previous state-of-the-art methods by large margins, obtaining a lead of more than 10% in mIoU on PASCAL VOC benchmark."}
{"main_page": "https://arxiv.org/abs/2404.00264", "pdf": "https://arxiv.org/pdf/2404.00264", "title": "DiLM: Distilling Dataset into Language Model for Text-level Dataset  Distillation", "authors": "Aru Maekawa, Satoshi Kosugi, Kotaro Funakoshi, Manabu Okumura", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Dataset distillation aims to compress a training dataset by creating a small number of informative synthetic samples such that neural networks trained on them perform as well as those trained on the original training dataset. Current text dataset distillation methods create each synthetic sample as a sequence of word embeddings instead of a text to apply gradient-based optimization; however, such embedding-level distilled datasets cannot be used for training other models whose word embedding weights are different from the model used for distillation. To address this issue, we propose a novel text dataset distillation approach, called Distilling dataset into Language Model (DiLM), which trains a language model to generate informative synthetic training samples as text data, instead of directly optimizing synthetic samples. We evaluated DiLM on various text classification datasets and showed that distilled synthetic datasets from DiLM outperform those from current coreset selection methods. DiLM achieved remarkable generalization performance in training different types of models and in-context learning of large language models. Our code will be available at https://github.com/arumaekawa/DiLM."}
{"main_page": "https://arxiv.org/abs/2404.00265", "pdf": "https://arxiv.org/pdf/2404.00265", "title": "Environment-Aware Codebook for RIS-Assisted MU-MISO Communications:  Implementation and Performance Analysis", "authors": "Zhiheng Yu, Jiancheng An, Lu Gan, Chau Yuen", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "Reconfigurable intelligent surface (RIS) provides a new electromagnetic response control solution, which can reshape the characteristics of wireless channels. In this paper, we propose a novel environment-aware codebook protocol for RIS-assisted multi-user multiple-input single-output (MU-MISO) systems. Specifically, we first introduce a channel training protocol which consists of off-line and on-line stages. Secondly, we propose an environment-aware codebook generation scheme, which utilizes the statistical channel state information and alternating optimization method to generate codewords offline. Then, in the on-line stage, we use these pre-designed codewords to configure the RIS, and the optimal codeword resulting in the highest sum rate is adopted for assisting in the downlink data transmission. Thirdly, we analyze the theoretical performance of the proposed protocol considering the channel estimation errors. Finally, numerical simulations are provided to verify our theoretical analysis and the performance of the proposed scheme."}
{"main_page": "https://arxiv.org/abs/2404.00267", "pdf": "https://arxiv.org/pdf/2404.00267", "title": "Secret Keepers: The Impact of LLMs on Linguistic Markers of Personal  Traits", "authors": "Zhivar Sourati, Meltem Ozcan, Colin McDaniel, Alireza Ziabari, Nuan Wen, Ala Tak, Fred Morstatter, Morteza Dehghani", "subjects": "Computation and Language (cs.CL)", "abstract": "Prior research has established associations between individuals' language usage and their personal traits; our linguistic patterns reveal information about our personalities, emotional states, and beliefs. However, with the increasing adoption of Large Language Models (LLMs) as writing assistants in everyday writing, a critical question emerges: are authors' linguistic patterns still predictive of their personal traits when LLMs are involved in the writing process? We investigate the impact of LLMs on the linguistic markers of demographic and psychological traits, specifically examining three LLMs - GPT3.5, Llama 2, and Gemini - across six different traits: gender, age, political affiliation, personality, empathy, and morality. Our findings indicate that although the use of LLMs slightly reduces the predictive power of linguistic patterns over authors' personal traits, the significant changes are infrequent, and the use of LLMs does not fully diminish the predictive power of authors' linguistic patterns over their personal traits. We also note that some theoretically established lexical-based linguistic markers lose their reliability as predictors when LLMs are used in the writing process. Our findings have important implications for the study of linguistic markers of personal traits in the age of LLMs."}
{"main_page": "https://arxiv.org/abs/2404.00268", "pdf": "https://arxiv.org/pdf/2404.00268", "title": "A Unified Framework for Adaptive Representation Enhancement and Inversed  Learning in Cross-Domain Recommendation", "authors": "Luankang Zhang, Hao Wang, Suojuan Zhang, Mingjia Yin, Yongqiang Han, Jiaqing Zhang, Defu Lian, Enhong Chen", "subjects": "Information Retrieval (cs.IR)", "abstract": "Cross-domain recommendation (CDR), aiming to extract and transfer knowledge across domains, has attracted wide attention for its efficacy in addressing data sparsity and cold-start problems. Despite significant advances in representation disentanglement to capture diverse user preferences, existing methods usually neglect representation enhancement and lack rigorous decoupling constraints, thereby limiting the transfer of relevant information. To this end, we propose a Unified Framework for Adaptive Representation Enhancement and Inversed Learning in Cross-Domain Recommendation (AREIL). Specifically, we first divide user embeddings into domain-shared and domain-specific components to disentangle mixed user preferences. Then, we incorporate intra-domain and inter-domain information to adaptively enhance the ability of user representations. In particular, we propose a graph convolution module to capture high-order information, and a self-attention module to reveal inter-domain correlations and accomplish adaptive fusion. Next, we adopt domain classifiers and gradient reversal layers to achieve inversed representation learning in a unified framework. Finally, we employ a cross-entropy loss for measuring recommendation performance and jointly optimize the entire framework via multi-task learning. Extensive experiments on multiple datasets validate the substantial improvement in the recommendation performance of AREIL. Moreover, ablation studies and representation visualizations further illustrate the effectiveness of adaptive enhancement and inversed learning in CDR."}
{"main_page": "https://arxiv.org/abs/2404.00269", "pdf": "https://arxiv.org/pdf/2404.00269", "title": "IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D  Object Reconstruction from Single RGB-D Images", "authors": "Yushuang Wu, Luyue Shi, Junhao Cai, Weihao Yuan, Lingteng Qiu, Zilong Dong, Liefeng Bo, Shuguang Cui, Xiaoguang Han", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Generalizable 3D object reconstruction from single-view RGB-D images remains a challenging task, particularly with real-world data. Current state-of-the-art methods develop Transformer-based implicit field learning, necessitating an intensive learning paradigm that requires dense query-supervision uniformly sampled throughout the entire space. We propose a novel approach, IPoD, which harmonizes implicit field learning with point diffusion. This approach treats the query points for implicit field learning as a noisy point cloud for iterative denoising, allowing for their dynamic adaptation to the target object shape. Such adaptive query points harness diffusion learning's capability for coarse shape recovery and also enhances the implicit representation's ability to delineate finer details. Besides, an additional self-conditioning mechanism is designed to use implicit predictions as the guidance of diffusion learning, leading to a cooperative system. Experiments conducted on the CO3D-v2 dataset affirm the superiority of IPoD, achieving 7.8% improvement in F-score and 28.6% in Chamfer distance over existing methods. The generalizability of IPoD is also demonstrated on the MVImgNet dataset. Our project page is at https://yushuang-wu.github.io/IPoD."}
{"main_page": "https://arxiv.org/abs/2404.00270", "pdf": "https://arxiv.org/pdf/2404.00270", "title": "Engineering A Workload-balanced Push-Relabel Algorithm for Massive  Graphs on GPUs", "authors": "Chou-Ying Hsieh, Po-Chieh Lin, Sy-Yen Kuo", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS)", "abstract": "The push-relabel algorithm is an efficient algorithm that solves the maximum flow/ minimum cut problems of its affinity to parallelization. As the size of graphs grows exponentially, researchers have used Graphics Processing Units (GPUs) to accelerate the computation of the push-relabel algorithm further. However, prior works need to handle the significant memory consumption to represent a massive residual graph. In addition, the nature of their algorithms has inherently imbalanced workload distribution on GPUs. This paper first identifies the two challenges with the memory and computational models. Based on the analysis of these models, we propose a workload-balanced push-relabel algorithm (WBPR) with two enhanced compressed sparse representations (CSR) and a vertex-centric approach. The enhanced CSR significantly reduces memory consumption, while the vertex-centric approach alleviates the workload imbalance and improves the utilization of the GPU. In the experiment, our approach reduces the memory consumption from O(V^2) to O(V + E). Moreover, we can achieve up to 7.31x and 2.29x runtime speedup compared to the state-of-the-art on real-world graphs in maximum flow and bipartite matching tasks, respectively. Our code will be open-sourced for further research on accelerating the push-relabel algorithm."}
{"main_page": "https://arxiv.org/abs/2404.00271", "pdf": "https://arxiv.org/pdf/2404.00271", "title": "TG-NAS: Leveraging Zero-Cost Proxies with Transformer and Graph  Convolution Networks for Efficient Neural Architecture Search", "authors": "Ye Qiao, Haocheng Xu, Sitao Huang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Neural architecture search (NAS) is an effective method for discovering new convolutional neural network (CNN) architectures. However, existing approaches often require time-consuming training or intensive sampling and evaluations. Zero-shot NAS aims to create training-free proxies for architecture performance prediction. However, existing proxies have suboptimal performance, and are often outperformed by simple metrics such as model parameter counts or the number of floating-point operations. Besides, existing model-based proxies cannot be generalized to new search spaces with unseen new types of operators without golden accuracy truth. A universally optimal proxy remains elusive. We introduce TG-NAS, a novel model-based universal proxy that leverages a transformer-based operator embedding generator and a graph convolution network (GCN) to predict architecture performance. This approach guides neural architecture search across any given search space without the need of retraining. Distinct from other model-based predictor subroutines, TG-NAS itself acts as a zero-cost (ZC) proxy, guiding architecture search with advantages in terms of data independence, cost-effectiveness, and consistency across diverse search spaces. Our experiments showcase its advantages over existing proxies across various NAS benchmarks, suggesting its potential as a foundational element for efficient architecture search. TG-NAS achieves up to 300X improvements in search efficiency compared to previous SOTA ZC proxy methods. Notably, it discovers competitive models with 93.75% CIFAR-10 accuracy on the NAS-Bench-201 space and 74.5% ImageNet top-1 accuracy on the DARTS space."}
{"main_page": "https://arxiv.org/abs/2404.00272", "pdf": "https://arxiv.org/pdf/2404.00272", "title": "HSIMamba: Hyperpsectral Imaging Efficient Feature Learning with  Bidirectional State Space for Classification", "authors": "Judy X Yang, Jun Zhou, Jing Wang, Hui Tian, Alan Wee Chung Liew", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Classifying hyperspectral images is a difficult task in remote sensing, due to their complex high-dimensional data. To address this challenge, we propose HSIMamba, a novel framework that uses bidirectional reversed convolutional neural network pathways to extract spectral features more efficiently. Additionally, it incorporates a specialized block for spatial analysis. Our approach combines the operational efficiency of CNNs with the dynamic feature extraction capability of attention mechanisms found in Transformers. However, it avoids the associated high computational demands. HSIMamba is designed to process data bidirectionally, significantly enhancing the extraction of spectral features and integrating them with spatial information for comprehensive analysis. This approach improves classification accuracy beyond current benchmarks and addresses computational inefficiencies encountered with advanced models like Transformers. HSIMamba were tested against three widely recognized datasets Houston 2013, Indian Pines, and Pavia University and demonstrated exceptional performance, surpassing existing state-of-the-art models in HSI classification. This method highlights the methodological innovation of HSIMamba and its practical implications, which are particularly valuable in contexts where computational resources are limited. HSIMamba redefines the standards of efficiency and accuracy in HSI classification, thereby enhancing the capabilities of remote sensing applications. Hyperspectral imaging has become a crucial tool for environmental surveillance, agriculture, and other critical areas that require detailed analysis of the Earth surface. Please see our code in HSIMamba for more details."}
{"main_page": "https://arxiv.org/abs/2404.00276", "pdf": "https://arxiv.org/pdf/2404.00276", "title": "Instruction-Driven Game Engines on Large Language Models", "authors": "Hongqiu Wu, Yan Wang, Xingyuan Liu, Hai Zhao, Min Zhang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "The Instruction-Driven Game Engine (IDGE) project aims to democratize game development by enabling a large language model (LLM) to follow free-form game rules and autonomously generate game-play processes. The IDGE allows users to create games by issuing simple natural language instructions, which significantly lowers the barrier for game development. We approach the learning process for IDGEs as a Next State Prediction task, wherein the model autoregressively predicts in-game states given player actions. It is a challenging task because the computation of in-game states must be precise; otherwise, slight errors could disrupt the game-play. To address this, we train the IDGE in a curriculum manner that progressively increases the model's exposure to complex scenarios. Our initial progress lies in developing an IDGE for Poker, a universally cherished card game. The engine we've designed not only supports a wide range of poker variants but also allows for high customization of rules through natural language inputs. Furthermore, it also favors rapid prototyping of new games from minimal samples, proposing an innovative paradigm in game development that relies on minimal prompt and data engineering. This work lays the groundwork for future advancements in instruction-driven game creation, potentially transforming how games are designed and played."}
{"main_page": "https://arxiv.org/abs/2404.00279", "pdf": "https://arxiv.org/pdf/2404.00279", "title": "Look-Around Before You Leap: High-Frequency Injected Transformer for  Image Restoration", "authors": "Shihao Zhou, Duosheng Chen, Jinshan Pan, Jufeng Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Transformer-based approaches have achieved superior performance in image restoration, since they can model long-term dependencies well. However, the limitation in capturing local information restricts their capacity to remove degradations. While existing approaches attempt to mitigate this issue by incorporating convolutional operations, the core component in Transformer, i.e., self-attention, which serves as a low-pass filter, could unintentionally dilute or even eliminate the acquired local patterns. In this paper, we propose HIT, a simple yet effective High-frequency Injected Transformer for image restoration. Specifically, we design a window-wise injection module (WIM), which incorporates abundant high-frequency details into the feature map, to provide reliable references for restoring high-quality images. We also develop a bidirectional interaction module (BIM) to aggregate features at different scales using a mutually reinforced paradigm, resulting in spatially and contextually improved representations. In addition, we introduce a spatial enhancement unit (SEU) to preserve essential spatial relationships that may be lost due to the computations carried out across channel dimensions in the BIM. Extensive experiments on 9 tasks (real noise, real rain streak, raindrop, motion blur, moir\\'e, shadow, snow, haze, and low-light condition) demonstrate that HIT with linear computational complexity performs favorably against the state-of-the-art methods. The source code and pre-trained models will be available at https://github.com/joshyZhou/HIT."}
{"main_page": "https://arxiv.org/abs/2404.00282", "pdf": "https://arxiv.org/pdf/2404.00282", "title": "Survey on Large Language Model-Enhanced Reinforcement Learning: Concept,  Taxonomy, and Methods", "authors": "Yuji Cao, Huan Zhao, Yuheng Cheng, Ting Shu, Guolong Liu, Gaoqi Liang, Junhua Zhao, Yun Li", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)", "abstract": "With extensive pre-trained knowledge and high-level general capabilities, large language models (LLMs) emerge as a promising avenue to augment reinforcement learning (RL) in aspects such as multi-task learning, sample efficiency, and task planning. In this survey, we provide a comprehensive review of the existing literature in $\\textit{LLM-enhanced RL}$ and summarize its characteristics compared to conventional RL methods, aiming to clarify the research scope and directions for future studies. Utilizing the classical agent-environment interaction paradigm, we propose a structured taxonomy to systematically categorize LLMs' functionalities in RL, including four roles: information processor, reward designer, decision-maker, and generator. Additionally, for each role, we summarize the methodologies, analyze the specific RL challenges that are mitigated, and provide insights into future directions. Lastly, potential applications, prospective opportunities and challenges of the $\\textit{LLM-enhanced RL}$ are discussed."}
{"main_page": "https://arxiv.org/abs/2404.00284", "pdf": "https://arxiv.org/pdf/2404.00284", "title": "A Likelihood Ratio Test of Genetic Relationship among Languages", "authors": "V.S.D.S.Mahesh Akavarapu, Arnab Bhattacharya", "subjects": "Computation and Language (cs.CL)", "abstract": "Lexical resemblances among a group of languages indicate that the languages could be genetically related, i.e., they could have descended from a common ancestral language. However, such resemblances can arise by chance and, hence, need not always imply an underlying genetic relationship. Many tests of significance based on permutation of wordlists and word similarity measures appeared in the past to determine the statistical significance of such relationships. We demonstrate that although existing tests may work well for bilateral comparisons, i.e., on pairs of languages, they are either infeasible by design or are prone to yield false positives when applied to groups of languages or language families. To this end, inspired by molecular phylogenetics, we propose a likelihood ratio test to determine if given languages are related based on the proportion of invariant character sites in the aligned wordlists applied during tree inference. Further, we evaluate some language families and show that the proposed test solves the problem of false positives. Finally, we demonstrate that the test supports the existence of macro language families such as Nostratic and Macro-Mayan."}
{"main_page": "https://arxiv.org/abs/2404.00285", "pdf": "https://arxiv.org/pdf/2404.00285", "title": "Long-Tailed Recognition on Binary Networks by Calibrating A Pre-trained  Model", "authors": "Jihun Kim, Dahyun Kim, Hyungrok Jung, Taeil Oh, Jonghyun Choi", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Deploying deep models in real-world scenarios entails a number of challenges, including computational efficiency and real-world (e.g., long-tailed) data distributions. We address the combined challenge of learning long-tailed distributions using highly resource-efficient binary neural networks as backbones. Specifically, we propose a calibrate-and-distill framework that uses off-the-shelf pretrained full-precision models trained on balanced datasets to use as teachers for distillation when learning binary networks on long-tailed datasets. To better generalize to various datasets, we further propose a novel adversarial balancing among the terms in the objective function and an efficient multiresolution learning scheme. We conducted the largest empirical study in the literature using 15 datasets, including newly derived long-tailed datasets from existing balanced datasets, and show that our proposed method outperforms prior art by large margins (>14.33% on average)."}
{"main_page": "https://arxiv.org/abs/2404.00287", "pdf": "https://arxiv.org/pdf/2404.00287", "title": "An Empirical Study of Automated Vulnerability Localization with Large  Language Models", "authors": "Jian Zhang, Chong Wang, Anran Li, Weisong Sun, Cen Zhang, Wei Ma, Yang Liu", "subjects": "Software Engineering (cs.SE); Cryptography and Security (cs.CR)", "abstract": "Recently, Automated Vulnerability Localization (AVL) has attracted much attention, aiming to facilitate diagnosis by pinpointing the lines of code responsible for discovered vulnerabilities. Large Language Models (LLMs) have shown potential in various domains, yet their effectiveness in vulnerability localization remains underexplored. In this work, we perform the first comprehensive study of LLMs for AVL. Our investigation encompasses 10+ leading LLMs suitable for code analysis, including ChatGPT and various open-source models, across three architectural types: encoder-only, encoder-decoder, and decoder-only, with model sizes ranging from 60M to 16B parameters. We explore the efficacy of these LLMs using 4 distinct paradigms: zero-shot learning, one-shot learning, discriminative fine-tuning, and generative fine-tuning. Our evaluation framework is applied to the BigVul-based dataset for C/C++, and an additional dataset comprising smart contract vulnerabilities. The results demonstrate that discriminative fine-tuning of LLMs can significantly outperform existing learning-based methods for AVL, while other paradigms prove less effective or unexpectedly ineffective for the task. We also identify challenges related to input length and unidirectional context in fine-tuning processes for encoders and decoders. We then introduce two remedial strategies: the sliding window and the right-forward embedding, both of which substantially enhance performance. Furthermore, our findings highlight certain generalization capabilities of LLMs across Common Weakness Enumerations (CWEs) and different projects, indicating a promising pathway toward their practical application in vulnerability localization."}
{"main_page": "https://arxiv.org/abs/2404.00288", "pdf": "https://arxiv.org/pdf/2404.00288", "title": "Seeing the Unseen: A Frequency Prompt Guided Transformer for Image  Restoration", "authors": "Shihao Zhou, Jinshan Pan, Jinglei Shi, Duosheng Chen, Lishen Qu, Jufeng Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "How to explore useful features from images as prompts to guide the deep image restoration models is an effective way to solve image restoration. In contrast to mining spatial relations within images as prompt, which leads to characteristics of different frequencies being neglected and further remaining subtle or undetectable artifacts in the restored image, we develop a Frequency Prompting image restoration method, dubbed FPro, which can effectively provide prompt components from a frequency perspective to guild the restoration model address these differences. Specifically, we first decompose input features into separate frequency parts via dynamically learned filters, where we introduce a gating mechanism for suppressing the less informative elements within the kernels. To propagate useful frequency information as prompt, we then propose a dual prompt block, consisting of a low-frequency prompt modulator (LPM) and a high-frequency prompt modulator (HPM), to handle signals from different bands respectively. Each modulator contains a generation process to incorporate prompting components into the extracted frequency maps, and a modulation part that modifies the prompt feature with the guidance of the decoder features. Experimental results on commonly used benchmarks have demonstrated the favorable performance of our pipeline against SOTA methods on 5 image restoration tasks, including deraining, deraindrop, demoir\\'eing, deblurring, and dehazing. The source code and pre-trained models will be available at https://github.com/joshyZhou/FPro."}
{"main_page": "https://arxiv.org/abs/2404.00292", "pdf": "https://arxiv.org/pdf/2404.00292", "title": "LAKE-RED: Camouflaged Images Generation by Latent Background Knowledge  Retrieval-Augmented Diffusion", "authors": "Pancheng Zhao, Peng Xu, Pengda Qin, Deng-Ping Fan, Zhicheng Zhang, Guoli Jia, Bowen Zhou, Jufeng Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Camouflaged vision perception is an important vision task with numerous practical applications. Due to the expensive collection and labeling costs, this community struggles with a major bottleneck that the species category of its datasets is limited to a small number of object species. However, the existing camouflaged generation methods require specifying the background manually, thus failing to extend the camouflaged sample diversity in a low-cost manner. In this paper, we propose a Latent Background Knowledge Retrieval-Augmented Diffusion (LAKE-RED) for camouflaged image generation. To our knowledge, our contributions mainly include: (1) For the first time, we propose a camouflaged generation paradigm that does not need to receive any background inputs. (2) Our LAKE-RED is the first knowledge retrieval-augmented method with interpretability for camouflaged generation, in which we propose an idea that knowledge retrieval and reasoning enhancement are separated explicitly, to alleviate the task-specific challenges. Moreover, our method is not restricted to specific foreground targets or backgrounds, offering a potential for extending camouflaged vision perception to more diverse domains. (3) Experimental results demonstrate that our method outperforms the existing approaches, generating more realistic camouflage images."}
{"main_page": "https://arxiv.org/abs/2404.00297", "pdf": "https://arxiv.org/pdf/2404.00297", "title": "TRABSA: Interpretable Sentiment Analysis of Tweets using Attention-based  BiLSTM and Twitter-RoBERTa", "authors": "Md Abrar Jahin, Md Sakib Hossain Shovon, M. F. Mridha", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Sentiment analysis is crucial for understanding public opinion and consumer behavior. Existing models face challenges with linguistic diversity, generalizability, and explainability. We propose TRABSA, a hybrid framework integrating transformer-based architectures, attention mechanisms, and BiLSTM networks to address this. Leveraging RoBERTa-trained on 124M tweets, we bridge gaps in sentiment analysis benchmarks, ensuring state-of-the-art accuracy. Augmenting datasets with tweets from 32 countries and US states, we compare six word-embedding techniques and three lexicon-based labeling techniques, selecting the best for optimal sentiment analysis. TRABSA outperforms traditional ML and deep learning models with 94% accuracy and significant precision, recall, and F1-score gains. Evaluation across diverse datasets demonstrates consistent superiority and generalizability. SHAP and LIME analyses enhance interpretability, improving confidence in predictions. Our study facilitates pandemic resource management, aiding resource planning, policy formation, and vaccination tactics."}
{"main_page": "https://arxiv.org/abs/2404.00299", "pdf": "https://arxiv.org/pdf/2404.00299", "title": "HOI-M3:Capture Multiple Humans and Objects Interaction within Contextual  Environment", "authors": "Juze Zhang, Jingyan Zhang, Zining Song, Zhanhe Shi, Chengfeng Zhao, Ye Shi, Jingyi Yu, Lan Xu, Jingya Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Humans naturally interact with both others and the surrounding multiple objects, engaging in various social activities. However, recent advances in modeling human-object interactions mostly focus on perceiving isolated individuals and objects, due to fundamental data scarcity. In this paper, we introduce HOI-M3, a novel large-scale dataset for modeling the interactions of Multiple huMans and Multiple objects. Notably, it provides accurate 3D tracking for both humans and objects from dense RGB and object-mounted IMU inputs, covering 199 sequences and 181M frames of diverse humans and objects under rich activities. With the unique HOI-M3 dataset, we introduce two novel data-driven tasks with companion strong baselines: monocular capture and unstructured generation of multiple human-object interactions. Extensive experiments demonstrate that our dataset is challenging and worthy of further research about multiple human-object interactions and behavior analysis. Our HOI-M3 dataset, corresponding codes, and pre-trained models will be disseminated to the community for future research."}
{"main_page": "https://arxiv.org/abs/2404.00300", "pdf": "https://arxiv.org/pdf/2404.00300", "title": "Enhancing Empathy in Virtual Reality: An Embodied Approach to Mindset  Modulation", "authors": "Seoyeon Bae, Yoon Kyung Lee, Jungcheol Lee, Jaeheon Kim, Haeseong Jeon, Seung-Hwan Lim, Byung-Cheol Kim, Sowon Hahn", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "A growth mindset has shown promising outcomes for increasing empathy ability. However, stimulating a growth mindset in VR-based empathy interventions is under-explored. In the present study, we implemented prosocial VR content, Our Neighbor Hero, focusing on embodying a virtual character to modulate players' mindsets. The virtual body served as a stepping stone, enabling players to identify with the character and cultivate a growth mindset as they followed mission instructions. We considered several implementation factors to assist players in positioning within the VR experience, including positive feedback, content difficulty, background lighting, and multimodal feedback. We conducted an experiment to investigate the intervention's effectiveness in increasing empathy. Our findings revealed that the VR content and mindset training encouraged participants to improve their growth mindsets and empathic motives. This VR content was developed for college students to enhance their empathy and teamwork skills. It has the potential to improve collaboration in organizational and community environments."}
{"main_page": "https://arxiv.org/abs/2404.00301", "pdf": "https://arxiv.org/pdf/2404.00301", "title": "Monocular Identity-Conditioned Facial Reflectance Reconstruction", "authors": "Xingyu Ren, Jiankang Deng, Yuhao Cheng, Jia Guo, Chao Ma, Yichao Yan, Wenhan Zhu, Xiaokang Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent 3D face reconstruction methods have made remarkable advancements, yet there remain huge challenges in monocular high-quality facial reflectance reconstruction. Existing methods rely on a large amount of light-stage captured data to learn facial reflectance models. However, the lack of subject diversity poses challenges in achieving good generalization and widespread applicability. In this paper, we learn the reflectance prior in image space rather than UV space and present a framework named ID2Reflectance. Our framework can directly estimate the reflectance maps of a single image while using limited reflectance data for training. Our key insight is that reflectance data shares facial structures with RGB faces, which enables obtaining expressive facial prior from inexpensive RGB data thus reducing the dependency on reflectance data. We first learn a high-quality prior for facial reflectance. Specifically, we pretrain multi-domain facial feature codebooks and design a codebook fusion method to align the reflectance and RGB domains. Then, we propose an identity-conditioned swapping module that injects facial identity from the target image into the pre-trained autoencoder to modify the identity of the source reflectance image. Finally, we stitch multi-view swapped reflectance images to obtain renderable assets. Extensive experiments demonstrate that our method exhibits excellent generalization capability and achieves state-of-the-art facial reflectance reconstruction results for in-the-wild faces. Our project page is https://xingyuren.github.io/id2reflectance/."}
{"main_page": "https://arxiv.org/abs/2404.00303", "pdf": "https://arxiv.org/pdf/2404.00303", "title": "A Comprehensive Study on NLP Data Augmentation for Hate Speech  Detection: Legacy Methods, BERT, and LLMs", "authors": "Md Saroar Jahan, Mourad Oussalah, Djamila Romaissa Beddia, Jhuma kabir Mim, Nabil Arhab", "subjects": "Computation and Language (cs.CL)", "abstract": "The surge of interest in data augmentation within the realm of NLP has been driven by the need to address challenges posed by hate speech domains, the dynamic nature of social media vocabulary, and the demands for large-scale neural networks requiring extensive training data. However, the prevalent use of lexical substitution in data augmentation has raised concerns, as it may inadvertently alter the intended meaning, thereby impacting the efficacy of supervised machine learning models. In pursuit of suitable data augmentation methods, this study explores both established legacy approaches and contemporary practices such as Large Language Models (LLM), including GPT in Hate Speech detection. Additionally, we propose an optimized utilization of BERT-based encoder models with contextual cosine similarity filtration, exposing significant limitations in prior synonym substitution methods. Our comparative analysis encompasses five popular augmentation techniques: WordNet and Fast-Text synonym replacement, Back-translation, BERT-mask contextual augmentation, and LLM. Our analysis across five benchmarked datasets revealed that while traditional methods like back-translation show low label alteration rates (0.3-1.5%), and BERT-based contextual synonym replacement offers sentence diversity but at the cost of higher label alteration rates (over 6%). Our proposed BERT-based contextual cosine similarity filtration markedly reduced label alteration to just 0.05%, demonstrating its efficacy in 0.7% higher F1 performance. However, augmenting data with GPT-3 not only avoided overfitting with up to sevenfold data increase but also improved embedding space coverage by 15% and classification F1 score by 1.4% over traditional methods, and by 0.8% over our method."}
{"main_page": "https://arxiv.org/abs/2404.00306", "pdf": "https://arxiv.org/pdf/2404.00306", "title": "Leveraging Intelligent Recommender system as a first step resilience  measure -- A data-driven supply chain disruption response framework", "authors": "Yang Hu", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI)", "abstract": "Interests in the value of digital technologies for its potential uses to increase supply chain resilience (SCRes) are increasing in light to the industry 4.0 and the global pandemic. Utilization of Recommender systems (RS) as a supply chain (SC) resilience measure is neglected although RS is a capable tool to enhance SC resilience from a reactive aspect. To address this problem, this research proposed a novel data-driven supply chain disruption response framework based on the intelligent recommender system techniques and validated the conceptual model through a practical use case. Results show that our framework can be implemented as an effective SC disruption mitigation measure in the very first response phrase and help SC participants get better reaction performance after the SC disruption."}
{"main_page": "https://arxiv.org/abs/2404.00308", "pdf": "https://arxiv.org/pdf/2404.00308", "title": "ST-LLM: Large Language Models Are Effective Temporal Learners", "authors": "Ruyang Liu, Chen Li, Haoran Tang, Yixiao Ge, Ying Shan, Ge Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Large Language Models (LLMs) have showcased impressive capabilities in text comprehension and generation, prompting research efforts towards video LLMs to facilitate human-AI interaction at the video level. However, how to effectively encode and understand videos in video-based dialogue systems remains to be solved. In this paper, we investigate a straightforward yet unexplored question: Can we feed all spatial-temporal tokens into the LLM, thus delegating the task of video sequence modeling to the LLMs? Surprisingly, this simple approach yields significant improvements in video understanding. Based upon this, we propose ST-LLM, an effective video-LLM baseline with Spatial-Temporal sequence modeling inside LLM. Furthermore, to address the overhead and stability issues introduced by uncompressed video tokens within LLMs, we develop a dynamic masking strategy with tailor-made training objectives. For particularly long videos, we have also designed a global-local input module to balance efficiency and effectiveness. Consequently, we harness LLM for proficient spatial-temporal modeling, while upholding efficiency and stability. Extensive experimental results attest to the effectiveness of our method. Through a more concise model and training pipeline, ST-LLM establishes a new state-of-the-art result on VideoChatGPT-Bench and MVBench. Codes have been available at https://github.com/TencentARC/ST-LLM."}
{"main_page": "https://arxiv.org/abs/2404.00309", "pdf": "https://arxiv.org/pdf/2404.00309", "title": "Model-Driven Deep Learning for Distributed Detection with Binary  Quantization", "authors": "Wei Guo, Meng He, Chuan Huang, Hengtao He, Shenghui Song, Jun Zhang, Khaled B. Letaief", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "Within the realm of rapidly advancing wireless sensor networks (WSNs), distributed detection assumes a significant role in various practical applications. However, critical challenge lies in maintaining robust detection performance while operating within the constraints of limited bandwidth and energy resources. This paper introduces a novel approach that combines model-driven deep learning (DL) with binary quantization to strike a balance between communication overhead and detection performance in WSNs. We begin by establishing the lower bound of detection error probability for distributed detection using the maximum a posteriori (MAP) criterion. Furthermore, we prove the global optimality of employing identical local quantizers across sensors, thereby maximizing the corresponding Chernoff information. Subsequently, the paper derives the minimum MAP detection error probability (MAPDEP) by inplementing identical binary probabilistic quantizers across the sensors. Moreover, the paper establishes the equivalence between utilizing all quantized data and their average as input to the detector at the fusion center (FC). In particular, we derive the Kullback-Leibler (KL) divergence, which measures the difference between the true posterior probability and output of the proposed detector. Leveraging the MAPDEP and KL divergence as loss functions, the paper proposes model-driven DL method to separately train the probability controller module in the quantizer and the detector module at the FC. Numerical results validate the convergence and effectiveness of the proposed method, which achieves near-optimal performance with reduced complexity for Gaussian hypothesis testing."}
{"main_page": "https://arxiv.org/abs/2404.00311", "pdf": "https://arxiv.org/pdf/2404.00311", "title": "Pricing4SaaS: Towards a pricing model to drive the operation of SaaS", "authors": "Alejandro Garc\u00eda-Fern\u00e1ndez, Jos\u00e9 Antonio Parejo, Antonio Ruiz-Cort\u00e9s", "subjects": "Software Engineering (cs.SE)", "abstract": "The Software as a Service (SaaS) model is a distribution and licensing model that leverages pricing structures and subscriptions to profit. The utilization of such structures allows Information Systems (IS) to meet a diverse range of client needs, while offering improved flexibility and scalability. However, they increase the complexity of variability management, as pricings are influenced by business factors, like strategic decisions, market trends or technological advancements. In pursuit of realizing the vision of pricing-driven IS engineering, this paper introduces Pricing4SaaS as a first step, a generalized specification model for the pricing structures of systems that apply the Software as a Service (SaaS) licensing model. With its proven expressiveness, demonstrated through the representation of 16 distinct popular SaaS systems, Pricing4SaaS aims to become the cornerstone of pricing-driven IS engineering."}
{"main_page": "https://arxiv.org/abs/2404.00312", "pdf": "https://arxiv.org/pdf/2404.00312", "title": "Bayesian Exploration of Pre-trained Models for Low-shot Image  Classification", "authors": "Yibo Miao, Yu Lei, Feng Zhou, Zhijie Deng", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Low-shot image classification is a fundamental task in computer vision, and the emergence of large-scale vision-language models such as CLIP has greatly advanced the forefront of research in this field. However, most existing CLIP-based methods lack the flexibility to effectively incorporate other pre-trained models that encompass knowledge distinct from CLIP. To bridge the gap, this work proposes a simple and effective probabilistic model ensemble framework based on Gaussian processes, which have previously demonstrated remarkable efficacy in processing small data. We achieve the integration of prior knowledge by specifying the mean function with CLIP and the kernel function with an ensemble of deep kernels built upon various pre-trained models. By regressing the classification label directly, our framework enables analytical inference, straightforward uncertainty quantification, and principled hyper-parameter tuning. Through extensive experiments on standard benchmarks, we demonstrate that our method consistently outperforms competitive ensemble baselines regarding predictive performance. Additionally, we assess the robustness of our method and the quality of the yielded uncertainty estimates on out-of-distribution datasets. We also illustrate that our method, despite relying on label regression, still enjoys superior model calibration compared to most deterministic baselines."}
{"main_page": "https://arxiv.org/abs/2404.00313", "pdf": "https://arxiv.org/pdf/2404.00313", "title": "Harmonizing Light and Darkness: A Symphony of Prior-guided Data  Synthesis and Adaptive Focus for Nighttime Flare Removal", "authors": "Lishen Qu, Shihao Zhou, Jinshan Pan, Jinglei Shi, Duosheng Chen, Jufeng Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Intense light sources often produce flares in captured images at night, which deteriorates the visual quality and negatively affects downstream applications. In order to train an effective flare removal network, a reliable dataset is essential. The mainstream flare removal datasets are semi-synthetic to reduce human labour, but these datasets do not cover typical scenarios involving multiple scattering flares. To tackle this issue, we synthesize a prior-guided dataset named Flare7K*, which contains multi-flare images where the brightness of flares adheres to the laws of illumination. Besides, flares tend to occupy localized regions of the image but existing networks perform flare removal on the entire image and sometimes modify clean areas incorrectly. Therefore, we propose a plug-and-play Adaptive Focus Module (AFM) that can adaptively mask the clean background areas and assist models in focusing on the regions severely affected by flares. Extensive experiments demonstrate that our data synthesis method can better simulate real-world scenes and several models equipped with AFM achieve state-of-the-art performance on the real-world test dataset."}
{"main_page": "https://arxiv.org/abs/2404.00318", "pdf": "https://arxiv.org/pdf/2404.00318", "title": "Exploring Unseen Environments with Robots using Large Language and  Vision Models through a Procedurally Generated 3D Scene Representation", "authors": "Arjun P S, Andrew Melnik, Gora Chand Nandi", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advancements in Generative Artificial Intelligence, particularly in the realm of Large Language Models (LLMs) and Large Vision Language Models (LVLMs), have enabled the prospect of leveraging cognitive planners within robotic systems. This work focuses on solving the object goal navigation problem by mimicking human cognition to attend, perceive and store task specific information and generate plans with the same. We introduce a comprehensive framework capable of exploring an unfamiliar environment in search of an object by leveraging the capabilities of Large Language Models(LLMs) and Large Vision Language Models (LVLMs) in understanding the underlying semantics of our world. A challenging task in using LLMs to generate high level sub-goals is to efficiently represent the environment around the robot. We propose to use a 3D scene modular representation, with semantically rich descriptions of the object, to provide the LLM with task relevant information. But providing the LLM with a mass of contextual information (rich 3D scene semantic representation), can lead to redundant and inefficient plans. We propose to use an LLM based pruner that leverages the capabilities of in-context learning to prune out irrelevant goal specific information."}
{"main_page": "https://arxiv.org/abs/2404.00320", "pdf": "https://arxiv.org/pdf/2404.00320", "title": "Advancing Multimodal Data Fusion in Pain Recognition: A Strategy  Leveraging Statistical Correlation and Human-Centered Perspectives", "authors": "Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "This research tackles the challenge of integrating heterogeneous data for specific behavior recognition within the domain of Pain Recognition, presenting a novel methodology that harmonizes statistical correlations with a human-centered approach. By leveraging a diverse range of deep learning architectures, we highlight the adaptability and efficacy of our approach in improving model performance across various complex scenarios. The novelty of our methodology is the strategic incorporation of statistical relevance weights and the segmentation of modalities from a human-centric perspective, enhancing model precision and providing a explainable analysis of multimodal data. This study surpasses traditional modality fusion techniques by underscoring the role of data diversity and customized modality segmentation in enhancing pain behavior analysis. Introducing a framework that matches each modality with an suited classifier, based on the statistical significance, signals a move towards customized and accurate multimodal fusion strategies. Our contributions extend beyond the field of Pain Recognition by delivering new insights into modality fusion and human-centered computing applications, contributing towards explainable AI and bolstering patient-centric healthcare interventions. Thus, we bridge a significant void in the effective and interpretable fusion of multimodal data, establishing a novel standard for forthcoming inquiries in pain behavior recognition and allied fields."}
{"main_page": "https://arxiv.org/abs/2404.00322", "pdf": "https://arxiv.org/pdf/2404.00322", "title": "Instrument-tissue Interaction Detection Framework for Surgical Video  Understanding", "authors": "Wenjun Lin, Yan Hu, Huazhu Fu, Mingming Yang, Chin-Boon Chng, Ryo Kawasaki, Cheekong Chui, Jiang Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Instrument-tissue interaction detection task, which helps understand surgical activities, is vital for constructing computer-assisted surgery systems but with many challenges. Firstly, most models represent instrument-tissue interaction in a coarse-grained way which only focuses on classification and lacks the ability to automatically detect instruments and tissues. Secondly, existing works do not fully consider relations between intra- and inter-frame of instruments and tissues. In the paper, we propose to represent instrument-tissue interaction as <instrument class, instrument bounding box, tissue class, tissue bounding box, action class> quintuple and present an Instrument-Tissue Interaction Detection Network (ITIDNet) to detect the quintuple for surgery videos understanding. Specifically, we propose a Snippet Consecutive Feature (SCF) Layer to enhance features by modeling relationships of proposals in the current frame using global context information in the video snippet. We also propose a Spatial Corresponding Attention (SCA) Layer to incorporate features of proposals between adjacent frames through spatial encoding. To reason relationships between instruments and tissues, a Temporal Graph (TG) Layer is proposed with intra-frame connections to exploit relationships between instruments and tissues in the same frame and inter-frame connections to model the temporal information for the same instance. For evaluation, we build a cataract surgery video (PhacoQ) dataset and a cholecystectomy surgery video (CholecQ) dataset. Experimental results demonstrate the promising performance of our model, which outperforms other state-of-the-art models on both datasets."}
{"main_page": "https://arxiv.org/abs/2404.00323", "pdf": "https://arxiv.org/pdf/2404.00323", "title": "CLIP-driven Outliers Synthesis for few-shot OOD detection", "authors": "Hao Sun, Rundong He, Zhongyi Han, Zhicong Lin, Yongshun Gong, Yilong Yin", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Few-shot OOD detection focuses on recognizing out-of-distribution (OOD) images that belong to classes unseen during training, with the use of only a small number of labeled in-distribution (ID) images. Up to now, a mainstream strategy is based on large-scale vision-language models, such as CLIP. However, these methods overlook a crucial issue: the lack of reliable OOD supervision information, which can lead to biased boundaries between in-distribution (ID) and OOD. To tackle this problem, we propose CLIP-driven Outliers Synthesis~(CLIP-OS). Firstly, CLIP-OS enhances patch-level features' perception by newly proposed patch uniform convolution, and adaptively obtains the proportion of ID-relevant information by employing CLIP-surgery-discrepancy, thus achieving separation between ID-relevant and ID-irrelevant. Next, CLIP-OS synthesizes reliable OOD data by mixing up ID-relevant features from different classes to provide OOD supervision information. Afterward, CLIP-OS leverages synthetic OOD samples by unknown-aware prompt learning to enhance the separability of ID and OOD. Extensive experiments across multiple benchmarks demonstrate that CLIP-OS achieves superior few-shot OOD detection capability."}
{"main_page": "https://arxiv.org/abs/2404.00326", "pdf": "https://arxiv.org/pdf/2404.00326", "title": "Implicit-explicit schemes for compressible Cahn-Hilliard-Navier-Stokes  equations", "authors": "Pep Mulet", "subjects": "Numerical Analysis (math.NA)", "abstract": "The isentropic compressible Cahn-Hilliard-Navier-Stokes equations is a system of fourth-order partial differential equations that model the evolution of some binary fluids under convection. The purpose of this paper is the design of efficient numerical schemes to approximate the solution of initial-boundary value problems with these equations. The efficiency stems from the implicit treatment of the high-order terms in the equations. Our proposal is a second-order linearly implicit-explicit time stepping scheme applied in a method of lines approach, in which the convective terms are treated explicitly and only linear systems have to be solved. Some experiments are performed to assess the validity and efficiency of this proposal."}
{"main_page": "https://arxiv.org/abs/2404.00330", "pdf": "https://arxiv.org/pdf/2404.00330", "title": "Memory-Scalable and Simplified Functional Map Learning", "authors": "Robin Magnet, Maks Ovsjanikov", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Deep functional maps have emerged in recent years as a prominent learning-based framework for non-rigid shape matching problems. While early methods in this domain only focused on learning in the functional domain, the latest techniques have demonstrated that by promoting consistency between functional and pointwise maps leads to significant improvements in accuracy. Unfortunately, existing approaches rely heavily on the computation of large dense matrices arising from soft pointwise maps, which compromises their efficiency and scalability. To address this limitation, we introduce a novel memory-scalable and efficient functional map learning pipeline. By leveraging the specific structure of functional maps, we offer the possibility to achieve identical results without ever storing the pointwise map in memory. Furthermore, based on the same approach, we present a differentiable map refinement layer adapted from an existing axiomatic refinement algorithm. Unlike many functional map learning methods, which use this algorithm at a post-processing step, ours can be easily used at train time, enabling to enforce consistency between the refined and initial versions of the map. Our resulting approach is both simpler, more efficient and more numerically stable, by avoiding differentiation through a linear system, while achieving close to state-of-the-art results in challenging scenarios."}
{"main_page": "https://arxiv.org/abs/2404.00333", "pdf": "https://arxiv.org/pdf/2404.00333", "title": "On Task and in Sync: Examining the Relationship between Gaze Synchrony  and Self-Reported Attention During Video Lecture Learning", "authors": "Babette B\u00fchler, Efe Bozkir, Hannah Deininger, Peter Gerjets, Ulrich Trautwein, Enkelejda Kasneci", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Successful learning depends on learners' ability to sustain attention, which is particularly challenging in online education due to limited teacher interaction. A potential indicator for attention is gaze synchrony, demonstrating predictive power for learning achievements in video-based learning in controlled experiments focusing on manipulating attention. This study (N=84) examines the relationship between gaze synchronization and self-reported attention of learners, using experience sampling, during realistic online video learning. Gaze synchrony was assessed through Kullback-Leibler Divergence of gaze density maps and MultiMatch algorithm scanpath comparisons. Results indicated significantly higher gaze synchronization in attentive participants for both measures and self-reported attention significantly predicted post-test scores. In contrast, synchrony measures did not correlate with learning outcomes. While supporting the hypothesis that attentive learners exhibit similar eye movements, the direct use of synchrony as an attention indicator poses challenges, requiring further research on the interplay of attention, gaze synchrony, and video content type."}
{"main_page": "https://arxiv.org/abs/2404.00335", "pdf": "https://arxiv.org/pdf/2404.00335", "title": "Learing Trimaps via Clicks for Image Matting", "authors": "Chenyi Zhang, Yihan Hu, Henghui Ding, Humphrey Shi, Yao Zhao, Yunchao Wei", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Despite significant advancements in image matting, existing models heavily depend on manually-drawn trimaps for accurate results in natural image scenarios. However, the process of obtaining trimaps is time-consuming, lacking user-friendliness and device compatibility. This reliance greatly limits the practical application of all trimap-based matting methods. To address this issue, we introduce Click2Trimap, an interactive model capable of predicting high-quality trimaps and alpha mattes with minimal user click inputs. Through analyzing real users' behavioral logic and characteristics of trimaps, we successfully propose a powerful iterative three-class training strategy and a dedicated simulation function, making Click2Trimap exhibit versatility across various scenarios. Quantitative and qualitative assessments on synthetic and real-world matting datasets demonstrate Click2Trimap's superior performance compared to all existing trimap-free matting methods. Especially, in the user study, Click2Trimap achieves high-quality trimap and matting predictions in just an average of 5 seconds per image, demonstrating its substantial practical value in real-world applications."}
{"main_page": "https://arxiv.org/abs/2404.00338", "pdf": "https://arxiv.org/pdf/2404.00338", "title": "Polymorphic Records for Dynamic Languages", "authors": "Giuseppe Castagna, Lo\u00efc Peyrot", "subjects": "Programming Languages (cs.PL)", "abstract": "We define and study \"row polymorphism\" for a type system with set-theoretic types, specifically union, intersection, and negation types. We consider record types that embed row variables and define a subtyping relation by interpreting types into sets of record values and by defining subtyping as the containment of interpretations. We define a functional calculus equipped with operations for field extension, selection, and deletion, its operational semantics, and a type system that we prove to be sound. We provide algorithms for deciding the typing and subtyping relations. This research is motivated by the current trend of defining static type system for dynamic languages and, in our case, by an ongoing effort of endowing the Elixir programming language with a gradual type system."}
{"main_page": "https://arxiv.org/abs/2404.00340", "pdf": "https://arxiv.org/pdf/2404.00340", "title": "Deep Reinforcement Learning in Autonomous Car Path Planning and Control:  A Survey", "authors": "Yiyang Chen, Chao Ji, Yunrui Cai, Tong Yan, Bo Su", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "Combining data-driven applications with control systems plays a key role in recent Autonomous Car research. This thesis offers a structured review of the latest literature on Deep Reinforcement Learning (DRL) within the realm of autonomous vehicle Path Planning and Control. It collects a series of DRL methodologies and algorithms and their applications in the field, focusing notably on their roles in trajectory planning and dynamic control. In this review, we delve into the application outcomes of DRL technologies in this domain. By summarizing these literatures, we highlight potential challenges, aiming to offer insights that might aid researchers engaged in related fields."}
{"main_page": "https://arxiv.org/abs/2404.00341", "pdf": "https://arxiv.org/pdf/2404.00341", "title": "Ontology in Holonic Cooperative Manufacturing: A Solution to Share and  Exchange the Knowledge", "authors": "Ahmed R.Sadik, Bodo Urban", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Cooperative manufacturing is a new trend in industry, which depends on the existence of a collaborative robot. A collaborative robot is usually a light-weight robot which is capable of operating safely with a human co-worker in a shared work environment. During this cooperation, a vast amount of information is exchanged between the collaborative robot and the worker. This information constructs the cooperative manufacturing knowledge, which describes the production components and environment. In this research, we propose a holonic control solution, which uses the ontology concept to represent the cooperative manufacturing knowledge. The holonic control solution is implemented as an autonomous multi-agent system that exchanges the manufacturing knowledge based on an ontology model. Ultimately, the research illustrates and implements the proposed solution over a cooperative assembly scenario, which involves two workers and one collaborative robot, whom cooperate together to assemble a customized product."}
{"main_page": "https://arxiv.org/abs/2404.00343", "pdf": "https://arxiv.org/pdf/2404.00343", "title": "Commonsense Scene Graph-based Target Localization for Object Search", "authors": "Wenqi Ge, Chao Tang, Hong Zhang", "subjects": "Robotics (cs.RO)", "abstract": "Object search is a fundamental skill for household robots, yet the core problem lies in the robot's ability to locate the target object accurately. The dynamic nature of household environments, characterized by the arbitrary placement of daily objects by users, makes it challenging to perform target localization. To efficiently locate the target object, the robot needs to be equipped with knowledge at both the object and room level. However, existing approaches rely solely on one type of knowledge, leading to unsatisfactory object localization performance and, consequently, inefficient object search processes. To address this problem, we propose a commonsense scene graph-based target localization, CSG-TL, to enhance target object search in the household environment. Given the pre-built map with stationary items, the robot models the room-level knowledge with object-level commonsense knowledge generated by a large language model (LLM) to a commonsense scene graph (CSG), supporting both types of knowledge for CSG-TL. To demonstrate the superiority of CSG-TL on target localization, extensive experiments are performed on the real-world ScanNet dataset and the AI2THOR simulator. Moreover, we have extended CSG-TL to an object search framework, CSG-OS, validated in both simulated and real-world environments. Code and videos are available at https://sites.google.com/view/csg-os."}
{"main_page": "https://arxiv.org/abs/2404.00344", "pdf": "https://arxiv.org/pdf/2404.00344", "title": "Can LLMs Master Math? Investigating Large Language Models on Math Stack  Exchange", "authors": "Ankit Satpute, Noah Giessing, Andre Greiner-Petter, Moritz Schubotz, Olaf Teschke, Akiko Aizawa, Bela Gipp", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities in various natural language tasks, often achieving performances that surpass those of humans. Despite these advancements, the domain of mathematics presents a distinctive challenge, primarily due to its specialized structure and the precision it demands. In this study, we adopted a two-step approach for investigating the proficiency of LLMs in answering mathematical questions. First, we employ the most effective LLMs, as identified by their performance on math question-answer benchmarks, to generate answers to 78 questions from the Math Stack Exchange (MSE). Second, a case analysis is conducted on the LLM that showed the highest performance, focusing on the quality and accuracy of its answers through manual evaluation. We found that GPT-4 performs best (nDCG of 0.48 and P@10 of 0.37) amongst existing LLMs fine-tuned for answering mathematics questions and outperforms the current best approach on ArqMATH3 Task1, considering P@10. Our Case analysis indicates that while the GPT-4 can generate relevant responses in certain instances, it does not consistently answer all questions accurately. This paper explores the current limitations of LLMs in navigating complex mathematical problem-solving. Through case analysis, we shed light on the gaps in LLM capabilities within mathematics, thereby setting the stage for future research and advancements in AI-driven mathematical reasoning. We make our code and findings publicly available for research: \\url{https://github.com/gipplab/LLM-Investig-MathStackExchange}"}
{"main_page": "https://arxiv.org/abs/2404.00345", "pdf": "https://arxiv.org/pdf/2404.00345", "title": "MaGRITTe: Manipulative and Generative 3D Realization from Image, Topview  and Text", "authors": "Takayuki Hara, Tatsuya Harada", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The generation of 3D scenes from user-specified conditions offers a promising avenue for alleviating the production burden in 3D applications. Previous studies required significant effort to realize the desired scene, owing to limited control conditions. We propose a method for controlling and generating 3D scenes under multimodal conditions using partial images, layout information represented in the top view, and text prompts. Combining these conditions to generate a 3D scene involves the following significant difficulties: (1) the creation of large datasets, (2) reflection on the interaction of multimodal conditions, and (3) domain dependence of the layout conditions. We decompose the process of 3D scene generation into 2D image generation from the given conditions and 3D scene generation from 2D images. 2D image generation is achieved by fine-tuning a pretrained text-to-image model with a small artificial dataset of partial images and layouts, and 3D scene generation is achieved by layout-conditioned depth estimation and neural radiance fields (NeRF), thereby avoiding the creation of large datasets. The use of a common representation of spatial information using 360-degree images allows for the consideration of multimodal condition interactions and reduces the domain dependence of the layout control. The experimental results qualitatively and quantitatively demonstrated that the proposed method can generate 3D scenes in diverse domains, from indoor to outdoor, according to multimodal conditions."}
{"main_page": "https://arxiv.org/abs/2404.00346", "pdf": "https://arxiv.org/pdf/2404.00346", "title": "Asymptotically Optimal Scheduling of Multiple Parallelizable Job Classes", "authors": "Benjamin Berg, Benjamin Moseley, Weina Wang, Mor Harchol-Balter", "subjects": "Performance (cs.PF); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Many modern computing workloads are composed of parallelizable jobs. A single parallelizable job can be completed more quickly if it is run on additional servers, however each job is typically limited in the number of servers it can run on (its parallelizability level). A job's parallelizability level is determined by the type of computation the job performs and how it was implemented. As a result, a single workload of parallelizable jobs generally consists of multiple $\\textit{job classes}$, where jobs from different classes may have different parallelizability levels. The inherent sizes of jobs from different classes may also be vastly different. This paper considers the important, practical problem of how to schedule an arbitrary number of classes of parallelizable jobs. Here, each class of jobs has an associated job size distribution and parallelizability level. Given a limited number of servers, $k$, we ask how to allocate the $k$ servers across a stream of arriving jobs in order to minimize the $\\textit{mean response time}$ -- the average time from when a job arrives to the system until it is completed. The problem of optimal scheduling in multiserver systems is known to be difficult, even when jobs are not parallelizable. To solve the harder problem of scheduling multiple classes of parallelizable jobs, we turn to asymptotic scaling regimes. We find that in lighter-load regimes (i.e., Sub-Halfin-Whitt), the optimal allocation algorithm is Least-Parallelizable-First (LPF), a policy that prioritizes jobs from the least parallelizable job classes. By contrast, we also find that in the heavier-load regimes (i.e., Super-NDS), the optimal allocation algorithm prioritizes the jobs with the Shortest Expected Remaining Processing Time (SERPT). We also develop scheduling policies that perform optimally when the scaling regime is not known to the system a priori."}
{"main_page": "https://arxiv.org/abs/2404.00349", "pdf": "https://arxiv.org/pdf/2404.00349", "title": "SGDFormer: One-stage Transformer-based Architecture for Cross-Spectral  Stereo Image Guided Denoising", "authors": "Runmin Zhang, Zhu Yu, Zehua Sheng, Jiacheng Ying, Si-Yuan Cao, Shu-Jie Chen, Bailin Yang, Junwei Li, Hui-Liang Shen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Cross-spectral image guided denoising has shown its great potential in recovering clean images with rich details, such as using the near-infrared image to guide the denoising process of the visible one. To obtain such image pairs, a feasible and economical way is to employ a stereo system, which is widely used on mobile devices. Current works attempt to generate an aligned guidance image to handle the disparity between two images. However, due to occlusion, spectral differences and noise degradation, the aligned guidance image generally exists ghosting and artifacts, leading to an unsatisfactory denoised result. To address this issue, we propose a one-stage transformer-based architecture, named SGDFormer, for cross-spectral Stereo image Guided Denoising. The architecture integrates the correspondence modeling and feature fusion of stereo images into a unified network. Our transformer block contains a noise-robust cross-attention (NRCA) module and a spatially variant feature fusion (SVFF) module. The NRCA module captures the long-range correspondence of two images in a coarse-to-fine manner to alleviate the interference of noise. The SVFF module further enhances salient structures and suppresses harmful artifacts through dynamically selecting useful information. Thanks to the above design, our SGDFormer can restore artifact-free images with fine structures, and achieves state-of-the-art performance on various datasets. Additionally, our SGDFormer can be extended to handle other unaligned cross-model guided restoration tasks such as guided depth super-resolution."}
{"main_page": "https://arxiv.org/abs/2404.00350", "pdf": "https://arxiv.org/pdf/2404.00350", "title": "A Context-Sensitive, Outlier-Based Static Analysis to Find Kernel Race  Conditions", "authors": "Niels Dossche, Bert Abrath, Bart Coppens", "subjects": "Software Engineering (cs.SE); Cryptography and Security (cs.CR)", "abstract": "Race conditions are a class of bugs in software where concurrent accesses to shared resources are not protected from each other. Consequences of race conditions include privilege escalation, denial of service, and memory corruption which can potentially lead to arbitrary code execution. However, in large code bases the exact rules as to which fields should be accessed under which locks are not always clear. We propose a novel static technique that infers rules for how field accesses should be locked, and then checks the code against these rules. Traditional static analysers for detecting race conditions are based on lockset analysis. Instead, we propose an outlier-based technique enhanced with a context-sensitive mechanism that scales well. We have implemented this analysis in LLIF, and evaluated it to find incorrectly protected field accesses in Linux v5.14.11. We thoroughly evaluate its ability to find race conditions, and study the causes for false positive reports. In addition, we reported a subset of the issues and submitted patches. The maintainers confirmed 24 bugs."}
{"main_page": "https://arxiv.org/abs/2404.00351", "pdf": "https://arxiv.org/pdf/2404.00351", "title": "Rethinking Attention-Based Multiple Instance Learning for Whole-Slide  Pathological Image Classification: An Instance Attribute Viewpoint", "authors": "Linghan Cai, Shenjin Huang, Ye Zhang, Jinpeng Lu, Yongbing Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Multiple instance learning (MIL) is a robust paradigm for whole-slide pathological image (WSI) analysis, processing gigapixel-resolution images with slide-level labels. As pioneering efforts, attention-based MIL (ABMIL) and its variants are increasingly becoming popular due to the characteristics of simultaneously handling clinical diagnosis and tumor localization. However, the attention mechanism exhibits limitations in discriminating between instances, which often misclassifies tissues and potentially impairs MIL performance. This paper proposes an Attribute-Driven MIL (AttriMIL) framework to address these issues. Concretely, we dissect the calculation process of ABMIL and present an attribute scoring mechanism that measures the contribution of each instance to bag prediction effectively, quantifying instance attributes. Based on attribute quantification, we develop a spatial attribute constraint and an attribute ranking constraint to model instance correlations within and across slides, respectively. These constraints encourage the network to capture the spatial correlation and semantic similarity of instances, improving the ability of AttriMIL to distinguish tissue types and identify challenging instances. Additionally, AttriMIL employs a histopathology adaptive backbone that maximizes the pre-trained model's feature extraction capability for collecting pathological features. Extensive experiments on three public benchmarks demonstrate that our AttriMIL outperforms existing state-of-the-art frameworks across multiple evaluation metrics. The implementation code is available at https://github.com/MedCAI/AttriMIL."}
{"main_page": "https://arxiv.org/abs/2404.00353", "pdf": "https://arxiv.org/pdf/2404.00353", "title": "CBF-Based STL Motion Planning for Social Navigation in Crowded  Environment", "authors": "Andrea Ruo, Lorenzo Sabattini, Valeria Villani", "subjects": "Robotics (cs.RO)", "abstract": "A motion planning methodology based on the combination of Control Barrier Functions (CBF) and Signal Temporal Logic (STL) is employed in this paper. This methodology allows task completion at any point within a specified time interval, considering a dynamic system subject to velocity constraints. In this work, we apply this approach into the context of Socially Responsible Navigation (SRN), introducing a rotation constraint. This constraint is designed to maintain the user within the robot's field of view (FOV), enhancing human-robot interaction with the concept of side-by-side human-robot companion. This angular constraint offers the possibility to customize social navigation to specific needs, thereby enabling safe SRN. Its validation is carried out through simulations demonstrating the system's effectiveness in adhering to spatio-temporal constraints, including those related to robot velocity, rotation, and the presence of static and dynamic obstacles."}
{"main_page": "https://arxiv.org/abs/2404.00354", "pdf": "https://arxiv.org/pdf/2404.00354", "title": "Follow me: an architecture for user identification and social navigation  with a mobile robot", "authors": "Andrea Ruo, Lorenzo Sabattini, Valeria Villani", "subjects": "Robotics (cs.RO)", "abstract": "Over the past decade, a multitude of service robots have been developed to fulfill a wide range of practical purposes. Notably, roles such as reception and robotic guidance have garnered extensive popularity. In these positions, robots are progressively assuming the responsibilities traditionally held by human staff in assisting customers. Ensuring the safe and socially acceptable operation of robots in such environments poses a fundamental challenge within the context of Socially Responsible Navigation (SRN). This article presents an architecture for user identification and social navigation with a mobile robot that employs computer vision, machine learning, and artificial intelligence algorithms to identify and guide users in a social navigation context, thereby providing an intuitive and user-friendly experience with the robot."}
{"main_page": "https://arxiv.org/abs/2404.00356", "pdf": "https://arxiv.org/pdf/2404.00356", "title": "CBF-Based Motion Planning for Socially Responsible Robot Navigation  Guaranteeing STL Specification", "authors": "Andrea Ruo, Lorenzo Sabattini, Valeria Villani", "subjects": "Robotics (cs.RO)", "abstract": "In the field of control engineering, the connection between Signal Temporal Logic (STL) and time-varying Control Barrier Functions (CBF) has attracted considerable attention. CBFs have demonstrated notable success in ensuring the safety of critical applications by imposing constraints on system states, while STL allows for precisely specifying spatio-temporal constraints on the behavior of robotic systems. Leveraging these methodologies, this paper addresses the safety-critical navigation problem, in Socially Responsible Navigation (SRN) context, presenting a CBF-based STL motion planning methodology. This methodology enables task completion at any time within a specified time interval considering a dynamic system subject to velocity constraints. The proposed approach involves real-time computation of a smooth CBF, with the computation of a dynamically adjusted parameter based on the available path space and the maximum allowable velocity. A simulation study is conducted to validate the methodology, ensuring safety in the presence of static and dynamic obstacles and demonstrating its compliance with spatio-temporal constraints under non-linear velocity constraints."}
{"main_page": "https://arxiv.org/abs/2404.00357", "pdf": "https://arxiv.org/pdf/2404.00357", "title": "Revisiting Random Weight Perturbation for Efficiently Improving  Generalization", "authors": "Tao Li, Qinghua Tao, Weihao Yan, Zehao Lei, Yingwen Wu, Kun Fang, Mingzhen He, Xiaolin Huang", "subjects": "Machine Learning (cs.LG)", "abstract": "Improving the generalization ability of modern deep neural networks (DNNs) is a fundamental challenge in machine learning. Two branches of methods have been proposed to seek flat minima and improve generalization: one led by sharpness-aware minimization (SAM) minimizes the worst-case neighborhood loss through adversarial weight perturbation (AWP), and the other minimizes the expected Bayes objective with random weight perturbation (RWP). While RWP offers advantages in computation and is closely linked to AWP on a mathematical basis, its empirical performance has consistently lagged behind that of AWP. In this paper, we revisit the use of RWP for improving generalization and propose improvements from two perspectives: i) the trade-off between generalization and convergence and ii) the random perturbation generation. Through extensive experimental evaluations, we demonstrate that our enhanced RWP methods achieve greater efficiency in enhancing generalization, particularly in large-scale problems, while also offering comparable or even superior performance to SAM. The code is released at https://github.com/nblt/mARWP."}
{"main_page": "https://arxiv.org/abs/2404.00358", "pdf": "https://arxiv.org/pdf/2404.00358", "title": "Spread Your Wings: A Radial Strip Transformer for Image Deblurring", "authors": "Duosheng Chen, Shihao Zhou, Jinshan Pan, Jinglei Shi, Lishen Qu, Jufeng Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Exploring motion information is important for the motion deblurring task. Recent the window-based transformer approaches have achieved decent performance in image deblurring. Note that the motion causing blurry results is usually composed of translation and rotation movements and the window-shift operation in the Cartesian coordinate system by the window-based transformer approaches only directly explores translation motion in orthogonal directions. Thus, these methods have the limitation of modeling the rotation part. To alleviate this problem, we introduce the polar coordinate-based transformer, which has the angles and distance to explore rotation motion and translation information together. In this paper, we propose a Radial Strip Transformer (RST), which is a transformer-based architecture that restores the blur images in a polar coordinate system instead of a Cartesian one. RST contains a dynamic radial embedding module (DRE) to extract the shallow feature by a radial deformable convolution. We design a polar mask layer to generate the offsets for the deformable convolution, which can reshape the convolution kernel along the radius to better capture the rotation motion information. Furthermore, we proposed a radial strip attention solver (RSAS) as deep feature extraction, where the relationship of windows is organized by azimuth and radius. This attention module contains radial strip windows to reweight image features in the polar coordinate, which preserves more useful information in rotation and translation motion together for better recovering the sharp images. Experimental results on six synthesis and real-world datasets prove that our method performs favorably against other SOTA methods for the image deblurring task."}
{"main_page": "https://arxiv.org/abs/2404.00360", "pdf": "https://arxiv.org/pdf/2404.00360", "title": "Reusable Architecture Growth for Continual Stereo Matching", "authors": "Chenghao Zhang, Gaofeng Meng, Bin Fan, Kun Tian, Zhaoxiang Zhang, Shiming Xiang, Chunhong Pan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The remarkable performance of recent stereo depth estimation models benefits from the successful use of convolutional neural networks to regress dense disparity. Akin to most tasks, this needs gathering training data that covers a number of heterogeneous scenes at deployment time. However, training samples are typically acquired continuously in practical applications, making the capability to learn new scenes continually even more crucial. For this purpose, we propose to perform continual stereo matching where a model is tasked to 1) continually learn new scenes, 2) overcome forgetting previously learned scenes, and 3) continuously predict disparities at inference. We achieve this goal by introducing a Reusable Architecture Growth (RAG) framework. RAG leverages task-specific neural unit search and architecture growth to learn new scenes continually in both supervised and self-supervised manners. It can maintain high reusability during growth by reusing previous units while obtaining good performance. Additionally, we present a Scene Router module to adaptively select the scene-specific architecture path at inference. Comprehensive experiments on numerous datasets show that our framework performs impressively in various weather, road, and city circumstances and surpasses the state-of-the-art methods in more challenging cross-dataset settings. Further experiments also demonstrate the adaptability of our method to unseen scenes, which can facilitate end-to-end stereo architecture learning and practical deployment."}
{"main_page": "https://arxiv.org/abs/2404.00361", "pdf": "https://arxiv.org/pdf/2404.00361", "title": "Controllable and Diverse Data Augmentation with Large Language Model for  Low-Resource Open-Domain Dialogue Generation", "authors": "Zhenhua Liu, Tong Zhu, Jianxiang Xiang, Wenliang Chen", "subjects": "Computation and Language (cs.CL)", "abstract": "Data augmentation (DA) is crucial to mitigate model training instability and over-fitting problems in low-resource open-domain dialogue generation. However, traditional DA methods often neglect semantic data diversity, restricting the overall quality. Recently, large language models (LLM) have been used for DA to generate diversified dialogues. However, they have limited controllability and tend to generate dialogues with a distribution shift compared to the seed dialogues. To maximize the augmentation diversity and address the controllability problem, we propose \\textbf{S}ummary-based \\textbf{D}ialogue \\textbf{A}ugmentation with LLM (SDA). Our approach enhances the controllability of LLM by using dialogue summaries as a planning tool. Based on summaries, SDA can generate high-quality and diverse dialogue data even with a small seed dataset. To evaluate the efficacy of data augmentation methods for open-domain dialogue, we designed a clustering-based metric to characterize the semantic diversity of the augmented dialogue data. The experimental results show that SDA can augment high-quality and semantically diverse dialogues given a small seed dataset and an LLM, and the augmented data can boost the performance of open-domain dialogue models."}
{"main_page": "https://arxiv.org/abs/2404.00362", "pdf": "https://arxiv.org/pdf/2404.00362", "title": "STBA: Towards Evaluating the Robustness of DNNs for Query-Limited  Black-box Scenario", "authors": "Renyang Liu, Kwok-Yan Lam, Wei Zhou, Sixing Wu, Jun Zhao, Dongting Hu, Mingming Gong", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Many attack techniques have been proposed to explore the vulnerability of DNNs and further help to improve their robustness. Despite the significant progress made recently, existing black-box attack methods still suffer from unsatisfactory performance due to the vast number of queries needed to optimize desired perturbations. Besides, the other critical challenge is that adversarial examples built in a noise-adding manner are abnormal and struggle to successfully attack robust models, whose robustness is enhanced by adversarial training against small perturbations. There is no doubt that these two issues mentioned above will significantly increase the risk of exposure and result in a failure to dig deeply into the vulnerability of DNNs. Hence, it is necessary to evaluate DNNs' fragility sufficiently under query-limited settings in a non-additional way. In this paper, we propose the Spatial Transform Black-box Attack (STBA), a novel framework to craft formidable adversarial examples in the query-limited scenario. Specifically, STBA introduces a flow field to the high-frequency part of clean images to generate adversarial examples and adopts the following two processes to enhance their naturalness and significantly improve the query efficiency: a) we apply an estimated flow field to the high-frequency part of clean images to generate adversarial examples instead of introducing external noise to the benign image, and b) we leverage an efficient gradient estimation method based on a batch of samples to optimize such an ideal flow field under query-limited settings. Compared to existing score-based black-box baselines, extensive experiments indicated that STBA could effectively improve the imperceptibility of the adversarial examples and remarkably boost the attack success rate under query-limited settings."}
{"main_page": "https://arxiv.org/abs/2404.00364", "pdf": "https://arxiv.org/pdf/2404.00364", "title": "Accurate Cutting-point Estimation for Robotic Lychee Harvesting through  Geometry-aware Learning", "authors": "Gengming Zhang, Hao Cao, Kewei Hu, Yaoqiang Pan, Yuqin Deng, Hongjun Wang, Hanwen Kang", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "abstract": "Accurately identifying lychee-picking points in unstructured orchard environments and obtaining their coordinate locations is critical to the success of lychee-picking robots. However, traditional two-dimensional (2D) image-based object detection methods often struggle due to the complex geometric structures of branches, leaves and fruits, leading to incorrect determination of lychee picking points. In this study, we propose a Fcaf3d-lychee network model specifically designed for the accurate localisation of lychee picking points. Point cloud data of lychee picking points in natural environments are acquired using Microsoft's Azure Kinect DK time-of-flight (TOF) camera through multi-view stitching. We augment the Fully Convolutional Anchor-Free 3D Object Detection (Fcaf3d) model with a squeeze-and-excitation(SE) module, which exploits human visual attention mechanisms for improved feature extraction of lychee picking points. The trained network model is evaluated on a test set of lychee-picking locations and achieves an impressive F1 score of 88.57%, significantly outperforming existing models. Subsequent three-dimensional (3D) position detection of picking points in real lychee orchard environments yields high accuracy, even under varying degrees of occlusion. Localisation errors of lychee picking points are within 1.5 cm in all directions, demonstrating the robustness and generality of the model."}
{"main_page": "https://arxiv.org/abs/2404.00366", "pdf": "https://arxiv.org/pdf/2404.00366", "title": "Efficient Multi-branch Segmentation Network for Situation Awareness in  Autonomous Navigation", "authors": "Guan-Cheng Zhou, Chen Chengb, Yan-zhou Chena", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Real-time and high-precision situational awareness technology is critical for autonomous navigation of unmanned surface vehicles (USVs). In particular, robust and fast obstacle semantic segmentation methods are essential. However, distinguishing between the sea and the sky is challenging due to the differences between port and maritime environments. In this study, we built a dataset that captured perspectives from USVs and unmanned aerial vehicles in a maritime port environment and analysed the data features. Statistical analysis revealed a high correlation between the distribution of the sea and sky and row positional information. Based on this finding, a three-branch semantic segmentation network with a row position encoding module (RPEM) was proposed to improve the prediction accuracy between the sea and the sky. The proposed RPEM highlights the effect of row coordinates on feature extraction. Compared to the baseline, the three-branch network with RPEM significantly improved the ability to distinguish between the sea and the sky without significantly reducing the computational speed."}
{"main_page": "https://arxiv.org/abs/2404.00367", "pdf": "https://arxiv.org/pdf/2404.00367", "title": "SA-LSPL:Sequence-Aware Long- and Short- Term Preference Learning for  next POI recommendation", "authors": "Bin Wang, Yan Zhang, Yan Ma, Yaohui Jin, Yanyan Xu", "subjects": "Computers and Society (cs.CY)", "abstract": "The next Point of Interest (POI) recommendation aims to recommend the next POI for users at a specific time. As users' check-in records can be viewed as a long sequence, methods based on Recurrent Neural Networks (RNNs) have recently shown good applicability to this task. However, existing methods often struggle to fully explore the spatio-temporal correlations and dependencies at the sequence level, and don't take full consideration for various factors influencing users' preferences. To address these issues, we propose a novel approach called Sequence-Aware Long- and Short-Term Preference Learning (SA-LSPL) for next-POI recommendation. We combine various information features to effectively model users' long-term preferences. Specifically, our proposed model uses a multi-modal embedding module to embed diverse check-in details, taking into account both user's personalized preferences and social influences comprehensively. Additionally, we consider explicit spatio-temporal correlations at the sequence level and implicit sequence dependencies. Furthermore, SA-LSPL learns the spatio-temporal correlations of consecutive and non-consecutive visits in the current check-in sequence, as well as transition dependencies between categories, providing a comprehensive capture of user's short-term preferences. Extensive experiments on two real-world datasets demonstrate the superiority of SA-LSPL over state-of-the-art baseline methods."}
{"main_page": "https://arxiv.org/abs/2404.00368", "pdf": "https://arxiv.org/pdf/2404.00368", "title": "Towards Variable and Coordinated Holistic Co-Speech Motion Generation", "authors": "Yifei Liu, Qiong Cao, Yandong Wen, Huaiguang Jiang, Changxing Ding", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper addresses the problem of generating lifelike holistic co-speech motions for 3D avatars, focusing on two key aspects: variability and coordination. Variability allows the avatar to exhibit a wide range of motions even with similar speech content, while coordination ensures a harmonious alignment among facial expressions, hand gestures, and body poses. We aim to achieve both with ProbTalk, a unified probabilistic framework designed to jointly model facial, hand, and body movements in speech. ProbTalk builds on the variational autoencoder (VAE) architecture and incorporates three core designs. First, we introduce product quantization (PQ) to the VAE, which enriches the representation of complex holistic motion. Second, we devise a novel non-autoregressive model that embeds 2D positional encoding into the product-quantized representation, thereby preserving essential structure information of the PQ codes. Last, we employ a secondary stage to refine the preliminary prediction, further sharpening the high-frequency details. Coupling these three designs enables ProbTalk to generate natural and diverse holistic co-speech motions, outperforming several state-of-the-art methods in qualitative and quantitative evaluations, particularly in terms of realism. Our code and model will be released for research purposes at https://feifeifeiliu.github.io/probtalk/."}
{"main_page": "https://arxiv.org/abs/2404.00369", "pdf": "https://arxiv.org/pdf/2404.00369", "title": "Worker Robot Cooperation and Integration into the Manufacturing Workcell  via the Holonic Control Architecture", "authors": "Ahmed R. Sadik, Bodo Urban, Omar Adel", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Systems and Control (eess.SY)", "abstract": "Worker-Robot Cooperation is a new industrial trend, which aims to sum the advantages of both the human and the industrial robot to afford a new intelligent manufacturing techniques. The cooperative manufacturing between the worker and the robot contains other elements such as the product parts and the manufacturing tools. All these production elements must cooperate in one manufacturing workcell to fulfill the production requirements. The manufacturing control system is the mean to connect all these cooperative elements together in one body. This manufacturing control system is distributed and autonomous due to the nature of the cooperative workcell. Accordingly, this article proposes the holonic control architecture as the manufacturing concept of the cooperative workcell. Furthermore, the article focuses on the feasibility of this manufacturing concept, by applying it over a case study that involves the cooperation between a dual-arm robot and a worker. During this case study, the worker uses a variety of hand gestures to cooperate with the robot to achieve the highest production flexibility"}
{"main_page": "https://arxiv.org/abs/2404.00370", "pdf": "https://arxiv.org/pdf/2404.00370", "title": "Inverse Optimal Cardano-Lyapunov Feedback for PDEs with Convection", "authors": "Mohamed Camil Belhadjoudja, Miroslav Krstic, Mohamed Maghenem, Emmanuel Witrant", "subjects": "Systems and Control (eess.SY); Analysis of PDEs (math.AP); Optimization and Control (math.OC)", "abstract": "We consider the problem of inverse optimal control design for systems that are not affine in the control. In particular, we consider some classes of partial differential equations (PDEs) with quadratic convection and counter-convection, for which the L2 norm is a control Lyapunov function (CLF) whose derivative has either a depressed cubic or a quadratic dependence in the boundary control input. We also consider diffusive PDEs with or without linear convection, for which a weighted L2 norm is a CLF whose derivative has a quadratic dependence in the control input. For each structure on the derivative of the CLF, we achieve inverse optimality with respect to a meaningful cost functional. For the case where the derivative of the CLF has a depressed cubic dependence in the control, we construct a cost functional for which the unique minimizer is the unique real root of a cubic polynomial: the Cardano-Lyapunov controller. When the derivative of the CLF is quadratic in the control, we construct a cost functional that is minimized by two distinct feedback laws, that correspond to the two distinct real roots of a quadratic equation. We show how to switch from one root to the other to reduce the control effort."}
{"main_page": "https://arxiv.org/abs/2404.00371", "pdf": "https://arxiv.org/pdf/2404.00371", "title": "From Learning to Analytics: Improving Model Efficacy with Goal-Directed  Client Selection", "authors": "Jingwen Tong, Zhenzhen Chen, Liqun Fu, Jun Zhang, Zhu Han", "subjects": "Machine Learning (cs.LG); Signal Processing (eess.SP)", "abstract": "Federated learning (FL) is an appealing paradigm for learning a global model among distributed clients while preserving data privacy. Driven by the demand for high-quality user experiences, evaluating the well-trained global model after the FL process is crucial. In this paper, we propose a closed-loop model analytics framework that allows for effective evaluation of the trained global model using clients' local data. To address the challenges posed by system and data heterogeneities in the FL process, we study a goal-directed client selection problem based on the model analytics framework by selecting a subset of clients for the model training. This problem is formulated as a stochastic multi-armed bandit (SMAB) problem. We first put forth a quick initial upper confidence bound (Quick-Init UCB) algorithm to solve this SMAB problem under the federated analytics (FA) framework. Then, we further propose a belief propagation-based UCB (BP-UCB) algorithm under the democratized analytics (DA) framework. Moreover, we derive two regret upper bounds for the proposed algorithms, which increase logarithmically over the time horizon. The numerical results demonstrate that the proposed algorithms achieve nearly optimal performance, with a gap of less than 1.44% and 3.12% under the FA and DA frameworks, respectively."}
{"main_page": "https://arxiv.org/abs/2404.00373", "pdf": "https://arxiv.org/pdf/2404.00373", "title": "The Devil is in the Edges: Monocular Depth Estimation with Edge-aware  Consistency Fusion", "authors": "Pengzhi Li, Yikang Ding, Haohan Wang, Chengshuai Tang, Zhiheng Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper presents a novel monocular depth estimation method, named ECFNet, for estimating high-quality monocular depth with clear edges and valid overall structure from a single RGB image. We make a thorough inquiry about the key factor that affects the edge depth estimation of the MDE networks, and come to a ratiocination that the edge information itself plays a critical role in predicting depth details. Driven by this analysis, we propose to explicitly employ the image edges as input for ECFNet and fuse the initial depths from different sources to produce the final depth. Specifically, ECFNet first uses a hybrid edge detection strategy to get the edge map and edge-highlighted image from the input image, and then leverages a pre-trained MDE network to infer the initial depths of the aforementioned three images. After that, ECFNet utilizes a layered fusion module (LFM) to fuse the initial depth, which will be further updated by a depth consistency module (DCM) to form the final estimation. Extensive experimental results on public datasets and ablation studies indicate that our method achieves state-of-the-art performance. Project page: https://zrealli.github.io/edgedepth."}
{"main_page": "https://arxiv.org/abs/2404.00376", "pdf": "https://arxiv.org/pdf/2404.00376", "title": "Small Language Models Learn Enhanced Reasoning Skills from Medical  Textbooks", "authors": "Hyunjae Kim, Hyeon Hwang, Jiwoo Lee, Sihyeon Park, Dain Kim, Taewhoo Lee, Chanwoong Yoon, Jiwoong Sohn, Donghee Choi, Jaewoo Kang", "subjects": "Computation and Language (cs.CL)", "abstract": "While recent advancements in commercial large language models (LM) have shown promising results in medical tasks, their closed-source nature poses significant privacy and security concerns, hindering their widespread use in the medical field. Despite efforts to create open-source models, their limited parameters often result in insufficient multi-step reasoning capabilities required for solving complex medical problems. To address this, we introduce Meerkat-7B, a novel medical AI system with 7 billion parameters. Meerkat-7B was trained using our new synthetic dataset consisting of high-quality chain-of-thought reasoning paths sourced from 18 medical textbooks, along with diverse instruction-following datasets. Our system achieved remarkable accuracy across seven medical benchmarks, surpassing GPT-3.5 by 13.1%, as well as outperforming the previous best 7B models such as MediTron-7B and BioMistral-7B by 13.4% and 9.8%, respectively. Notably, it surpassed the passing threshold of the United States Medical Licensing Examination (USMLE) for the first time for a 7B-parameter model. Additionally, our system offered more detailed free-form responses to clinical queries compared to existing 7B and 13B models, approaching the performance level of GPT-3.5. This significantly narrows the performance gap with large LMs, showcasing its effectiveness in addressing complex medical challenges."}
{"main_page": "https://arxiv.org/abs/2404.00380", "pdf": "https://arxiv.org/pdf/2404.00380", "title": "DHR: Dual Features-Driven Hierarchical Rebalancing in Inter- and  Intra-Class Regions for Weakly-Supervised Semantic Segmentation", "authors": "Sanghyun Jo, Fei Pan, In-Jae Yu, Kyungsu Kim", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Weakly-supervised semantic segmentation (WSS) ensures high-quality segmentation with limited data and excels when employed as input seed masks for large-scale vision models such as Segment Anything. However, WSS faces challenges related to minor classes since those are overlooked in images with adjacent multiple classes, a limitation originating from the overfitting of traditional expansion methods like Random Walk. We first address this by employing unsupervised and weakly-supervised feature maps instead of conventional methodologies, allowing for hierarchical mask enhancement. This method distinctly categorizes higher-level classes and subsequently separates their associated lower-level classes, ensuring all classes are correctly restored in the mask without losing minor ones. Our approach, validated through extensive experimentation, significantly improves WSS across five benchmarks (VOC: 79.8\\%, COCO: 53.9\\%, Context: 49.0\\%, ADE: 32.9\\%, Stuff: 37.4\\%), reducing the gap with fully supervised methods by over 84\\% on the VOC validation set. Code is available at https://github.com/shjo-april/DHR."}
{"main_page": "https://arxiv.org/abs/2404.00383", "pdf": "https://arxiv.org/pdf/2404.00383", "title": "SpikingJET: Enhancing Fault Injection for Fully and Convolutional  Spiking Neural Networks", "authors": "Anil Bayram Gogebakan, Enrico Magliano, Alessio Carpegna, Annachiara Ruospo, Alessandro Savino, Stefano Di Carlo", "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)", "abstract": "As artificial neural networks become increasingly integrated into safety-critical systems such as autonomous vehicles, devices for medical diagnosis, and industrial automation, ensuring their reliability in the face of random hardware faults becomes paramount. This paper introduces SpikingJET, a novel fault injector designed specifically for fully connected and convolutional Spiking Neural Networks (SNNs). Our work underscores the critical need to evaluate the resilience of SNNs to hardware faults, considering their growing prominence in real-world applications. SpikingJET provides a comprehensive platform for assessing the resilience of SNNs by inducing errors and injecting faults into critical components such as synaptic weights, neuron model parameters, internal states, and activation functions. This paper demonstrates the effectiveness of Spiking-JET through extensive software-level experiments on various SNN architectures, revealing insights into their vulnerability and resilience to hardware faults. Moreover, highlighting the importance of fault resilience in SNNs contributes to the ongoing effort to enhance the reliability and safety of Neural Network (NN)-powered systems in diverse domains."}
{"main_page": "https://arxiv.org/abs/2404.00384", "pdf": "https://arxiv.org/pdf/2404.00384", "title": "TTD: Text-Tag Self-Distillation Enhancing Image-Text Alignment in CLIP  to Alleviate Single Tag Bias", "authors": "Sanghyun Jo, Soohyun Ryu, Sungyub Kim, Eunho Yang, Kyungsu Kim", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We identify a critical bias in contemporary CLIP-based models, which we denote as \\textit{single tag bias}. This bias manifests as a disproportionate focus on a singular tag (word) while neglecting other pertinent tags, stemming from CLIP's text embeddings that prioritize one specific tag in image-text relationships. When deconstructing text into individual tags, only one tag tends to have high relevancy with CLIP's image embedding, leading to an imbalanced tag relevancy. This results in an uneven alignment among multiple tags present in the text. To tackle this challenge, we introduce a novel two-step fine-tuning approach. First, our method leverages the similarity between tags and their nearest pixels for scoring, enabling the extraction of image-relevant tags from the text. Second, we present a self-distillation strategy aimed at aligning the combined masks from extracted tags with the text-derived mask. This approach mitigates the single tag bias, thereby significantly improving the alignment of CLIP's model without necessitating additional data or supervision. Our technique demonstrates model-agnostic improvements in multi-tag classification and segmentation tasks, surpassing competing methods that rely on external resources. Code is available at https://github.com/shjo-april/TTD."}
{"main_page": "https://arxiv.org/abs/2404.00385", "pdf": "https://arxiv.org/pdf/2404.00385", "title": "Constrained Layout Generation with Factor Graphs", "authors": "Mohammed Haroon Dupty, Yanfei Dong, Sicong Leng, Guoji Fu, Yong Liang Goh, Wei Lu, Wee Sun Lee", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "This paper addresses the challenge of object-centric layout generation under spatial constraints, seen in multiple domains including floorplan design process. The design process typically involves specifying a set of spatial constraints that include object attributes like size and inter-object relations such as relative positioning. Existing works, which typically represent objects as single nodes, lack the granularity to accurately model complex interactions between objects. For instance, often only certain parts of an object, like a room's right wall, interact with adjacent objects. To address this gap, we introduce a factor graph based approach with four latent variable nodes for each room, and a factor node for each constraint. The factor nodes represent dependencies among the variables to which they are connected, effectively capturing constraints that are potentially of a higher order. We then develop message-passing on the bipartite graph, forming a factor graph neural network that is trained to produce a floorplan that aligns with the desired requirements. Our approach is simple and generates layouts faithful to the user requirements, demonstrated by a large improvement in IOU scores over existing methods. Additionally, our approach, being inferential and accurate, is well-suited to the practical human-in-the-loop design process where specifications evolve iteratively, offering a practical and powerful tool for AI-guided design."}
{"main_page": "https://arxiv.org/abs/2404.00386", "pdf": "https://arxiv.org/pdf/2404.00386", "title": "Jetsons at FinNLP 2024: Towards Understanding the ESG Impact of a News  Article using Transformer-based Models", "authors": "Parag Pravin Dakle, Alolika Gon, Sihan Zha, Liang Wang, SaiKrishna Rallabandi, Preethi Raghavan", "subjects": "Computation and Language (cs.CL)", "abstract": "In this paper, we describe the different approaches explored by the Jetsons team for the Multi-Lingual ESG Impact Duration Inference (ML-ESG-3) shared task. The shared task focuses on predicting the duration and type of the ESG impact of a news article. The shared task dataset consists of 2,059 news titles and articles in English, French, Korean, and Japanese languages. For the impact duration classification task, we fine-tuned XLM-RoBERTa with a custom fine-tuning strategy and using self-training and DeBERTa-v3 using only English translations. These models individually ranked first on the leaderboard for Korean and Japanese and in an ensemble for the English language, respectively. For the impact type classification task, our XLM-RoBERTa model fine-tuned using a custom fine-tuning strategy ranked first for the English language."}
{"main_page": "https://arxiv.org/abs/2404.00387", "pdf": "https://arxiv.org/pdf/2404.00387", "title": "Inexactness and Correction of Floating-Point Reciprocal, Division and  Square Root", "authors": "Lucas M. Dutton, Christopher Kumar Anand, Robert Enenkel, Silvia Melitta M\u00fcller", "subjects": "Mathematical Software (cs.MS); Hardware Architecture (cs.AR)", "abstract": "Floating-point arithmetic performance determines the overall performance of important applications, from graphics to AI. Meeting the IEEE-754 specification for floating-point requires that final results of addition, subtraction, multiplication, division, and square root are correctly rounded based on the user-selected rounding mode. A frustrating fact for implementers is that naive rounding methods will not produce correctly rounded results even when intermediate results with greater accuracy and precision are available. In contrast, our novel algorithm can correct approximations of reciprocal, division and square root, even ones with slightly lower than target precision. In this paper, we present a family of algorithms that can both increase the accuracy (and potentially the precision) of an estimate and correctly round it according to all binary IEEE-754 rounding modes. We explain how it may be efficiently implemented in hardware, and for completeness, we present proofs that it is not necessary to include equality tests associated with round-to-nearest-even mode for reciprocal, division and square root functions, because it is impossible for input(s) in a given precision to have exact answers exactly midway between representable floating-point numbers in that precision. In fact, our simpler proofs are sometimes stronger."}
{"main_page": "https://arxiv.org/abs/2404.00391", "pdf": "https://arxiv.org/pdf/2404.00391", "title": "Robust and structure-preserving time-discretisation and linearisation  schemes for singular and degenerate evolution systems arising in models for  biofilm growth", "authors": "R.K.H. Smeets, K. Mitra, I.S. Pop, S. Sonner", "subjects": "Numerical Analysis (math.NA); Analysis of PDEs (math.AP)", "abstract": "We propose and analyse numerical schemes for a system of quasilinear, degenerate evolution equations modelling biofilm growth as well as other processes such as flow through porous media and the spreading of wildfires. The first equation in the system is parabolic and exhibits degenerate and singular diffusion, while the second is either uniformly parabolic or an ordinary differential equation. First, we introduce a semi-implicit time discretisation that has the benefit of decoupling the equations. We prove the positivity, boundedness, and convergence of the time-discrete solutions to the time-continuous solution. Then, we introduce an iterative linearisation scheme to solve the resulting nonlinear time-discrete problems. Under weak assumptions on the time-step size, we prove that the scheme converges irrespective of the space discretisation and mesh. Moreover, if the problem is non-degenerate, the convergence becomes faster as the time-step size decreases. Finally, employing the finite element method for the spatial discretisation, we study the behaviour of the scheme, and compare its performance to other commonly used schemes. These tests confirm that the proposed scheme is robust and fast."}
{"main_page": "https://arxiv.org/abs/2404.00392", "pdf": "https://arxiv.org/pdf/2404.00392", "title": "Designing a User-centric Framework for Information Quality Ranking of  Large-scale Street View Images", "authors": "Tahiya Chowdhury, Ilan Mandel, Jorge Ortiz, Wendy Ju", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Street view imagery (SVI), largely captured via outfitted fleets or mounted dashcams in consumer vehicles is a rapidly growing source of geospatial data used in urban sensing and development. These datasets are often collected opportunistically, are massive in size, and vary in quality which limits the scope and extent of their use in urban planning. Thus far there has not been much work to identify the obstacles experienced and tools needed by the users of such datasets. This severely limits the opportunities of using emerging street view images in supporting novel research questions that can improve the quality of urban life. This work includes a formative interview study with 5 expert users of large-scale street view datasets from academia, urban planning, and related professions which identifies novel use cases, challenges, and opportunities to increase the utility of these datasets. Based on the user findings, we present a framework to evaluate the quality of information for street images across three attributes (spatial, temporal, and content) that stakeholders can utilize for estimating the value of a dataset, and to improve it over time for their respective use case. We then present a case study using novel street view images where we evaluate our framework and present practical use cases for users. We discuss the implications for designing future systems to support the collection and use of street view data to assist in sensing and planning the urban environment."}
{"main_page": "https://arxiv.org/abs/2404.00394", "pdf": "https://arxiv.org/pdf/2404.00394", "title": "Analysis of Fairness-promoting Optimization Schemes of Photovoltaic  Curtailments for Voltage Regulation in Power Distribution Networks", "authors": "Rahul K. Gupta, Daniel K. Molzahn", "subjects": "Systems and Control (eess.SY)", "abstract": "Active power curtailment of photovoltaic (PV) generation is commonly exercised to mitigate over-voltage issues in power distribution networks. However, fairness concerns arise as certain PV plants may experience more significant curtailments than others depending on their locations within the network. Existing literature tackles this issue through fairness-promoting/aware optimization schemes. These schemes can be broadly categorized into two types. The first type maximizes an additional fairness objective along with the main objective of curtailment minimization. The second type is formulated as a feedback controller, where fairness is accounted for by assigning different weights (as feedback) in the curtailment minimization objective for each PV plant based on previous curtailment actions. In this work, we combine these two schemes and provide extensive analyses and comparisons of these two fairness schemes. We compare the performance in terms of fairness and net curtailments for several benchmark test networks."}
{"main_page": "https://arxiv.org/abs/2404.00395", "pdf": "https://arxiv.org/pdf/2404.00395", "title": "A First Ontological Model for the Description of the Art Market in the  Semantic Web", "authors": "Manuele Veggi", "subjects": "Digital Libraries (cs.DL)", "abstract": "This dissertation presents the first version of a project at the Fondazione Federico Zeri, aimed at modelling the art market starting from the recognition of the peculiarities of this sector and relying on the data collected by this institute during its research activities on its documentary collection. Specifically, this study describes the development of an ontology, able to describe agents, events and sources which define the art market and enable its investigation. The recognition of existing conceptual models is hence followed by the description of the adopted methodology, based on the protocol SAMOD. The central section provides a general overview of the final ontology, integrating the results of a preliminary study. Lastly, the appendix lists motivating scenarios, examples and competency questions collected during the first SAMOD iterations, as well as a first alignment with existing models."}
{"main_page": "https://arxiv.org/abs/2404.00397", "pdf": "https://arxiv.org/pdf/2404.00397", "title": "An Analysis of BPE Vocabulary Trimming in Neural Machine Translation", "authors": "Marco Cognetta, Tatsuya Hiraoka, Naoaki Okazaki, Rico Sennrich, Yuval Pinter", "subjects": "Computation and Language (cs.CL)", "abstract": "We explore threshold vocabulary trimming in Byte-Pair Encoding subword tokenization, a postprocessing step that replaces rare subwords with their component subwords. The technique is available in popular tokenization libraries but has not been subjected to rigorous scientific scrutiny. While the removal of rare subwords is suggested as best practice in machine translation implementations, both as a means to reduce model size and for improving model performance through robustness, our experiments indicate that, across a large space of hyperparameter settings, vocabulary trimming fails to improve performance, and is even prone to incurring heavy degradation."}
{"main_page": "https://arxiv.org/abs/2404.00399", "pdf": "https://arxiv.org/pdf/2404.00399", "title": "Aurora-M: The First Open Source Multilingual Language Model Red-teamed  according to the U.S. Executive Order", "authors": "Taishi Nakamura, Mayank Mishra, Simone Tedeschi, Yekun Chai, Jason T Stillerman, Felix Friedrich, Prateek Yadav, Tanmay Laud, Vu Minh Chien, Terry Yue Zhuo, Diganta Misra, Ben Bogin, Xuan-Son Vu, Marzena Karpinska, Arnav Varma Dantuluri, Wojciech Kusa, Tommaso Furlanello, Rio Yokota, Niklas Muennighoff, Suhas Pai, Tosin Adewumi, Veronika Laippala, Xiaozhe Yao, Adalberto Junior, Alpay Ariyak, Aleksandr Drozd, Jordan Clive, Kshitij Gupta, Liangyu Chen, Qi Sun, Ken Tsui, Noah Persaud, Nour Fahmy, Tianlong Chen, Mohit Bansal, Nicolo Monti, Tai Dang, Ziyang Luo, Tien-Tung Bui, Roberto Navigli, Virendra Mehta, Matthew Blumberg, Victor May, Huu Nguyen, Sampo Pyysalo", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Pretrained language models underpin several AI applications, but their high computational cost for training limits accessibility. Initiatives such as BLOOM and StarCoder aim to democratize access to pretrained models for collaborative community development. However, such existing models face challenges: limited multilingual capabilities, continual pretraining causing catastrophic forgetting, whereas pretraining from scratch is computationally expensive, and compliance with AI safety and development laws. This paper presents Aurora-M, a 15B parameter multilingual open-source model trained on English, Finnish, Hindi, Japanese, Vietnamese, and code. Continually pretrained from StarCoderPlus on 435 billion additional tokens, Aurora-M surpasses 2 trillion tokens in total training token count. It is the first open-source multilingual model fine-tuned on human-reviewed safety instructions, thus aligning its development not only with conventional red-teaming considerations, but also with the specific concerns articulated in the Biden-Harris Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. Aurora-M is rigorously evaluated across various tasks and languages, demonstrating robustness against catastrophic forgetting and outperforming alternatives in multilingual settings, particularly in safety evaluations. To promote responsible open-source LLM development, Aurora-M and its variants are released at https://huggingface.co/collections/aurora-m/aurora-m-models-65fdfdff62471e09812f5407 ."}
{"main_page": "https://arxiv.org/abs/2404.00401", "pdf": "https://arxiv.org/pdf/2404.00401", "title": "How Robust are the Tabular QA Models for Scientific Tables? A Study  using Customized Dataset", "authors": "Akash Ghosh, B Venkata Sahith, Niloy Ganguly, Pawan Goyal, Mayank Singh", "subjects": "Computation and Language (cs.CL)", "abstract": "Question-answering (QA) on hybrid scientific tabular and textual data deals with scientific information, and relies on complex numerical reasoning. In recent years, while tabular QA has seen rapid progress, understanding their robustness on scientific information is lacking due to absence of any benchmark dataset. To investigate the robustness of the existing state-of-the-art QA models on scientific hybrid tabular data, we propose a new dataset, \"SciTabQA\", consisting of 822 question-answer pairs from scientific tables and their descriptions. With the help of this dataset, we assess the state-of-the-art Tabular QA models based on their ability (i) to use heterogeneous information requiring both structured data (table) and unstructured data (text) and (ii) to perform complex scientific reasoning tasks. In essence, we check the capability of the models to interpret scientific tables and text. Our experiments show that \"SciTabQA\" is an innovative dataset to study question-answering over scientific heterogeneous data. We benchmark three state-of-the-art Tabular QA models, and find that the best F1 score is only 0.462."}
{"main_page": "https://arxiv.org/abs/2404.00403", "pdf": "https://arxiv.org/pdf/2404.00403", "title": "UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion  Cause", "authors": "Guimin Hu, Zhihong Zhu, Daniel Hershcovich, Hasti Seifi, Jiayuan Xie", "subjects": "Computation and Language (cs.CL)", "abstract": "Multimodal emotion recognition in conversation (MERC) and multimodal emotion-cause pair extraction (MECPE) has recently garnered significant attention. Emotions are the expression of affect or feelings; responses to specific events, thoughts, or situations are known as emotion causes. Both are like two sides of a coin, collectively describing human behaviors and intents. However, most existing works treat MERC and MECPE as separate tasks, which may result in potential challenges in integrating emotion and cause in real-world applications. In this paper, we propose a Unified Multimodal Emotion recognition and Emotion-Cause analysis framework (UniMEEC) to explore the causality and complementarity between emotion and emotion cause. Concretely, UniMEEC reformulates the MERC and MECPE tasks as two mask prediction problems, enhancing the interaction between emotion and cause. Meanwhile, UniMEEC shares the prompt learning among modalities for probing modality-specific knowledge from the Pre-trained model. Furthermore, we propose a task-specific hierarchical context aggregation to control the information flow to the task. Experiment results on four public benchmark datasets verify the model performance on MERC and MECPE tasks and achieve consistent improvements compared with state-of-the-art methods."}
{"main_page": "https://arxiv.org/abs/2404.00404", "pdf": "https://arxiv.org/pdf/2404.00404", "title": "Value, Representation, Information and Communication", "authors": "Xiangjun Peng", "subjects": "Information Theory (cs.IT)", "abstract": "A new analytic framework is first formalized via the usage of the Monadology (Leibniz 1898), to expand the understanding of Zermelo-Fraenkel-choice set theory (ZFC) and Von Neumann-Bernays-Godel set theory (NBG). Implicitly, the framework levels value, representation and information separately. Given the fact that there exists a coincidental equivalence between Von Neumann universe and originally-formalized motivation in ZFC, this work hypothesizes the essential of ordered values for one monand, to carry out efficient communication with the rest. This work then focuses on the relationship among values, representation and information (and suggests potential methods for quantitative analysis). First, this framework generalizes the definition of values and representations from \"Indexes approximate Values\" principle by (Peng 2023) via surreal numbers (Knuth 1974). Second, credited to surreal numbers, this work recursively connects representations and information via subsets of sets. Therefore, the definition to metric space(s) is naturally formed by representations, and quantitative methods (e.g., Hausdorff Distance) can be applied for quantitative analysis among (sub)sets. Third, this framework conjectures that: as long as the metric space is (or can be formed as) complete, the existence tests can be performed via Cauchy Sequence (or its generalized methods). This work finally revisits the communication theory, and suggests new perspectives from the new analytic framework. Particularly, this work hypothesizes a (quantitative) relationship between values and representation, and conjectures that: the optimal construction of representations exists, and it can be derived as the core value of one monad via Cauchy Inequality (or its generalized methods)."}
{"main_page": "https://arxiv.org/abs/2404.00405", "pdf": "https://arxiv.org/pdf/2404.00405", "title": "A Taxonomy for Human-LLM Interaction Modes: An Initial Exploration", "authors": "Jie Gao, Simret Araya Gebreegziabher, Kenny Tsu Wei Choo, Toby Jia-Jun Li, Simon Tangi Perrault, Thomas W. Malone", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "With ChatGPT's release, conversational prompting has become the most popular form of human-LLM interaction. However, its effectiveness is limited for more complex tasks involving reasoning, creativity, and iteration. Through a systematic analysis of HCI papers published since 2021, we identified four key phases in the human-LLM interaction flow - planning, facilitating, iterating, and testing - to precisely understand the dynamics of this process. Additionally, we have developed a taxonomy of four primary interaction modes: Mode 1: Standard Prompting, Mode 2: User Interface, Mode 3: Context-based, and Mode 4: Agent Facilitator. This taxonomy was further enriched using the \"5W1H\" guideline method, which involved a detailed examination of definitions, participant roles (Who), the phases that happened (When), human objectives and LLM abilities (What), and the mechanics of each interaction mode (How). We anticipate this taxonomy will contribute to the future design and evaluation of human-LLM interaction."}
{"main_page": "https://arxiv.org/abs/2404.00406", "pdf": "https://arxiv.org/pdf/2404.00406", "title": "TACO -- Twitter Arguments from COnversations", "authors": "Marc Feger, Stefan Dietze", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Twitter has emerged as a global hub for engaging in online conversations and as a research corpus for various disciplines that have recognized the significance of its user-generated content. Argument mining is an important analytical task for processing and understanding online discourse. Specifically, it aims to identify the structural elements of arguments, denoted as information and inference. These elements, however, are not static and may require context within the conversation they are in, yet there is a lack of data and annotation frameworks addressing this dynamic aspect on Twitter. We contribute TACO, the first dataset of Twitter Arguments utilizing 1,814 tweets covering 200 entire conversations spanning six heterogeneous topics annotated with an agreement of 0.718 Krippendorff's alpha among six experts. Second, we provide our annotation framework, incorporating definitions from the Cambridge Dictionary, to define and identify argument components on Twitter. Our transformer-based classifier achieves an 85.06\\% macro F1 baseline score in detecting arguments. Moreover, our data reveals that Twitter users tend to engage in discussions involving informed inferences and information. TACO serves multiple purposes, such as training tweet classifiers to manage tweets based on inference and information elements, while also providing valuable insights into the conversational reply patterns of tweets."}
{"main_page": "https://arxiv.org/abs/2404.00408", "pdf": "https://arxiv.org/pdf/2404.00408", "title": "Deep Learning with Parametric Lenses", "authors": "Geoffrey S. H. Cruttwell, Bruno Gavranovic, Neil Ghani, Paul Wilson, Fabio Zanasi", "subjects": "Machine Learning (cs.LG); Logic in Computer Science (cs.LO)", "abstract": "We propose a categorical semantics for machine learning algorithms in terms of lenses, parametric maps, and reverse derivative categories. This foundation provides a powerful explanatory and unifying framework: it encompasses a variety of gradient descent algorithms such as ADAM, AdaGrad, and Nesterov momentum, as well as a variety of loss functions such as MSE and Softmax cross-entropy, and different architectures, shedding new light on their similarities and differences. Furthermore, our approach to learning has examples generalising beyond the familiar continuous domains (modelled in categories of smooth maps) and can be realised in the discrete setting of Boolean and polynomial circuits. We demonstrate the practical significance of our framework with an implementation in Python."}
{"main_page": "https://arxiv.org/abs/2404.00409", "pdf": "https://arxiv.org/pdf/2404.00409", "title": "3DGSR: Implicit Surface Reconstruction with 3D Gaussian Splatting", "authors": "Xiaoyang Lyu, Yang-Tian Sun, Yi-Hua Huang, Xiuzhe Wu, Ziyi Yang, Yilun Chen, Jiangmiao Pang, Xiaojuan Qi", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "In this paper, we present an implicit surface reconstruction method with 3D Gaussian Splatting (3DGS), namely 3DGSR, that allows for accurate 3D reconstruction with intricate details while inheriting the high efficiency and rendering quality of 3DGS. The key insight is incorporating an implicit signed distance field (SDF) within 3D Gaussians to enable them to be aligned and jointly optimized. First, we introduce a differentiable SDF-to-opacity transformation function that converts SDF values into corresponding Gaussians' opacities. This function connects the SDF and 3D Gaussians, allowing for unified optimization and enforcing surface constraints on the 3D Gaussians. During learning, optimizing the 3D Gaussians provides supervisory signals for SDF learning, enabling the reconstruction of intricate details. However, this only provides sparse supervisory signals to the SDF at locations occupied by Gaussians, which is insufficient for learning a continuous SDF. Then, to address this limitation, we incorporate volumetric rendering and align the rendered geometric attributes (depth, normal) with those derived from 3D Gaussians. This consistency regularization introduces supervisory signals to locations not covered by discrete 3D Gaussians, effectively eliminating redundant surfaces outside the Gaussian sampling range. Our extensive experimental results demonstrate that our 3DGSR method enables high-quality 3D surface reconstruction while preserving the efficiency and rendering quality of 3DGS. Besides, our method competes favorably with leading surface reconstruction techniques while offering a more efficient learning process and much better rendering qualities. The code will be available at https://github.com/CVMI-Lab/3DGSR."}
{"main_page": "https://arxiv.org/abs/2404.00412", "pdf": "https://arxiv.org/pdf/2404.00412", "title": "SVGCraft: Beyond Single Object Text-to-SVG Synthesis with Comprehensive  Canvas Layout", "authors": "Ayan Banerjee, Nityanand Mathur, Josep Llad\u00f3s, Umapada Pal, Anjan Dutta", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Generating VectorArt from text prompts is a challenging vision task, requiring diverse yet realistic depictions of the seen as well as unseen entities. However, existing research has been mostly limited to the generation of single objects, rather than comprehensive scenes comprising multiple elements. In response, this work introduces SVGCraft, a novel end-to-end framework for the creation of vector graphics depicting entire scenes from textual descriptions. Utilizing a pre-trained LLM for layout generation from text prompts, this framework introduces a technique for producing masked latents in specified bounding boxes for accurate object placement. It introduces a fusion mechanism for integrating attention maps and employs a diffusion U-Net for coherent composition, speeding up the drawing process. The resulting SVG is optimized using a pre-trained encoder and LPIPS loss with opacity modulation to maximize similarity. Additionally, this work explores the potential of primitive shapes in facilitating canvas completion in constrained environments. Through both qualitative and quantitative assessments, SVGCraft is demonstrated to surpass prior works in abstraction, recognizability, and detail, as evidenced by its performance metrics (CLIP-T: 0.4563, Cosine Similarity: 0.6342, Confusion: 0.66, Aesthetic: 6.7832). The code will be available at https://github.com/ayanban011/SVGCraft."}
{"main_page": "https://arxiv.org/abs/2404.00414", "pdf": "https://arxiv.org/pdf/2404.00414", "title": "Chebyshev and The Fast Fourier Transform Methods for Signal  Interpolation", "authors": "Ishmael N. Amartey", "subjects": "Numerical Analysis (math.NA); Signal Processing (eess.SP)", "abstract": "Approximation theorem is one of the most important aspects of numerical analysis that has evolved over the years with many different approaches. Some of the most popular approximation methods include the Lebesgue approximation theorem, the Weierstrass approximation, and the Fourier approximation theorem. The limitations associated with various approximation methods are too crucial to ignore, and thus, the nature of a specific dataset may require using a specific approximation method for such estimates. In this report, we shall delve into Chebyshev's polynomials interpolation in detail as an alternative approach to reconstructing signals and compare the reconstruction to that of the Fourier polynomials. We will also explore the advantages and limitations of the Chebyshev polynomials and discuss in detail their mathematical formulation and equivalence to the cosine function over a given interval [a, b]."}
{"main_page": "https://arxiv.org/abs/2404.00415", "pdf": "https://arxiv.org/pdf/2404.00415", "title": "CoDa: Constrained Generation based Data Augmentation for Low-Resource  NLP", "authors": "Chandra Kiran Reddy Evuru, Sreyan Ghosh, Sonal Kumar, Ramaneswaran S, Utkarsh Tyagi, Dinesh Manocha", "subjects": "Computation and Language (cs.CL)", "abstract": "We present CoDa (Constrained Generation based Data Augmentation), a controllable, effective, and training-free data augmentation technique for low-resource (data-scarce) NLP. Our approach is based on prompting off-the-shelf instruction-following Large Language Models (LLMs) for generating text that satisfies a set of constraints. Precisely, we extract a set of simple constraints from every instance in the low-resource dataset and verbalize them to prompt an LLM to generate novel and diverse training instances. Our findings reveal that synthetic data that follows simple constraints in the downstream dataset act as highly effective augmentations, and CoDa can achieve this without intricate decoding-time constrained generation techniques or fine-tuning with complex algorithms that eventually make the model biased toward the small number of training instances. Additionally, CoDa is the first framework that provides users explicit control over the augmentation generation process, thereby also allowing easy adaptation to several domains. We demonstrate the effectiveness of CoDa across 11 datasets spanning 3 tasks and 3 low-resource settings. CoDa outperforms all our baselines, qualitatively and quantitatively, with improvements of 0.12%-7.19%. Code is available here: https://github.com/Sreyan88/CoDa"}
{"main_page": "https://arxiv.org/abs/2404.00416", "pdf": "https://arxiv.org/pdf/2404.00416", "title": "Circular-arc graphs and the Helly property", "authors": "Jan Derbisz, Tomasz Krawczyk", "subjects": "Data Structures and Algorithms (cs.DS); Discrete Mathematics (cs.DM)", "abstract": "In this paper we investigate some problems related to the Helly properties of circular-arc graphs, which are defined as intersection graphs of arcs of a fixed circle. As such, circular-arc graphs are among the simplest classes of intersection graphs whose models might not satisfy the Helly property. In particular, some cliques of a circular-arc graph might be Helly in some but not all arc intersection models of the graph. Our first result is an alternative proof of a theorem by Lin and Szwarcfiter which asserts that for every circular-arc graph $G$ either every normalized model of $G$ satisfies the Helly property or no normalized model of $G$ satisfies this property. Further, we study the Helly properties of a single clique of a circular-arc graph $G$. We divide the cliques of $G$ into three types: a clique $C$ of $G$ is always-Helly/always-non-Helly/ambiguous if $C$ is Helly in every/no/(some but not all) normalized model of $G$. We provide a combinatorial description for the cliques of each type, and based on it, we devise a polynomial time algorithm which determines the type of a given clique. Finally, we study the Helly Cliques problem, in which we are given an $n$-vertex circular-arc graph $G$ and some of its cliques $C_1, \\ldots, C_k$ and we ask if there is an arc intersection model of $G$ in which all the cliques $C_1, \\ldots, C_k$ satisfy the Helly property. We show that: (1) the Helly Cliques problem admits a $2^{O(k\\log{k})}n^{O(1)}$-time algorithm (that is, it is FPT when parametrized by the number of cliques given in the input), (2) assuming Exponential Time Hypothesis (ETH), the Helly Cliques problem cannot be solved in time $2^{o(k)}n^{O(1)}$, (3) the Helly Cliques problem admits a polynomial kernel of size $O(k^6)$. All our results use a data structure, called a PQM-tree, which maintains all normalized models of a circular-arc graph $G$."}
{"main_page": "https://arxiv.org/abs/2404.00417", "pdf": "https://arxiv.org/pdf/2404.00417", "title": "Orchestrate Latent Expertise: Advancing Online Continual Learning with  Multi-Level Supervision and Reverse Self-Distillation", "authors": "HongWei Yan, Liyuan Wang, Kaisheng Ma, Yi Zhong", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "To accommodate real-world dynamics, artificial intelligence systems need to cope with sequentially arriving content in an online manner. Beyond regular Continual Learning (CL) attempting to address catastrophic forgetting with offline training of each task, Online Continual Learning (OCL) is a more challenging yet realistic setting that performs CL in a one-pass data stream. Current OCL methods primarily rely on memory replay of old training samples. However, a notable gap from CL to OCL stems from the additional overfitting-underfitting dilemma associated with the use of rehearsal buffers: the inadequate learning of new training samples (underfitting) and the repeated learning of a few old training samples (overfitting). To this end, we introduce a novel approach, Multi-level Online Sequential Experts (MOSE), which cultivates the model as stacked sub-experts, integrating multi-level supervision and reverse self-distillation. Supervision signals across multiple stages facilitate appropriate convergence of the new task while gathering various strengths from experts by knowledge distillation mitigates the performance decline of old tasks. MOSE demonstrates remarkable efficacy in learning new samples and preserving past knowledge through multi-level experts, thereby significantly advancing OCL performance over state-of-the-art baselines (e.g., up to 7.3% on Split CIFAR-100 and 6.1% on Split Tiny-ImageNet)."}
{"main_page": "https://arxiv.org/abs/2404.00418", "pdf": "https://arxiv.org/pdf/2404.00418", "title": "Continual Learning for Autonomous Robots: A Prototype-based Approach", "authors": "Elvin Hajizada, Balachandran Swaminathan, Yulia Sandamirskaya", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Humans and animals learn throughout their lives from limited amounts of sensed data, both with and without supervision. Autonomous, intelligent robots of the future are often expected to do the same. The existing continual learning (CL) methods are usually not directly applicable to robotic settings: they typically require buffering and a balanced replay of training data. A few-shot online continual learning (FS-OCL) setting has been proposed to address more realistic scenarios where robots must learn from a non-repeated sparse data stream. To enable truly autonomous life-long learning, an additional challenge of detecting novelties and learning new items without supervision needs to be addressed. We address this challenge with our new prototype-based approach called Continually Learning Prototypes (CLP). In addition to being capable of FS-OCL learning, CLP also detects novel objects and learns them without supervision. To mitigate forgetting, CLP utilizes a novel metaplasticity mechanism that adapts the learning rate individually per prototype. CLP is rehearsal-free, hence does not require a memory buffer, and is compatible with neuromorphic hardware, characterized by ultra-low power consumption, real-time processing abilities, and on-chip learning. Indeed, we have open-sourced a simple version of CLP in the neuromorphic software framework Lava, targetting Intel's neuromorphic chip Loihi 2. We evaluate CLP on a robotic vision dataset, OpenLORIS. In a low-instance FS-OCL scenario, CLP shows state-of-the-art results. In the open world, CLP detects novelties with superior precision and recall and learns features of the detected novel classes without supervision, achieving a strong baseline of 99% base class and 65%/76% (5-shot/10-shot) novel class accuracy."}
{"main_page": "https://arxiv.org/abs/2404.00419", "pdf": "https://arxiv.org/pdf/2404.00419", "title": "Do Vision-Language Models Understand Compound Nouns?", "authors": "Sonal Kumar, Sreyan Ghosh, S Sakshi, Utkarsh Tyagi, Dinesh Manocha", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Open-vocabulary vision-language models (VLMs) like CLIP, trained using contrastive loss, have emerged as a promising new paradigm for text-to-image retrieval. However, do VLMs understand compound nouns (CNs) (e.g., lab coat) as well as they understand nouns (e.g., lab)? We curate Compun, a novel benchmark with 400 unique and commonly used CNs, to evaluate the effectiveness of VLMs in interpreting CNs. The Compun benchmark challenges a VLM for text-to-image retrieval where, given a text prompt with a CN, the task is to select the correct image that shows the CN among a pair of distractor images that show the constituent nouns that make up the CN. Next, we perform an in-depth analysis to highlight CLIPs' limited understanding of certain types of CNs. Finally, we present an alternative framework that moves beyond hand-written templates for text prompts widely used by CLIP-like models. We employ a Large Language Model to generate multiple diverse captions that include the CN as an object in the scene described by the caption. Our proposed method improves CN understanding of CLIP by 8.25% on Compun. Code and benchmark are available at: https://github.com/sonalkum/Compun"}
{"main_page": "https://arxiv.org/abs/2404.00420", "pdf": "https://arxiv.org/pdf/2404.00420", "title": "Learning Service Selection Decision Making Behaviors During Scientific  Workflow Development", "authors": "Xihao Xie, Jia Zhang, Rahul Ramachandran, Tsengdar J. Lee, Seungwon Lee", "subjects": "Software Engineering (cs.SE); Machine Learning (cs.LG)", "abstract": "Increasingly, more software services have been published onto the Internet, making it a big challenge to recommend services in the process of a scientific workflow composition. In this paper, a novel context-aware approach is proposed to recommending next services in a workflow development process, through learning service representation and service selection decision making behaviors from workflow provenance. Inspired by natural language sentence generation, the composition process of a scientific workflow is formalized as a step-wise procedure within the context of the goal of workflow, and the problem of next service recommendation is mapped to next word prediction. Historical service dependencies are first extracted from scientific workflow provenance to build a knowledge graph. Service sequences are then generated based on diverse composition path generation strategies. Afterwards, the generated corpus of composition paths are leveraged to study previous decision making strategies. Such a trained goal-oriented next service prediction model will be used to recommend top K candidate services during workflow composition process. Extensive experiments on a real-word repository have demonstrated the effectiveness of this approach."}
{"main_page": "https://arxiv.org/abs/2404.00423", "pdf": "https://arxiv.org/pdf/2404.00423", "title": "Keep your memory dump shut: Unveiling data leaks in password managers", "authors": "Efstratios Chatzoglou, Vyron Kampourakis, Zisis Tsiatsikas, Georgios Karopoulos, Georgios Kambourakis", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Password management has long been a persistently challenging task. This led to the introduction of password management software, which has been around for at least 25 years in various forms, including desktop and browser-based applications. This work assesses the ability of two dozen password managers, 12 desktop applications, and 12 browser-plugins, to effectively protect the confidentiality of secret credentials in six representative scenarios. Our analysis focuses on the period during which a Password Manager (PM) resides in the RAM. Despite the sensitive nature of these applications, our results show that across all scenarios, only three desktop PM applications and two browser plugins do not store plaintext passwords in the system memory. Oddly enough, at the time of writing, only two vendors recognized the exploit as a vulnerability, reserving CVE-2023-23349, while the rest chose to disregard or underrate the issue."}
{"main_page": "https://arxiv.org/abs/2404.00426", "pdf": "https://arxiv.org/pdf/2404.00426", "title": "Self-Corrective Sensor Fusion for Drone Positioning in Indoor Facilities", "authors": "Francisco Javier Gonz\u00e1lez-Casta\u00f1o, Felipe Gil-Casti\u00f1eira, David Rodr\u00edguez-Pereira, Jos\u00e9 \u00c1ngel Regueiro-Janeiro, Silvia Garc\u00eda-M\u00e9ndez, David Candal-Ventureira", "subjects": "Robotics (cs.RO); Signal Processing (eess.SP)", "abstract": "Drones may be more advantageous than fixed cameras for quality control applications in industrial facilities, since they can be redeployed dynamically and adjusted to production planning. The practical scenario that has motivated this paper, image acquisition with drones in a car manufacturing plant, requires drone positioning accuracy in the order of 5 cm. During repetitive manufacturing processes, it is assumed that quality control imaging drones will follow highly deterministic periodic paths, stop at predefined points to take images and send them to image recognition servers. Therefore, by relying on prior knowledge about production chain schedules, it is possible to optimize the positioning technologies for the drones to stay at all times within the boundaries of their flight plans, which will be composed of stopping points and the paths in between. This involves mitigating issues such as temporary blocking of line-of-sight between the drone and any existing radio beacons; sensor data noise; and the loss of visual references. We present a self-corrective solution for this purpose. It corrects visual odometer readings based on filtered and clustered Ultra-Wide Band (UWB) data, as an alternative to direct Kalman fusion. The approach combines the advantages of these technologies when at least one of them works properly at any measurement spot. It has three method components: independent Kalman filtering, data association by means of stream clustering and mutual correction of sensor readings based on the generation of cumulative correction vectors. The approach is inspired by the observation that UWB positioning works reasonably well at static spots whereas visual odometer measurements reflect straight displacements correctly but can underestimate their length. Our experimental results demonstrate the advantages of the approach in the application scenario over Kalman fusion."}
{"main_page": "https://arxiv.org/abs/2404.00427", "pdf": "https://arxiv.org/pdf/2404.00427", "title": "Extracting Manifold Information from Point Clouds", "authors": "Patrick Guidotti", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computational Geometry (cs.CG); Numerical Analysis (math.NA)", "abstract": "A kernel based method is proposed for the construction of signature (defining) functions of subsets of $\\mathbb{R}^d$. The subsets can range from full dimensional manifolds (open subsets) to point clouds (a finite number of points) and include bounded smooth manifolds of any codimension. The interpolation and analysis of point clouds are the main application. Two extreme cases in terms of regularity are considered, where the data set is interpolated by an analytic surface, at the one extreme, and by a H\\\"older continuous surface, at the other. The signature function can be computed as a linear combination of translated kernels, the coefficients of which are the solution of a finite dimensional linear problem. Once it is obtained, it can be used to estimate the dimension as well as the normal and the curvatures of the interpolated surface. The method is global and does not require explicit knowledge of local neighborhoods or any other structure present in the data set. It admits a variational formulation with a natural ``regularized'' counterpart, that proves to be useful in dealing with data sets corrupted by numerical error or noise. The underlying analytical structure of the approach is presented in general before it is applied to the case of point clouds."}
{"main_page": "https://arxiv.org/abs/2404.00429", "pdf": "https://arxiv.org/pdf/2404.00429", "title": "Multiway Point Cloud Mosaicking with Diffusion and Global Optimization", "authors": "Shengze Jin (Department of Computer Science, ETH Zurich, Switzerland), Iro Armeni (Department of Civil and Environmental Engineering, Stanford University), Marc Pollefeys (Department of Computer Science, ETH Zurich, Switzerland and Microsoft Mixed Reality & AI Lab, Zurich, Switzerland), Daniel Barath (Department of Computer Science, ETH Zurich, Switzerland)", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We introduce a novel framework for multiway point cloud mosaicking (named Wednesday), designed to co-align sets of partially overlapping point clouds -- typically obtained from 3D scanners or moving RGB-D cameras -- into a unified coordinate system. At the core of our approach is ODIN, a learned pairwise registration algorithm that iteratively identifies overlaps and refines attention scores, employing a diffusion-based process for denoising pairwise correlation matrices to enhance matching accuracy. Further steps include constructing a pose graph from all point clouds, performing rotation averaging, a novel robust algorithm for re-estimating translations optimally in terms of consensus maximization and translation optimization. Finally, the point cloud rotations and positions are optimized jointly by a diffusion-based approach. Tested on four diverse, large-scale datasets, our method achieves state-of-the-art pairwise and multiway registration results by a large margin on all benchmarks. Our code and models are available at https://github.com/jinsz/Multiway-Point-Cloud-Mosaicking-with-Diffusion-and-Global-Optimization."}
{"main_page": "https://arxiv.org/abs/2404.00431", "pdf": "https://arxiv.org/pdf/2404.00431", "title": "Visualizing Routes with AI-Discovered Street-View Patterns", "authors": "Tsung Heng Wu, Md Amiruzzaman, Ye Zhao, Deepshikha Bhati, Jing Yang", "subjects": "Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "abstract": "Street-level visual appearances play an important role in studying social systems, such as understanding the built environment, driving routes, and associated social and economic factors. It has not been integrated into a typical geographical visualization interface (e.g., map services) for planning driving routes. In this paper, we study this new visualization task with several new contributions. First, we experiment with a set of AI techniques and propose a solution of using semantic latent vectors for quantifying visual appearance features. Second, we calculate image similarities among a large set of street-view images and then discover spatial imagery patterns. Third, we integrate these discovered patterns into driving route planners with new visualization techniques. Finally, we present VivaRoutes, an interactive visualization prototype, to show how visualizations leveraged with these discovered patterns can help users effectively and interactively explore multiple routes. Furthermore, we conducted a user study to assess the usefulness and utility of VivaRoutes."}
{"main_page": "https://arxiv.org/abs/2404.00434", "pdf": "https://arxiv.org/pdf/2404.00434", "title": "On Accessibility Fairness in Intermodal Autonomous Mobility-on-Demand  Systems", "authors": "Mauro Salazar, Sara Betancour Giraldo, Fabio Paparella, Leonardo Pedroso", "subjects": "Systems and Control (eess.SY)", "abstract": "Research on the operation of mobility systems so far has mostly focused on minimizing cost-centered metrics such as average travel time, distance driven, and operational costs. Whilst capturing economic indicators, such metrics do not account for transportation justice aspects. In this paper, we present an optimization model to plan the operation of Intermodal Autonomous Mobility-on-Demand (I-AMoD) systems, where self-driving vehicles provide on-demand mobility jointly with public transit and active modes, with the goal to minimize the accessibility unfairness experienced by the population. Specifically, we first leverage a previously developed network flow model to compute the I-AMoD system operation in a minimum-time manner. Second, we formally define accessibility unfairness, and use it to frame the maximum-accessibility-fairness problem and cast it as a linear program. We showcase our framework for a real-world case-study in the city of Eindhoven, NL. Our results show that it is possible to reach an operation that is on average fully fair at the cost of a slight travel time increase compared to a minimum-travel-time solution. Thereby we observe that the accessibility fairness of individual paths is, on average, worse than the average values obtained from flows, setting the stage for a discussion on the definition of accessibility fairness itself."}
{"main_page": "https://arxiv.org/abs/2404.00437", "pdf": "https://arxiv.org/pdf/2404.00437", "title": "Automatic explanation of the classification of Spanish legal judgments  in jurisdiction-dependent law categories with tree estimators", "authors": "Jaime Gonz\u00e1lez-Gonz\u00e1lez, Francisco de Arriba-P\u00e9rez, Silvia Garc\u00eda-M\u00e9ndez, Andrea Busto-Casti\u00f1eira, Francisco J. Gonz\u00e1lez-Casta\u00f1o", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Automatic legal text classification systems have been proposed in the literature to address knowledge extraction from judgments and detect their aspects. However, most of these systems are black boxes even when their models are interpretable. This may raise concerns about their trustworthiness. Accordingly, this work contributes with a system combining Natural Language Processing (NLP) with Machine Learning (ML) to classify legal texts in an explainable manner. We analyze the features involved in the decision and the threshold bifurcation values of the decision paths of tree structures and present this information to the users in natural language. This is the first work on automatic analysis of legal texts combining NLP and ML along with Explainable Artificial Intelligence techniques to automatically make the models' decisions understandable to end users. Furthermore, legal experts have validated our solution, and this knowledge has also been incorporated into the explanation process as \"expert-in-the-loop\" dictionaries. Experimental results on an annotated data set in law categories by jurisdiction demonstrate that our system yields competitive classification performance, with accuracy values well above 90%, and that its automatic explanations are easily understandable even to non-expert users."}
{"main_page": "https://arxiv.org/abs/2404.00438", "pdf": "https://arxiv.org/pdf/2404.00438", "title": "Communication Efficient Distributed Training with Distributed Lion", "authors": "Bo Liu, Lemeng Wu, Lizhang Chen, Kaizhao Liang, Jiaxu Zhu, Chen Liang, Raghuraman Krishnamoorthi, Qiang Liu", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)", "abstract": "The Lion optimizer has been a promising competitor with the AdamW for training large AI models, with advantages on memory, computation, and sample efficiency. In this paper, we introduce Distributed Lion, an innovative adaptation of Lion for distributed training environments. Leveraging the sign operator in Lion, our Distributed Lion only requires communicating binary or lower-precision vectors between workers to the center server, significantly reducing the communication cost. Our theoretical analysis confirms Distributed Lion's convergence properties. Empirical results demonstrate its robustness across a range of tasks, worker counts, and batch sizes, on both vision and language problems. Notably, Distributed Lion attains comparable performance to standard Lion or AdamW optimizers applied on aggregated gradients, but with significantly reduced communication bandwidth. This feature is particularly advantageous for training large models. In addition, we also demonstrate that Distributed Lion presents a more favorable performance-bandwidth balance compared to existing efficient distributed methods such as deep gradient compression and ternary gradients."}
{"main_page": "https://arxiv.org/abs/2404.00439", "pdf": "https://arxiv.org/pdf/2404.00439", "title": "DOCMASTER: A Unified Platform for Annotation, Training, & Inference in  Document Question-Answering", "authors": "Alex Nguyen, Zilong Wang, Jingbo Shang, Dheeraj Mekala", "subjects": "Computation and Language (cs.CL)", "abstract": "The application of natural language processing models to PDF documents is pivotal for various business applications yet the challenge of training models for this purpose persists in businesses due to specific hurdles. These include the complexity of working with PDF formats that necessitate parsing text and layout information for curating training data and the lack of privacy-preserving annotation tools. This paper introduces DOCMASTER, a unified platform designed for annotating PDF documents, model training, and inference, tailored to document question-answering. The annotation interface enables users to input questions and highlight text spans within the PDF file as answers, saving layout information and text spans accordingly. Furthermore, DOCMASTER supports both state-of-the-art layout-aware and text models for comprehensive training purposes. Importantly, as annotations, training, and inference occur on-device, it also safeguards privacy. The platform has been instrumental in driving several research prototypes concerning document analysis such as the AI assistant utilized by University of California San Diego's (UCSD) International Services and Engagement Office (ISEO) for processing a substantial volume of PDF documents."}
{"main_page": "https://arxiv.org/abs/2404.00441", "pdf": "https://arxiv.org/pdf/2404.00441", "title": "CCWSIM: An Efficient and Fast Wavelet-Based CCSIM for Categorical  Characterization of Large-Scale", "authors": "Mojtaba Bavandsavadkoohi, Erwan Gloaguen, Behzad Tokhmechi, Alireza Arab-Amiri, Bernard Giroux", "subjects": "Graphics (cs.GR)", "abstract": "Over the last couple of decades, there has been a surge in various approaches to multiple-point statistics simulation, commonly referred to as MPS. These methods have aimed to improve several critical aspects of realism in the results, including spatial continuity, conditioning, stochasticity, and computational efficiency. Nevertheless, achieving a simultaneous enhancement of these crucial factors has presented challenges to researchers. In the approach that we propose, CCSIM is combined with the Discrete Wavelet Transform (DWT) to address some of these concerns. The primary step in the method involves the computation of the DWT for both the Training Image (TI) and a region shared with previously simulated grids at a specific level of wavelet decomposition. Then, the degree of similarity between the wavelet approximation coefficients is measured using a Cross-Correlation Function (CCF). These approximation coefficients offer a compressed representation of the pattern while capturing its primary variations and essential characteristics, thereby expediting the search for the best-matched pattern. Once the best-matched pattern in the wavelet approximation coefficients is identified, the original pattern can be perfectly reconstructed by integrating the DWT detail coefficients through an Inverse-DWT transformation. Experiments conducted across diverse categorical TIs demonstrate simulations comparable to multi-scale CCSIM (MS-CCSIM), accompanied by an enhancement in facies connectivity and pattern reproduction. The source code implementations are available at https://github.com/MBS1984/CCWSIM."}
{"main_page": "https://arxiv.org/abs/2404.00442", "pdf": "https://arxiv.org/pdf/2404.00442", "title": "Interactive Multi-Robot Flocking with Gesture Responsiveness and Musical  Accompaniment", "authors": "Catie Cuan, Kyle Jeffrey, Kim Kleiven, Adrian Li, Emre Fisher, Matt Harrison, Benjie Holson, Allison Okamura, Matt Bennice", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "abstract": "For decades, robotics researchers have pursued various tasks for multi-robot systems, from cooperative manipulation to search and rescue. These tasks are multi-robot extensions of classical robotic tasks and often optimized on dimensions such as speed or efficiency. As robots transition from commercial and research settings into everyday environments, social task aims such as engagement or entertainment become increasingly relevant. This work presents a compelling multi-robot task, in which the main aim is to enthrall and interest. In this task, the goal is for a human to be drawn to move alongside and participate in a dynamic, expressive robot flock. Towards this aim, the research team created algorithms for robot movements and engaging interaction modes such as gestures and sound. The contributions are as follows: (1) a novel group navigation algorithm involving human and robot agents, (2) a gesture responsive algorithm for real-time, human-robot flocking interaction, (3) a weight mode characterization system for modifying flocking behavior, and (4) a method of encoding a choreographer's preferences inside a dynamic, adaptive, learned system. An experiment was performed to understand individual human behavior while interacting with the flock under three conditions: weight modes selected by a human choreographer, a learned model, or subset list. Results from the experiment showed that the perception of the experience was not influenced by the weight mode selection. This work elucidates how differing task aims such as engagement manifest in multi-robot system design and execution, and broadens the domain of multi-robot tasks."}
{"main_page": "https://arxiv.org/abs/2404.00443", "pdf": "https://arxiv.org/pdf/2404.00443", "title": "UDE-based Dynamic Motion Force Control of Mobile Manipulators", "authors": "Songqun Gao, Wendi Ding, Qinyuan Ren, Ben M. Chen", "subjects": "Robotics (cs.RO)", "abstract": "Mobile manipulators are known for their superior mobility over manipulators on fixed bases, offering promising applications in smart industry and housekeeping scenarios. However, the dynamic coupling nature between the mobile base and the manipulator presents challenges for the physical interactive tasks of the mobile manipulator. Current methods suffer from complex modeling processes and poor transferability. To address this, this article presents a novel dynamic model of the manipulator on the mobile base that requires only the manipulator dynamics and the kinematic information of the mobile base. In addition, embedding the dynamic model, an uncertainty and disturbance estimator-based (UDE-based) dynamic motion/force control scheme is proposed for the mobile manipulator, which compensates for the dynamic coupling and other unmodeled uncertainties. Passivity and stability analyses justify the proposed control law. Simulation and experimental results on our mobile manipulator platform demonstrate the feasibility and effectiveness of our proposed methodology."}
{"main_page": "https://arxiv.org/abs/2404.00446", "pdf": "https://arxiv.org/pdf/2404.00446", "title": "Towards a semantic characterisation of global type well-formedness", "authors": "Ilaria Castellani, Paola Giannini", "subjects": "Logic in Computer Science (cs.LO)", "abstract": "We address the question of characterising the well-formedness properties of multiparty session types semantically, i.e., as properties of the semantic model used to interpret types. Choosing Prime Event Structures (PESs) as our semantic model, we present semantic counterparts for the two properties that underpin global type well-formedness, namely projectability and boundedness, in this model. As a first step towards a characterisation of the class of PESs corresponding to well-formed global types, we identify some simple structural properties satisfied by such PESs."}
{"main_page": "https://arxiv.org/abs/2404.00447", "pdf": "https://arxiv.org/pdf/2404.00447", "title": "Synthetic Dataset Generation and Learning From Demonstration Applied to  Industrial Manipulation", "authors": "Alireza Barekatain, Hamed Rahimi Nohooji, Holger Voos", "subjects": "Robotics (cs.RO)", "abstract": "The aim of this study is to investigate an automated industrial manipulation pipeline, where assembly tasks can be flexibly adapted to production without the need for a robotic expert, both for the vision system and the robot program. The objective of this study is first, to develop a synthetic-dataset-generation pipeline with a special focus on industrial parts, and second, to use Learning-from-Demonstration (LfD) methods to replace manual robot programming, so that a non-robotic expert/process engineer can introduce a new manipulation task by teaching it to the robot."}
{"main_page": "https://arxiv.org/abs/2404.00450", "pdf": "https://arxiv.org/pdf/2404.00450", "title": "Planning and Editing What You Retrieve for Enhanced Tool Learning", "authors": "Tenghao Huang, Dongwon Jung, Muhao Chen", "subjects": "Computation and Language (cs.CL)", "abstract": "Recent advancements in integrating external tools with Large Language Models (LLMs) have opened new frontiers, with applications in mathematical reasoning, code generators, and smart assistants. However, existing methods, relying on simple one-time retrieval strategies, fall short on effectively and accurately shortlisting relevant tools. This paper introduces a novel \\modelname (\\modelmeaning) approach, encompassing ``Plan-and-Retrieve (P\\&R)'' and ``Edit-and-Ground (E\\&G)'' paradigms. The P\\&R paradigm consists of a neural retrieval module for shortlisting relevant tools and an LLM-based query planner that decomposes complex queries into actionable tasks, enhancing the effectiveness of tool utilization. The E\\&G paradigm utilizes LLMs to enrich tool descriptions based on user scenarios, bridging the gap between user queries and tool functionalities. Experiment results demonstrate that these paradigms significantly improve the recall and NDCG in tool retrieval tasks, significantly surpassing current state-of-the-art models."}
{"main_page": "https://arxiv.org/abs/2404.00451", "pdf": "https://arxiv.org/pdf/2404.00451", "title": "Thin-Shell Object Manipulations With Differentiable Physics Simulations", "authors": "Yian Wang, Juntian Zheng, Zhehuan Chen, Zhou Xian, Gu Zhang, Chao Liu, Chuang Gan", "subjects": "Robotics (cs.RO)", "abstract": "In this work, we aim to teach robots to manipulate various thin-shell materials. Prior works studying thin-shell object manipulation mostly rely on heuristic policies or learn policies from real-world video demonstrations, and only focus on limited material types and tasks (e.g., cloth unfolding). However, these approaches face significant challenges when extended to a wider variety of thin-shell materials and a diverse range of tasks. While virtual simulations are shown to be effective in diverse robot skill learning and evaluation, prior thin-shell simulation environments only support a subset of thin-shell materials, which also limits their supported range of tasks. We introduce ThinShellLab - a fully differentiable simulation platform tailored for robotic interactions with diverse thin-shell materials possessing varying material properties, enabling flexible thin-shell manipulation skill learning and evaluation. Our experiments suggest that manipulating thin-shell objects presents several unique challenges: 1) thin-shell manipulation relies heavily on frictional forces due to the objects' co-dimensional nature, 2) the materials being manipulated are highly sensitive to minimal variations in interaction actions, and 3) the constant and frequent alteration in contact pairs makes trajectory optimization methods susceptible to local optima, and neither standard reinforcement learning algorithms nor trajectory optimization methods (either gradient-based or gradient-free) are able to solve the tasks alone. To overcome these challenges, we present an optimization scheme that couples sampling-based trajectory optimization and gradient-based optimization, boosting both learning efficiency and converged performance across various proposed tasks. In addition, the differentiable nature of our platform facilitates a smooth sim-to-real transition."}
{"main_page": "https://arxiv.org/abs/2404.00456", "pdf": "https://arxiv.org/pdf/2404.00456", "title": "QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs", "authors": "Saleh Ashkboos, Amirkeivan Mohtashami, Maximilian L. Croci, Bo Li, Martin Jaggi, Dan Alistarh, Torsten Hoefler, James Hensman", "subjects": "Machine Learning (cs.LG)", "abstract": "We introduce QuaRot, a new Quantization scheme based on Rotations, which is able to quantize LLMs end-to-end, including all weights, activations, and KV cache in 4 bits. QuaRot rotates LLMs in a way that removes outliers from the hidden state without changing the output, making quantization easier. This computational invariance is applied to the hidden state (residual) of the LLM, as well as to the activations of the feed-forward components, aspects of the attention mechanism and to the KV cache. The result is a quantized model where all matrix multiplications are performed in 4-bits, without any channels identified for retention in higher precision. Our quantized LLaMa2-70B model has losses of at most 0.29 WikiText-2 perplexity and retains 99% of the zero-shot performance. Code is available at: https://github.com/spcl/QuaRot."}
{"main_page": "https://arxiv.org/abs/2404.00457", "pdf": "https://arxiv.org/pdf/2404.00457", "title": "MetaIE: Distilling a Meta Model from LLM for All Kinds of Information  Extraction Tasks", "authors": "Letian Peng, Zilong Wang, Feng Yao, Zihan Wang, Jingbo Shang", "subjects": "Computation and Language (cs.CL)", "abstract": "Information extraction (IE) is a fundamental area in natural language processing where prompting large language models (LLMs), even with in-context examples, cannot defeat small LMs tuned on very small IE datasets. We observe that IE tasks, such as named entity recognition and relation extraction, all focus on extracting important information, which can be formalized as a label-to-span matching. In this paper, we propose a novel framework MetaIE to build a small LM as meta-model by learning to extract \"important information\", i.e., the meta-understanding of IE, so that this meta-model can be adapted to all kind of IE tasks effectively and efficiently. Specifically, MetaIE obtains the small LM via a symbolic distillation from an LLM following the label-to-span scheme. We construct the distillation dataset via sampling sentences from language model pre-training datasets (e.g., OpenWebText in our implementation) and prompting an LLM to identify the typed spans of \"important information\". We evaluate the meta-model under the few-shot adaptation setting. Extensive results on 13 datasets from 6 IE tasks confirm that MetaIE can offer a better starting point for few-shot tuning on IE datasets and outperform other meta-models from (1) vanilla language model pre-training, (2) multi-IE-task pre-training with human annotations, and (3) single-IE-task symbolic distillation from LLM. Moreover, we provide comprehensive analyses of MetaIE, such as the size of the distillation dataset, the meta-model architecture, and the size of the meta-model."}
{"main_page": "https://arxiv.org/abs/2404.00458", "pdf": "https://arxiv.org/pdf/2404.00458", "title": "Beyond One-Size-Fits-All: Multi-Domain, Multi-Task Framework for  Embedding Model Selection", "authors": "Vivek Khetan", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "This position paper proposes a systematic approach towards developing a framework to help select the most effective embedding models for natural language processing (NLP) tasks, addressing the challenge posed by the proliferation of both proprietary and open-source encoder models."}
{"main_page": "https://arxiv.org/abs/2404.00459", "pdf": "https://arxiv.org/pdf/2404.00459", "title": "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning", "authors": "Eli Schwartz, Leshem Choshen, Joseph Shtok, Sivan Doveh, Leonid Karlinsky, Assaf Arbelle", "subjects": "Computation and Language (cs.CL)", "abstract": "Language models struggle with handling numerical data and performing arithmetic operations. We hypothesize that this limitation can be partially attributed to non-intuitive textual numbers representation. When a digit is read or generated by a causal language model it does not know its place value (e.g. thousands vs. hundreds) until the entire number is processed. To address this issue, we propose a simple adjustment to how numbers are represented by including the count of digits before each number. For instance, instead of \"42\", we suggest using \"{2:42}\" as the new format. This approach, which we term NumeroLogic, offers an added advantage in number generation by serving as a Chain of Thought (CoT). By requiring the model to consider the number of digits first, it enhances the reasoning process before generating the actual number. We use arithmetic tasks to demonstrate the effectiveness of the NumeroLogic formatting. We further demonstrate NumeroLogic applicability to general natural language modeling, improving language understanding performance in the MMLU benchmark."}
{"main_page": "https://arxiv.org/abs/2404.00461", "pdf": "https://arxiv.org/pdf/2404.00461", "title": "Shortcuts Arising from Contrast: Effective and Covert Clean-Label  Attacks in Prompt-Based Learning", "authors": "Xiaopeng Xie, Ming Yan, Xiwen Zhou, Chenlong Zhao, Suli Wang, Yong Zhang, Joey Tianyi Zhou", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "abstract": "Prompt-based learning paradigm has demonstrated remarkable efficacy in enhancing the adaptability of pretrained language models (PLMs), particularly in few-shot scenarios. However, this learning paradigm has been shown to be vulnerable to backdoor attacks. The current clean-label attack, employing a specific prompt as a trigger, can achieve success without the need for external triggers and ensure correct labeling of poisoned samples, which is more stealthy compared to the poisoned-label attack, but on the other hand, it faces significant issues with false activations and poses greater challenges, necessitating a higher rate of poisoning. Using conventional negative data augmentation methods, we discovered that it is challenging to trade off between effectiveness and stealthiness in a clean-label setting. In addressing this issue, we are inspired by the notion that a backdoor acts as a shortcut and posit that this shortcut stems from the contrast between the trigger and the data utilized for poisoning. In this study, we propose a method named Contrastive Shortcut Injection (CSI), by leveraging activation values, integrates trigger design and data selection strategies to craft stronger shortcut features. With extensive experiments on full-shot and few-shot text classification tasks, we empirically validate CSI's high effectiveness and high stealthiness at low poisoning rates. Notably, we found that the two approaches play leading roles in full-shot and few-shot settings, respectively."}
{"main_page": "https://arxiv.org/abs/2404.00462", "pdf": "https://arxiv.org/pdf/2404.00462", "title": "Zero-shot Safety Prediction for Autonomous Robots with Foundation World  Models", "authors": "Zhenjiang Mao, Siqi Dai, Yuang Geng, Ivan Ruchkin", "subjects": "Machine Learning (cs.LG); Robotics (cs.RO)", "abstract": "A world model creates a surrogate world to train a controller and predict safety violations by learning the internal dynamic model of systems. However, the existing world models rely solely on statistical learning of how observations change in response to actions, lacking precise quantification of how accurate the surrogate dynamics are, which poses a significant challenge in safety-critical systems. To address this challenge, we propose foundation world models that embed observations into meaningful and causally latent representations. This enables the surrogate dynamics to directly predict causal future states by leveraging a training-free large language model. In two common benchmarks, this novel model outperforms standard world models in the safety prediction task and has a performance comparable to supervised learning despite not using any data. We evaluate its performance with a more specialized and system-relevant metric by comparing estimated states instead of aggregating observation-wide error."}
{"main_page": "https://arxiv.org/abs/2404.00463", "pdf": "https://arxiv.org/pdf/2404.00463", "title": "Addressing Both Statistical and Causal Gender Fairness in NLP Models", "authors": "Hannah Chen, Yangfeng Ji, David Evans", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Statistical fairness stipulates equivalent outcomes for every protected group, whereas causal fairness prescribes that a model makes the same prediction for an individual regardless of their protected characteristics. Counterfactual data augmentation (CDA) is effective for reducing bias in NLP models, yet models trained with CDA are often evaluated only on metrics that are closely tied to the causal fairness notion; similarly, sampling-based methods designed to promote statistical fairness are rarely evaluated for causal fairness. In this work, we evaluate both statistical and causal debiasing methods for gender bias in NLP models, and find that while such methods are effective at reducing bias as measured by the targeted metric, they do not necessarily improve results on other bias metrics. We demonstrate that combinations of statistical and causal debiasing techniques are able to reduce bias measured through both types of metrics."}
{"main_page": "https://arxiv.org/abs/2404.00464", "pdf": "https://arxiv.org/pdf/2404.00464", "title": "Leveraging Pre-trained and Transformer-derived Embeddings from EHRs to  Characterize Heterogeneity Across Alzheimer's Disease and Related Dementias", "authors": "Matthew West, Colin Magdamo, Lily Cheng, Yingnan He, Sudeshna Das", "subjects": "Machine Learning (cs.LG)", "abstract": "Alzheimer's disease is a progressive, debilitating neurodegenerative disease that affects 50 million people globally. Despite this substantial health burden, available treatments for the disease are limited and its fundamental causes remain poorly understood. Previous work has suggested the existence of clinically-meaningful sub-types, which it is suggested may correspond to distinct etiologies, disease courses, and ultimately appropriate treatments. Here, we use unsupervised learning techniques on electronic health records (EHRs) from a cohort of memory disorder patients to characterise heterogeneity in this disease population. Pre-trained embeddings for medical codes as well as transformer-derived Clinical BERT embeddings of free text are used to encode patient EHRs. We identify the existence of sub-populations on the basis of comorbidities and shared textual features, and discuss their clinical significance."}
{"main_page": "https://arxiv.org/abs/2404.00466", "pdf": "https://arxiv.org/pdf/2404.00466", "title": "Computation and Communication Efficient Lightweighting Vertical  Federated Learning", "authors": "Heqiang Wang, Jieming Bian, Lei Wang", "subjects": "Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "The exploration of computational and communication efficiency within Federated Learning (FL) has emerged as a prominent and crucial field of study. While most existing efforts to enhance these efficiencies have focused on Horizontal FL, the distinct processes and model structures of Vertical FL preclude the direct application of Horizontal FL-based techniques. In response, we introduce the concept of Lightweight Vertical Federated Learning (LVFL), targeting both computational and communication efficiencies. This approach involves separate lightweighting strategies for the feature model, to improve computational efficiency, and for feature embedding, to enhance communication efficiency. Moreover, we establish a convergence bound for our LVFL algorithm, which accounts for both communication and computational lightweighting ratios. Our evaluation of the algorithm on a image classification dataset reveals that LVFL significantly alleviates computational and communication demands while preserving robust learning performance. This work effectively addresses the gaps in communication and computational efficiency within Vertical FL."}
{"main_page": "https://arxiv.org/abs/2404.00469", "pdf": "https://arxiv.org/pdf/2404.00469", "title": "SceneGraphLoc: Cross-Modal Coarse Visual Localization on 3D Scene Graphs", "authors": "Yang Miao, Francis Engelmann, Olga Vysotska, Federico Tombari, Marc Pollefeys, D\u00e1niel B\u00e9la Bar\u00e1th", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We introduce a novel problem, i.e., the localization of an input image within a multi-modal reference map represented by a database of 3D scene graphs. These graphs comprise multiple modalities, including object-level point clouds, images, attributes, and relationships between objects, offering a lightweight and efficient alternative to conventional methods that rely on extensive image databases. Given the available modalities, the proposed method SceneGraphLoc learns a fixed-sized embedding for each node (i.e., representing an object instance) in the scene graph, enabling effective matching with the objects visible in the input query image. This strategy significantly outperforms other cross-modal methods, even without incorporating images into the map embeddings. When images are leveraged, SceneGraphLoc achieves performance close to that of state-of-the-art techniques depending on large image databases, while requiring three orders-of-magnitude less storage and operating orders-of-magnitude faster. The code will be made public."}
{"main_page": "https://arxiv.org/abs/2404.00470", "pdf": "https://arxiv.org/pdf/2404.00470", "title": "Classification of Short Segment Pediatric Heart Sounds Based on a  Transformer-Based Convolutional Neural Network", "authors": "Md Hassanuzzaman, Nurul Akhtar Hasan, Mohammad Abdullah Al Mamun, Khawza I Ahmed, Ahsan H Khandoker, Raqibul Mostafa", "subjects": "Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)", "abstract": "Congenital anomalies arising as a result of a defect in the structure of the heart and great vessels are known as congenital heart diseases or CHDs. A PCG can provide essential details about the mechanical conduction system of the heart and point out specific patterns linked to different kinds of CHD. This study aims to investigate the minimum signal duration required for the automatic classification of heart sounds. This study also investigated the optimum signal quality assessment indicator (Root Mean Square of Successive Differences) RMSSD and (Zero Crossings Rate) ZCR value. Mel-frequency cepstral coefficients (MFCCs) based feature is used as an input to build a Transformer-Based residual one-dimensional convolutional neural network, which is then used for classifying the heart sound. The study showed that 0.4 is the ideal threshold for getting suitable signals for the RMSSD and ZCR indicators. Moreover, a minimum signal length of 5s is required for effective heart sound classification. It also shows that a shorter signal (3 s heart sound) does not have enough information to categorize heart sounds accurately, and the longer signal (15 s heart sound) may contain more noise. The best accuracy, 93.69%, is obtained for the 5s signal to distinguish the heart sound."}
{"main_page": "https://arxiv.org/abs/2404.00473", "pdf": "https://arxiv.org/pdf/2404.00473", "title": "Privacy Backdoors: Stealing Data with Corrupted Pretrained Models", "authors": "Shanglun Feng, Florian Tram\u00e8r", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "Practitioners commonly download pretrained machine learning models from open repositories and finetune them to fit specific applications. We show that this practice introduces a new risk of privacy backdoors. By tampering with a pretrained model's weights, an attacker can fully compromise the privacy of the finetuning data. We show how to build privacy backdoors for a variety of models, including transformers, which enable an attacker to reconstruct individual finetuning samples, with a guaranteed success! We further show that backdoored models allow for tight privacy attacks on models trained with differential privacy (DP). The common optimistic practice of training DP models with loose privacy guarantees is thus insecure if the model is not trusted. Overall, our work highlights a crucial and overlooked supply chain attack on machine learning privacy."}
{"main_page": "https://arxiv.org/abs/2404.00474", "pdf": "https://arxiv.org/pdf/2404.00474", "title": "Linguistic Calibration of Language Models", "authors": "Neil Band, Xuechen Li, Tengyu Ma, Tatsunori Hashimoto", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)", "abstract": "Language models (LMs) may lead their users to make suboptimal downstream decisions when they confidently hallucinate. This issue can be mitigated by having the LM verbally convey the probability that its claims are correct, but existing models cannot produce text with calibrated confidence statements. Through the lens of decision-making, we formalize linguistic calibration for long-form generations: an LM is linguistically calibrated if its generations enable its users to make calibrated probabilistic predictions. This definition enables a training framework where a supervised finetuning step bootstraps an LM to emit long-form generations with confidence statements such as \"I estimate a 30% chance of...\" or \"I am certain that...\", followed by a reinforcement learning step which rewards generations that enable a user to provide calibrated answers to related questions. We linguistically calibrate Llama 2 7B and find in automated and human evaluations of long-form generations that it is significantly more calibrated than strong finetuned factuality baselines with comparable accuracy. These findings generalize under distribution shift on question-answering and under a significant task shift to person biography generation. Our results demonstrate that long-form generations may be calibrated end-to-end by constructing an objective in the space of the predictions that users make in downstream decision-making."}
{"main_page": "https://arxiv.org/abs/2404.00477", "pdf": "https://arxiv.org/pdf/2404.00477", "title": "DE-HNN: An effective neural model for Circuit Netlist representation", "authors": "Zhishang Luo, Truong Son Hy, Puoya Tabaghi, Donghyeon Koh, Michael Defferrard, Elahe Rezaei, Ryan Carey, Rhett Davis, Rajeev Jain, Yusu Wang", "subjects": "Machine Learning (cs.LG); Hardware Architecture (cs.AR)", "abstract": "The run-time for optimization tools used in chip design has grown with the complexity of designs to the point where it can take several days to go through one design cycle which has become a bottleneck. Designers want fast tools that can quickly give feedback on a design. Using the input and output data of the tools from past designs, one can attempt to build a machine learning model that predicts the outcome of a design in significantly shorter time than running the tool. The accuracy of such models is affected by the representation of the design data, which is usually a netlist that describes the elements of the digital circuit and how they are connected. Graph representations for the netlist together with graph neural networks have been investigated for such models. However, the characteristics of netlists pose several challenges for existing graph learning frameworks, due to the large number of nodes and the importance of long-range interactions between nodes. To address these challenges, we represent the netlist as a directed hypergraph and propose a Directional Equivariant Hypergraph Neural Network (DE-HNN) for the effective learning of (directed) hypergraphs. Theoretically, we show that our DE-HNN can universally approximate any node or hyperedge based function that satisfies certain permutation equivariant and invariant properties natural for directed hypergraphs. We compare the proposed DE-HNN with several State-of-the-art (SOTA) machine learning models for (hyper)graphs and netlists, and show that the DE-HNN significantly outperforms them in predicting the outcome of optimized place-and-route tools directly from the input netlists. Our source code and the netlists data used are publicly available at https://github.com/YusuLab/chips.git"}
{"main_page": "https://arxiv.org/abs/2404.00478", "pdf": "https://arxiv.org/pdf/2404.00478", "title": "Forensic Scientometrics -- An emerging discipline to protect the  scholarly record", "authors": "Leslie D. McIntosh, Cynthia Hudson Vitale", "subjects": "Digital Libraries (cs.DL)", "abstract": "Forensic Scientometrics (FoSci) is emerging as a vital discipline at the intersection of scientific integrity and security. Scholarship and scholarly communication are critical for maintaining scientific integrity, influencing public trust in science, health, technology, policy, and law. Yet, these foundations are threatened by the misuse of scientific research for personal, commercial, ideological, and geopolitical gains, including questionable practices and misconduct. The rise of paper mills and predatory publishers, along with ideological and geopolitical motivations, undermines academic integrity. This field pioneers the integration of traditional scientometric methods with ethics to address pressing challenges in research integrity and security, crucial in an era of heightened scrutiny over science's reliability. FoSci's development signifies a collective commitment to maintaining scientific trust, marked by a call for official recognition and support from stakeholders across the scientific ecosystem."}
{"main_page": "https://arxiv.org/abs/2404.00482", "pdf": "https://arxiv.org/pdf/2404.00482", "title": "Cross-lingual Named Entity Corpus for Slavic Languages", "authors": "Jakub Piskorski, Micha\u0142 Marci\u0144czuk, Roman Yangarber", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "This paper presents a corpus manually annotated with named entities for six Slavic languages - Bulgarian, Czech, Polish, Slovenian, Russian, and Ukrainian. This work is the result of a series of shared tasks, conducted in 2017-2023 as a part of the Workshops on Slavic Natural Language Processing. The corpus consists of 5 017 documents on seven topics. The documents are annotated with five classes of named entities. Each entity is described by a category, a lemma, and a unique cross-lingual identifier. We provide two train-tune dataset splits - single topic out and cross topics. For each split, we set benchmarks using a transformer-based neural network architecture with the pre-trained multilingual models - XLM-RoBERTa-large for named entity mention recognition and categorization, and mT5-large for named entity lemmatization and linking."}
{"main_page": "https://arxiv.org/abs/2404.00484", "pdf": "https://arxiv.org/pdf/2404.00484", "title": "Edinburgh Clinical NLP at SemEval-2024 Task 2: Fine-tune your model  unless you have access to GPT-4", "authors": "Aryo Pradipta Gema, Giwon Hong, Pasquale Minervini, Luke Daines, Beatrice Alex", "subjects": "Computation and Language (cs.CL)", "abstract": "The NLI4CT task assesses Natural Language Inference systems in predicting whether hypotheses entail or contradict evidence from Clinical Trial Reports. In this study, we evaluate various Large Language Models (LLMs) with multiple strategies, including Chain-of-Thought, In-Context Learning, and Parameter-Efficient Fine-Tuning (PEFT). We propose a PEFT method to improve the consistency of LLMs by merging adapters that were fine-tuned separately using triplet and language modelling objectives. We found that merging the two PEFT adapters improves the F1 score (+0.0346) and consistency (+0.152) of the LLMs. However, our novel methods did not produce more accurate results than GPT-4 in terms of faithfulness and consistency. Averaging the three metrics, GPT-4 ranks joint-first in the competition with 0.8328. Finally, our contamination analysis with GPT-4 indicates that there was no test data leakage."}
{"main_page": "https://arxiv.org/abs/2404.00485", "pdf": "https://arxiv.org/pdf/2404.00485", "title": "DiffHuman: Probabilistic Photorealistic 3D Reconstruction of Humans", "authors": "Akash Sengupta, Thiemo Alldieck, Nikos Kolotouros, Enric Corona, Andrei Zanfir, Cristian Sminchisescu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present DiffHuman, a probabilistic method for photorealistic 3D human reconstruction from a single RGB image. Despite the ill-posed nature of this problem, most methods are deterministic and output a single solution, often resulting in a lack of geometric detail and blurriness in unseen or uncertain regions. In contrast, DiffHuman predicts a probability distribution over 3D reconstructions conditioned on an input 2D image, which allows us to sample multiple detailed 3D avatars that are consistent with the image. DiffHuman is implemented as a conditional diffusion model that denoises pixel-aligned 2D observations of an underlying 3D shape representation. During inference, we may sample 3D avatars by iteratively denoising 2D renders of the predicted 3D representation. Furthermore, we introduce a generator neural network that approximates rendering with considerably reduced runtime (55x speed up), resulting in a novel dual-branch diffusion framework. Our experiments show that DiffHuman can produce diverse and detailed reconstructions for the parts of the person that are unseen or uncertain in the input image, while remaining competitive with the state-of-the-art when reconstructing visible surfaces."}
{"main_page": "https://arxiv.org/abs/2404.00486", "pdf": "https://arxiv.org/pdf/2404.00486", "title": "Dialectical Alignment: Resolving the Tension of 3H and Security Threats  of LLMs", "authors": "Shu Yang, Jiayuan Su, Han Jiang, Mengdi Li, Keyuan Cheng, Muhammad Asif Ali, Lijie Hu, Di Wang", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "With the rise of large language models (LLMs), ensuring they embody the principles of being helpful, honest, and harmless (3H), known as Human Alignment, becomes crucial. While existing alignment methods like RLHF, DPO, etc., effectively fine-tune LLMs to match preferences in the preference dataset, they often lead LLMs to highly receptive human input and external evidence, even when this information is poisoned. This leads to a tendency for LLMs to be Adaptive Chameleons when external evidence conflicts with their parametric memory. This exacerbates the risk of LLM being attacked by external poisoned data, which poses a significant security risk to LLM system applications such as Retrieval-augmented generation (RAG). To address the challenge, we propose a novel framework: Dialectical Alignment (DA), which (1) utilizes AI feedback to identify optimal strategies for LLMs to navigate inter-context conflicts and context-memory conflicts with different external evidence in context window (i.e., different ratios of poisoned factual contexts); (2) constructs the SFT dataset as well as the preference dataset based on the AI feedback and strategies above; (3) uses the above datasets for LLM alignment to defense poisoned context attack while preserving the effectiveness of in-context knowledge editing. Our experiments show that the dialectical alignment model improves poisoned data attack defense by 20 and does not require any additional prompt engineering or prior declaration of ``you may be attacked`` to the LLMs' context window."}
{"main_page": "https://arxiv.org/abs/2404.00487", "pdf": "https://arxiv.org/pdf/2404.00487", "title": "Contextual AI Journaling: Integrating LLM and Time Series Behavioral  Sensing Technology to Promote Self-Reflection and Well-being using the  MindScape App", "authors": "Subigya Nepal, Arvind Pillai, William Campbell, Talie Massachi, Eunsol Soul Choi, Orson Xu, Joanna Kuc, Jeremy Huckins, Jason Holden, Colin Depp, Nicholas Jacobson, Mary Czerwinski, Eric Granholm, Andrew T. Campbell", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "abstract": "MindScape aims to study the benefits of integrating time series behavioral patterns (e.g., conversational engagement, sleep, location) with Large Language Models (LLMs) to create a new form of contextual AI journaling, promoting self-reflection and well-being. We argue that integrating behavioral sensing in LLMs will likely lead to a new frontier in AI. In this Late-Breaking Work paper, we discuss the MindScape contextual journal App design that uses LLMs and behavioral sensing to generate contextual and personalized journaling prompts crafted to encourage self-reflection and emotional development. We also discuss the MindScape study of college students based on a preliminary user study and our upcoming study to assess the effectiveness of contextual AI journaling in promoting better well-being on college campuses. MindScape represents a new application class that embeds behavioral intelligence in AI."}
{"main_page": "https://arxiv.org/abs/2404.00488", "pdf": "https://arxiv.org/pdf/2404.00488", "title": "Noise-Aware Training of Layout-Aware Language Models", "authors": "Ritesh Sarkhel, Xiaoqi Ren, Lauro Beltrao Costa, Guolong Su, Vincent Perot, Yanan Xie, Emmanouil Koukoumidis, Arnab Nandi", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "A visually rich document (VRD) utilizes visual features along with linguistic cues to disseminate information. Training a custom extractor that identifies named entities from a document requires a large number of instances of the target document type annotated at textual and visual modalities. This is an expensive bottleneck in enterprise scenarios, where we want to train custom extractors for thousands of different document types in a scalable way. Pre-training an extractor model on unlabeled instances of the target document type, followed by a fine-tuning step on human-labeled instances does not work in these scenarios, as it surpasses the maximum allowable training time allocated for the extractor. We address this scenario by proposing a Noise-Aware Training method or NAT in this paper. Instead of acquiring expensive human-labeled documents, NAT utilizes weakly labeled documents to train an extractor in a scalable way. To avoid degradation in the model's quality due to noisy, weakly labeled samples, NAT estimates the confidence of each training sample and incorporates it as uncertainty measure during training. We train multiple state-of-the-art extractor models using NAT. Experiments on a number of publicly available and in-house datasets show that NAT-trained models are not only robust in performance -- it outperforms a transfer-learning baseline by up to 6% in terms of macro-F1 score, but it is also more label-efficient -- it reduces the amount of human-effort required to obtain comparable performance by up to 73%."}
{"main_page": "https://arxiv.org/abs/2404.00489", "pdf": "https://arxiv.org/pdf/2404.00489", "title": "PROMPT-SAW: Leveraging Relation-Aware Graphs for Textual Prompt  Compression", "authors": "Muhammad Asif Ali, Zhengping Li, Shu Yang, Keyuan Cheng, Yang Cao, Tianhao Huang, Lijie Hu, Lu Yu, Di Wang", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Large language models (LLMs) have shown exceptional abilities for multiple different natural language processing tasks. While prompting is a crucial tool for LLM inference, we observe that there is a significant cost associated with exceedingly lengthy prompts. Existing attempts to compress lengthy prompts lead to sub-standard results in terms of readability and interpretability of the compressed prompt, with a detrimental impact on prompt utility. To address this, we propose PROMPT-SAW: Prompt compresSion via Relation AWare graphs, an effective strategy for prompt compression over task-agnostic and task-aware prompts. PROMPT-SAW uses the prompt's textual information to build a graph, later extracts key information elements in the graph to come up with the compressed prompt. We also propose GSM8K-AUG, i.e., an extended version of the existing GSM8k benchmark for task-agnostic prompts in order to provide a comprehensive evaluation platform. Experimental evaluation using benchmark datasets shows that prompts compressed by PROMPT-SAW are not only better in terms of readability, but they also outperform the best-performing baseline models by up to 14.3 and 13.7 respectively for task-aware and task-agnostic settings while compressing the original prompt text by 33.0 and 56.7."}
{"main_page": "https://arxiv.org/abs/2404.00491", "pdf": "https://arxiv.org/pdf/2404.00491", "title": "Denoising Monte Carlo Renders With Diffusion Models", "authors": "Vaibhav Vavilala, Rahul Vasanth, David Forsyth", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Physically-based renderings contain Monte-Carlo noise, with variance that increases as the number of rays per pixel decreases. This noise, while zero-mean for good modern renderers, can have heavy tails (most notably, for scenes containing specular or refractive objects). Learned methods for restoring low fidelity renders are highly developed, because suppressing render noise means one can save compute and use fast renders with few rays per pixel. We demonstrate that a diffusion model can denoise low fidelity renders successfully. Furthermore, our method can be conditioned on a variety of natural render information, and this conditioning helps performance. Quantitative experiments show that our method is competitive with SOTA across a range of sampling rates, but current metrics slightly favor competitor methods. Qualitative examination of the reconstructions suggests that the metrics themselves may not be reliable. The image prior applied by a diffusion method strongly favors reconstructions that are \"like\" real images -- so have straight shadow boundaries, curved specularities, no \"fireflies\" and the like -- and metrics do not account for this. We show numerous examples where methods preferred by current metrics produce qualitatively weaker reconstructions than ours."}
{"main_page": "https://arxiv.org/abs/2404.00492", "pdf": "https://arxiv.org/pdf/2404.00492", "title": "Multi-hop Question Answering under Temporal Knowledge Editing", "authors": "Keyuan Cheng, Gang Lin, Haoyang Fei, Yuxuan zhai, Lu Yu, Muhammad Asif Ali, Lijie Hu, Di Wang", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Multi-hop question answering (MQA) under knowledge editing (KE) has garnered significant attention in the era of large language models. However, existing models for MQA under KE exhibit poor performance when dealing with questions containing explicit temporal contexts. To address this limitation, we propose a novel framework, namely TEMPoral knowLEdge augmented Multi-hop Question Answering (TEMPLE-MQA). Unlike previous methods, TEMPLE-MQA first constructs a time-aware graph (TAG) to store edit knowledge in a structured manner. Then, through our proposed inference path, structural retrieval, and joint reasoning stages, TEMPLE-MQA effectively discerns temporal contexts within the question query. Experiments on benchmark datasets demonstrate that TEMPLE-MQA significantly outperforms baseline models. Additionally, we contribute a new dataset, namely TKEMQA, which serves as the inaugural benchmark tailored specifically for MQA with temporal scopes."}
{"main_page": "https://arxiv.org/abs/2404.00494", "pdf": "https://arxiv.org/pdf/2404.00494", "title": "Designing Robot Identity: The Role of Voice, Clothing, and Task on Robot  Gender Perception", "authors": "Nathaniel S. Dennler, Mina Kian, Stefanos Nikolaidis, Maja Matari\u0107", "subjects": "Robotics (cs.RO)", "abstract": "Perceptions of gender are a significant aspect of human-human interaction, and gender has wide-reaching social implications for robots deployed in contexts where they are expected to interact with humans. This work explored two flexible modalities for communicating gender in robots--voice and appearance--and we studied their individual and combined influences on a robot's perceived gender. We evaluated the perception of a robot's gender through three video-based studies. First, we conducted a study (n=65) on the gender perception of robot voices by varying speaker identity and pitch. Second, we conducted a study (n=93) on the gender perception of robot clothing designed for two different tasks. Finally, building on the results of the first two studies, we completed a large integrative video-based study (n=273) involving two human-robot interaction tasks. We found that voice and clothing can be used to reliably establish a robot's perceived gender, and that combining these two modalities can have different effects on the robot's perceived gender. Taken together, these results inform the design of robot voices and clothing as individual and interacting components in the perceptions of robot gender."}
{"main_page": "https://arxiv.org/abs/2404.00495", "pdf": "https://arxiv.org/pdf/2404.00495", "title": "Configurable Safety Tuning of Language Models with Synthetic Preference  Data", "authors": "Victor Gallego", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "State-of-the-art language model fine-tuning techniques, such as Direct Preference Optimization (DPO), restrict user control by hard-coding predefined behaviors into the model. To address this, we propose a novel method, Configurable Safety Tuning (CST), that augments DPO using synthetic preference data to facilitate flexible safety configuration of LLMs at inference time. CST overcomes the constraints of vanilla DPO by introducing a system prompt specifying safety configurations, enabling LLM deployers to disable/enable safety preferences based on their need, just changing the system prompt. Our experimental evaluations indicate that CST successfully manages different safety configurations and retains the original functionality of LLMs, showing it is a robust method for configurable deployment. Data and models available at https://github.com/vicgalle/configurable-safety-tuning"}
{"main_page": "https://arxiv.org/abs/2404.00498", "pdf": "https://arxiv.org/pdf/2404.00498", "title": "94% on CIFAR-10 in 3.29 Seconds on a Single GPU", "authors": "Keller Jordan", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "CIFAR-10 is among the most widely used datasets in machine learning, facilitating thousands of research projects per year. To accelerate research and reduce the cost of experiments, we introduce training methods for CIFAR-10 which reach 94% accuracy in 3.29 seconds, 95% in 10.4 seconds, and 96% in 46.3 seconds, when run on a single NVIDIA A100 GPU. As one factor contributing to these training speeds, we propose a derandomized variant of horizontal flipping augmentation, which we show improves over the standard method in every case where flipping is beneficial over no flipping at all. Our code is released at https://github.com/KellerJordan/cifar10-airbench."}
{"main_page": "https://arxiv.org/abs/2404.00500", "pdf": "https://arxiv.org/pdf/2404.00500", "title": "The Shape of Word Embeddings: Recognizing Language Phylogenies through  Topological Data Analysis", "authors": "Ond\u0159ej Draganov, Steven Skiena", "subjects": "Computation and Language (cs.CL); Algebraic Topology (math.AT)", "abstract": "Word embeddings represent language vocabularies as clouds of $d$-dimensional points. We investigate how information is conveyed by the general shape of these clouds, outside of representing the semantic meaning of each token. Specifically, we use the notion of persistent homology from topological data analysis (TDA) to measure the distances between language pairs from the shape of their unlabeled embeddings. We use these distance matrices to construct language phylogenetic trees over 81 Indo-European languages. Careful evaluation shows that our reconstructed trees exhibit strong similarities to the reference tree."}
{"main_page": "https://arxiv.org/abs/2404.00502", "pdf": "https://arxiv.org/pdf/2404.00502", "title": "Conditional Pseudo-Reversible Normalizing Flow for Surrogate Modeling in  Quantifying Uncertainty Propagation", "authors": "Minglei Yang, Pengjun Wang, Ming Fan, Dan Lu, Yanzhao Cao, Guannan Zhang", "subjects": "Machine Learning (cs.LG); Numerical Analysis (math.NA)", "abstract": "We introduce a conditional pseudo-reversible normalizing flow for constructing surrogate models of a physical model polluted by additive noise to efficiently quantify forward and inverse uncertainty propagation. Existing surrogate modeling approaches usually focus on approximating the deterministic component of physical model. However, this strategy necessitates knowledge of noise and resorts to auxiliary sampling methods for quantifying inverse uncertainty propagation. In this work, we develop the conditional pseudo-reversible normalizing flow model to directly learn and efficiently generate samples from the conditional probability density functions. The training process utilizes dataset consisting of input-output pairs without requiring prior knowledge about the noise and the function. Our model, once trained, can generate samples from any conditional probability density functions whose high probability regions are covered by the training set. Moreover, the pseudo-reversibility feature allows for the use of fully-connected neural network architectures, which simplifies the implementation and enables theoretical analysis. We provide a rigorous convergence analysis of the conditional pseudo-reversible normalizing flow model, showing its ability to converge to the target conditional probability density function using the Kullback-Leibler divergence. To demonstrate the effectiveness of our method, we apply it to several benchmark tests and a real-world geologic carbon storage problem."}
{"main_page": "https://arxiv.org/abs/2404.00504", "pdf": "https://arxiv.org/pdf/2404.00504", "title": "NYC-Indoor-VPR: A Long-Term Indoor Visual Place Recognition Dataset with  Semi-Automatic Annotation", "authors": "Diwei Sheng, Anbang Yang, John-Ross Rizzo, Chen Feng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Visual Place Recognition (VPR) in indoor environments is beneficial to humans and robots for better localization and navigation. It is challenging due to appearance changes at various frequencies, and difficulties of obtaining ground truth metric trajectories for training and evaluation. This paper introduces the NYC-Indoor-VPR dataset, a unique and rich collection of over 36,000 images compiled from 13 distinct crowded scenes in New York City taken under varying lighting conditions with appearance changes. Each scene has multiple revisits across a year. To establish the ground truth for VPR, we propose a semiautomatic annotation approach that computes the positional information of each image. Our method specifically takes pairs of videos as input and yields matched pairs of images along with their estimated relative locations. The accuracy of this matching is refined by human annotators, who utilize our annotation software to correlate the selected keyframes. Finally, we present a benchmark evaluation of several state-of-the-art VPR algorithms using our annotated dataset, revealing its challenge and thus value for VPR research."}
{"main_page": "https://arxiv.org/abs/2404.00505", "pdf": "https://arxiv.org/pdf/2404.00505", "title": "Transfer Learning with Reconstruction Loss", "authors": "Wei Cui, Wei Yu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI); Machine Learning (stat.ML)", "abstract": "In most applications of utilizing neural networks for mathematical optimization, a dedicated model is trained for each specific optimization objective. However, in many scenarios, several distinct yet correlated objectives or tasks often need to be optimized on the same set of problem inputs. Instead of independently training a different neural network for each problem separately, it would be more efficient to exploit the correlations between these objectives and to train multiple neural network models with shared model parameters and feature representations. To achieve this, this paper first establishes the concept of common information: the shared knowledge required for solving the correlated tasks, then proposes a novel approach for model training by adding into the model an additional reconstruction stage associated with a new reconstruction loss. This loss is for reconstructing the common information starting from a selected hidden layer in the model. The proposed approach encourages the learned features to be general and transferable, and therefore can be readily used for efficient transfer learning. For numerical simulations, three applications are studied: transfer learning on classifying MNIST handwritten digits, the device-to-device wireless network power allocation, and the multiple-input-single-output network downlink beamforming and localization. Simulation results suggest that the proposed approach is highly efficient in data and model complexity, is resilient to over-fitting, and has competitive performances."}
{"main_page": "https://arxiv.org/abs/2404.00506", "pdf": "https://arxiv.org/pdf/2404.00506", "title": "Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models", "authors": "Shaofei Shen, Chenhao Zhang, Yawen Zhao, Alina Bialkowski, Weitong Chen, Miao Xu", "subjects": "Machine Learning (cs.LG)", "abstract": "Machine unlearning aims to remove information derived from forgotten data while preserving that of the remaining dataset in a well-trained model. With the increasing emphasis on data privacy, several approaches to machine unlearning have emerged. However, these methods typically rely on complete supervision throughout the unlearning process. Unfortunately, obtaining such supervision, whether for the forgetting or remaining data, can be impractical due to the substantial cost associated with annotating real-world datasets. This challenge prompts us to propose a supervision-free unlearning approach that operates without the need for labels during the unlearning process. Specifically, we introduce a variational approach to approximate the distribution of representations for the remaining data. Leveraging this approximation, we adapt the original model to eliminate information from the forgotten data at the representation level. To further address the issue of lacking supervision information, which hinders alignment with ground truth, we introduce a contrastive loss to facilitate the matching of representations between the remaining data and those of the original model, thus preserving predictive performance. Experimental results across various unlearning tasks demonstrate the effectiveness of our proposed method, Label-Agnostic Forgetting (LAF) without using any labels, which achieves comparable performance to state-of-the-art methods that rely on full supervision information. Furthermore, our approach excels in semi-supervised scenarios, leveraging limited supervision information to outperform fully supervised baselines. This work not only showcases the viability of supervision-free unlearning in deep models but also opens up a new possibility for future research in unlearning at the representation level."}
{"main_page": "https://arxiv.org/abs/2404.00507", "pdf": "https://arxiv.org/pdf/2404.00507", "title": "THEMIS: Time, Heterogeneity, and Energy Minded Scheduling for Fair  Multi-Tenant Use in FPGAs", "authors": "Emre Karabulut, Arsalan Ali Malik, Amro Awad, Aydin Aysu", "subjects": "Operating Systems (cs.OS); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Using correct design metrics and understanding the limitations of the underlying technology is critical to developing effective scheduling algorithms. Unfortunately, existing scheduling techniques used \\emph{incorrect} metrics and had \\emph{unrealistic} assumptions for fair scheduling of multi-tenant FPGAs where each tenant is aimed to share approximately the same number of resources both spatially and temporally. This paper introduces an enhanced fair scheduling algorithm for multi-tenant FPGA use, addressing previous metric and assumption issues, with three specific improvements claimed First, our method ensures spatiotemporal fairness by considering both spatial and temporal aspects, addressing the limitation of prior work that assumed uniform task latency. Second, we incorporate energy considerations into fairness by adjusting scheduling intervals and accounting for energy overhead, thereby balancing energy efficiency with fairness. Third, we acknowledge overlooked aspects of FPGA multi-tenancy, including heterogeneous regions and the constraints on dynamically merging/splitting partially reconfigurable regions. We develop and evaluate our improved fair scheduling algorithm with these three enhancements. Inspired by the Greek goddess of law and personification of justice, we name our fair scheduling solution THEMIS: \\underline{T}ime, \\underline{H}eterogeneity, and \\underline{E}nergy \\underline{Mi}nded \\underline{S}cheduling. We used the Xilinx Zedboard XC7Z020 to quantify our approach's savings. Compared to previous algorithms, our improved scheduling algorithm enhances fairness between 24.2--98.4\\% and allows a trade-off between 55.3$\\times$ in energy vs. 69.3$\\times$ in fairness. The paper thus informs cloud providers about future scheduling optimizations for fairness with related challenges and opportunities."}
{"main_page": "https://arxiv.org/abs/2404.00509", "pdf": "https://arxiv.org/pdf/2404.00509", "title": "DailyMAE: Towards Pretraining Masked Autoencoders in One Day", "authors": "Jiantao Wu, Shentong Mo, Sara Atito, Zhenhua Feng, Josef Kittler, Muhammad Awais", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recently, masked image modeling (MIM), an important self-supervised learning (SSL) method, has drawn attention for its effectiveness in learning data representation from unlabeled data. Numerous studies underscore the advantages of MIM, highlighting how models pretrained on extensive datasets can enhance the performance of downstream tasks. However, the high computational demands of pretraining pose significant challenges, particularly within academic environments, thereby impeding the SSL research progress. In this study, we propose efficient training recipes for MIM based SSL that focuses on mitigating data loading bottlenecks and employing progressive training techniques and other tricks to closely maintain pretraining performance. Our library enables the training of a MAE-Base/16 model on the ImageNet 1K dataset for 800 epochs within just 18 hours, using a single machine equipped with 8 A100 GPUs. By achieving speed gains of up to 5.8 times, this work not only demonstrates the feasibility of conducting high-efficiency SSL training but also paves the way for broader accessibility and promotes advancement in SSL research particularly for prototyping and initial testing of SSL ideas. The code is available in https://github.com/erow/FastSSL."}
{"main_page": "https://arxiv.org/abs/2404.00510", "pdf": "https://arxiv.org/pdf/2404.00510", "title": "Denoising Low-dose Images Using Deep Learning of Time Series Images", "authors": "Yang Shao, Toshie Yaguchi, Toshiaki Tanigaki", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Digital image devices have been widely applied in many fields, including scientific imaging, recognition of individuals, and remote sensing. As the application of these imaging technologies to autonomous driving and measurement, image noise generated when observation cannot be performed with a sufficient dose has become a major problem. Machine learning denoise technology is expected to be the solver of this problem, but there are the following problems. Here we report, artifacts generated by machine learning denoise in ultra-low dose observation using an in-situ observation video of an electron microscope as an example. And as a method to solve this problem, we propose a method to decompose a time series image into a 2D image of the spatial axis and time to perform machine learning denoise. Our method opens new avenues accurate and stable reconstruction of continuous high-resolution images from low-dose imaging in science, industry, and life."}
{"main_page": "https://arxiv.org/abs/2404.00511", "pdf": "https://arxiv.org/pdf/2404.00511", "title": "MIPS at SemEval-2024 Task 3: Multimodal Emotion-Cause Pair Extraction in  Conversations with Multimodal Language Models", "authors": "Zebang Cheng, Fuqiang Niu, Yuxiang Lin, Zhi-Qi Cheng, Bowen Zhang, Xiaojiang Peng", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)", "abstract": "This paper presents our winning submission to Subtask 2 of SemEval 2024 Task 3 on multimodal emotion cause analysis in conversations. We propose a novel Multimodal Emotion Recognition and Multimodal Emotion Cause Extraction (MER-MCE) framework that integrates text, audio, and visual modalities using specialized emotion encoders. Our approach sets itself apart from top-performing teams by leveraging modality-specific features for enhanced emotion understanding and causality inference. Experimental evaluation demonstrates the advantages of our multimodal approach, with our submission achieving a competitive weighted F1 score of 0.3435, ranking third with a margin of only 0.0339 behind the 1st team and 0.0025 behind the 2nd team. Project: https://github.com/MIPS-COLT/MER-MCE.git"}
{"main_page": "https://arxiv.org/abs/2404.00513", "pdf": "https://arxiv.org/pdf/2404.00513", "title": "Transformer based Pluralistic Image Completion with Reduced Information  Loss", "authors": "Qiankun Liu, Yuqi Jiang, Zhentao Tan, Dongdong Chen, Ying Fu, Qi Chu, Gang Hua, Nenghai Yu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Transformer based methods have achieved great success in image inpainting recently. However, we find that these solutions regard each pixel as a token, thus suffering from an information loss issue from two aspects: 1) They downsample the input image into much lower resolutions for efficiency consideration. 2) They quantize $256^3$ RGB values to a small number (such as 512) of quantized color values. The indices of quantized pixels are used as tokens for the inputs and prediction targets of the transformer. To mitigate these issues, we propose a new transformer based framework called \"PUT\". Specifically, to avoid input downsampling while maintaining computation efficiency, we design a patch-based auto-encoder P-VQVAE. The encoder converts the masked image into non-overlapped patch tokens and the decoder recovers the masked regions from the inpainted tokens while keeping the unmasked regions unchanged. To eliminate the information loss caused by input quantization, an Un-quantized Transformer is applied. It directly takes features from the P-VQVAE encoder as input without any quantization and only regards the quantized tokens as prediction targets. Furthermore, to make the inpainting process more controllable, we introduce semantic and structural conditions as extra guidance. Extensive experiments show that our method greatly outperforms existing transformer based methods on image fidelity and achieves much higher diversity and better fidelity than state-of-the-art pluralistic inpainting methods on complex large-scale datasets (e.g., ImageNet). Codes are available at https://github.com/liuqk3/PUT."}
{"main_page": "https://arxiv.org/abs/2404.00514", "pdf": "https://arxiv.org/pdf/2404.00514", "title": "Human-Robot Co-Transportation with Human Uncertainty-Aware MPC and Pose  Optimization", "authors": "Al Jaber Mahmud, Amir Hossain Raj, Duc M. Nguyen, Xuesu Xiao, Xuan Wang", "subjects": "Robotics (cs.RO)", "abstract": "This paper proposes a new control algorithm for human-robot co-transportation based on a robot manipulator equipped with a mobile base and a robotic arm. The primary focus is to adapt to human uncertainties through the robot's whole-body dynamics and pose optimization. We introduce an augmented Model Predictive Control (MPC) formulation that explicitly models human uncertainties and contains extra variables than regular MPC to optimize the pose of the robotic arm. The core of our methodology involves a two-step iterative design: At each planning horizon, we select the best pose of the robotic arm (joint angle combination) from a candidate set, aiming to achieve the lowest estimated control cost. This selection is based on solving an uncertainty-aware Discrete Algebraic Ricatti Equation (DARE), which also informs the optimal control inputs for both the mobile base and the robotic arm. To validate the effectiveness of the proposed approach, we provide theoretical derivation for the uncertainty-aware DARE and perform simulated and proof-of-concept hardware experiments using a Fetch robot under varying conditions, including different nominal trajectories and noise levels. The results reveal that our proposed approach outperforms baseline algorithms, maintaining similar execution time with that do not consider human uncertainty or do not perform pose optimization."}
{"main_page": "https://arxiv.org/abs/2404.00520", "pdf": "https://arxiv.org/pdf/2404.00520", "title": "Competition-Aware Decision-Making Approach for Mobile Robots in Racing  Scenarios", "authors": "Kyoungtae Ji, Sangjae Bae, Nan Li, Kyoungseok Han", "subjects": "Robotics (cs.RO); Optimization and Control (math.OC)", "abstract": "This paper presents a game-theoretic strategy for racing, where the autonomous ego agent seeks to block a racing opponent that aims to overtake the ego agent. After a library of trajectory candidates and an associated reward matrix are constructed, the optimal trajectory in terms of maximizing the cumulative reward over the planning horizon is determined based on the level-K reasoning framework. In particular, the level of the opponent is estimated online according to its behavior over a past window and is then used to determine the trajectory for the ego agent. Taking into account that the opponent may change its level and strategy during the decision process of the ego agent, we introduce a trajectory mixing strategy that blends the level-K optimal trajectory with a fail-safe trajectory. The overall algorithm was tested and evaluated in various simulated racing scenarios, which also includes human-in-the-loop experiments. Comparative analysis against the conventional level-K framework demonstrates the superiority of our proposed approach in terms of overtake-blocking success rates."}
{"main_page": "https://arxiv.org/abs/2404.00521", "pdf": "https://arxiv.org/pdf/2404.00521", "title": "CHAIN: Enhancing Generalization in Data-Efficient GANs via lipsCHitz  continuity constrAIned Normalization", "authors": "Yao Ni, Piotr Koniusz", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Generative Adversarial Networks (GANs) significantly advanced image generation but their performance heavily depends on abundant training data. In scenarios with limited data, GANs often struggle with discriminator overfitting and unstable training. Batch Normalization (BN), despite being known for enhancing generalization and training stability, has rarely been used in the discriminator of Data-Efficient GANs. Our work addresses this gap by identifying a critical flaw in BN: the tendency for gradient explosion during the centering and scaling steps. To tackle this issue, we present CHAIN (lipsCHitz continuity constrAIned Normalization), which replaces the conventional centering step with zero-mean regularization and integrates a Lipschitz continuity constraint in the scaling step. CHAIN further enhances GAN training by adaptively interpolating the normalized and unnormalized features, effectively avoiding discriminator overfitting. Our theoretical analyses firmly establishes CHAIN's effectiveness in reducing gradients in latent features and weights, improving stability and generalization in GAN training. Empirical evidence supports our theory. CHAIN achieves state-of-the-art results in data-limited scenarios on CIFAR-10/100, ImageNet, five low-shot and seven high-resolution few-shot image datasets."}
{"main_page": "https://arxiv.org/abs/2404.00522", "pdf": "https://arxiv.org/pdf/2404.00522", "title": "Minimum-Norm Interpolation Under Covariate Shift", "authors": "Neil Mallinar, Austin Zane, Spencer Frei, Bin Yu", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Transfer learning is a critical part of real-world machine learning deployments and has been extensively studied in experimental works with overparameterized neural networks. However, even in the simplest setting of linear regression a notable gap still exists in the theoretical understanding of transfer learning. In-distribution research on high-dimensional linear regression has led to the identification of a phenomenon known as \\textit{benign overfitting}, in which linear interpolators overfit to noisy training labels and yet still generalize well. This behavior occurs under specific conditions on the source covariance matrix and input data dimension. Therefore, it is natural to wonder how such high-dimensional linear models behave under transfer learning. We prove the first non-asymptotic excess risk bounds for benignly-overfit linear interpolators in the transfer learning setting. From our analysis, we propose a taxonomy of \\textit{beneficial} and \\textit{malignant} covariate shifts based on the degree of overparameterization. We follow our analysis with empirical studies that show these beneficial and malignant covariate shifts for linear interpolators on real image data, and for fully-connected neural networks in settings where the input data dimension is larger than the training sample size."}
{"main_page": "https://arxiv.org/abs/2404.00524", "pdf": "https://arxiv.org/pdf/2404.00524", "title": "TexVocab: Texture Vocabulary-conditioned Human Avatars", "authors": "Yuxiao Liu, Zhe Li, Yebin Liu, Haoqian Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "To adequately utilize the available image evidence in multi-view video-based avatar modeling, we propose TexVocab, a novel avatar representation that constructs a texture vocabulary and associates body poses with texture maps for animation. Given multi-view RGB videos, our method initially back-projects all the available images in the training videos to the posed SMPL surface, producing texture maps in the SMPL UV domain. Then we construct pairs of human poses and texture maps to establish a texture vocabulary for encoding dynamic human appearances under various poses. Unlike the commonly used joint-wise manner, we further design a body-part-wise encoding strategy to learn the structural effects of the kinematic chain. Given a driving pose, we query the pose feature hierarchically by decomposing the pose vector into several body parts and interpolating the texture features for synthesizing fine-grained human dynamics. Overall, our method is able to create animatable human avatars with detailed and dynamic appearances from RGB videos, and the experiments show that our method outperforms state-of-the-art approaches. The project page can be found at https://texvocab.github.io/."}
{"main_page": "https://arxiv.org/abs/2404.00525", "pdf": "https://arxiv.org/pdf/2404.00525", "title": "Creating synthetic energy meter data using conditional diffusion and  building metadata", "authors": "Chun Fu, Hussain Kazmi, Matias Quintana, Clayton Miller", "subjects": "Machine Learning (cs.LG); Systems and Control (eess.SY)", "abstract": "Advances in machine learning and increased computational power have driven progress in energy-related research. However, limited access to private energy data from buildings hinders traditional regression models relying on historical data. While generative models offer a solution, previous studies have primarily focused on short-term generation periods (e.g., daily profiles) and a limited number of meters. Thus, the study proposes a conditional diffusion model for generating high-quality synthetic energy data using relevant metadata. Using a dataset comprising 1,828 power meters from various buildings and countries, this model is compared with traditional methods like Conditional Generative Adversarial Networks (CGAN) and Conditional Variational Auto-Encoders (CVAE). It explicitly handles long-term annual consumption profiles, harnessing metadata such as location, weather, building, and meter type to produce coherent synthetic data that closely resembles real-world energy consumption patterns. The results demonstrate the proposed diffusion model's superior performance, with a 36% reduction in Frechet Inception Distance (FID) score and a 13% decrease in Kullback-Leibler divergence (KL divergence) compared to the following best method. The proposed method successfully generates high-quality energy data through metadata, and its code will be open-sourced, establishing a foundation for a broader array of energy data generation models in the future."}
{"main_page": "https://arxiv.org/abs/2404.00526", "pdf": "https://arxiv.org/pdf/2404.00526", "title": "The Emotional Impact of Game Duration: A Framework for Understanding  Player Emotions in Extended Gameplay Sessions", "authors": "Anoop Kumar, Suresh Dodda, Navin Kamuni, Venkata Sai Mahesh Vuppalapati", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "abstract": "Video games have played a crucial role in entertainment since their development in the 1970s, becoming even more prominent during the lockdown period when people were looking for ways to entertain them. However, at that time, players were unaware of the significant impact that playtime could have on their feelings. This has made it challenging for designers and developers to create new games since they have to control the emotional impact that these games will take on players. Thus, the purpose of this study is to look at how a player's emotions are affected by the duration of the game. In order to achieve this goal, a framework for emotion detection is created. According to the experiment's results, the volunteers' general ability to express emotions increased from 20 to 60 minutes. In comparison to shorter gameplay sessions, the experiment found that extended gameplay sessions did significantly affect the player's emotions. According to the results, it was recommended that in order to lessen the potential emotional impact that playing computer and video games may have in the future, game producers should think about creating shorter, entertaining games."}
{"main_page": "https://arxiv.org/abs/2404.00527", "pdf": "https://arxiv.org/pdf/2404.00527", "title": "Prophet Inequalities with Cancellation Costs", "authors": "Farbod Ekbatani, Rad Niazadeh, Pranav Nuti, Jan Vondrak", "subjects": "Data Structures and Algorithms (cs.DS); Computer Science and Game Theory (cs.GT)", "abstract": "Most of the literature on online algorithms and sequential decision-making focuses on settings with \"irrevocable decisions\" where the algorithm's decision upon arrival of the new input is set in stone and can never change in the future. One canonical example is the classic prophet inequality problem, where realizations of a sequence of independent random variables $X_1, X_2,\\ldots$ with known distributions are drawn one by one and a decision maker decides when to stop and accept the arriving random variable, with the goal of maximizing the expected value of their pick. We consider \"prophet inequalities with recourse\" in the linear buyback cost setting, where after accepting a variable $X_i$, we can still discard $X_i$ later and accept another variable $X_j$, at a \\textit{buyback cost} of $f \\times X_i$. The goal is to maximize the expected net reward, which is the value of the final accepted variable minus the total buyback cost. Our first main result is an optimal prophet inequality in the regime of $f \\geq 1$, where we prove that we can achieve an expected reward $\\frac{1+f}{1+2f}$ times the expected offline optimum. The problem is still open for $0<f<1$ and we give some partial results in this regime. In particular, as our second main result, we characterize the asymptotic behavior of the competitive ratio for small $f$ and provide almost matching upper and lower bounds that show a factor of $1-\\Theta\\left(f\\log(\\frac{1}{f})\\right)$. Our results are obtained by two fundamentally different approaches: One is inspired by various proofs of the classical prophet inequality, while the second is based on combinatorial optimization techniques involving LP duality, flows, and cuts."}
{"main_page": "https://arxiv.org/abs/2404.00528", "pdf": "https://arxiv.org/pdf/2404.00528", "title": "Generative weather for improved crop model simulations", "authors": "Yuji Saikai", "subjects": "Machine Learning (cs.LG)", "abstract": "Accurate and precise crop yield prediction is invaluable for decision making at both farm levels and regional levels. To make yield prediction, crop models are widely used for their capability to simulate hypothetical scenarios. While accuracy and precision of yield prediction critically depend on weather inputs to simulations, surprisingly little attention has been paid to preparing weather inputs. We propose a new method to construct generative models for long-term weather forecasts and ultimately improve crop yield prediction. We demonstrate use of the method in two representative scenarios -- single-year production of wheat, barley and canola and three-year production using rotations of these crops. Results show significant improvement from the conventional method, measured in terms of mean and standard deviation of prediction errors. Our method outperformed the conventional method in every one of 18 metrics for the first scenario and in 29 out of 36 metrics for the second scenario. For individual crop modellers to start applying the method to their problems, technical details are carefully explained, and all the code, trained PyTorch models, APSIM simulation files and result data are made available."}
{"main_page": "https://arxiv.org/abs/2404.00529", "pdf": "https://arxiv.org/pdf/2404.00529", "title": "Super Non-singular Decompositions of Polynomials and their Application  to Robustly Learning Low-degree PTFs", "authors": "Ilias Diakonikolas, Daniel M. Kane, Vasilis Kontonis, Sihan Liu, Nikos Zarifis", "subjects": "Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)", "abstract": "We study the efficient learnability of low-degree polynomial threshold functions (PTFs) in the presence of a constant fraction of adversarial corruptions. Our main algorithmic result is a polynomial-time PAC learning algorithm for this concept class in the strong contamination model under the Gaussian distribution with error guarantee $O_{d, c}(\\text{opt}^{1-c})$, for any desired constant $c>0$, where $\\text{opt}$ is the fraction of corruptions. In the strong contamination model, an omniscient adversary can arbitrarily corrupt an $\\text{opt}$-fraction of the data points and their labels. This model generalizes the malicious noise model and the adversarial label noise model. Prior to our work, known polynomial-time algorithms in this corruption model (or even in the weaker adversarial label noise model) achieved error $\\tilde{O}_d(\\text{opt}^{1/(d+1)})$, which deteriorates significantly as a function of the degree $d$. Our algorithm employs an iterative approach inspired by localization techniques previously used in the context of learning linear threshold functions. Specifically, we use a robust perceptron algorithm to compute a good partial classifier and then iterate on the unclassified points. In order to achieve this, we need to take a set defined by a number of polynomial inequalities and partition it into several well-behaved subsets. To this end, we develop new polynomial decomposition techniques that may be of independent interest."}
{"main_page": "https://arxiv.org/abs/2404.00530", "pdf": "https://arxiv.org/pdf/2404.00530", "title": "Comparing Bad Apples to Good Oranges: Aligning Large Language Models via  Joint Preference Optimization", "authors": "Hritik Bansal, Ashima Suvarna, Gantavya Bhatt, Nanyun Peng, Kai-Wei Chang, Aditya Grover", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "A common technique for aligning large language models (LLMs) relies on acquiring human preferences by comparing multiple generations conditioned on a fixed context. This only leverages the pairwise comparisons when the generations are placed in an identical context. However, such conditional rankings often fail to capture the complex and multidimensional aspects of human preferences. In this work, we revisit the traditional paradigm of preference acquisition and propose a new axis that is based on eliciting preferences jointly over the instruction-response pairs. While prior preference optimizations are designed for conditional ranking protocols (e.g., DPO), our proposed preference acquisition protocol introduces DOVE, a new preference optimization objective that upweights the joint probability of the chosen instruction-response pair over the rejected instruction-response pair. Interestingly, we find that the LLM trained with joint instruction-response preference data using DOVE outperforms the LLM trained with DPO by 5.2% and 3.3% win-rate for the summarization and open-ended dialogue datasets, respectively. Our findings reveal that joint preferences over instruction and response pairs can significantly enhance the alignment of LLMs by tapping into a broader spectrum of human preference elicitation. The data and code is available at https://github.com/Hritikbansal/dove."}
{"main_page": "https://arxiv.org/abs/2404.00532", "pdf": "https://arxiv.org/pdf/2404.00532", "title": "LLMs are Good Action Recognizers", "authors": "Haoxuan Qu, Yujun Cai, Jun Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Skeleton-based action recognition has attracted lots of research attention. Recently, to build an accurate skeleton-based action recognizer, a variety of works have been proposed. Among them, some works use large model architectures as backbones of their recognizers to boost the skeleton data representation capability, while some other works pre-train their recognizers on external data to enrich the knowledge. In this work, we observe that large language models which have been extensively used in various natural language processing tasks generally hold both large model architectures and rich implicit knowledge. Motivated by this, we propose a novel LLM-AR framework, in which we investigate treating the Large Language Model as an Action Recognizer. In our framework, we propose a linguistic projection process to project each input action signal (i.e., each skeleton sequence) into its ``sentence format'' (i.e., an ``action sentence''). Moreover, we also incorporate our framework with several designs to further facilitate this linguistic projection process. Extensive experiments demonstrate the efficacy of our proposed framework."}
{"main_page": "https://arxiv.org/abs/2404.00538", "pdf": "https://arxiv.org/pdf/2404.00538", "title": "Eclipse Attack Detection on a Blockchain Network as a Non-Parametric  Change Detection Problem", "authors": "Anurag Gupta, Brian Sadler", "subjects": "Cryptography and Security (cs.CR); Applications (stat.AP)", "abstract": "This paper introduces a novel non-parametric change detection algorithm to identify eclipse attacks on a blockchain network; the non-parametric algorithm relies only on the empirical mean and variance of the dataset, making it highly adaptable. An eclipse attack occurs when malicious actors isolate blockchain users, disrupting their ability to reach consensus with the broader network, thereby distorting their local copy of the ledger. To detect an eclipse attack, we monitor changes in the Fr\\'echet mean and variance of the evolving blockchain communication network connecting blockchain users. First, we leverage the Johnson-Lindenstrauss lemma to project large-dimensional networks into a lower-dimensional space, preserving essential statistical properties. Subsequently, we employ a non-parametric change detection procedure, leading to a test statistic that converges weakly to a Brownian bridge process in the absence of an eclipse attack. This enables us to quantify the false alarm rate of the detector. Our detector can be implemented as a smart contract on the blockchain, offering a tamper-proof and reliable solution. Finally, we use numerical examples to compare the proposed eclipse attack detector with a detector based on the random forest model."}
{"main_page": "https://arxiv.org/abs/2404.00539", "pdf": "https://arxiv.org/pdf/2404.00539", "title": "Solving the QAP by Two-Stage Graph Pointer Networks and Reinforcement  Learning", "authors": "Satoko Iida, Ryota Yasudo", "subjects": "Machine Learning (cs.LG)", "abstract": "Quadratic Assignment Problem (QAP) is a practical combinatorial optimization problems that has been studied for several years. Since it is NP-hard, solving large problem instances of QAP is challenging. Although heuristics can find semi-optimal solutions, the execution time significantly increases as the problem size increases. Recently, solving combinatorial optimization problems by deep learning has been attracting attention as a faster solver than heuristics. Even with deep learning, however, solving large QAP is still challenging. In this paper, we propose the deep reinforcement learning model called the two-stage graph pointer network (GPN) for solving QAP. Two-stage GPN relies on GPN, which has been proposed for Euclidean Traveling Salesman Problem (TSP). First, we extend GPN for general TSP, and then we add new algorithms to that model for solving QAP. Our experimental results show that our two-stage GPN provides semi-optimal solutions for benchmark problem instances from TSPlib and QAPLIB."}
{"main_page": "https://arxiv.org/abs/2404.00540", "pdf": "https://arxiv.org/pdf/2404.00540", "title": "Embodied Active Defense: Leveraging Recurrent Feedback to Counter  Adversarial Patches", "authors": "Lingxuan Wu, Xiao Yang, Yinpeng Dong, Liuwei Xie, Hang Su, Jun Zhu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The vulnerability of deep neural networks to adversarial patches has motivated numerous defense strategies for boosting model robustness. However, the prevailing defenses depend on single observation or pre-established adversary information to counter adversarial patches, often failing to be confronted with unseen or adaptive adversarial attacks and easily exhibiting unsatisfying performance in dynamic 3D environments. Inspired by active human perception and recurrent feedback mechanisms, we develop Embodied Active Defense (EAD), a proactive defensive strategy that actively contextualizes environmental information to address misaligned adversarial patches in 3D real-world settings. To achieve this, EAD develops two central recurrent sub-modules, i.e., a perception module and a policy module, to implement two critical functions of active vision. These models recurrently process a series of beliefs and observations, facilitating progressive refinement of their comprehension of the target object and enabling the development of strategic actions to counter adversarial patches in 3D environments. To optimize learning efficiency, we incorporate a differentiable approximation of environmental dynamics and deploy patches that are agnostic to the adversary strategies. Extensive experiments demonstrate that EAD substantially enhances robustness against a variety of patches within just a few steps through its action policy in safety-critical tasks (e.g., face recognition and object detection), without compromising standard accuracy. Furthermore, due to the attack-agnostic characteristic, EAD facilitates excellent generalization to unseen attacks, diminishing the averaged attack success rate by 95 percent across a range of unseen adversarial attacks."}
{"main_page": "https://arxiv.org/abs/2404.00544", "pdf": "https://arxiv.org/pdf/2404.00544", "title": "Deep Extrinsic Manifold Representation for Vision Tasks", "authors": "Tongtong Zhang, Xian Wei, Yuanxiang Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Non-Euclidean data is frequently encountered across different fields, yet there is limited literature that addresses the fundamental challenge of training neural networks with manifold representations as outputs. We introduce the trick named Deep Extrinsic Manifold Representation (DEMR) for visual tasks in this context. DEMR incorporates extrinsic manifold embedding into deep neural networks, which helps generate manifold representations. The DEMR approach does not directly optimize the complex geodesic loss. Instead, it focuses on optimizing the computation graph within the embedded Euclidean space, allowing for adaptability to various architectural requirements. We provide empirical evidence supporting the proposed concept on two types of manifolds, $SE(3)$ and its associated quotient manifolds. This evidence offers theoretical assurances regarding feasibility, asymptotic properties, and generalization capability. The experimental results show that DEMR effectively adapts to point cloud alignment, producing outputs in $ SE(3) $, as well as in illumination subspace learning with outputs on the Grassmann manifold."}
{"main_page": "https://arxiv.org/abs/2404.00546", "pdf": "https://arxiv.org/pdf/2404.00546", "title": "On the Estimation of Image-matching Uncertainty in Visual Place  Recognition", "authors": "Mubariz Zaffar, Liangliang Nan, Julian F. P. Kooij", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "In Visual Place Recognition (VPR) the pose of a query image is estimated by comparing the image to a map of reference images with known reference poses. As is typical for image retrieval problems, a feature extractor maps the query and reference images to a feature space, where a nearest neighbor search is then performed. However, till recently little attention has been given to quantifying the confidence that a retrieved reference image is a correct match. Highly certain but incorrect retrieval can lead to catastrophic failure of VPR-based localization pipelines. This work compares for the first time the main approaches for estimating the image-matching uncertainty, including the traditional retrieval-based uncertainty estimation, more recent data-driven aleatoric uncertainty estimation, and the compute-intensive geometric verification. We further formulate a simple baseline method, ``SUE'', which unlike the other methods considers the freely-available poses of the reference images in the map. Our experiments reveal that a simple L2-distance between the query and reference descriptors is already a better estimate of image-matching uncertainty than current data-driven approaches. SUE outperforms the other efficient uncertainty estimation methods, and its uncertainty estimates complement the computationally expensive geometric verification approach. Future works for uncertainty estimation in VPR should consider the baselines discussed in this work."}
{"main_page": "https://arxiv.org/abs/2404.00548", "pdf": "https://arxiv.org/pdf/2404.00548", "title": "Denoising Distillation Makes Event-Frame Transformers as Accurate Gaze  Trackers", "authors": "Jiading Li, Zhiyu Zhu, Jinhui Hou, Junhui Hou, Jinjian Wu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper tackles the problem of passive gaze estimation using both event and frame data. Considering inherently different physiological structures, it's intractable to accurately estimate purely based on a given state. Thus, we reformulate the gaze estimation as the quantification of state transitions from the current state to several prior registered anchor states. Technically, we propose a two-stage learning-based gaze estimation framework to divide the whole gaze estimation process into a coarse-to-fine process of anchor state selection and final gaze location. Moreover, to improve generalization ability, we align a group of local experts with a student network, where a novel denoising distillation algorithm is introduced to utilize denoising diffusion technique to iteratively remove inherent noise of event data. Extensive experiments demonstrate the effectiveness of the proposed method, which greatly surpasses state-of-the-art methods by a large extent of 15$\\%$. The code will be publicly available at https://github.com/jdjdli/Denoise_distill_EF_gazetracker."}
{"main_page": "https://arxiv.org/abs/2404.00552", "pdf": "https://arxiv.org/pdf/2404.00552", "title": "Comparison of Methods in Human Skin Decomposition", "authors": "Hao Gong, Michel Desvignes", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Decomposition of skin pigment plays an important role in medical fields. Human skin can be decomposed into two primitive components, hemoglobin and melanin. It is our goal to apply these results for diagnosis of skin cancer. In this paper, various methods for skin pigment decomposition are reviewed comparatively and the performance of each method is evaluated both theoretically and experimentally. In addition, isometric feature mapping (Isomap) is introduced in order to improve the dimensionality reduction performance in context of skin decomposition."}
{"main_page": "https://arxiv.org/abs/2404.00553", "pdf": "https://arxiv.org/pdf/2404.00553", "title": "Reduced-order Koopman modeling and predictive control of nonlinear  processes", "authors": "Xuewen Zhang, Minghao Han, Xunyuan Yin", "subjects": "Systems and Control (eess.SY)", "abstract": "In this paper, we propose an efficient data-driven predictive control approach for general nonlinear processes based on a reduced-order Koopman operator. A Kalman-based sparse identification of nonlinear dynamics method is employed to select lifting functions for Koopman identification. The selected lifting functions are used to project the original nonlinear state-space into a higher-dimensional linear function space, in which Koopman-based linear models can be constructed for the underlying nonlinear process. To curb the significant increase in the dimensionality of the resulting full-order Koopman models caused by the use of lifting functions, we propose a reduced-order Koopman modeling approach based on proper orthogonal decomposition. A computationally efficient linear robust predictive control scheme is established based on the reduced-order Koopman model. A case study on a benchmark chemical process is conducted to illustrate the effectiveness of the proposed method. Comprehensive comparisons are conducted to demonstrate the advantage of the proposed method."}
{"main_page": "https://arxiv.org/abs/2404.00557", "pdf": "https://arxiv.org/pdf/2404.00557", "title": "DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented  Dialogue Representations", "authors": "Weihao Zeng, Dayuan Fu, Keqing He, Yejie Wang, Yukai Xu, Weiran Xu", "subjects": "Computation and Language (cs.CL)", "abstract": "Language models pre-trained on general text have achieved impressive results in diverse fields. Yet, the distinct linguistic characteristics of task-oriented dialogues (TOD) compared to general text limit the practical utility of existing language models. Current task-oriented dialogue pre-training methods overlook the one-to-many property of conversations, where multiple responses can be appropriate given the same conversation context. In this paper, we propose a novel dialogue pre-training model called DivTOD, which collaborates with LLMs to learn diverse task-oriented dialogue representations. DivTOD guides LLMs in transferring diverse knowledge to smaller models while removing domain knowledge that contradicts task-oriented dialogues. Experiments show that our model outperforms strong TOD baselines on various downstream dialogue tasks and learns the intrinsic diversity of task-oriented dialogues."}
{"main_page": "https://arxiv.org/abs/2404.00559", "pdf": "https://arxiv.org/pdf/2404.00559", "title": "Hierarchical Climate Control Strategy for Electric Vehicles with  Door-Opening Consideration", "authors": "Sanghyeon Nam, Hyejin Lee, Youngki Kim, Kyoung hyun Kwak, Kyoungseok Han", "subjects": "Systems and Control (eess.SY)", "abstract": "This study proposes a novel climate control strategy for electric vehicles (EVs) by addressing door-opening interruptions, an overlooked aspect in EV thermal management. We create and validate an EV simulation model that incorporates door-opening scenarios. Three controllers are compared using the simulation model: (i) a hierarchical non-linear model predictive control (NMPC) with a unique coolant dividing layer and a component for cabin air inflow regulation based on door-opening signals; (ii) a single MPC controller; and (iii) a rule-based controller. The hierarchical controller outperforms, reducing door-opening temperature drops by 46.96% and 51.33% compared to single layer MPC and rule-based methods in the relevant section. Additionally, our strategy minimizes the maximum temperature gaps between the sections during recovery by 86.4% and 78.7%, surpassing single layer MPC and rule-based approaches, respectively. We believe that this result opens up future possibilities for incorporating the thermal comfort of passengers across all sections within the vehicle."}
{"main_page": "https://arxiv.org/abs/2404.00560", "pdf": "https://arxiv.org/pdf/2404.00560", "title": "A Theory for Length Generalization in Learning to Reason", "authors": "Changnan Xiao, Bing Liu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Length generalization (LG) is a challenging problem in learning to reason. It refers to the phenomenon that when trained on reasoning problems of smaller lengths or sizes, the resulting model struggles with problems of larger sizes or lengths. Although LG has been studied by many researchers, the challenge remains. This paper proposes a theoretical study of LG for problems whose reasoning processes can be modeled as DAGs (directed acyclic graphs). The paper first identifies and proves the conditions under which LG can be achieved in learning to reason. It then designs problem representations based on the theory to learn to solve challenging reasoning problems like parity, addition, and multiplication, using a Transformer to achieve perfect LG."}
{"main_page": "https://arxiv.org/abs/2404.00562", "pdf": "https://arxiv.org/pdf/2404.00562", "title": "Text2HOI: Text-guided 3D Motion Generation for Hand-Object Interaction", "authors": "Junuk Cha, Jihyeon Kim, Jae Shin Yoon, Seungryul Baek", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper introduces the first text-guided work for generating the sequence of hand-object interaction in 3D. The main challenge arises from the lack of labeled data where existing ground-truth datasets are nowhere near generalizable in interaction type and object category, which inhibits the modeling of diverse 3D hand-object interaction with the correct physical implication (e.g., contacts and semantics) from text prompts. To address this challenge, we propose to decompose the interaction generation task into two subtasks: hand-object contact generation; and hand-object motion generation. For contact generation, a VAE-based network takes as input a text and an object mesh, and generates the probability of contacts between the surfaces of hands and the object during the interaction. The network learns a variety of local geometry structure of diverse objects that is independent of the objects' category, and thus, it is applicable to general objects. For motion generation, a Transformer-based diffusion model utilizes this 3D contact map as a strong prior for generating physically plausible hand-object motion as a function of text prompts by learning from the augmented labeled dataset; where we annotate text labels from many existing 3D hand and object motion data. Finally, we further introduce a hand refiner module that minimizes the distance between the object surface and hand joints to improve the temporal stability of the object-hand contacts and to suppress the penetration artifacts. In the experiments, we demonstrate that our method can generate more realistic and diverse interactions compared to other baseline methods. We also show that our method is applicable to unseen objects. We will release our model and newly labeled data as a strong foundation for future research. Codes and data are available in: https://github.com/JunukCha/Text2HOI."}
{"main_page": "https://arxiv.org/abs/2404.00563", "pdf": "https://arxiv.org/pdf/2404.00563", "title": "Exploiting Inter-sample and Inter-feature Relations in Dataset  Distillation", "authors": "Wenxiao Deng, Wenbin Li, Tianyu Ding, Lei Wang, Hongguang Zhang, Kuihua Huang, Jing Huo, Yang Gao", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Dataset distillation has emerged as a promising approach in deep learning, enabling efficient training with small synthetic datasets derived from larger real ones. Particularly, distribution matching-based distillation methods attract attention thanks to its effectiveness and low computational cost. However, these methods face two primary limitations: the dispersed feature distribution within the same class in synthetic datasets, reducing class discrimination, and an exclusive focus on mean feature consistency, lacking precision and comprehensiveness. To address these challenges, we introduce two novel constraints: a class centralization constraint and a covariance matching constraint. The class centralization constraint aims to enhance class discrimination by more closely clustering samples within classes. The covariance matching constraint seeks to achieve more accurate feature distribution matching between real and synthetic datasets through local feature covariance matrices, particularly beneficial when sample sizes are much smaller than the number of features. Experiments demonstrate notable improvements with these constraints, yielding performance boosts of up to 6.6% on CIFAR10, 2.9% on SVHN, 2.5% on CIFAR100, and 2.5% on TinyImageNet, compared to the state-of-the-art relevant methods. In addition, our method maintains robust performance in cross-architecture settings, with a maximum performance drop of 1.7% on four architectures. Code is available at https://github.com/VincenDen/IID."}
{"main_page": "https://arxiv.org/abs/2404.00565", "pdf": "https://arxiv.org/pdf/2404.00565", "title": "Leveraging Corpus Metadata to Detect Template-based Translation: An  Exploratory Case Study of the Egyptian Arabic Wikipedia Edition", "authors": "Saied Alshahrani, Hesham Haroon, Ali Elfilali, Mariama Njie, Jeanna Matthews", "subjects": "Computation and Language (cs.CL)", "abstract": "Wikipedia articles (content pages) are commonly used corpora in Natural Language Processing (NLP) research, especially in low-resource languages other than English. Yet, a few research studies have studied the three Arabic Wikipedia editions, Arabic Wikipedia (AR), Egyptian Arabic Wikipedia (ARZ), and Moroccan Arabic Wikipedia (ARY), and documented issues in the Egyptian Arabic Wikipedia edition regarding the massive automatic creation of its articles using template-based translation from English to Arabic without human involvement, overwhelming the Egyptian Arabic Wikipedia with articles that do not only have low-quality content but also with articles that do not represent the Egyptian people, their culture, and their dialect. In this paper, we aim to mitigate the problem of template translation that occurred in the Egyptian Arabic Wikipedia by identifying these template-translated articles and their characteristics through exploratory analysis and building automatic detection systems. We first explore the content of the three Arabic Wikipedia editions in terms of density, quality, and human contributions and utilize the resulting insights to build multivariate machine learning classifiers leveraging articles' metadata to detect the template-translated articles automatically. We then publicly deploy and host the best-performing classifier, XGBoost, as an online application called EGYPTIAN WIKIPEDIA SCANNER and release the extracted, filtered, and labeled datasets to the research community to benefit from our datasets and the online, web-based detection system."}
{"main_page": "https://arxiv.org/abs/2404.00566", "pdf": "https://arxiv.org/pdf/2404.00566", "title": "CodeBenchGen: Creating Scalable Execution-based Code Generation  Benchmarks", "authors": "Yiqing Xie, Alex Xie, Divyanshu Sheth, Pengfei Liu, Daniel Fried, Carolyn Rose", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL)", "abstract": "To facilitate evaluation of code generation systems across diverse scenarios, we present CodeBenchGen, a framework to create scalable execution-based benchmarks that only requires light guidance from humans. Specifically, we leverage a large language model (LLM) to convert an arbitrary piece of code into an evaluation example, including test cases for execution-based evaluation. We illustrate the usefulness of our framework by creating a dataset, Exec-CSN, which includes 1,931 examples involving 293 libraries revised from code in 367 GitHub repositories taken from the CodeSearchNet dataset. To demonstrate the complexity and solvability of examples in Exec-CSN, we present a human study demonstrating that 81.3% of the examples can be solved by humans and 61% are rated as ``requires effort to solve''. We conduct code generation experiments on open-source and proprietary models and analyze the performance of both humans and models. We will release the code of both the framework and the dataset upon acceptance."}
{"main_page": "https://arxiv.org/abs/2404.00569", "pdf": "https://arxiv.org/pdf/2404.00569", "title": "CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through  Weighted Samplers and Consistency Models", "authors": "Xiang Li, Fan Bu, Ambuj Mehrish, Yingting Li, Jiale Han, Bo Cheng, Soujanya Poria", "subjects": "Sound (cs.SD); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)", "abstract": "Neural Text-to-Speech (TTS) systems find broad applications in voice assistants, e-learning, and audiobook creation. The pursuit of modern models, like Diffusion Models (DMs), holds promise for achieving high-fidelity, real-time speech synthesis. Yet, the efficiency of multi-step sampling in Diffusion Models presents challenges. Efforts have been made to integrate GANs with DMs, speeding up inference by approximating denoising distributions, but this introduces issues with model convergence due to adversarial training. To overcome this, we introduce CM-TTS, a novel architecture grounded in consistency models (CMs). Drawing inspiration from continuous-time diffusion models, CM-TTS achieves top-quality speech synthesis in fewer steps without adversarial training or pre-trained model dependencies. We further design weighted samplers to incorporate different sampling positions into model training with dynamic probabilities, ensuring unbiased learning throughout the entire training process. We present a real-time mel-spectrogram generation consistency model, validated through comprehensive evaluations. Experimental results underscore CM-TTS's superiority over existing single-step speech synthesis systems, representing a significant advancement in the field."}
{"main_page": "https://arxiv.org/abs/2404.00570", "pdf": "https://arxiv.org/pdf/2404.00570", "title": "ParaICL: Towards Robust Parallel In-Context Learning", "authors": "Xingxuan Li, Xuan-Phi Nguyen, Shafiq Joty, Lidong Bing", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) have become the norm in natural language processing (NLP), excelling in few-shot in-context learning (ICL) with their remarkable abilities. Nonetheless, the success of ICL largely hinges on the choice of few-shot demonstration examples, making the selection process increasingly crucial. Existing methods have delved into optimizing the quantity and semantic similarity of these examples to improve ICL performances. However, our preliminary experiments indicate that the effectiveness of ICL is limited by the length of the input context. Moreover, varying combinations of few-shot demonstration examples can significantly boost accuracy across different test samples. To address this, we propose a novel method named parallel in-context learning (ParaICL) that effectively utilizes all demonstration examples without exceeding the manageable input context length. ParaICL employs parallel batching to distribute demonstration examples into different batches according to the semantic similarities of the questions in the demonstrations to the test question. It then computes normalized batch semantic scores for each batch. A weighted average semantic objective, constrained by adaptive plausibility, is applied to select the most appropriate tokens. Through extensive experiments, we validate the effectiveness of ParaICL and conduct ablation studies to underscore its design rationale. We further demonstrate that ParaICL can seamlessly integrate with existing methods."}
{"main_page": "https://arxiv.org/abs/2404.00571", "pdf": "https://arxiv.org/pdf/2404.00571", "title": "Explainable Multi-hop Question Generation: An End-to-End Approach  without Intermediate Question Labeling", "authors": "Seonjeong Hwang, Yunsu Kim, Gary Geunbae Lee", "subjects": "Computation and Language (cs.CL)", "abstract": "In response to the increasing use of interactive artificial intelligence, the demand for the capacity to handle complex questions has increased. Multi-hop question generation aims to generate complex questions that requires multi-step reasoning over several documents. Previous studies have predominantly utilized end-to-end models, wherein questions are decoded based on the representation of context documents. However, these approaches lack the ability to explain the reasoning process behind the generated multi-hop questions. Additionally, the question rewriting approach, which incrementally increases the question complexity, also has limitations due to the requirement of labeling data for intermediate-stage questions. In this paper, we introduce an end-to-end question rewriting model that increases question complexity through sequential rewriting. The proposed model has the advantage of training with only the final multi-hop questions, without intermediate questions. Experimental results demonstrate the effectiveness of our model in generating complex questions, particularly 3- and 4-hop questions, which are appropriately paired with input answers. We also prove that our model logically and incrementally increases the complexity of questions, and the generated multi-hop questions are also beneficial for training question answering models."}
{"main_page": "https://arxiv.org/abs/2404.00572", "pdf": "https://arxiv.org/pdf/2404.00572", "title": "ADs: Active Data-sharing for Data Quality Assurance in Advanced  Manufacturing Systems", "authors": "Yue Zhao, Yuxuan Li, Chenang Liu, Yinan Wang", "subjects": "Machine Learning (cs.LG)", "abstract": "Machine learning (ML) methods are widely used in industrial applications, which usually require a large amount of training data. However, data collection needs extensive time costs and investments in the manufacturing system, and data scarcity commonly exists. Therefore, data-sharing is widely enabled among multiple machines with similar functionality to augment the dataset for building ML methods. However, distribution mismatch inevitably exists in their data due to different working conditions, while the ML methods are assumed to be built and tested on the dataset following the same distribution. Thus, an Active Data-sharing (ADs) framework is proposed to ensure the quality of the shared data among multiple machines. It is designed to simultaneously select the most informative data points benefiting the downstream tasks and mitigate the distribution mismatch among all selected data points. The proposed method is validated on anomaly detection on in-situ monitoring data from three additive manufacturing processes."}
{"main_page": "https://arxiv.org/abs/2404.00573", "pdf": "https://arxiv.org/pdf/2404.00573", "title": "\"My agent understands me better\": Integrating Dynamic Human-like Memory  Recall and Consolidation in LLM-Based Agents", "authors": "Yuki Hou, Haruki Tamoto, Homei Miyashita", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "In this study, we propose a novel human-like memory architecture designed for enhancing the cognitive abilities of large language model based dialogue agents. Our proposed architecture enables agents to autonomously recall memories necessary for response generation, effectively addressing a limitation in the temporal cognition of LLMs. We adopt the human memory cue recall as a trigger for accurate and efficient memory recall. Moreover, we developed a mathematical model that dynamically quantifies memory consolidation, considering factors such as contextual relevance, elapsed time, and recall frequency. The agent stores memories retrieved from the user's interaction history in a database that encapsulates each memory's content and temporal context. Thus, this strategic storage allows agents to recall specific memories and understand their significance to the user in a temporal context, similar to how humans recognize and recall past experiences."}
{"main_page": "https://arxiv.org/abs/2404.00576", "pdf": "https://arxiv.org/pdf/2404.00576", "title": "Automated Bi-Fold Weighted Ensemble Algorithms and its Application to  Brain Tumor Detection and Classification", "authors": "PoTsang B. Huang, Muhammad Rizwan, Mehboob Ali", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The uncontrolled and unstructured growth of brain cells is known as brain tumor, which has one of the highest mortality rates among diseases from all types of cancers. Due to limited diagnostic and treatment capabilities, they pose significant challenges, especially in third-world countries. Early diagnosis plays a vital role in effectively managing brain tumors and reducing mortality rates. However, the availability of diagnostic methods is hindered by various limitations, including high costs and lengthy result acquisition times, impeding early detection of the disease. In this study, we present two cutting-edge bi-fold weighted voting ensemble models that aim to boost the effectiveness of weighted ensemble methods. These two proposed methods combine the classification outcomes from multiple classifiers and determine the optimal result by selecting the one with the highest probability in the first approach, and the highest weighted prediction in the second technique. These approaches significantly improve the overall performance of weighted ensemble techniques. In the first proposed method, we improve the soft voting technique (SVT) by introducing a novel unsupervised weight calculating schema (UWCS) to enhance its weight assigning capability, known as the extended soft voting technique (ESVT). Secondly, we propose a novel weighted method (NWM) by using the proposed UWCS. Both of our approaches incorporate three distinct models: a custom-built CNN, VGG-16, and InceptionResNetV2 which has been trained on publicly available datasets. The effectiveness of our proposed systems is evaluated through blind testing, where exceptional results are achieved. We then establish a comparative analysis of the performance of our proposed methods with that of SVT to show their superiority and effectiveness."}
{"main_page": "https://arxiv.org/abs/2404.00578", "pdf": "https://arxiv.org/pdf/2404.00578", "title": "M3D: Advancing 3D Medical Image Analysis with Multi-Modal Large Language  Models", "authors": "Fan Bai, Yuxin Du, Tiejun Huang, Max Q.-H. Meng, Bo Zhao", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Medical image analysis is essential to clinical diagnosis and treatment, which is increasingly supported by multi-modal large language models (MLLMs). However, previous research has primarily focused on 2D medical images, leaving 3D images under-explored, despite their richer spatial information. This paper aims to advance 3D medical image analysis with MLLMs. To this end, we present a large-scale 3D multi-modal medical dataset, M3D-Data, comprising 120K image-text pairs and 662K instruction-response pairs specifically tailored for various 3D medical tasks, such as image-text retrieval, report generation, visual question answering, positioning, and segmentation. Additionally, we propose M3D-LaMed, a versatile multi-modal large language model for 3D medical image analysis. Furthermore, we introduce a new 3D multi-modal medical benchmark, M3D-Bench, which facilitates automatic evaluation across eight tasks. Through comprehensive evaluation, our method proves to be a robust model for 3D medical image analysis, outperforming existing solutions. All code, data, and models are publicly available at: https://github.com/BAAI-DCAI/M3D."}
{"main_page": "https://arxiv.org/abs/2404.00579", "pdf": "https://arxiv.org/pdf/2404.00579", "title": "A Review of Modern Recommender Systems Using Generative Models  (Gen-RecSys)", "authors": "Yashar Deldjoo, Zhankui He, Julian McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, Ren\u00e9 Vidal, Maheswaran Sathiamoorthy, Atoosa Kasirzadeh, Silvia Milano", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "abstract": "Traditional recommender systems (RS) have used user-item rating histories as their primary data source, with collaborative filtering being one of the principal methods. However, generative models have recently developed abilities to model and sample from complex data distributions, including not only user-item interaction histories but also text, images, and videos - unlocking this rich data for novel recommendation tasks. Through this comprehensive and multi-disciplinary survey, we aim to connect the key advancements in RS using Generative Models (Gen-RecSys), encompassing: a foundational overview of interaction-driven generative models; the application of large language models (LLM) for generative recommendation, retrieval, and conversational recommendation; and the integration of multimodal models for processing and generating image and video content in RS. Our holistic perspective allows us to highlight necessary paradigms for evaluating the impact and harm of Gen-RecSys and identify open challenges. A more up-to-date version of the papers is maintained at: https://github.com/yasdel/LLM-RecSys."}
{"main_page": "https://arxiv.org/abs/2404.00581", "pdf": "https://arxiv.org/pdf/2404.00581", "title": "Correspondence between Composite Theories and Distributive Laws", "authors": "Alo\u00efs Rosset, Maaike Zwart, Helle Hvid Hansen, J\u00f6rg Endrullis", "subjects": "Logic in Computer Science (cs.LO); Category Theory (math.CT)", "abstract": "Composite theories are the algebraic equivalent of distributive laws. In this paper, we delve into the details of this correspondence and concretely show how to construct a composite theory from a distributive law and vice versa. Using term rewriting methods, we also describe when a minimal set of equations axiomatises the composite theory."}
{"main_page": "https://arxiv.org/abs/2404.00586", "pdf": "https://arxiv.org/pdf/2404.00586", "title": "RLGNet: Repeating-Local-Global History Network for Temporal Knowledge  Graph Reasoning", "authors": "Ao Lv, Yongzhong Huang, Guige Ouyang, Yue Chen, Haoran Xie", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Temporal Knowledge Graph (TKG) reasoning is based on historical information to predict the future. Therefore, parsing and mining historical information is key to predicting the future. Most existing methods fail to concurrently address and comprehend historical information from both global and local perspectives. Neglecting the global view might result in overlooking macroscopic trends and patterns, while ignoring the local view can lead to missing critical detailed information. Additionally, some methods do not focus on learning from high-frequency repeating events, which means they may not fully grasp frequently occurring historical events. To this end, we propose the \\textbf{R}epetitive-\\textbf{L}ocal-\\textbf{G}lobal History \\textbf{Net}work(RLGNet). We utilize a global history encoder to capture the overarching nature of historical information. Subsequently, the local history encoder provides information related to the query timestamp. Finally, we employ the repeating history encoder to identify and learn from frequently occurring historical events. In the evaluation on six benchmark datasets, our approach generally outperforms existing TKG reasoning models in multi-step and single-step reasoning tasks."}
{"main_page": "https://arxiv.org/abs/2404.00588", "pdf": "https://arxiv.org/pdf/2404.00588", "title": "Memory-based Cross-modal Semantic Alignment Network for Radiology Report  Generation", "authors": "Yitian Tao, Liyan Ma, Jing Yu, Han Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Generating radiology reports automatically reduces the workload of radiologists and helps the diagnoses of specific diseases. Many existing methods take this task as modality transfer process. However, since the key information related to disease accounts for a small proportion in both image and report, it is hard for the model to learn the latent relation between the radiology image and its report, thus failing to generate fluent and accurate radiology reports. To tackle this problem, we propose a memory-based cross-modal semantic alignment model (MCSAM) following an encoder-decoder paradigm. MCSAM includes a well initialized long-term clinical memory bank to learn disease-related representations as well as prior knowledge for different modalities to retrieve and use the retrieved memory to perform feature consolidation. To ensure the semantic consistency of the retrieved cross modal prior knowledge, a cross-modal semantic alignment module (SAM) is proposed. SAM is also able to generate semantic visual feature embeddings which can be added to the decoder and benefits report generation. More importantly, to memorize the state and additional information while generating reports with the decoder, we use learnable memory tokens which can be seen as prompts. Extensive experiments demonstrate the promising performance of our proposed method which generates state-of-the-art performance on the MIMIC-CXR dataset."}
{"main_page": "https://arxiv.org/abs/2404.00589", "pdf": "https://arxiv.org/pdf/2404.00589", "title": "Harnessing the Power of Large Language Model for Uncertainty Aware Graph  Processing", "authors": "Zhenyu Qian, Yiming Qian, Yuting Song, Fei Gao, Hai Jin, Chen Yu, Xia Xie", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Handling graph data is one of the most difficult tasks. Traditional techniques, such as those based on geometry and matrix factorization, rely on assumptions about the data relations that become inadequate when handling large and complex graph data. On the other hand, deep learning approaches demonstrate promising results in handling large graph data, but they often fall short of providing interpretable explanations. To equip the graph processing with both high accuracy and explainability, we introduce a novel approach that harnesses the power of a large language model (LLM), enhanced by an uncertainty-aware module to provide a confidence score on the generated answer. We experiment with our approach on two graph processing tasks: few-shot knowledge graph completion and graph classification. Our results demonstrate that through parameter efficient fine-tuning, the LLM surpasses state-of-the-art algorithms by a substantial margin across ten diverse benchmark datasets. Moreover, to address the challenge of explainability, we propose an uncertainty estimation based on perturbation, along with a calibration scheme to quantify the confidence scores of the generated answers. Our confidence measure achieves an AUC of 0.8 or higher on seven out of the ten datasets in predicting the correctness of the answer generated by LLM."}
{"main_page": "https://arxiv.org/abs/2404.00590", "pdf": "https://arxiv.org/pdf/2404.00590", "title": "CuSINeS: Curriculum-driven Structure Induced Negative Sampling for  Statutory Article Retrieval", "authors": "T.Y.S.S Santosh, Kristina Kaiser, Matthias Grabmair", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "abstract": "In this paper, we introduce CuSINeS, a negative sampling approach to enhance the performance of Statutory Article Retrieval (SAR). CuSINeS offers three key contributions. Firstly, it employs a curriculum-based negative sampling strategy guiding the model to focus on easier negatives initially and progressively tackle more difficult ones. Secondly, it leverages the hierarchical and sequential information derived from the structural organization of statutes to evaluate the difficulty of samples. Lastly, it introduces a dynamic semantic difficulty assessment using the being-trained model itself, surpassing conventional static methods like BM25, adapting the negatives to the model's evolving competence. Experimental results on a real-world expert-annotated SAR dataset validate the effectiveness of CuSINeS across four different baselines, demonstrating its versatility."}
{"main_page": "https://arxiv.org/abs/2404.00591", "pdf": "https://arxiv.org/pdf/2404.00591", "title": "Task-Space Riccati Feedback based Whole Body Control for Underactuated  Legged Locomotion", "authors": "Shunpeng Yang, Zejun Hong, Sen Li, Patrick Wensing, Wei Zhang, Hua Chen", "subjects": "Robotics (cs.RO)", "abstract": "This manuscript primarily aims to enhance the performance of whole-body controllers(WBC) for underactuated legged locomotion. We introduce a systematic parameter design mechanism for the floating-base feedback control within the WBC. The proposed approach involves utilizing the linearized model of unactuated dynamics to formulate a Linear Quadratic Regulator(LQR) and solving a Riccati gain while accounting for potential physical constraints through a second-order approximation of the log-barrier function. And then the user-tuned feedback gain for the floating base task is replaced by a new one constructed from the solved Riccati gain. Extensive simulations conducted in MuJoCo with a point bipedal robot, as well as real-world experiments performed on a quadruped robot, demonstrate the effectiveness of the proposed method. In the different bipedal locomotion tasks, compared with the user-tuned method, the proposed approach is at least 12% better and up to 50% better at linear velocity tracking, and at least 7% better and up to 47% better at angular velocity tracking. In the quadruped experiment, linear velocity tracking is improved by at least 3% and angular velocity tracking is improved by at least 23% using the proposed method."}
{"main_page": "https://arxiv.org/abs/2404.00593", "pdf": "https://arxiv.org/pdf/2404.00593", "title": "LAESI: Leaf Area Estimation with Synthetic Imagery", "authors": "Jacek Ka\u0142u\u017cny, Yannik Schreckenberg, Karol Cyganik, Peter Annigh\u00f6fer, S\u00f6ren Pirk, Dominik L. Michels, Mikolaj Cieslak, Farhah Assaad-Gerbert, Bedrich Benes, Wojciech Pa\u0142ubicki", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)", "abstract": "We introduce LAESI, a Synthetic Leaf Dataset of 100,000 synthetic leaf images on millimeter paper, each with semantic masks and surface area labels. This dataset provides a resource for leaf morphology analysis primarily aimed at beech and oak leaves. We evaluate the applicability of the dataset by training machine learning models for leaf surface area prediction and semantic segmentation, using real images for validation. Our validation shows that these models can be trained to predict leaf surface area with a relative error not greater than an average human annotator. LAESI also provides an efficient framework based on 3D procedural models and generative AI for the large-scale, controllable generation of data with potential further applications in agriculture and biology. We evaluate the inclusion of generative AI in our procedural data generation pipeline and show how data filtering based on annotation consistency results in datasets which allow training the highest performing vision models."}
{"main_page": "https://arxiv.org/abs/2404.00594", "pdf": "https://arxiv.org/pdf/2404.00594", "title": "LexAbSumm: Aspect-based Summarization of Legal Decisions", "authors": "T.Y.S.S Santosh, Mahmoud Aly, Matthias Grabmair", "subjects": "Computation and Language (cs.CL)", "abstract": "Legal professionals frequently encounter long legal judgments that hold critical insights for their work. While recent advances have led to automated summarization solutions for legal documents, they typically provide generic summaries, which may not meet the diverse information needs of users. To address this gap, we introduce LexAbSumm, a novel dataset designed for aspect-based summarization of legal case decisions, sourced from the European Court of Human Rights jurisdiction. We evaluate several abstractive summarization models tailored for longer documents on LexAbSumm, revealing a challenge in conditioning these models to produce aspect-specific summaries. We release LexAbSum to facilitate research in aspect-based summarization for legal domain."}
{"main_page": "https://arxiv.org/abs/2404.00595", "pdf": "https://arxiv.org/pdf/2404.00595", "title": "Query-driven Relevant Paragraph Extraction from Legal Judgments", "authors": "T.Y.S.S Santosh, Elvin Quero Hernandez, Matthias Grabmair", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "Legal professionals often grapple with navigating lengthy legal judgements to pinpoint information that directly address their queries. This paper focus on this task of extracting relevant paragraphs from legal judgements based on the query. We construct a specialized dataset for this task from the European Court of Human Rights (ECtHR) using the case law guides. We assess the performance of current retrieval models in a zero-shot way and also establish fine-tuning benchmarks using various models. The results highlight the significant gap between fine-tuned and zero-shot performance, emphasizing the challenge of handling distribution shift in the legal domain. We notice that the legal pre-training handles distribution shift on the corpus side but still struggles on query side distribution shift, with unseen legal queries. We also explore various Parameter Efficient Fine-Tuning (PEFT) methods to evaluate their practicality within the context of information retrieval, shedding light on the effectiveness of different PEFT methods across diverse configurations with pre-training and model architectures influencing the choice of PEFT method."}
{"main_page": "https://arxiv.org/abs/2404.00596", "pdf": "https://arxiv.org/pdf/2404.00596", "title": "ECtHR-PCR: A Dataset for Precedent Understanding and Prior Case  Retrieval in the European Court of Human Rights", "authors": "T.Y.S.S Santosh, Rashid Gustav Haddad, Matthias Grabmair", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "In common law jurisdictions, legal practitioners rely on precedents to construct arguments, in line with the doctrine of \\emph{stare decisis}. As the number of cases grow over the years, prior case retrieval (PCR) has garnered significant attention. Besides lacking real-world scale, existing PCR datasets do not simulate a realistic setting, because their queries use complete case documents while only masking references to prior cases. The query is thereby exposed to legal reasoning not yet available when constructing an argument for an undecided case as well as spurious patterns left behind by citation masks, potentially short-circuiting a comprehensive understanding of case facts and legal principles. To address these limitations, we introduce a PCR dataset based on judgements from the European Court of Human Rights (ECtHR), which explicitly separate facts from arguments and exhibit precedential practices, aiding us to develop this PCR dataset to foster systems' comprehensive understanding. We benchmark different lexical and dense retrieval approaches with various negative sampling strategies, adapting them to deal with long text sequences using hierarchical variants. We found that difficulty-based negative sampling strategies were not effective for the PCR task, highlighting the need for investigation into domain-specific difficulty criteria. Furthermore, we observe performance of the dense models degrade with time and calls for further research into temporal adaptation of retrieval models. Additionally, we assess the influence of different views , Halsbury's and Goodhart's, in practice in ECtHR jurisdiction using PCR task."}
{"main_page": "https://arxiv.org/abs/2404.00597", "pdf": "https://arxiv.org/pdf/2404.00597", "title": "Parameter and Data-Efficient Spectral StyleDCGAN", "authors": "Aryan Garg", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present a simple, highly parameter, and data-efficient adversarial network for unconditional face generation. Our method: Spectral Style-DCGAN or SSD utilizes only 6.574 million parameters and 4739 dog faces from the Animal Faces HQ (AFHQ) dataset as training samples while preserving fidelity at low resolutions up to 64x64. Code available at https://github.com/Aryan-Garg/StyleDCGAN."}
{"main_page": "https://arxiv.org/abs/2404.00598", "pdf": "https://arxiv.org/pdf/2404.00598", "title": "Robust Beamforming Design and Antenna Selection for Dynamic HRIS-aided  Massive MIMO Systems", "authors": "Jintao Wang, Binggui Zhou, Chengzhi Ma, Shiqi Gong, Guanghua Yang, Shaodan Ma", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "In this paper, a dynamic hybrid active-passive reconfigurable intelligent surface (HRIS) is proposed to further enhance the massive multiple-input-multiple-output (MIMO) system, since it supports the dynamic placement of active and passive elements. Specifically, considering the impact of the hardware impairments (HWIs), we investigate the channel-aware configuration of the receive antennas at the base station (BS) and the active/passive elements at the HRIS to improve the reliability of system. To this end, we investigate the average mean-square-error (MSE) minimization problem for the HRIS-aided massive MIMO system by jointly optimizing the BS receive antenna selection matrix, the reflection phase coefficients, the reflection amplitude matrix, and the mode selection matrix of the HRIS under the power budget of the HRIS. To tackle the non-convexity and intractability of this problem, we first transform the binary and discrete variables into continuous ones, and then propose a penalty-based exact block coordinate descent (BCD) algorithm to solve these subproblems alternately. Numerical simulations demonstrate the great superiority of the proposed scheme over the conventional benchmark schemes."}
{"main_page": "https://arxiv.org/abs/2404.00599", "pdf": "https://arxiv.org/pdf/2404.00599", "title": "EvoCodeBench: An Evolving Code Generation Benchmark Aligned with  Real-World Code Repositories", "authors": "Jia Li, Ge Li, Xuanming Zhang, Yihong Dong, Zhi Jin", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "abstract": "How to evaluate Large Language Models (LLMs) in code generation is an open question. Existing benchmarks demonstrate poor alignment with real-world code repositories and are insufficient to evaluate the coding abilities of LLMs. This paper proposes a new benchmark - EvoCodeBench to address the preceding problems, which has three primary advances. (1) EvoCodeBench aligns with real-world repositories in multiple dimensions, e.g., code distributions and dependency distributions. (2) EvoCodeBench offers comprehensive annotations (e.g., requirements, reference code, and reference dependencies), and robust evaluation metrics (e.g., Pass@k and Recall@k). (3) EvoCodeBench is an evolving benchmark to avoid data leakage. We build an automatic pipeline to update EvoCodeBench from the latest repositories. We release the first version - EvoCodeBench-2403, containing 275 samples from 25 real-world repositories. Based on EvoCodeBench, we propose repository-level code generation and evaluate 10 popular LLMs (e.g., gpt-4, gpt-3.5, DeepSeek Coder, StarCoder 2, CodeLLaMa, Gemma, and Qwen 1.5). Our experiments reveal the coding abilities of these LLMs in real-world repositories. For example, the highest Pass@1 of gpt-4 only is 20.73% in our experiments. We also analyze failed cases and summarize the shortcomings of existing LLMs in EvoCodeBench. We release EvoCodeBench, all prompts, and LLMs' completions for further community analysis."}
{"main_page": "https://arxiv.org/abs/2404.00600", "pdf": "https://arxiv.org/pdf/2404.00600", "title": "AI Act and Large Language Models (LLMs): When critical issues and  privacy impact require human and ethical oversight", "authors": "Nicola Fabiano", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "The imposing evolution of artificial intelligence systems and, specifically, of Large Language Models (LLM) makes it necessary to carry out assessments of their level of risk and the impact they may have in the area of privacy, personal data protection and at an ethical level, especially on the weakest and most vulnerable. This contribution addresses human oversight, ethical oversight, and privacy impact assessment."}
{"main_page": "https://arxiv.org/abs/2404.00602", "pdf": "https://arxiv.org/pdf/2404.00602", "title": "1-out-of-n Oblivious Signatures: Security Revisited and a Generic  Construction with an Efficient Communication Cost", "authors": "Masayuki Tezuka, Keisuke Tanaka", "subjects": "Cryptography and Security (cs.CR)", "abstract": "1-out-of-n oblivious signature by Chen (ESORIC 1994) is a protocol between the user and the signer. In this scheme, the user makes a list of n messages and chooses the message that the user wants to obtain a signature from the list. The user interacts with the signer by providing this message list and obtains the signature for only the chosen message without letting the signer identify which messages the user chooses. Tso et al. (ISPEC 2008) presented a formal treatment of 1-out-of-n oblivious signatures. They defined unforgeability and ambiguity for 1-out-of-n oblivious signatures as a security requirement. In this work, first, we revisit the unforgeability security definition by Tso et al. and point out that their security definition has problems. We address these problems by modifying their security model and redefining unforgeable security. Second, we improve the generic construction of a 1-out-of-n oblivious signature scheme by Zhou et al. (IEICE Trans 2022). We reduce the communication cost by modifying their scheme with a Merkle tree. Then we prove the security of our modified scheme."}
{"main_page": "https://arxiv.org/abs/2404.00603", "pdf": "https://arxiv.org/pdf/2404.00603", "title": "Weak Distribution Detectors Lead to Stronger Generalizability of  Vision-Language Prompt Tuning", "authors": "Kun Ding, Haojian Zhang, Qiang Yu, Ying Wang, Shiming Xiang, Chunhong Pan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We propose a generalized method for boosting the generalization ability of pre-trained vision-language models (VLMs) while fine-tuning on downstream few-shot tasks. The idea is realized by exploiting out-of-distribution (OOD) detection to predict whether a sample belongs to a base distribution or a novel distribution and then using the score generated by a dedicated competition based scoring function to fuse the zero-shot and few-shot classifier. The fused classifier is dynamic, which will bias towards the zero-shot classifier if a sample is more likely from the distribution pre-trained on, leading to improved base-to-novel generalization ability. Our method is performed only in test stage, which is applicable to boost existing methods without time-consuming re-training. Extensive experiments show that even weak distribution detectors can still improve VLMs' generalization ability. Specifically, with the help of OOD detectors, the harmonic mean of CoOp and ProGrad increase by 2.6 and 1.5 percentage points over 11 recognition datasets in the base-to-novel setting."}
{"main_page": "https://arxiv.org/abs/2404.00604", "pdf": "https://arxiv.org/pdf/2404.00604", "title": "Extensive Self-Contrast Enables Feedback-Free Language Model Alignment", "authors": "Xiao Liu, Xixuan Song, Yuxiao Dong, Jie Tang", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Reinforcement learning from human feedback (RLHF) has been a central technique for recent large language model (LLM) alignment. However, its heavy dependence on costly human or LLM-as-Judge preference feedback could stymie its wider applications. In this work, we introduce Self-Contrast, a feedback-free large language model alignment method via exploiting extensive self-generated negatives. With only supervised fine-tuning (SFT) targets, Self-Contrast leverages the LLM itself to generate massive diverse candidates, and harnesses a pre-trained embedding model to filter multiple negatives according to text similarity. Theoretically, we illustrate that in this setting, merely scaling negative responses can still effectively approximate situations with more balanced positive and negative preference annotations. Our experiments with direct preference optimization (DPO) on three datasets show that, Self-Contrast could consistently outperform SFT and standard DPO training by large margins. And as the number of self-generated negatives increases, the performance of Self-Contrast continues to grow. Code and data are available at https://github.com/THUDM/Self-Contrast."}
{"main_page": "https://arxiv.org/abs/2404.00610", "pdf": "https://arxiv.org/pdf/2404.00610", "title": "RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation", "authors": "Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo, Jie Fu", "subjects": "Computation and Language (cs.CL)", "abstract": "Large Language Models (LLMs) exhibit remarkable capabilities but are prone to generating inaccurate or hallucinatory responses. This limitation stems from their reliance on vast pretraining datasets, making them susceptible to errors in unseen scenarios. To tackle these challenges, Retrieval-Augmented Generation (RAG) addresses this by incorporating external, relevant documents into the response generation process, thus leveraging non-parametric knowledge alongside LLMs' in-context learning abilities. However, existing RAG implementations primarily focus on initial input for context retrieval, overlooking the nuances of ambiguous or complex queries that necessitate further clarification or decomposition for accurate responses. To this end, we propose learning to Refine Query for Retrieval Augmented Generation (RQ-RAG) in this paper, endeavoring to enhance the model by equipping it with capabilities for explicit rewriting, decomposition, and disambiguation. Our experimental results indicate that our method, when applied to a 7B Llama2 model, surpasses the previous state-of-the-art (SOTA) by an average of 1.9\\% across three single-hop QA datasets, and also demonstrates enhanced performance in handling complex, multi-hop QA datasets. Our code is available at https://github.com/chanchimin/RQ-RAG."}
{"main_page": "https://arxiv.org/abs/2404.00611", "pdf": "https://arxiv.org/pdf/2404.00611", "title": "Object-level Copy-Move Forgery Image Detection based on Inconsistency  Mining", "authors": "Jingyu Wang, Niantai Jing, Ziyao Liu, Jie Nie, Yuxin Qi, Chi-Hung Chi, Kwok-Yan Lam", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "In copy-move tampering operations, perpetrators often employ techniques, such as blurring, to conceal tampering traces, posing significant challenges to the detection of object-level targets with intact structures. Focus on these challenges, this paper proposes an Object-level Copy-Move Forgery Image Detection based on Inconsistency Mining (IMNet). To obtain complete object-level targets, we customize prototypes for both the source and tampered regions and dynamically update them. Additionally, we extract inconsistent regions between coarse similar regions obtained through self-correlation calculations and regions composed of prototypes. The detected inconsistent regions are used as supplements to coarse similar regions to refine pixel-level detection. We operate experiments on three public datasets which validate the effectiveness and the robustness of the proposed IMNet."}
{"main_page": "https://arxiv.org/abs/2404.00612", "pdf": "https://arxiv.org/pdf/2404.00612", "title": "Resource Allocation for Green Probabilistic Semantic Communication with  Rate Splitting", "authors": "Ruopeng Xu, Zhaohui Yang, Zhouxiang Zhao, Qianqian Yang, Zhaoyang Zhang", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "In this paper, the energy efficient design for probabilistic semantic communication (PSC) system with rate splitting multiple access (RSMA) is investigated. Basic principles are first reviewed to show how the PSC system works to extract, compress and transmit the semantic information in a task-oriented transmission. Subsequently, the process of how multiuser semantic information can be represented, compressed and transmitted with RSMA is presented, during which the semantic compression ratio (SCR) is introduced to directly measure the computation overhead in a transmission task, and communication overhead is indirectly described as well. Hence, the problem of wireless resource allocation jointly considering the computation and communication consumption for the PSC system with RSMA is investigated. Both conventional wireless resource constraints and unique constraints on semantic communication are considered to maximize the energy efficiency (EE). Simulation results verify the effectiveness of the proposed scheme."}
{"main_page": "https://arxiv.org/abs/2404.00613", "pdf": "https://arxiv.org/pdf/2404.00613", "title": "On $(\u03b8, \u0398)$-cyclic codes and their applications in  constructing QECCs", "authors": "Awadhesh Kumar Shukla, Sachin Pathak, Om Prakash Pandey, Vipul Mishra, Ashish Kumar Upadhyay", "subjects": "Information Theory (cs.IT)", "abstract": "Let $\\mathbb F_q$ be a finite field, where $q$ is an odd prime power. Let $R=\\mathbb{F}_q+u\\mathbb{F}_q+v\\mathbb{F}_q+uv\\mathbb F_q$ with $u^2=u,v^2=v,uv=vu$. In this paper, we study the algebraic structure of $(\\theta, \\Theta)$-cyclic codes of block length $(r,s )$ over $\\mathbb{F}_qR.$ Specifically, we analyze the structure of these codes as left $R[x:\\Theta]$-submodules of $\\mathfrak{R}_{r,s} = \\frac{\\mathbb{F}_q[x:\\theta]}{\\langle x^r-1\\rangle} \\times \\frac{R[x:\\Theta]}{\\langle x^s-1\\rangle}$. Our investigation involves determining generator polynomials and minimal generating sets for this family of codes. Further, we discuss the algebraic structure of separable codes. A relationship between the generator polynomials of $(\\theta, \\Theta)$-cyclic codes over $\\mathbb F_qR$ and their duals is established. Moreover, we calculate the generator polynomials of dual of $(\\theta, \\Theta)$-cyclic codes. As an application of our study, we provide a construction of quantum error-correcting codes (QECCs) from $(\\theta, \\Theta)$-cyclic codes of block length $(r,s)$ over $\\mathbb{F}_qR$. We support our theoretical results with illustrative examples."}
{"main_page": "https://arxiv.org/abs/2404.00614", "pdf": "https://arxiv.org/pdf/2404.00614", "title": "Learning to Plan for Language Modeling from Unlabeled Data", "authors": "Nathan Cornille, Marie-Francine Moens, Florian Mai", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "By training to predict the next token in an unlabeled corpus, large language models learn to perform many tasks without any labeled data. However, their next-token-prediction objective arguably limits their performance in scenarios that require planning, such as writing a coherent article. In this paper, we train a module for planning the future writing process via a self-supervised learning objective. By conditioning on generated latent plans, our model extends the successful language model formula to more abstract planning in an unsupervised way. Empirically, we demonstrate that our method improves language modeling performance in general, particularly with respect to the text structure. Because our framework uses a planner module that is unsupervised and external to the language model, new planner modules can be trained at large scale and easily be shared with the community."}
{"main_page": "https://arxiv.org/abs/2404.00618", "pdf": "https://arxiv.org/pdf/2404.00618", "title": "A Multi-Branched Radial Basis Network Approach to Predicting Complex  Chaotic Behaviours", "authors": "Aarush Sinha", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)", "abstract": "In this study, we propose a multi branched network approach to predict the dynamics of a physics attractor characterized by intricate and chaotic behavior. We introduce a unique neural network architecture comprised of Radial Basis Function (RBF) layers combined with an attention mechanism designed to effectively capture nonlinear inter-dependencies inherent in the attractor's temporal evolution. Our results demonstrate successful prediction of the attractor's trajectory across 100 predictions made using a real-world dataset of 36,700 time-series observations encompassing approximately 28 minutes of activity. To further illustrate the performance of our proposed technique, we provide comprehensive visualizations depicting the attractor's original and predicted behaviors alongside quantitative measures comparing observed versus estimated outcomes. Overall, this work showcases the potential of advanced machine learning algorithms in elucidating hidden structures in complex physical systems while offering practical applications in various domains requiring accurate short-term forecasting capabilities."}
{"main_page": "https://arxiv.org/abs/2404.00620", "pdf": "https://arxiv.org/pdf/2404.00620", "title": "Reporting Eye-Tracking Data Quality: Towards a New Standard", "authors": "Deborah N. Jakobi, Daniel G. Krakowczyk, Lena A. J\u00e4ger", "subjects": "Computation and Language (cs.CL)", "abstract": "Eye-tracking datasets are often shared in the format used by their creators for their original analyses, usually resulting in the exclusion of data considered irrelevant to the primary purpose. In order to increase re-usability of existing eye-tracking datasets for more diverse and initially not considered use cases, this work advocates a new approach of sharing eye-tracking data. Instead of publishing filtered and pre-processed datasets, the eye-tracking data at all pre-processing stages should be published together with data quality reports. In order to transparently report data quality and enable cross-dataset comparisons, we develop data quality reporting standards and metrics that can be automatically applied to a dataset, and integrate them into the open-source Python package pymovements (https://github.com/aeye-lab/pymovements)."}
{"main_page": "https://arxiv.org/abs/2404.00621", "pdf": "https://arxiv.org/pdf/2404.00621", "title": "Multimodal Pretraining, Adaptation, and Generation for Recommendation: A  Survey", "authors": "Qijiong Liu, Jieming Zhu, Yanting Yang, Quanyu Dai, Zhaocheng Du, Xiao-Ming Wu, Zhou Zhao, Rui Zhang, Zhenhua Dong", "subjects": "Information Retrieval (cs.IR); Multimedia (cs.MM)", "abstract": "Personalized recommendation serves as a ubiquitous channel for users to discover information or items tailored to their interests. However, traditional recommendation models primarily rely on unique IDs and categorical features for user-item matching, potentially overlooking the nuanced essence of raw item contents across multiple modalities such as text, image, audio, and video. This underutilization of multimodal data poses a limitation to recommender systems, especially in multimedia services like news, music, and short-video platforms. The recent advancements in pretrained multimodal models offer new opportunities and challenges in developing content-aware recommender systems. This survey seeks to provide a comprehensive exploration of the latest advancements and future trajectories in multimodal pretraining, adaptation, and generation techniques, as well as their applications to recommender systems. Furthermore, we discuss open challenges and opportunities for future research in this domain. We hope that this survey, along with our tutorial materials, will inspire further research efforts to advance this evolving landscape."}
{"main_page": "https://arxiv.org/abs/2404.00622", "pdf": "https://arxiv.org/pdf/2404.00622", "title": "OpenMines: A Light and Comprehensive Mining Simulation Environment for  Truck Dispatching", "authors": "Shi Meng, Bin Tian, Xiaotong Zhang, Shuangying Qi, Caiji Zhang, Qiang Zhang", "subjects": "Multiagent Systems (cs.MA); Systems and Control (eess.SY)", "abstract": "Mine fleet management algorithms can significantly reduce operational costs and enhance productivity in mining systems. Most current fleet management algorithms are evaluated based on self-implemented or proprietary simulation environments, posing challenges for replication and comparison. This paper models the simulation environment for mine fleet management from a complex systems perspective. Building upon previous work, we introduce probabilistic, user-defined events for random event simulation and implement various evaluation metrics and baselines, effectively reflecting the robustness of fleet management algorithms against unforeseen incidents. We present ``OpenMines'', an open-source framework encompassing the entire process of mine system modeling, algorithm development, and evaluation, facilitating future algorithm comparison and replication in the field. Code is available in https://github.com/370025263/openmines."}
{"main_page": "https://arxiv.org/abs/2404.00623", "pdf": "https://arxiv.org/pdf/2404.00623", "title": "Variational Autoencoders for exteroceptive perception in reinforcement  learning-based collision avoidance", "authors": "Thomas Nakken Larsen, Eirik Runde Barlaug, Adil Rasheed", "subjects": "Machine Learning (cs.LG); Robotics (cs.RO)", "abstract": "Modern control systems are increasingly turning to machine learning algorithms to augment their performance and adaptability. Within this context, Deep Reinforcement Learning (DRL) has emerged as a promising control framework, particularly in the domain of marine transportation. Its potential for autonomous marine applications lies in its ability to seamlessly combine path-following and collision avoidance with an arbitrary number of obstacles. However, current DRL algorithms require disproportionally large computational resources to find near-optimal policies compared to the posed control problem when the searchable parameter space becomes large. To combat this, our work delves into the application of Variational AutoEncoders (VAEs) to acquire a generalized, low-dimensional latent encoding of a high-fidelity range-finding sensor, which serves as the exteroceptive input to a DRL agent. The agent's performance, encompassing path-following and collision avoidance, is systematically tested and evaluated within a stochastic simulation environment, presenting a comprehensive exploration of our proposed approach in maritime control systems."}
{"main_page": "https://arxiv.org/abs/2404.00625", "pdf": "https://arxiv.org/pdf/2404.00625", "title": "Scalable second-order consensus of hierarchical groups", "authors": "Jiamin Wang, Jian Liu, Feng Xiao, Ning Xi, Yuanshi Zheng", "subjects": "Systems and Control (eess.SY)", "abstract": "Motivated by widespread dominance hierarchy, growth of group sizes, and feedback mechanisms in social species, we are devoted to exploring the scalable second-order consensus of hierarchical groups. More specifically, a hierarchical group consists of a collection of agents with double-integrator dynamics on a directed acyclic graph with additional reverse edges, which characterize feedback mechanisms across hierarchical layers. As the group size grows and the reverse edges appear, we investigate whether the absolute velocity protocol and the relative velocity protocol can preserve the system consensus property without tuning the control gains. It is rigorously proved that the absolute velocity protocol is able to achieve completely scalable second-order consensus but the relative velocity protocol cannot. This result theoretically reveals how the scalable coordination behavior in hierarchical groups is determined by local interaction rules. Moreover, we develop a hierarchical structure in order to achieve scalable second-order consensus for networks of any size and with any number of reverse edges."}
{"main_page": "https://arxiv.org/abs/2404.00626", "pdf": "https://arxiv.org/pdf/2404.00626", "title": "Domain Generalizable Person Search Using Unreal Dataset", "authors": "Minyoung Oh, Duhyun Kim, Jae-Young Sim", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Collecting and labeling real datasets to train the person search networks not only requires a lot of time and effort, but also accompanies privacy issues. The weakly-supervised and unsupervised domain adaptation methods have been proposed to alleviate the labeling burden for target datasets, however, their generalization capability is limited. We introduce a novel person search method based on the domain generalization framework, that uses an automatically labeled unreal dataset only for training but is applicable to arbitrary unseen real datasets. To alleviate the domain gaps when transferring the knowledge from the unreal source dataset to the real target datasets, we estimate the fidelity of person instances which is then used to train the end-to-end network adaptively. Moreover, we devise a domain-invariant feature learning scheme to encourage the network to suppress the domain-related features. Experimental results demonstrate that the proposed method provides the competitive performance to existing person search methods even though it is applicable to arbitrary unseen datasets without any prior knowledge and re-training burdens."}
{"main_page": "https://arxiv.org/abs/2404.00628", "pdf": "https://arxiv.org/pdf/2404.00628", "title": "Fluid Antenna Relay Assisted Communication Systems Through Antenna  Location Optimization", "authors": "Ruopeng Xu, Yixuan Chen, Jiawen Kang, Minrui Xu, Zhaohui Yang, Chongwen Huang, Niyato Dusit", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "In this paper, we investigate the problem of resource allocation for fluid antenna relay (FAR) system with antenna location optimization. In the considered model, each user transmits information to a base station (BS) with help of FAR. The antenna location of the FAR is flexible and can be adapted to dynamic location distribution of the users. We formulate a sum rate maximization problem through jointly optimizing the antenna location and bandwidth allocation with meeting the minimum rate requirements, total bandwidth budget, and feasible antenna region constraints. To solve this problem, we obtain the optimal bandwidth in closed form. Based on the optimal bandwidth, the original problem is reduced to the antenna location optimization problem and an alternating algorithm is proposed. Simulation results verify the effectiveness of the proposed algorithm and the sum rate can be increased by up to 125% compared to the conventional schemes."}
{"main_page": "https://arxiv.org/abs/2404.00629", "pdf": "https://arxiv.org/pdf/2404.00629", "title": "Against The Achilles' Heel: A Survey on Red Teaming for Generative  Models", "authors": "Lizhi Lin, Honglin Mu, Zenan Zhai, Minghan Wang, Yuxia Wang, Renxi Wang, Junjie Gao, Yixuan Zhang, Wanxiang Che, Timothy Baldwin, Xudong Han, Haonan Li", "subjects": "Computation and Language (cs.CL)", "abstract": "Generative models are rapidly gaining popularity and being integrated into everyday applications, raising concerns over their safety issues as various vulnerabilities are exposed. Faced with the problem, the field of red teaming is experiencing fast-paced growth, which highlights the need for a comprehensive organization covering the entire pipeline and addressing emerging topics for the community. Our extensive survey, which examines over 120 papers, introduces a taxonomy of fine-grained attack strategies grounded in the inherent capabilities of language models. Additionally, we have developed the searcher framework that unifies various automatic red teaming approaches. Moreover, our survey covers novel areas including multimodal attacks and defenses, risks around multilingual models, overkill of harmless queries, and safety of downstream applications. We hope this survey can provide a systematic perspective on the field and unlock new areas of research."}
{"main_page": "https://arxiv.org/abs/2404.00631", "pdf": "https://arxiv.org/pdf/2404.00631", "title": "Network-Assisted Full-Duplex Cell-Free mmWave Networks: Hybrid MIMO  Processing and Multi-Agent DRL-Based Power Allocation", "authors": "Qingrui Fan, Yu Zhang, Jiamin Li, Dongming Wang, Hongbiao Zhang, Xiaohu You", "subjects": "Information Theory (cs.IT); Multiagent Systems (cs.MA); Signal Processing (eess.SP)", "abstract": "This paper investigates the network-assisted full-duplex (NAFD) cell-free millimeter-wave (mmWave) networks, where the distribution of the transmitting access points (T-APs) and receiving access points (R-APs) across distinct geographical locations mitigates cross-link interference, facilitating the attainment of a truly flexible duplex mode. To curtail deployment expenses and power consumption for mmWave band operations, each AP incorporates a hybrid digital-analog structure encompassing precoder/combiner functions. However, this incorporation introduces processing intricacies within channel estimation and precoding/combining design. In this paper, we first present a hybrid multiple-input multiple-output (MIMO) processing framework and derive explicit expressions for both uplink and downlink achievable rates. Then we formulate a power allocation problem to maximize the weighted bidirectional sum rates. To tackle this non-convex problem, we develop a collaborative multi-agent deep reinforcement learning (MADRL) algorithm called multi-agent twin delayed deep deterministic policy gradient (MATD3) for NAFD cell-free mmWave networks. Specifically, given the tightly coupled nature of both uplink and downlink power coefficients in NAFD cell-free mmWave networks, the MATD3 algorithm resolves such coupled conflicts through an interactive learning process between agents and the environment. Finally, the simulation results validate the effectiveness of the proposed channel estimation methods within our hybrid MIMO processing paradigm, and demonstrate that our MATD3 algorithm outperforms both multi-agent deep deterministic policy gradient (MADDPG) and conventional power allocation strategies."}
{"main_page": "https://arxiv.org/abs/2404.00633", "pdf": "https://arxiv.org/pdf/2404.00633", "title": "IPT-V2: Efficient Image Processing Transformer using Hierarchical  Attentions", "authors": "Zhijun Tu, Kunpeng Du, Hanting Chen, Hailing Wang, Wei Li, Jie Hu, Yunhe Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advances have demonstrated the powerful capability of transformer architecture in image restoration. However, our analysis indicates that existing transformerbased methods can not establish both exact global and local dependencies simultaneously, which are much critical to restore the details and missing content of degraded images. To this end, we present an efficient image processing transformer architecture with hierarchical attentions, called IPTV2, adopting a focal context self-attention (FCSA) and a global grid self-attention (GGSA) to obtain adequate token interactions in local and global receptive fields. Specifically, FCSA applies the shifted window mechanism into the channel self-attention, helps capture the local context and mutual interaction across channels. And GGSA constructs long-range dependencies in the cross-window grid, aggregates global information in spatial dimension. Moreover, we introduce structural re-parameterization technique to feed-forward network to further improve the model capability. Extensive experiments demonstrate that our proposed IPT-V2 achieves state-of-the-art results on various image processing tasks, covering denoising, deblurring, deraining and obtains much better trade-off for performance and computational complexity than previous methods. Besides, we extend our method to image generation as latent diffusion backbone, and significantly outperforms DiTs."}
{"main_page": "https://arxiv.org/abs/2404.00634", "pdf": "https://arxiv.org/pdf/2404.00634", "title": "Designing Human-AI Systems: Anthropomorphism and Framing Bias on  Human-AI Collaboration", "authors": "Samuel Aleksander S\u00e1nchez Olszewski", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "AI is redefining how humans interact with technology, leading to a synergetic collaboration between the two. Nevertheless, the effects of human cognition on this collaboration remain unclear. This study investigates the implications of two cognitive biases, anthropomorphism and framing effect, on human-AI collaboration within a hiring setting. Subjects were asked to select job candidates with the help of an AI-powered recommendation tool. The tool was manipulated to have either human-like or robot-like characteristics and presented its recommendations in either positive or negative frames. The results revealed that the framing of AI's recommendations had no significant influence on subjects' decisions. In contrast, anthropomorphism significantly affected subjects' agreement with AI recommendations. Contrary to expectations, subjects were less likely to agree with the AI if it had human-like characteristics. These findings demonstrate that cognitive biases can impact human-AI collaboration and highlight the need for tailored approaches to AI product design, rather than a single, universal solution."}
{"main_page": "https://arxiv.org/abs/2404.00636", "pdf": "https://arxiv.org/pdf/2404.00636", "title": "Learning to Generate Conditional Tri-plane for 3D-aware Expression  Controllable Portrait Animation", "authors": "Taekyung Ki, Dongchan Min, Gyeongsu Chae", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "abstract": "In this paper, we present Export3D, a one-shot 3D-aware portrait animation method that is able to control the facial expression and camera view of a given portrait image. To achieve this, we introduce a tri-plane generator that directly generates a tri-plane of 3D prior by transferring the expression parameter of 3DMM into the source image. The tri-plane is then decoded into the image of different view through a differentiable volume rendering. Existing portrait animation methods heavily rely on image warping to transfer the expression in the motion space, challenging on disentanglement of appearance and expression. In contrast, we propose a contrastive pre-training framework for appearance-free expression parameter, eliminating undesirable appearance swap when transferring a cross-identity expression. Extensive experiments show that our pre-training framework can learn the appearance-free expression representation hidden in 3DMM, and our model can generate 3D-aware expression controllable portrait image without appearance swap in the cross-identity manner."}
{"main_page": "https://arxiv.org/abs/2404.00638", "pdf": "https://arxiv.org/pdf/2404.00638", "title": "HypeBoy: Generative Self-Supervised Representation Learning on  Hypergraphs", "authors": "Sunwoo Kim, Shinhwan Kang, Fanchen Bu, Soo Yong Lee, Jaemin Yoo, Kijung Shin", "subjects": "Machine Learning (cs.LG)", "abstract": "Hypergraphs are marked by complex topology, expressing higher-order interactions among multiple nodes with hyperedges, and better capturing the topology is essential for effective representation learning. Recent advances in generative self-supervised learning (SSL) suggest that hypergraph neural networks learned from generative self supervision have the potential to effectively encode the complex hypergraph topology. Designing a generative SSL strategy for hypergraphs, however, is not straightforward. Questions remain with regard to its generative SSL task, connection to downstream tasks, and empirical properties of learned representations. In light of the promises and challenges, we propose a novel generative SSL strategy for hypergraphs. We first formulate a generative SSL task on hypergraphs, hyperedge filling, and highlight its theoretical connection to node classification. Based on the generative SSL task, we propose a hypergraph SSL method, HypeBoy. HypeBoy learns effective general-purpose hypergraph representations, outperforming 16 baseline methods across 11 benchmark datasets."}
{"main_page": "https://arxiv.org/abs/2404.00639", "pdf": "https://arxiv.org/pdf/2404.00639", "title": "RL-MUL: Multiplier Design Optimization with Deep Reinforcement Learning", "authors": "Dongsheng Zuo, Jiadong Zhu, Yikang Ouyang, Yuzhe Ma", "subjects": "Hardware Architecture (cs.AR); Machine Learning (cs.LG)", "abstract": "Multiplication is a fundamental operation in many applications, and multipliers are widely adopted in various circuits. However, optimizing multipliers is challenging and non-trivial due to the huge design space. In this paper, we propose RL-MUL, a multiplier design optimization framework based on reinforcement learning. Specifically, we utilize matrix and tensor representations for the compressor tree of a multiplier, based on which the convolutional neural networks can be seamlessly incorporated as the agent network. The agent can learn to optimize the multiplier structure based on a Pareto-driven reward which is customized to accommodate the trade-off between area and delay. Additionally, the capability of RL-MUL is extended to optimize the fused multiply-accumulator (MAC) designs. Experiments are conducted on different bit widths of multipliers. The results demonstrate that the multipliers produced by RL-MUL can dominate all baseline designs in terms of area and delay. The performance gain of RL-MUL is further validated by comparing the area and delay of processing element arrays using multipliers from RL-MUL and baseline approaches."}
{"main_page": "https://arxiv.org/abs/2404.00640", "pdf": "https://arxiv.org/pdf/2404.00640", "title": "Face It Yourselves: An LLM-Based Two-Stage Strategy to Localize  Configuration Errors via Logs", "authors": "Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, Zibin Zheng", "subjects": "Software Engineering (cs.SE); Machine Learning (cs.LG)", "abstract": "Configurable software systems are prone to configuration errors, resulting in significant losses to companies. However, diagnosing these errors is challenging due to the vast and complex configuration space. These errors pose significant challenges for both experienced maintainers and new end-users, particularly those without access to the source code of the software systems. Given that logs are easily accessible to most end-users, we conduct a preliminary study to outline the challenges and opportunities of utilizing logs in localizing configuration errors. Based on the insights gained from the preliminary study, we propose an LLM-based two-stage strategy for end-users to localize the root-cause configuration properties based on logs. We further implement a tool, LogConfigLocalizer, aligned with the design of the aforementioned strategy, hoping to assist end-users in coping with configuration errors through log analysis. To the best of our knowledge, this is the first work to localize the root-cause configuration properties for end-users based on Large Language Models~(LLMs) and logs. We evaluate the proposed strategy on Hadoop by LogConfigLocalizer and prove its efficiency with an average accuracy as high as 99.91%. Additionally, we also demonstrate the effectiveness and necessity of different phases of the methodology by comparing it with two other variants and a baseline tool. Moreover, we validate the proposed methodology through a practical case study to demonstrate its effectiveness and feasibility."}
{"main_page": "https://arxiv.org/abs/2404.00644", "pdf": "https://arxiv.org/pdf/2404.00644", "title": "SoK: Liquid Staking Tokens (LSTs)", "authors": "Krzysztof Gogol, Yaron Velner, Benjamin Kraner, Claudio Tessone", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Liquid Staking Tokens (LSTs) function as tokenized representations of staked native assets while also accruing staking rewards. They emerged as a preferred method of staking within Proof of Stake (PoS) blockchains, owing to their ease of use and tradability. In this Systematization of Knowledge (SoK), we establish a general framework describing the design choices and protocols underlying liquid staking. We then employ the framework to systematically compare the top LST implementations, examining their node operator selection, validator operations, and staking rewards distribution models. We further discuss security concerns associated with liquid staking, its implications for PoS blockchain security, and Distributed Validator technology (DVT) as a potential solution. Finally, we empirically analyze LSTs' performance and find that the design choices and market events affect peg stability; particularly, LSTs with centralized governance and operations are more efficient in tracking staking rewards."}
{"main_page": "https://arxiv.org/abs/2404.00645", "pdf": "https://arxiv.org/pdf/2404.00645", "title": "Attire-Based Anomaly Detection in Restricted Areas Using YOLOv8 for  Enhanced CCTV Security", "authors": "Abdul Aziz A.B, Aindri Bajpai", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This research introduces an innovative security enhancement approach, employing advanced image analysis and soft computing. The focus is on an intelligent surveillance system that detects unauthorized individuals in restricted areas by analyzing attire. Traditional security measures face challenges in monitoring unauthorized access. Leveraging YOLOv8, an advanced object detection algorithm, our system identifies authorized personnel based on their attire in CCTV footage. The methodology involves training the YOLOv8 model on a comprehensive dataset of uniform patterns, ensuring precise recognition in specific regions. Soft computing techniques enhance adaptability to dynamic environments and varying lighting conditions. This research contributes to image analysis and soft computing, providing a sophisticated security solution. Emphasizing uniform-based anomaly detection, it establishes a foundation for robust security systems in restricted areas. The outcomes highlight the potential of YOLOv8-based surveillance in ensuring safety in sensitive locations."}
{"main_page": "https://arxiv.org/abs/2404.00648", "pdf": "https://arxiv.org/pdf/2404.00648", "title": "SpiralMLP: A Lightweight Vision MLP Architecture", "authors": "Haojie Mu, Burhan Ul Tayyab, Nicholas Chua", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present SpiralMLP, a novel architecture that introduces a Spiral FC layer as a replacement for the conventional Token Mixing approach. Differing from several existing MLP-based models that primarily emphasize axes, our Spiral FC layer is designed as a deformable convolution layer with spiral-like offsets. We further adapt Spiral FC into two variants: Self-Spiral FC and Cross-Spiral FC, which enable both local and global feature integration seamlessly, eliminating the need for additional processing steps. To thoroughly investigate the effectiveness of the spiral-like offsets and validate our design, we conduct ablation studies and explore optimal configurations. In empirical tests, SpiralMLP reaches state-of-the-art performance, similar to Transformers, CNNs, and other MLPs, benchmarking on ImageNet-1k, COCO and ADE20K. SpiralMLP still maintains linear computational complexity O(HW) and is compatible with varying input image resolutions. Our study reveals that targeting the full receptive field is not essential for achieving high performance, instead, adopting a refined approach offers better results."}
{"main_page": "https://arxiv.org/abs/2404.00650", "pdf": "https://arxiv.org/pdf/2404.00650", "title": "Deep Instruction Tuning for Segment Anything Model", "authors": "Xiaorui Huang, Gen Luo, Chaoyang Zhu, Bo Tong, Yiyi Zhou, Xiaoshuai Sun, Rongrong Ji", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Segment Anything Model (SAM) exhibits powerful yet versatile capabilities on (un) conditional image segmentation tasks recently. Although SAM can support various segmentation prompts, we note that, compared to point- and box-guided segmentation, it performs much worse on text-instructed tasks. We argue that deep text instruction tuning is key to mitigate such shortcoming caused by the shallow fusion scheme in its default light-weight mask decoder. In this paper, two \\emph{deep instruction tuning} (DIT) methods are proposed, one is end-to-end and the other is layer-wise. With these tuning methods, we can regard the image encoder of SAM as a stand-alone vision-language learner in contrast to building another deep fusion branch. Extensive experiments on three highly competitive benchmark datasets of referring image segmentation show that a simple end-to-end DIT improves SAM by a large margin, with layer-wise DIT further boosts the performance to state-of-the-art. Our code is anonymously released at: https://github.com/wysnzzzz/DIT."}
{"main_page": "https://arxiv.org/abs/2404.00651", "pdf": "https://arxiv.org/pdf/2404.00651", "title": "Learning Off-policy with Model-based Intrinsic Motivation For Active  Online Exploration", "authors": "Yibo Wang, Jiang Zhao", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Recent advancements in deep reinforcement learning (RL) have demonstrated notable progress in sample efficiency, spanning both model-based and model-free paradigms. Despite the identification and mitigation of specific bottlenecks in prior works, the agent's exploration ability remains under-emphasized in the realm of sample-efficient RL. This paper investigates how to achieve sample-efficient exploration in continuous control tasks. We introduce an RL algorithm that incorporates a predictive model and off-policy learning elements, where an online planner enhanced by a novelty-aware terminal value function is employed for sample collection. Leveraging the forward predictive error within a latent state space, we derive an intrinsic reward without incurring parameters overhead. This reward establishes a solid connection to model uncertainty, allowing the agent to effectively overcome the asymptotic performance gap. Through extensive experiments, our method shows competitive or even superior performance compared to prior works, especially the sparse reward cases."}
{"main_page": "https://arxiv.org/abs/2404.00653", "pdf": "https://arxiv.org/pdf/2404.00653", "title": "Dual DETRs for Multi-Label Temporal Action Detection", "authors": "Yuhan Zhu, Guozhen Zhang, Jing Tan, Gangshan Wu, Limin Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Temporal Action Detection (TAD) aims to identify the action boundaries and the corresponding category within untrimmed videos. Inspired by the success of DETR in object detection, several methods have adapted the query-based framework to the TAD task. However, these approaches primarily followed DETR to predict actions at the instance level (i.e., identify each action by its center point), leading to sub-optimal boundary localization. To address this issue, we propose a new Dual-level query-based TAD framework, namely DualDETR, to detect actions from both instance-level and boundary-level. Decoding at different levels requires semantics of different granularity, therefore we introduce a two-branch decoding structure. This structure builds distinctive decoding processes for different levels, facilitating explicit capture of temporal cues and semantics at each level. On top of the two-branch design, we present a joint query initialization strategy to align queries from both levels. Specifically, we leverage encoder proposals to match queries from each level in a one-to-one manner. Then, the matched queries are initialized using position and content prior from the matched action proposal. The aligned dual-level queries can refine the matched proposal with complementary cues during subsequent decoding. We evaluate DualDETR on three challenging multi-label TAD benchmarks. The experimental results demonstrate the superior performance of DualDETR to the existing state-of-the-art methods, achieving a substantial improvement under det-mAP and delivering impressive results under seg-mAP."}
{"main_page": "https://arxiv.org/abs/2404.00655", "pdf": "https://arxiv.org/pdf/2404.00655", "title": "Characterizing GSVD by singular value expansion of linear operators and  its computation", "authors": "Haibo Li", "subjects": "Numerical Analysis (math.NA)", "abstract": "The generalized singular value decomposition (GSVD) of a matrix pair $\\{A, L\\}$ with $A\\in\\mathbb{R}^{m\\times n}$ and $L\\in\\mathbb{R}^{p\\times n}$ generalizes the singular value decomposition (SVD) of a single matrix. In this paper, we provide a new understanding of GSVD from the viewpoint of SVD, based on which we propose a new iterative method for computing nontrivial GSVD components of a large-scale matrix pair. By introducing two linear operators $\\mathcal{A}$ and $\\mathcal{L}$ induced by $\\{A, L\\}$ between two finite-dimensional Hilbert spaces and applying the theory of singular value expansion (SVE) for linear compact operators, we show that the GSVD of $\\{A, L\\}$ is nothing but the SVEs of $\\mathcal{A}$ and $\\mathcal{L}$. This result characterizes completely the structure of GSVD for any matrix pair with the same number of columns. As a direct application of this result, we generalize the standard Golub-Kahan bidiagonalization (GKB) that is a basic routine for large-scale SVD computation such that the resulting generalized GKB (gGKB) process can be used to approximate nontrivial extreme GSVD components of $\\{A, L\\}$, which is named the gGKB\\_GSVD algorithm. We use the GSVD of $\\{A, L\\}$ to study several basic properties of gGKB and also provide preliminary results about convergence and accuracy of gGKB\\_GSVD for GSVD computation. Numerical experiments are presented to demonstrate the effectiveness of this method."}
{"main_page": "https://arxiv.org/abs/2404.00656", "pdf": "https://arxiv.org/pdf/2404.00656", "title": "WavLLM: Towards Robust and Adaptive Speech Large Language Model", "authors": "Shujie Hu, Long Zhou, Shujie Liu, Sanyuan Chen, Hongkun Hao, Jing Pan, Xunying Liu, Jinyu Li, Sunit Sivasankaran, Linquan Liu, Furu Wei", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "The recent advancements in large language models (LLMs) have revolutionized the field of natural language processing, progressively broadening their scope to multimodal perception and generation. However, effectively integrating listening capabilities into LLMs poses significant challenges, particularly with respect to generalizing across varied contexts and executing complex auditory tasks. In this work, we introduce WavLLM, a robust and adaptive speech large language model with dual encoders, and a prompt-aware LoRA weight adapter, optimized by a two-stage curriculum learning approach. Leveraging dual encoders, we decouple different types of speech information, utilizing a Whisper encoder to process the semantic content of speech, and a WavLM encoder to capture the unique characteristics of the speaker's identity. Within the curriculum learning framework, WavLLM first builds its foundational capabilities by optimizing on mixed elementary single tasks, followed by advanced multi-task training on more complex tasks such as combinations of the elementary tasks. To enhance the flexibility and adherence to different tasks and instructions, a prompt-aware LoRA weight adapter is introduced in the second advanced multi-task training stage. We validate the proposed model on universal speech benchmarks including tasks such as ASR, ST, SV, ER, and also apply it to specialized datasets like Gaokao English listening comprehension set for SQA, and speech Chain-of-Thought (CoT) evaluation set. Experiments demonstrate that the proposed model achieves state-of-the-art performance across a range of speech tasks on the same model size, exhibiting robust generalization capabilities in executing complex tasks using CoT approach. Furthermore, our model successfully completes Gaokao tasks without specialized training. The codes, models, audio, and Gaokao evaluation set can be accessed at \\url{aka.ms/wavllm}."}
{"main_page": "https://arxiv.org/abs/2404.00657", "pdf": "https://arxiv.org/pdf/2404.00657", "title": "Observations on Building RAG Systems for Technical Documents", "authors": "Sumit Soman, Sujoy Roychowdhury", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Retrieval augmented generation (RAG) for technical documents creates challenges as embeddings do not often capture domain information. We review prior art for important factors affecting RAG and perform experiments to highlight best practices and potential challenges to build RAG systems for technical documents."}
{"main_page": "https://arxiv.org/abs/2404.00658", "pdf": "https://arxiv.org/pdf/2404.00658", "title": "KTPFormer: Kinematics and Trajectory Prior Knowledge-Enhanced  Transformer for 3D Human Pose Estimation", "authors": "Jihua Peng, Yanghong Zhou, P.Y. Mok", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper presents a novel Kinematics and Trajectory Prior Knowledge-Enhanced Transformer (KTPFormer), which overcomes the weakness in existing transformer-based methods for 3D human pose estimation that the derivation of Q, K, V vectors in their self-attention mechanisms are all based on simple linear mapping. We propose two prior attention modules, namely Kinematics Prior Attention (KPA) and Trajectory Prior Attention (TPA) to take advantage of the known anatomical structure of the human body and motion trajectory information, to facilitate effective learning of global dependencies and features in the multi-head self-attention. KPA models kinematic relationships in the human body by constructing a topology of kinematics, while TPA builds a trajectory topology to learn the information of joint motion trajectory across frames. Yielding Q, K, V vectors with prior knowledge, the two modules enable KTPFormer to model both spatial and temporal correlations simultaneously. Extensive experiments on three benchmarks (Human3.6M, MPI-INF-3DHP and HumanEva) show that KTPFormer achieves superior performance in comparison to state-of-the-art methods. More importantly, our KPA and TPA modules have lightweight plug-and-play designs and can be integrated into various transformer-based networks (i.e., diffusion-based) to improve the performance with only a very small increase in the computational overhead. The code is available at: https://github.com/JihuaPeng/KTPFormer."}
{"main_page": "https://arxiv.org/abs/2404.00661", "pdf": "https://arxiv.org/pdf/2404.00661", "title": "DeeDSR: Towards Real-World Image Super-Resolution via Degradation-Aware  Stable Diffusion", "authors": "Chunyang Bi, Xin Luo, Sheng Shen, Mengxi Zhang, Huanjing Yue, Jingyu Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Diffusion models, known for their powerful generative capabilities, play a crucial role in addressing real-world super-resolution challenges. However, these models often focus on improving local textures while neglecting the impacts of global degradation, which can significantly reduce semantic fidelity and lead to inaccurate reconstructions and suboptimal super-resolution performance. To address this issue, we introduce a novel two-stage, degradation-aware framework that enhances the diffusion model's ability to recognize content and degradation in low-resolution images. In the first stage, we employ unsupervised contrastive learning to obtain representations of image degradations. In the second stage, we integrate a degradation-aware module into a simplified ControlNet, enabling flexible adaptation to various degradations based on the learned representations. Furthermore, we decompose the degradation-aware features into global semantics and local details branches, which are then injected into the diffusion denoising module to modulate the target generation. Our method effectively recovers semantically precise and photorealistic details, particularly under significant degradation conditions, demonstrating state-of-the-art performance across various benchmarks. Codes will be released at https://github.com/bichunyang419/DeeDSR."}
{"main_page": "https://arxiv.org/abs/2404.00665", "pdf": "https://arxiv.org/pdf/2404.00665", "title": "On cumulative and relative cumulative past information generating  function", "authors": "Santosh Kumar Chaudhary, Nitin Gupta, Achintya Roy", "subjects": "Information Theory (cs.IT)", "abstract": "In this paper, we introduce the cumulative past information generating function (CPIG) and relative cumulative past information generating function (RCPIG). We study its properties. We establish its relation with generalized cumulative past entropy (GCPE). We defined CPIG stochastic order and its relation with dispersive order. We provide the results for the CPIG measure of the convoluted random variables in terms of the measures of its components. We found some inequality relating to Shannon entropy, CPIG and GCPE. Some characterization and estimation results are also discussed regarding CPIG. We defined divergence measures between two random variables, Jensen-cumulative past information generating function(JCPIG), Jensen fractional cumulative past entropy measure, cumulative past Taneja entropy, and Jensen cumulative past Taneja entropy information measure."}
{"main_page": "https://arxiv.org/abs/2404.00666", "pdf": "https://arxiv.org/pdf/2404.00666", "title": "Accelerated Parameter-Free Stochastic Optimization", "authors": "Itai Kreisler, Maor Ivgi, Oliver Hinder, Yair Carmon", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC)", "abstract": "We propose a method that achieves near-optimal rates for smooth stochastic convex optimization and requires essentially no prior knowledge of problem parameters. This improves on prior work which requires knowing at least the initial distance to optimality d0. Our method, U-DoG, combines UniXGrad (Kavis et al., 2019) and DoG (Ivgi et al., 2023) with novel iterate stabilization techniques. It requires only loose bounds on d0 and the noise magnitude, provides high probability guarantees under sub-Gaussian noise, and is also near-optimal in the non-smooth case. Our experiments show consistent, strong performance on convex problems and mixed results on neural network training."}
{"main_page": "https://arxiv.org/abs/2404.00667", "pdf": "https://arxiv.org/pdf/2404.00667", "title": "Weakly-Supervised Cross-Domain Segmentation of Electron Microscopy with  Sparse Point Annotation", "authors": "Dafei Qiu, Shan Xiong, Jiajin Yi, Jialin Peng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Accurate segmentation of organelle instances from electron microscopy (EM) images plays an essential role in many neuroscience researches. However, practical scenarios usually suffer from high annotation costs, label scarcity, and large domain diversity. While unsupervised domain adaptation (UDA) that assumes no annotation effort on the target data is promising to alleviate these challenges, its performance on complicated segmentation tasks is still far from practical usage. To address these issues, we investigate a highly annotation-efficient weak supervision, which assumes only sparse center-points on a small subset of object instances in the target training images. To achieve accurate segmentation with partial point annotations, we introduce instance counting and center detection as auxiliary tasks and design a multitask learning framework to leverage correlations among the counting, detection, and segmentation, which are all tasks with partial or no supervision. Building upon the different domain-invariances of the three tasks, we enforce counting estimation with a novel soft consistency loss as a global prior for center detection, which further guides the per-pixel segmentation. To further compensate for annotation sparsity, we develop a cross-position cut-and-paste for label augmentation and an entropy-based pseudo-label selection. The experimental results highlight that, by simply using extremely weak annotation, e.g., 15\\% sparse points, for model training, the proposed model is capable of significantly outperforming UDA methods and produces comparable performance as the supervised counterpart. The high robustness of our model shown in the validations and the low requirement of expert knowledge for sparse point annotation further improve the potential application value of our model."}
{"main_page": "https://arxiv.org/abs/2404.00670", "pdf": "https://arxiv.org/pdf/2404.00670", "title": "Statistical Analysis by Semiparametric Additive Regression and LSTM-FCN  Based Hierarchical Classification for Computer Vision Quantification of  Parkinsonian Bradykinesia", "authors": "Youngseo Cho, In Hee Kwak, Dohyeon Kim, Jinhee Na, Hanjoo Sung, Jeongjae Lee, Young Eun Kim, Hyeo-il Ma", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM); Applications (stat.AP)", "abstract": "Bradykinesia, characterized by involuntary slowing or decrement of movement, is a fundamental symptom of Parkinson's Disease (PD) and is vital for its clinical diagnosis. Despite various methodologies explored to quantify bradykinesia, computer vision-based approaches have shown promising results. However, these methods often fall short in adequately addressing key bradykinesia characteristics in repetitive limb movements: \"occasional arrest\" and \"decrement in amplitude.\" This research advances vision-based quantification of bradykinesia by introducing nuanced numerical analysis to capture decrement in amplitudes and employing a simple deep learning technique, LSTM-FCN, for precise classification of occasional arrests. Our approach structures the classification process hierarchically, tailoring it to the unique dynamics of bradykinesia in PD. Statistical analysis of the extracted features, including those representing arrest and fatigue, has demonstrated their statistical significance in most cases. This finding underscores the importance of considering \"occasional arrest\" and \"decrement in amplitude\" in bradykinesia quantification of limb movement. Our enhanced diagnostic tool has been rigorously tested on an extensive dataset comprising 1396 motion videos from 310 PD patients, achieving an accuracy of 80.3%. The results confirm the robustness and reliability of our method."}
{"main_page": "https://arxiv.org/abs/2404.00672", "pdf": "https://arxiv.org/pdf/2404.00672", "title": "A General and Efficient Training for Transformer via Token Expansion", "authors": "Wenxuan Huang, Yunhang Shen, Jiao Xie, Baochang Zhang, Gaoqi He, Ke Li, Xing Sun, Shaohui Lin", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The remarkable performance of Vision Transformers (ViTs) typically requires an extremely large training cost. Existing methods have attempted to accelerate the training of ViTs, yet typically disregard method universality with accuracy dropping. Meanwhile, they break the training consistency of the original transformers, including the consistency of hyper-parameters, architecture, and strategy, which prevents them from being widely applied to different Transformer networks. In this paper, we propose a novel token growth scheme Token Expansion (termed ToE) to achieve consistent training acceleration for ViTs. We introduce an \"initialization-expansion-merging\" pipeline to maintain the integrity of the intermediate feature distribution of original transformers, preventing the loss of crucial learnable information in the training process. ToE can not only be seamlessly integrated into the training and fine-tuning process of transformers (e.g., DeiT and LV-ViT), but also effective for efficient training frameworks (e.g., EfficientTrain), without twisting the original training hyper-parameters, architecture, and introducing additional training strategies. Extensive experiments demonstrate that ToE achieves about 1.3x faster for the training of ViTs in a lossless manner, or even with performance gains over the full-token training baselines. Code is available at https://github.com/Osilly/TokenExpansion ."}
{"main_page": "https://arxiv.org/abs/2404.00673", "pdf": "https://arxiv.org/pdf/2404.00673", "title": "A Survey of Privacy-Preserving Model Explanations: Privacy Risks,  Attacks, and Countermeasures", "authors": "Thanh Tam Nguyen, Thanh Trung Huynh, Zhao Ren, Thanh Toan Nguyen, Phi Le Nguyen, Hongzhi Yin, Quoc Viet Hung Nguyen", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "As the adoption of explainable AI (XAI) continues to expand, the urgency to address its privacy implications intensifies. Despite a growing corpus of research in AI privacy and explainability, there is little attention on privacy-preserving model explanations. This article presents the first thorough survey about privacy attacks on model explanations and their countermeasures. Our contribution to this field comprises a thorough analysis of research papers with a connected taxonomy that facilitates the categorisation of privacy attacks and countermeasures based on the targeted explanations. This work also includes an initial investigation into the causes of privacy leaks. Finally, we discuss unresolved issues and prospective research directions uncovered in our analysis. This survey aims to be a valuable resource for the research community and offers clear insights for those new to this domain. To support ongoing research, we have established an online resource repository, which will be continuously updated with new and relevant findings. Interested readers are encouraged to access our repository at https://github.com/tamlhp/awesome-privex."}
{"main_page": "https://arxiv.org/abs/2404.00674", "pdf": "https://arxiv.org/pdf/2404.00674", "title": "Knowledge NeRF: Few-shot Novel View Synthesis for Dynamic Articulated  Objects", "authors": "Wenxiao Cai, Xinyue Lei\u0131nst, Xinyu He, Junming Leo Chen, Yangang Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present Knowledge NeRF to synthesize novel views for dynamic scenes.Reconstructing dynamic 3D scenes from few sparse views and rendering them from arbitrary perspectives is a challenging problem with applications in various domains. Previous dynamic NeRF methods learn the deformation of articulated objects from monocular videos. However, qualities of their reconstructed scenes are limited.To clearly reconstruct dynamic scenes, we propose a new framework by considering two frames at a time.We pretrain a NeRF model for an articulated object.When articulated objects moves, Knowledge NeRF learns to generate novel views at the new state by incorporating past knowledge in the pretrained NeRF model with minimal observations in the present state. We propose a projection module to adapt NeRF for dynamic scenes, learning the correspondence between pretrained knowledge base and current states. Experimental results demonstrate the effectiveness of our method in reconstructing dynamic 3D scenes with 5 input images in one state. Knowledge NeRF is a new pipeline and promising solution for novel view synthesis in dynamic articulated objects. The data and implementation are publicly available at https://github.com/RussRobin/Knowledge_NeRF."}
{"main_page": "https://arxiv.org/abs/2404.00675", "pdf": "https://arxiv.org/pdf/2404.00675", "title": "LLM meets Vision-Language Models for Zero-Shot One-Class Classification", "authors": "Yassir Bendou, Giulia Lioi, Bastien Pasdeloup, Lukas Mauch, Ghouthi Boukli Hacene, Fabien Cardinaux, Vincent Gripon", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "We consider the problem of zero-shot one-class visual classification. In this setting, only the label of the target class is available, and the goal is to discriminate between positive and negative query samples without requiring any validation example from the target task. We propose a two-step solution that first queries large language models for visually confusing objects and then relies on vision-language pre-trained models (e.g., CLIP) to perform classification. By adapting large-scale vision benchmarks, we demonstrate the ability of the proposed method to outperform adapted off-the-shelf alternatives in this setting. Namely, we propose a realistic benchmark where negative query samples are drawn from the same original dataset as positive ones, including a granularity-controlled version of iNaturalist, where negative samples are at a fixed distance in the taxonomy tree from the positive ones. Our work shows that it is possible to discriminate between a single category and other semantically related ones using only its label"}
{"main_page": "https://arxiv.org/abs/2404.00676", "pdf": "https://arxiv.org/pdf/2404.00676", "title": "OmniLocalRF: Omnidirectional Local Radiance Fields from Dynamic Videos", "authors": "Dongyoung Choi, Hyeonjoong Jang, Min H. Kim", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "Omnidirectional cameras are extensively used in various applications to provide a wide field of vision. However, they face a challenge in synthesizing novel views due to the inevitable presence of dynamic objects, including the photographer, in their wide field of view. In this paper, we introduce a new approach called Omnidirectional Local Radiance Fields (OmniLocalRF) that can render static-only scene views, removing and inpainting dynamic objects simultaneously. Our approach combines the principles of local radiance fields with the bidirectional optimization of omnidirectional rays. Our input is an omnidirectional video, and we evaluate the mutual observations of the entire angle between the previous and current frames. To reduce ghosting artifacts of dynamic objects and inpaint occlusions, we devise a multi-resolution motion mask prediction module. Unlike existing methods that primarily separate dynamic components through the temporal domain, our method uses multi-resolution neural feature planes for precise segmentation, which is more suitable for long 360-degree videos. Our experiments validate that OmniLocalRF outperforms existing methods in both qualitative and quantitative metrics, especially in scenarios with complex real-world scenes. In particular, our approach eliminates the need for manual interaction, such as drawing motion masks by hand and additional pose estimation, making it a highly effective and efficient solution."}
{"main_page": "https://arxiv.org/abs/2404.00678", "pdf": "https://arxiv.org/pdf/2404.00678", "title": "OmniSDF: Scene Reconstruction using Omnidirectional Signed Distance  Functions and Adaptive Binoctrees", "authors": "Hakyeong Kim, Andreas Meuleman, Hyeonjoong Jang, James Tompkin, Min H. Kim", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "We present a method to reconstruct indoor and outdoor static scene geometry and appearance from an omnidirectional video moving in a small circular sweep. This setting is challenging because of the small baseline and large depth ranges, making it difficult to find ray crossings. To better constrain the optimization, we estimate geometry as a signed distance field within a spherical binoctree data structure and use a complementary efficient tree traversal strategy based on a breadth-first search for sampling. Unlike regular grids or trees, the shape of this structure well-matches the camera setting, creating a better memory-quality trade-off. From an initial depth estimate, the binoctree is adaptively subdivided throughout the optimization; previous methods use a fixed depth that leaves the scene undersampled. In comparison with three neural optimization methods and two non-neural methods, ours shows decreased geometry error on average, especially in a detailed scene, while significantly reducing the required number of voxels to represent such details."}
{"main_page": "https://arxiv.org/abs/2404.00679", "pdf": "https://arxiv.org/pdf/2404.00679", "title": "Weak-to-Strong 3D Object Detection with X-Ray Distillation", "authors": "Alexander Gambashidze, Aleksandr Dadukin, Maksim Golyadkin, Maria Razzhivina, Ilya Makarov", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper addresses the critical challenges of sparsity and occlusion in LiDAR-based 3D object detection. Current methods often rely on supplementary modules or specific architectural designs, potentially limiting their applicability to new and evolving architectures. To our knowledge, we are the first to propose a versatile technique that seamlessly integrates into any existing framework for 3D Object Detection, marking the first instance of Weak-to-Strong generalization in 3D computer vision. We introduce a novel framework, X-Ray Distillation with Object-Complete Frames, suitable for both supervised and semi-supervised settings, that leverages the temporal aspect of point cloud sequences. This method extracts crucial information from both previous and subsequent LiDAR frames, creating Object-Complete frames that represent objects from multiple viewpoints, thus addressing occlusion and sparsity. Given the limitation of not being able to generate Object-Complete frames during online inference, we utilize Knowledge Distillation within a Teacher-Student framework. This technique encourages the strong Student model to emulate the behavior of the weaker Teacher, which processes simple and informative Object-Complete frames, effectively offering a comprehensive view of objects as if seen through X-ray vision. Our proposed methods surpass state-of-the-art in semi-supervised learning by 1-1.5 mAP and enhance the performance of five established supervised models by 1-2 mAP on standard autonomous driving datasets, even with default hyperparameters. Code for Object-Complete frames is available here: https://github.com/sakharok13/X-Ray-Teacher-Patching-Tools."}
{"main_page": "https://arxiv.org/abs/2404.00680", "pdf": "https://arxiv.org/pdf/2404.00680", "title": "Learning to Rank Patches for Unbiased Image Redundancy Reduction", "authors": "Yang Luo, Zhineng Chen, Peng Zhou, Zuxuan Wu, Xieping Gao, Yu-Gang Jiang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Images suffer from heavy spatial redundancy because pixels in neighboring regions are spatially correlated. Existing approaches strive to overcome this limitation by reducing less meaningful image regions. However, current leading methods rely on supervisory signals. They may compel models to preserve content that aligns with labeled categories and discard content belonging to unlabeled categories. This categorical inductive bias makes these methods less effective in real-world scenarios. To address this issue, we propose a self-supervised framework for image redundancy reduction called Learning to Rank Patches (LTRP). We observe that image reconstruction of masked image modeling models is sensitive to the removal of visible patches when the masking ratio is high (e.g., 90\\%). Building upon it, we implement LTRP via two steps: inferring the semantic density score of each patch by quantifying variation between reconstructions with and without this patch, and learning to rank the patches with the pseudo score. The entire process is self-supervised, thus getting out of the dilemma of categorical inductive bias. We design extensive experiments on different datasets and tasks. The results demonstrate that LTRP outperforms both supervised and other self-supervised methods due to the fair assessment of image content."}
{"main_page": "https://arxiv.org/abs/2404.00681", "pdf": "https://arxiv.org/pdf/2404.00681", "title": "CoUDA: Coherence Evaluation via Unified Data Augmentation", "authors": "Dawei Zhu, Wenhao Wu, Yifan Song, Fangwei Zhu, Ziqiang Cao, Sujian Li", "subjects": "Computation and Language (cs.CL)", "abstract": "Coherence evaluation aims to assess the organization and structure of a discourse, which remains challenging even in the era of large language models. Due to the scarcity of annotated data, data augmentation is commonly used for training coherence evaluation models. However, previous augmentations for this task primarily rely on heuristic rules, lacking designing criteria as guidance. In this paper, we take inspiration from linguistic theory of discourse structure, and propose a data augmentation framework named CoUDA. CoUDA breaks down discourse coherence into global and local aspects, and designs augmentation strategies for both aspects, respectively. Especially for local coherence, we propose a novel generative strategy for constructing augmentation samples, which involves post-pretraining a generative model and applying two controlling mechanisms to control the difficulty of generated samples. During inference, CoUDA also jointly evaluates both global and local aspects to comprehensively assess the overall coherence of a discourse. Extensive experiments in coherence evaluation show that, with only 233M parameters, CoUDA achieves state-of-the-art performance in both pointwise scoring and pairwise ranking tasks, even surpassing recent GPT-3.5 and GPT-4 based metrics."}
{"main_page": "https://arxiv.org/abs/2404.00683", "pdf": "https://arxiv.org/pdf/2404.00683", "title": "Improved approximation ratio for covering pliable set families", "authors": "Zeev Nutov", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "A classic result of Williamson, Goemans, Mihail, and Vazirani [STOC 1993: 708-717] states that the problem of covering an uncrossable set family by a min-cost edge set admits approximation ratio $2$, by a primal-dual algorithm with a reverse delete phase. Recently, Bansal, Cheriyan, Grout, and Ibrahimpur [ICALP 2023: 15:1-15:19] showed that this algorithm achieves approximation ratio $16$ for a larger class of set families, that have much weaker uncrossing properties. In this paper we will refine their analysis and show an approximation ratio of $10$. This also improves approximation ratios for several variants of the Capacitated $k$-Edge Connected Spanning Subgraph problem."}
{"main_page": "https://arxiv.org/abs/2404.00684", "pdf": "https://arxiv.org/pdf/2404.00684", "title": "Generative Retrieval as Multi-Vector Dense Retrieval", "authors": "Shiguang Wu, Wenda Wei, Mengqi Zhang, Zhumin Chen, Jun Ma, Zhaochun Ren, Maarten de Rijke, Pengjie Ren", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "abstract": "Generative retrieval generates identifiers of relevant documents in an end-to-end manner using a sequence-to-sequence architecture for a given query. The relation between generative retrieval and other retrieval methods, especially those based on matching within dense retrieval models, is not yet fully comprehended. Prior work has demonstrated that generative retrieval with atomic identifiers is equivalent to single-vector dense retrieval. Accordingly, generative retrieval exhibits behavior analogous to hierarchical search within a tree index in dense retrieval when using hierarchical semantic identifiers. However, prior work focuses solely on the retrieval stage without considering the deep interactions within the decoder of generative retrieval. In this paper, we fill this gap by demonstrating that generative retrieval and multi-vector dense retrieval share the same framework for measuring the relevance to a query of a document. Specifically, we examine the attention layer and prediction head of generative retrieval, revealing that generative retrieval can be understood as a special case of multi-vector dense retrieval. Both methods compute relevance as a sum of products of query and document vectors and an alignment matrix. We then explore how generative retrieval applies this framework, employing distinct strategies for computing document token vectors and the alignment matrix. We have conducted experiments to verify our conclusions and show that both paradigms exhibit commonalities of term matching in their alignment matrix."}
{"main_page": "https://arxiv.org/abs/2404.00686", "pdf": "https://arxiv.org/pdf/2404.00686", "title": "Utilizing Maximum Mean Discrepancy Barycenter for Propagating the  Uncertainty of Value Functions in Reinforcement Learning", "authors": "Srinjoy Roy, Swagatam Das", "subjects": "Machine Learning (cs.LG)", "abstract": "Accounting for the uncertainty of value functions boosts exploration in Reinforcement Learning (RL). Our work introduces Maximum Mean Discrepancy Q-Learning (MMD-QL) to improve Wasserstein Q-Learning (WQL) for uncertainty propagation during Temporal Difference (TD) updates. MMD-QL uses the MMD barycenter for this purpose, as MMD provides a tighter estimate of closeness between probability measures than the Wasserstein distance. Firstly, we establish that MMD-QL is Probably Approximately Correct in MDP (PAC-MDP) under the average loss metric. Concerning the accumulated rewards, experiments on tabular environments show that MMD-QL outperforms WQL and other algorithms. Secondly, we incorporate deep networks into MMD-QL to create MMD Q-Network (MMD-QN). Making reasonable assumptions, we analyze the convergence rates of MMD-QN using function approximation. Empirical results on challenging Atari games demonstrate that MMD-QN performs well compared to benchmark deep RL algorithms, highlighting its effectiveness in handling large state-action spaces."}
{"main_page": "https://arxiv.org/abs/2404.00688", "pdf": "https://arxiv.org/pdf/2404.00688", "title": "Meta Learning in Bandits within Shared Affine Subspaces", "authors": "Steven Bilaj, Sofien Dhouib, Setareh Maghsudi", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "We study the problem of meta-learning several contextual stochastic bandits tasks by leveraging their concentration around a low-dimensional affine subspace, which we learn via online principal component analysis to reduce the expected regret over the encountered bandits. We propose and theoretically analyze two strategies that solve the problem: One based on the principle of optimism in the face of uncertainty and the other via Thompson sampling. Our framework is generic and includes previously proposed approaches as special cases. Besides, the empirical results show that our methods significantly reduce the regret on several bandit tasks."}
{"main_page": "https://arxiv.org/abs/2404.00691", "pdf": "https://arxiv.org/pdf/2404.00691", "title": "Graph-Based vs. Error State Kalman Filter-Based Fusion Of 5G And  Inertial Data For MAV Indoor Pose Estimation", "authors": "Meisam Kabiri, Claudio Cimarelli, Hriday Bavle, Jose Luis Sanchez-Lopez, Holger Voos", "subjects": "Robotics (cs.RO)", "abstract": "5G New Radio Time of Arrival (ToA) data has the potential to revolutionize indoor localization for micro aerial vehicles (MAVs). However, its performance under varying network setups, especially when combined with IMU data for real-time localization, has not been fully explored so far. In this study, we develop an error state Kalman filter (ESKF) and a pose graph optimization (PGO) approach to address this gap. We systematically evaluate the performance of the derived approaches for real-time MAV localization in realistic scenarios with 5G base stations in Line-Of-Sight (LOS), demonstrating the potential of 5G technologies in this domain. In order to experimentally test and compare our localization approaches, we augment the EuRoC MAV benchmark dataset for visual-inertial odometry with simulated yet highly realistic 5G ToA measurements. Our experimental results comprehensively assess the impact of varying network setups, including varying base station numbers and network configurations, on ToA-based MAV localization performance. The findings show promising results for seamless and robust localization using 5G ToA measurements, achieving an accuracy of 15 cm throughout the entire trajectory within a graph-based framework with five 5G base stations, and an accuracy of up to 34 cm in the case of ESKF-based localization. Additionally, we measure the run time of both algorithms and show that they are both fast enough for real-time implementation."}
{"main_page": "https://arxiv.org/abs/2404.00694", "pdf": "https://arxiv.org/pdf/2404.00694", "title": "DMSSN: Distilled Mixed Spectral-Spatial Network for Hyperspectral  Salient Object Detection", "authors": "Haolin Qin, Tingfa Xu, Peifu Liu, Jingxuan Xu, Jianan Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Hyperspectral salient object detection (HSOD) has exhibited remarkable promise across various applications, particularly in intricate scenarios where conventional RGB-based approaches fall short. Despite the considerable progress in HSOD method advancements, two critical challenges require immediate attention. Firstly, existing hyperspectral data dimension reduction techniques incur a loss of spectral information, which adversely affects detection accuracy. Secondly, previous methods insufficiently harness the inherent distinctive attributes of hyperspectral images (HSIs) during the feature extraction process. To address these challenges, we propose a novel approach termed the Distilled Mixed Spectral-Spatial Network (DMSSN), comprising a Distilled Spectral Encoding process and a Mixed Spectral-Spatial Transformer (MSST) feature extraction network. The encoding process utilizes knowledge distillation to construct a lightweight autoencoder for dimension reduction, striking a balance between robust encoding capabilities and low computational costs. The MSST extracts spectral-spatial features through multiple attention head groups, collaboratively enhancing its resistance to intricate scenarios. Moreover, we have created a large-scale HSOD dataset, HSOD-BIT, to tackle the issue of data scarcity in this field and meet the fundamental data requirements of deep network training. Extensive experiments demonstrate that our proposed DMSSN achieves state-of-the-art performance on multiple datasets. We will soon make the code and dataset publicly available on https://github.com/anonymous0519/HSOD-BIT."}
{"main_page": "https://arxiv.org/abs/2404.00696", "pdf": "https://arxiv.org/pdf/2404.00696", "title": "Privacy Re-identification Attacks on Tabular GANs", "authors": "Abdallah Alshantti, Adil Rasheed, Frank Westad", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "Generative models are subject to overfitting and thus may potentially leak sensitive information from the training data. In this work. we investigate the privacy risks that can potentially arise from the use of generative adversarial networks (GANs) for creating tabular synthetic datasets. For the purpose, we analyse the effects of re-identification attacks on synthetic data, i.e., attacks which aim at selecting samples that are predicted to correspond to memorised training samples based on their proximity to the nearest synthetic records. We thus consider multiple settings where different attackers might have different access levels or knowledge of the generative model and predictive, and assess which information is potentially most useful for launching more successful re-identification attacks. In doing so we also consider the situation for which re-identification attacks are formulated as reconstruction attacks, i.e., the situation where an attacker uses evolutionary multi-objective optimisation for perturbing synthetic samples closer to the training space. The results indicate that attackers can indeed pose major privacy risks by selecting synthetic samples that are likely representative of memorised training samples. In addition, we notice that privacy threats considerably increase when the attacker either has knowledge or has black-box access to the generative models. We also find that reconstruction attacks through multi-objective optimisation even increase the risk of identifying confidential samples."}
{"main_page": "https://arxiv.org/abs/2404.00699", "pdf": "https://arxiv.org/pdf/2404.00699", "title": "How Much are LLMs Contaminated? A Comprehensive Survey and the  LLMSanitize Library", "authors": "Mathieu Ravaut, Bosheng Ding, Fangkai Jiao, Hailin Chen, Xingxuan Li, Ruochen Zhao, Chengwei Qin, Caiming Xiong, Shafiq Joty", "subjects": "Computation and Language (cs.CL)", "abstract": "With the rise of Large Language Models (LLMs) in recent years, new opportunities are emerging, but also new challenges, and contamination is quickly becoming critical. Business applications and fundraising in AI have reached a scale at which a few percentage points gained on popular question-answering benchmarks could translate into dozens of millions of dollars, placing high pressure on model integrity. At the same time, it is becoming harder and harder to keep track of the data that LLMs have seen; if not impossible with closed-source models like GPT-4 and Claude-3 not divulging any information on the training set. As a result, contamination becomes a critical issue: LLMs' performance may not be reliable anymore, as the high performance may be at least partly due to their previous exposure to the data. This limitation jeopardizes the entire progress in the field of NLP, yet, there remains a lack of methods on how to efficiently address contamination, or a clear consensus on prevention, mitigation and classification of contamination. In this paper, we survey all recent work on contamination with LLMs, and help the community track contamination levels of LLMs by releasing an open-source Python library named LLMSanitize implementing major contamination detection algorithms, which link is: https://github.com/ntunlp/LLMSanitize."}
{"main_page": "https://arxiv.org/abs/2404.00701", "pdf": "https://arxiv.org/pdf/2404.00701", "title": "Training-Free Semantic Segmentation via LLM-Supervision", "authors": "Wenfang Sun, Yingjun Du, Gaowen Liu, Ramana Kompella, Cees G.M. Snoek", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advancements in open vocabulary models, like CLIP, have notably advanced zero-shot classification and segmentation by utilizing natural language for class-specific embeddings. However, most research has focused on improving model accuracy through prompt engineering, prompt learning, or fine-tuning with limited labeled data, thereby overlooking the importance of refining the class descriptors. This paper introduces a new approach to text-supervised semantic segmentation using supervision by a large language model (LLM) that does not require extra training. Our method starts from an LLM, like GPT-3, to generate a detailed set of subclasses for more accurate class representation. We then employ an advanced text-supervised semantic segmentation model to apply the generated subclasses as target labels, resulting in diverse segmentation results tailored to each subclass's unique characteristics. Additionally, we propose an assembly that merges the segmentation maps from the various subclass descriptors to ensure a more comprehensive representation of the different aspects in the test images. Through comprehensive experiments on three standard benchmarks, our method outperforms traditional text-supervised semantic segmentation methods by a marked margin."}
{"main_page": "https://arxiv.org/abs/2404.00702", "pdf": "https://arxiv.org/pdf/2404.00702", "title": "Tired of Plugins? Large Language Models Can Be End-To-End Recommenders", "authors": "Wenlin Zhang, Chuhan, Wu, Xiangyang Li, Yuhao Wang, Kuicai Dong, Yichao Wang, Xinyi Dai, Xiangyu Zhao, Huifeng Guo, Ruiming Tang", "subjects": "Information Retrieval (cs.IR)", "abstract": "Recommender systems aim to predict user interest based on historical behavioral data. They are mainly designed in sequential pipelines, requiring lots of data to train different sub-systems, and are hard to scale to new domains. Recently, Large Language Models (LLMs) have demonstrated remarkable generalized capabilities, enabling a singular model to tackle diverse recommendation tasks across various scenarios. Nonetheless, existing LLM-based recommendation systems utilize LLM purely for a single task of the recommendation pipeline. Besides, these systems face challenges in presenting large-scale item sets to LLMs in natural language format, due to the constraint of input length. To address these challenges, we introduce an LLM-based end-to-end recommendation framework: UniLLMRec. Specifically, UniLLMRec integrates multi-stage tasks (e.g. recall, ranking, re-ranking) via chain-of-recommendations. To deal with large-scale items, we propose a novel strategy to structure all items into an item tree, which can be dynamically updated and effectively retrieved. UniLLMRec shows promising zero-shot results in comparison with conventional supervised models. Additionally, it boasts high efficiency, reducing the input token need by 86% compared to existing LLM-based models. Such efficiency not only accelerates task completion but also optimizes resource utilization. To facilitate model understanding and to ensure reproducibility, we have made our code publicly available."}
{"main_page": "https://arxiv.org/abs/2404.00704", "pdf": "https://arxiv.org/pdf/2404.00704", "title": "Sponge: Inference Serving with Dynamic SLOs Using In-Place Vertical  Scaling", "authors": "Kamran Razavi, Saeid Ghafouri, Max M\u00fchlh\u00e4user, Pooyan Jamshidi, Lin Wang", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Mobile and IoT applications increasingly adopt deep learning inference to provide intelligence. Inference requests are typically sent to a cloud infrastructure over a wireless network that is highly variable, leading to the challenge of dynamic Service Level Objectives (SLOs) at the request level. This paper presents Sponge, a novel deep learning inference serving system that maximizes resource efficiency while guaranteeing dynamic SLOs. Sponge achieves its goal by applying in-place vertical scaling, dynamic batching, and request reordering. Specifically, we introduce an Integer Programming formulation to capture the resource allocation problem, providing a mathematical model of the relationship between latency, batch size, and resources. We demonstrate the potential of Sponge through a prototype implementation and preliminary experiments and discuss future works."}
{"main_page": "https://arxiv.org/abs/2404.00710", "pdf": "https://arxiv.org/pdf/2404.00710", "title": "Unknown Prompt, the only Lacuna: Unveiling CLIP's Potential for Open  Domain Generalization", "authors": "Mainak Singha, Ankit Jha, Shirsha Bose, Ashwin Nair, Moloud Abdar, Biplab Banerjee", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We delve into Open Domain Generalization (ODG), marked by domain and category shifts between training's labeled source and testing's unlabeled target domains. Existing solutions to ODG face limitations due to constrained generalizations of traditional CNN backbones and errors in detecting target open samples in the absence of prior knowledge. Addressing these pitfalls, we introduce ODG-CLIP, harnessing the semantic prowess of the vision-language model, CLIP. Our framework brings forth three primary innovations: Firstly, distinct from prevailing paradigms, we conceptualize ODG as a multi-class classification challenge encompassing both known and novel categories. Central to our approach is modeling a unique prompt tailored for detecting unknown class samples, and to train this, we employ a readily accessible stable diffusion model, elegantly generating proxy images for the open class. Secondly, aiming for domain-tailored classification (prompt) weights while ensuring a balance of precision and simplicity, we devise a novel visual stylecentric prompt learning mechanism. Finally, we infuse images with class-discriminative knowledge derived from the prompt space to augment the fidelity of CLIP's visual embeddings. We introduce a novel objective to safeguard the continuity of this infused semantic intel across domains, especially for the shared classes. Through rigorous testing on diverse datasets, covering closed and open-set DG contexts, ODG-CLIP demonstrates clear supremacy, consistently outpacing peers with performance boosts between 8%-16%. Code will be available at https://github.com/mainaksingha01/ODG-CLIP."}
{"main_page": "https://arxiv.org/abs/2404.00712", "pdf": "https://arxiv.org/pdf/2404.00712", "title": "Survey of Computerized Adaptive Testing: A Machine Learning Perspective", "authors": "Qi Liu, Yan Zhuang, Haoyang Bi, Zhenya Huang, Weizhe Huang, Jiatong Li, Junhao Yu, Zirui Liu, Zirui Hu, Yuting Hong, Zachary A. Pardos, Haiping Ma, Mengxiao Zhu, Shijin Wang, Enhong Chen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Information Retrieval (cs.IR)", "abstract": "Computerized Adaptive Testing (CAT) provides an efficient and tailored method for assessing the proficiency of examinees, by dynamically adjusting test questions based on their performance. Widely adopted across diverse fields like education, healthcare, sports, and sociology, CAT has revolutionized testing practices. While traditional methods rely on psychometrics and statistics, the increasing complexity of large-scale testing has spurred the integration of machine learning techniques. This paper aims to provide a machine learning-focused survey on CAT, presenting a fresh perspective on this adaptive testing method. By examining the test question selection algorithm at the heart of CAT's adaptivity, we shed light on its functionality. Furthermore, we delve into cognitive diagnosis models, question bank construction, and test control within CAT, exploring how machine learning can optimize these components. Through an analysis of current methods, strengths, limitations, and challenges, we strive to develop robust, fair, and efficient CAT systems. By bridging psychometric-driven CAT research with machine learning, this survey advocates for a more inclusive and interdisciplinary approach to the future of adaptive testing."}
{"main_page": "https://arxiv.org/abs/2404.00714", "pdf": "https://arxiv.org/pdf/2404.00714", "title": "Neural Radiance Field-based Visual Rendering: A Comprehensive Review", "authors": "Mingyuan Yao, Yukang Huo, Yang Ran, Qingbin Tian, Ruifeng Wang, Haihua Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "In recent years, Neural Radiance Fields (NeRF) has made remarkable progress in the field of computer vision and graphics, providing strong technical support for solving key tasks including 3D scene understanding, new perspective synthesis, human body reconstruction, robotics, and so on, the attention of academics to this research result is growing. As a revolutionary neural implicit field representation, NeRF has caused a continuous research boom in the academic community. Therefore, the purpose of this review is to provide an in-depth analysis of the research literature on NeRF within the past two years, to provide a comprehensive academic perspective for budding researchers. In this paper, the core architecture of NeRF is first elaborated in detail, followed by a discussion of various improvement strategies for NeRF, and case studies of NeRF in diverse application scenarios, demonstrating its practical utility in different domains. In terms of datasets and evaluation metrics, This paper details the key resources needed for NeRF model training. Finally, this paper provides a prospective discussion on the future development trends and potential challenges of NeRF, aiming to provide research inspiration for researchers in the field and to promote the further development of related technologies."}
{"main_page": "https://arxiv.org/abs/2404.00717", "pdf": "https://arxiv.org/pdf/2404.00717", "title": "End-to-End Autonomous Driving through V2X Cooperation", "authors": "Haibao Yu, Wenxian Yang, Jiaru Zhong, Zhenwei Yang, Siqi Fan, Ping Luo, Zaiqing Nie", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "abstract": "Cooperatively utilizing both ego-vehicle and infrastructure sensor data via V2X communication has emerged as a promising approach for advanced autonomous driving. However, current research mainly focuses on improving individual modules, rather than taking end-to-end learning to optimize final planning performance, resulting in underutilized data potential. In this paper, we introduce UniV2X, a pioneering cooperative autonomous driving framework that seamlessly integrates all key driving modules across diverse views into a unified network. We propose a sparse-dense hybrid data transmission and fusion mechanism for effective vehicle-infrastructure cooperation, offering three advantages: 1) Effective for simultaneously enhancing agent perception, online mapping, and occupancy prediction, ultimately improving planning performance. 2) Transmission-friendly for practical and limited communication conditions. 3) Reliable data fusion with interpretability of this hybrid data. We implement UniV2X, as well as reproducing several benchmark methods, on the challenging DAIR-V2X, the real-world cooperative driving dataset. Experimental results demonstrate the effectiveness of UniV2X in significantly enhancing planning performance, as well as all intermediate output performance. Code is at https://github.com/AIR-THU/UniV2X."}
{"main_page": "https://arxiv.org/abs/2404.00722", "pdf": "https://arxiv.org/pdf/2404.00722", "title": "DRCT: Saving Image Super-resolution away from Information Bottleneck", "authors": "Chih-Chung Hsu, Chia-Ming Lee, Yi-Shiuan Chou", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "In recent years, Vision Transformer-based applications to low-level vision tasks have achieved widespread success. Unlike CNN-based models, Transformers are more adept at capturing long-range dependencies, enabling the reconstruction of images utilizing information from non-local areas. In the domain of super-resolution, Swin-transformer-based approaches have become mainstream due to their capacity to capture global spatial information and their shifting-window attention mechanism that facilitates the interchange of information between different windows. Many researchers have enhanced image quality and network efficiency by expanding the receptive field or designing complex networks, yielding commendable results. However, we observed that spatial information tends to diminish during the forward propagation process due to increased depth, leading to a loss of spatial information and, consequently, limiting the model's potential. To address this, we propose the Dense-residual-connected Transformer (DRCT), aimed at mitigating the loss of spatial information through dense-residual connections between layers, thereby unleashing the model's potential and enhancing performance. Experiment results indicate that our approach is not only straightforward but also achieves remarkable efficiency, surpassing state-of-the-art methods and performing commendably at NTIRE2024."}
{"main_page": "https://arxiv.org/abs/2404.00724", "pdf": "https://arxiv.org/pdf/2404.00724", "title": "Absolute-Unified Multi-Class Anomaly Detection via Class-Agnostic  Distribution Alignment", "authors": "Jia Guo, Shuai Lu, Weihang Zhang, Huiqi Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Conventional unsupervised anomaly detection (UAD) methods build separate models for each object category. Recent studies have proposed to train a unified model for multiple classes, namely model-unified UAD. However, such methods still implement the unified model separately on each class during inference with respective anomaly decision thresholds, which hinders their application when the image categories are entirely unavailable. In this work, we present a simple yet powerful method to address multi-class anomaly detection without any class information, namely \\textit{absolute-unified} UAD. We target the crux of prior works in this challenging setting: different objects have mismatched anomaly score distributions. We propose Class-Agnostic Distribution Alignment (CADA) to align the mismatched score distribution of each implicit class without knowing class information, which enables unified anomaly detection for all classes and samples. The essence of CADA is to predict each class's score distribution of normal samples given any image, normal or anomalous, of this class. As a general component, CADA can activate the potential of nearly all UAD methods under absolute-unified setting. Our approach is extensively evaluated under the proposed setting on two popular UAD benchmark datasets, MVTec AD and VisA, where we exceed previous state-of-the-art by a large margin."}
{"main_page": "https://arxiv.org/abs/2404.00725", "pdf": "https://arxiv.org/pdf/2404.00725", "title": "The Larger the Better? Improved LLM Code-Generation via Budget  Reallocation", "authors": "Michael Hassid, Tal Remez, Jonas Gehring, Roy Schwartz, Yossi Adi", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "It is a common belief that large language models (LLMs) are better than smaller-sized ones. However, larger models also require significantly more time and compute during inference. This begs the question: what happens when both models operate under the same budget? (e.g., compute, run-time). To address this question, we analyze code generation LLMs of various sizes and make comparisons such as running a 70B model once vs. generating five outputs from a 13B model and selecting one. Our findings reveal that, in a standard unit-test setup, the repeated use of smaller models can yield consistent improvements, with gains of up to 15% across five tasks. On the other hand, in scenarios where unit-tests are unavailable, a ranking-based selection of candidates from the smaller model falls short of the performance of a single output from larger ones. Our results highlight the potential of using smaller models instead of larger ones, and the importance of studying approaches for ranking LLM outputs."}
{"main_page": "https://arxiv.org/abs/2404.00727", "pdf": "https://arxiv.org/pdf/2404.00727", "title": "A Controlled Reevaluation of Coreference Resolution Models", "authors": "Ian Porada, Xiyuan Zou, Jackie Chi Kit Cheung", "subjects": "Computation and Language (cs.CL)", "abstract": "All state-of-the-art coreference resolution (CR) models involve finetuning a pretrained language model. Whether the superior performance of one CR model over another is due to the choice of language model or other factors, such as the task-specific architecture, is difficult or impossible to determine due to lack of a standardized experimental setup. To resolve this ambiguity, we systematically evaluate five CR models and control for certain design decisions including the pretrained language model used by each. When controlling for language model size, encoder-based CR models outperform more recent decoder-based models in terms of both accuracy and inference speed. Surprisingly, among encoder-based CR models, more recent models are not always more accurate, and the oldest CR model that we test generalizes the best to out-of-domain textual genres. We conclude that controlling for the choice of language model reduces most, but not all, of the increase in F1 score reported in the past five years."}
{"main_page": "https://arxiv.org/abs/2404.00728", "pdf": "https://arxiv.org/pdf/2404.00728", "title": "Investigating Youths' Everyday Understanding of Machine Learning  Applications: a Knowledge-in-Pieces Perspective", "authors": "Luis Morales-Navarro, Yasmin B. Kafai", "subjects": "Computers and Society (cs.CY)", "abstract": "Despite recent calls for including artificial intelligence (AI) literacy in K-12 education, not enough attention has been paid to studying youths' everyday knowledge about machine learning (ML). Most research has examined how youths attribute intelligence to AI/ML systems. Other studies have centered on youths' theories and hypotheses about ML highlighting their misconceptions and how these may hinder learning. However, research on conceptual change shows that youths may not have coherent theories about scientific phenomena and instead have knowledge pieces that can be productive for formal learning. We investigate teens' everyday understanding of ML through a knowledge-in-pieces perspective. Our analyses reveal that youths showed some understanding that ML applications learn from training data and that applications recognize patterns in input data and depending on these provide different outputs. We discuss how these findings expand our knowledge base and implications for the design of tools and activities to introduce youths to ML."}
{"main_page": "https://arxiv.org/abs/2404.00729", "pdf": "https://arxiv.org/pdf/2404.00729", "title": "Nonparametric End-to-End Probabilistic Forecasting of Distributed  Generation Outputs Considering Missing Data Imputation", "authors": "Minghui Chen, Zichao Meng, Yanping Liu, Longbo Luo, Ye Guo, Kang Wang", "subjects": "Systems and Control (eess.SY); Machine Learning (cs.LG)", "abstract": "In this paper, we introduce a nonparametric end-to-end method for probabilistic forecasting of distributed renewable generation outputs while including missing data imputation. Firstly, we employ a nonparametric probabilistic forecast model utilizing the long short-term memory (LSTM) network to model the probability distributions of distributed renewable generations' outputs. Secondly, we design an end-to-end training process that includes missing data imputation through iterative imputation and iterative loss-based training procedures. This two-step modeling approach effectively combines the strengths of the nonparametric method with the end-to-end approach. Consequently, our approach demonstrates exceptional capabilities in probabilistic forecasting for the outputs of distributed renewable generations while effectively handling missing values. Simulation results confirm the superior performance of our approach compared to existing alternatives."}
{"main_page": "https://arxiv.org/abs/2404.00732", "pdf": "https://arxiv.org/pdf/2404.00732", "title": "An Abundance of Katherines: The Game Theory of Baby Naming", "authors": "Katy Blumer, Kate Donahue, Katie Fritz, Kate Ivanovich, Katherine Lee, Katie Luo, Cathy Meng, Katie Van Koevering", "subjects": "Computer Science and Game Theory (cs.GT); Computers and Society (cs.CY)", "abstract": "In this paper, we study the highly competitive arena of baby naming. Through making several Extremely Reasonable Assumptions (namely, that parents are myopic, perfectly knowledgeable agents who pick a name based solely on its uniquness), we create a model which is not only tractable and clean, but also perfectly captures the real world. We then extend our investigation with numerical experiments, as well as analysis of large language model tools. We conclude by discussing avenues for future research."}
{"main_page": "https://arxiv.org/abs/2404.00733", "pdf": "https://arxiv.org/pdf/2404.00733", "title": "Smooth Information Gathering in Two-Player Noncooperative Games", "authors": "Fernando Palafox, Jesse Milzman, Dong Ho Lee, Ryan Park, David Fridovich-Keil", "subjects": "Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Systems and Control (eess.SY)", "abstract": "We present a mathematical framework for modeling two-player noncooperative games in which one player (the defender) is uncertain of the costs of the game and the second player's (the attacker's) intention but can preemptively allocate information-gathering resources to reduce this uncertainty. We obtain the defender's decisions by solving a two-stage problem. In Stage 1, the defender allocates information-gathering resources, and in Stage 2, the information-gathering resources output a signal that informs the defender about the costs of the game and the attacker's intent, and then both players play a noncooperative game. We provide a gradient-based algorithm to solve the two-stage game and apply this framework to a tower-defense game which can be interpreted as a variant of a Colonel Blotto game with smooth payoff functions and uncertainty over battlefield valuations. Finally, we analyze how optimal decisions shift with changes in information-gathering allocations and perturbations in the cost functions."}
{"main_page": "https://arxiv.org/abs/2404.00739", "pdf": "https://arxiv.org/pdf/2404.00739", "title": "Opera Graeca Adnotata: Building a 34M+ Token Multilayer Corpus for  Ancient Greek", "authors": "Giuseppe G. A. Celano", "subjects": "Computation and Language (cs.CL)", "abstract": "In this article, the beta version 0.1.0 of Opera Graeca Adnotata (OGA), the largest open-access multilayer corpus for Ancient Greek (AG) is presented. OGA consists of 1,687 literary works and 34M+ tokens coming from the PerseusDL and OpenGreekAndLatin GitHub repositories, which host AG texts ranging from about 800 BCE to about 250 CE. The texts have been enriched with seven annotation layers: (i) tokenization layer; (ii) sentence segmentation layer; (iii) lemmatization layer; (iv) morphological layer; (v) dependency layer; (vi) dependency function layer; (vii) Canonical Text Services (CTS) citation layer. The creation of each layer is described by highlighting the main technical and annotation-related issues encountered. Tokenization, sentence segmentation, and CTS citation are performed by rule-based algorithms, while morphosyntactic annotation is the output of the COMBO parser trained on the data of the Ancient Greek Dependency Treebank. For the sake of scalability and reusability, the corpus is released in the standoff formats PAULA XML and its offspring LAULA XML."}
{"main_page": "https://arxiv.org/abs/2404.00741", "pdf": "https://arxiv.org/pdf/2404.00741", "title": "Rethinking Interactive Image Segmentation with Low Latency, High  Quality, and Diverse Prompts", "authors": "Qin Liu, Jaemin Cho, Mohit Bansal, Marc Niethammer", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The goal of interactive image segmentation is to delineate specific regions within an image via visual or language prompts. Low-latency and high-quality interactive segmentation with diverse prompts remain challenging for existing specialist and generalist models. Specialist models, with their limited prompts and task-specific designs, experience high latency because the image must be recomputed every time the prompt is updated, due to the joint encoding of image and visual prompts. Generalist models, exemplified by the Segment Anything Model (SAM), have recently excelled in prompt diversity and efficiency, lifting image segmentation to the foundation model era. However, for high-quality segmentations, SAM still lags behind state-of-the-art specialist models despite SAM being trained with x100 more segmentation masks. In this work, we delve deep into the architectural differences between the two types of models. We observe that dense representation and fusion of visual prompts are the key design choices contributing to the high segmentation quality of specialist models. In light of this, we reintroduce this dense design into the generalist models, to facilitate the development of generalist models with high segmentation quality. To densely represent diverse visual prompts, we propose to use a dense map to capture five types: clicks, boxes, polygons, scribbles, and masks. Thus, we propose SegNext, a next-generation interactive segmentation approach offering low latency, high quality, and diverse prompt support. Our method outperforms current state-of-the-art methods on HQSeg-44K and DAVIS, both quantitatively and qualitatively."}
{"main_page": "https://arxiv.org/abs/2404.00742", "pdf": "https://arxiv.org/pdf/2404.00742", "title": "Adapting to Length Shift: FlexiLength Network for Trajectory Prediction", "authors": "Yi Xu, Yun Fu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Trajectory prediction plays an important role in various applications, including autonomous driving, robotics, and scene understanding. Existing approaches mainly focus on developing compact neural networks to increase prediction precision on public datasets, typically employing a standardized input duration. However, a notable issue arises when these models are evaluated with varying observation lengths, leading to a significant performance drop, a phenomenon we term the Observation Length Shift. To address this issue, we introduce a general and effective framework, the FlexiLength Network (FLN), to enhance the robustness of existing trajectory prediction techniques against varying observation periods. Specifically, FLN integrates trajectory data with diverse observation lengths, incorporates FlexiLength Calibration (FLC) to acquire temporal invariant representations, and employs FlexiLength Adaptation (FLA) to further refine these representations for more accurate future trajectory predictions. Comprehensive experiments on multiple datasets, ie, ETH/UCY, nuScenes, and Argoverse 1, demonstrate the effectiveness and flexibility of our proposed FLN framework."}
{"main_page": "https://arxiv.org/abs/2404.00746", "pdf": "https://arxiv.org/pdf/2404.00746", "title": "Mining Weighted Sequential Patterns in Incremental Uncertain Databases", "authors": "Kashob Kumar Roy, Md Hasibul Haque Moon, Md Mahmudur Rahman, Chowdhury Farhan Ahmed, Carson Kai-Sang Leung", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI)", "abstract": "Due to the rapid development of science and technology, the importance of imprecise, noisy, and uncertain data is increasing at an exponential rate. Thus, mining patterns in uncertain databases have drawn the attention of researchers. Moreover, frequent sequences of items from these databases need to be discovered for meaningful knowledge with great impact. In many real cases, weights of items and patterns are introduced to find interesting sequences as a measure of importance. Hence, a constraint of weight needs to be handled while mining sequential patterns. Besides, due to the dynamic nature of databases, mining important information has become more challenging. Instead of mining patterns from scratch after each increment, incremental mining algorithms utilize previously mined information to update the result immediately. Several algorithms exist to mine frequent patterns and weighted sequences from incremental databases. However, these algorithms are confined to mine the precise ones. Therefore, we have developed an algorithm to mine frequent sequences in an uncertain database in this work. Furthermore, we have proposed two new techniques for mining when the database is incremental. Extensive experiments have been conducted for performance evaluation. The analysis showed the efficiency of our proposed framework."}
{"main_page": "https://arxiv.org/abs/2404.00748", "pdf": "https://arxiv.org/pdf/2404.00748", "title": "Benchmark Transparency: Measuring the Impact of Data on Evaluation", "authors": "Venelin Kovatchev, Matthew Lease", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "In this paper we present an exploratory research on quantifying the impact that data distribution has on the performance and evaluation of NLP models. We propose an automated framework that measures the data point distribution across 6 different dimensions: ambiguity, difficulty, discriminability, length, noise, and perplexity. We use disproportional stratified sampling to measure how much the data distribution affects absolute (Acc/F1) and relative (Rank) model performance. We experiment on 2 different datasets (SQUAD and MNLI) and test a total of 135 different models (125 on SQUAD and 10 on MNLI). We demonstrate that without explicit control of the data distribution, standard evaluation frameworks are inconsistent and unreliable. We find that the impact of the data is statistically significant and is often larger than the impact of changing the metric. In a second set of experiments, we demonstrate that the impact of data on evaluation is not just observable, but also predictable. We propose to use benchmark transparency as a method for comparing datasets and quantifying the similarity between them. We find that the ``dataset similarity vector'' can be used to predict how well a model generalizes out of distribution."}
{"main_page": "https://arxiv.org/abs/2404.00750", "pdf": "https://arxiv.org/pdf/2404.00750", "title": "Can Language Models Recognize Convincing Arguments?", "authors": "Paula Rescala, Manoel Horta Ribeiro, Tiancheng Hu, Robert West", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "abstract": "The remarkable and ever-increasing capabilities of Large Language Models (LLMs) have raised concerns about their potential misuse for creating personalized, convincing misinformation and propaganda. To gain insights into LLMs' persuasive capabilities without directly engaging in experimentation with humans, we propose studying their performance on the related task of detecting convincing arguments. We extend a dataset by Durmus & Cardie (2018) with debates, votes, and user traits and propose tasks measuring LLMs' ability to (1) distinguish between strong and weak arguments, (2) predict stances based on beliefs and demographic characteristics, and (3) determine the appeal of an argument to an individual based on their traits. We show that LLMs perform on par with humans in these tasks and that combining predictions from different LLMs yields significant performance gains, even surpassing human performance. The data and code released with this paper contribute to the crucial ongoing effort of continuously evaluating and monitoring the rapidly evolving capabilities and potential impact of LLMs."}
{"main_page": "https://arxiv.org/abs/2404.00752", "pdf": "https://arxiv.org/pdf/2404.00752", "title": "On the True Distribution Approximation of Minimum Bayes-Risk Decoding", "authors": "Atsumoto Ohashi, Ukyo Honda, Tetsuro Morimura, Yuu Jinnai", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Minimum Bayes-risk (MBR) decoding has recently gained renewed attention in text generation. MBR decoding considers texts sampled from a model as pseudo-references and selects the text with the highest similarity to the others. Therefore, sampling is one of the key elements of MBR decoding, and previous studies reported that the performance varies by sampling methods. From a theoretical standpoint, this performance variation is likely tied to how closely the samples approximate the true distribution of references. However, this approximation has not been the subject of in-depth study. In this study, we propose using anomaly detection to measure the degree of approximation. We first closely examine the performance variation and then show that previous hypotheses about samples do not correlate well with the variation, but our introduced anomaly scores do. The results are the first to empirically support the link between the performance and the core assumption of MBR decoding."}
{"main_page": "https://arxiv.org/abs/2404.00756", "pdf": "https://arxiv.org/pdf/2404.00756", "title": "Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery", "authors": "Cristina Cornelio, Mohammed Diab", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO); Robotics (cs.RO)", "abstract": "Recognizing failures during task execution and implementing recovery procedures is challenging in robotics. Traditional approaches rely on the availability of extensive data or a tight set of constraints, while more recent approaches leverage large language models (LLMs) to verify task steps and replan accordingly. However, these methods often operate offline, necessitating scene resets and incurring in high costs. This paper introduces Recover, a neuro-symbolic framework for online failure identification and recovery. By integrating ontologies, logical rules, and LLM-based planners, Recover exploits symbolic information to enhance the ability of LLMs to generate recovery plans and also to decrease the associated costs. In order to demonstrate the capabilities of our method in a simulated kitchen environment, we introduce OntoThor, an ontology describing the AI2Thor simulator setting. Empirical evaluation shows that OntoThor's logical rules accurately detect all failures in the analyzed tasks, and that Recover considerably outperforms, for both failure detection and recovery, a baseline method reliant solely on LLMs."}
{"main_page": "https://arxiv.org/abs/2404.00758", "pdf": "https://arxiv.org/pdf/2404.00758", "title": "From Robustness to Improved Generalization and Calibration in  Pre-trained Language Models", "authors": "Josip Juki\u0107, Jan \u0160najder", "subjects": "Computation and Language (cs.CL)", "abstract": "Enhancing generalization and uncertainty quantification in pre-trained language models (PLMs) is crucial for their effectiveness and reliability. Building on machine learning research that established the importance of robustness for improving generalization, we investigate the role of representation smoothness, achieved via Jacobian and Hessian regularization, in enhancing PLM performance. Although such regularization methods have proven effective in computer vision, their application in natural language processing (NLP), where PLM inputs are derived from a discrete domain, poses unique challenges. We introduce a novel two-phase regularization approach, JacHess, which minimizes the norms of the Jacobian and Hessian matrices within PLM intermediate representations relative to their inputs. Our evaluation using the GLUE benchmark demonstrates that JacHess significantly improves in-domain generalization and calibration in PLMs, outperforming unregularized fine-tuning and other similar regularization methods."}
{"main_page": "https://arxiv.org/abs/2404.00762", "pdf": "https://arxiv.org/pdf/2404.00762", "title": "Enchanting Program Specification Synthesis by Large Language Models  using Static Analysis and Program Verification", "authors": "Cheng Wen, Jialun Cao, Jie Su, Zhiwu Xu, Shengchao Qin, Mengda He, Haokun Li, Shing-Chi Cheung, Cong Tian", "subjects": "Software Engineering (cs.SE)", "abstract": "Formal verification provides a rigorous and systematic approach to ensure the correctness and reliability of software systems. Yet, constructing specifications for the full proof relies on domain expertise and non-trivial manpower. In view of such needs, an automated approach for specification synthesis is desired. While existing automated approaches are limited in their versatility, i.e., they either focus only on synthesizing loop invariants for numerical programs, or are tailored for specific types of programs or invariants. Programs involving multiple complicated data types (e.g., arrays, pointers) and code structures (e.g., nested loops, function calls) are often beyond their capabilities. To help bridge this gap, we present AutoSpec, an automated approach to synthesize specifications for automated program verification. It overcomes the shortcomings of existing work in specification versatility, synthesizing satisfiable and adequate specifications for full proof. It is driven by static analysis and program verification, and is empowered by large language models (LLMs). AutoSpec addresses the practical challenges in three ways: (1) driving \\name by static analysis and program verification, LLMs serve as generators to generate candidate specifications, (2) programs are decomposed to direct the attention of LLMs, and (3) candidate specifications are validated in each round to avoid error accumulation during the interaction with LLMs. In this way, AutoSpec can incrementally and iteratively generate satisfiable and adequate specifications. The evaluation shows its effectiveness and usefulness, as it outperforms existing works by successfully verifying 79% of programs through automatic specification synthesis, a significant improvement of 1.592x. It can also be successfully applied to verify the programs in a real-world X509-parser project."}
{"main_page": "https://arxiv.org/abs/2404.00766", "pdf": "https://arxiv.org/pdf/2404.00766", "title": "SoK: The Faults in our Graph Benchmarks", "authors": "Puneet Mehrotra, Vaastav Anand, Daniel Margo, Milad Rezaei Hajidehi, Margo Seltzer", "subjects": "Databases (cs.DB)", "abstract": "Graph-structured data is prevalent in domains such as social networks, financial transactions, brain networks, and protein interactions. As a result, the research community has produced new databases and analytics engines to process such data. Unfortunately, there is not yet widespread benchmark standardization in graph processing, and the heterogeneity of evaluations found in the literature can lead researchers astray. Evaluations frequently ignore datasets' statistical idiosyncrasies, which significantly affect system performance. Scalability studies often use datasets that fit easily in memory on a modest desktop. Some studies rely on synthetic graph generators, but these generators produce graphs with unnatural characteristics that also affect performance, producing misleading results. Currently, the community has no consistent and principled manner with which to compare systems and provide guidance to developers who wish to select the system most suited to their application. We provide three different systematizations of benchmarking practices. First, we present a 12-year literary review of graph processing benchmarking, including a summary of the prevalence of specific datasets and benchmarks used in these papers. Second, we demonstrate the impact of two statistical properties of datasets that drastically affect benchmark performance. We show how different assignments of IDs to vertices, called vertex orderings, dramatically alter benchmark performance due to the caching behavior they induce. We also show the impact of zero-degree vertices on the runtime of benchmarks such as breadth-first search and single-source shortest path. We show that these issues can cause performance to change by as much as 38% on several popular graph processing systems. Finally, we suggest best practices to account for these issues when evaluating graph systems."}
{"main_page": "https://arxiv.org/abs/2404.00768", "pdf": "https://arxiv.org/pdf/2404.00768", "title": "Adversarially-Robust Inference on Trees via Belief Propagation", "authors": "Samuel B. Hopkins, Anqi Li", "subjects": "Data Structures and Algorithms (cs.DS); Probability (math.PR); Statistics Theory (math.ST); Machine Learning (stat.ML)", "abstract": "We introduce and study the problem of posterior inference on tree-structured graphical models in the presence of a malicious adversary who can corrupt some observed nodes. In the well-studied broadcasting on trees model, corresponding to the ferromagnetic Ising model on a $d$-regular tree with zero external field, when a natural signal-to-noise ratio exceeds one (the celebrated Kesten-Stigum threshold), the posterior distribution of the root given the leaves is bounded away from $\\mathrm{Ber}(1/2)$, and carries nontrivial information about the sign of the root. This posterior distribution can be computed exactly via dynamic programming, also known as belief propagation. We first confirm a folklore belief that a malicious adversary who can corrupt an inverse-polynomial fraction of the leaves of their choosing makes this inference impossible. Our main result is that accurate posterior inference about the root vertex given the leaves is possible when the adversary is constrained to make corruptions at a $\\rho$-fraction of randomly-chosen leaf vertices, so long as the signal-to-noise ratio exceeds $O(\\log d)$ and $\\rho \\leq c \\varepsilon$ for some universal $c > 0$. Since inference becomes information-theoretically impossible when $\\rho \\gg \\varepsilon$, this amounts to an information-theoretically optimal fraction of corruptions, up to a constant multiplicative factor. Furthermore, we show that the canonical belief propagation algorithm performs this inference."}
{"main_page": "https://arxiv.org/abs/2404.00769", "pdf": "https://arxiv.org/pdf/2404.00769", "title": "An Active Perception Game for Robust Autonomous Exploration", "authors": "Siming He, Yuezhan Tao, Igor Spasojevic, Vijay Kumar, Pratik Chaudhari", "subjects": "Robotics (cs.RO)", "abstract": "We formulate active perception for an autonomous agent that explores an unknown environment as a two-player zero-sum game: the agent aims to maximize information gained from the environment while the environment aims to minimize the information gained by the agent. In each episode, the environment reveals a set of actions with their potentially erroneous information gain. In order to select the best action, the robot needs to recover the true information gain from the erroneous one. The robot does so by minimizing the discrepancy between its estimate of information gain and the true information gain it observes after taking the action. We propose an online convex optimization algorithm that achieves sub-linear expected regret $O(T^{3/4})$ for estimating the information gain. We also provide a bound on the regret of active perception performed by any (near-)optimal prediction and trajectory selection algorithms. We evaluate this approach using semantic neural radiance fields (NeRFs) in simulated realistic 3D environments to show that the robot can discover up to 12% more objects using the improved estimate of the information gain. On the M3ED dataset, the proposed algorithm reduced the error of information gain prediction in occupancy map by over 67%. In real-world experiments using occupancy maps on a Jackal ground robot, we show that this approach can calculate complicated trajectories that efficiently explore all occluded regions."}
{"main_page": "https://arxiv.org/abs/2404.00774", "pdf": "https://arxiv.org/pdf/2404.00774", "title": "SOAR: Improved Indexing for Approximate Nearest Neighbor Search", "authors": "Philip Sun, David Simcha, Dave Dopson, Ruiqi Guo, Sanjiv Kumar", "subjects": "Machine Learning (cs.LG)", "abstract": "This paper introduces SOAR: Spilling with Orthogonality-Amplified Residuals, a novel data indexing technique for approximate nearest neighbor (ANN) search. SOAR extends upon previous approaches to ANN search, such as spill trees, that utilize multiple redundant representations while partitioning the data to reduce the probability of missing a nearest neighbor during search. Rather than training and computing these redundant representations independently, however, SOAR uses an orthogonality-amplified residual loss, which optimizes each representation to compensate for cases where other representations perform poorly. This drastically improves the overall index quality, resulting in state-of-the-art ANN benchmark performance while maintaining fast indexing times and low memory consumption."}
{"main_page": "https://arxiv.org/abs/2404.00775", "pdf": "https://arxiv.org/pdf/2404.00775", "title": "Measuring audio prompt adherence with distribution-based embedding  distances", "authors": "Maarten Grachten", "subjects": "Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "An increasing number of generative music models can be conditioned on an audio prompt that serves as musical context for which the model is to create an accompaniment (often further specified using a text prompt). Evaluation of how well model outputs adhere to the audio prompt is often done in a model or problem specific manner, presumably because no generic evaluation method for audio prompt adherence has emerged. Such a method could be useful both in the development and training of new models, and to make performance comparable across models. In this paper we investigate whether commonly used distribution-based distances like Fr\\'echet Audio Distance (FAD), can be used to measure audio prompt adherence. We propose a simple procedure based on a small number of constituents (an embedding model, a projection, an embedding distance, and a data fusion method), that we systematically assess using a baseline validation. In a follow-up experiment we test the sensitivity of the proposed audio adherence measure to pitch and time shift perturbations. The results show that the proposed measure is sensitive to such perturbations, even when the reference and candidate distributions are from different music collections. Although more experimentation is needed to answer unaddressed questions like the robustness of the measure to acoustic artifacts that do not affect the audio prompt adherence, the current results suggest that distribution-based embedding distances provide a viable way of measuring audio prompt adherence. An python/pytorch implementation of the proposed measure is publicly available as a github repository."}
{"main_page": "https://arxiv.org/abs/2404.00776", "pdf": "https://arxiv.org/pdf/2404.00776", "title": "PyTorch Frame: A Modular Framework for Multi-Modal Tabular Learning", "authors": "Weihua Hu, Yiwen Yuan, Zecheng Zhang, Akihiro Nitta, Kaidi Cao, Vid Kocijan, Jure Leskovec, Matthias Fey", "subjects": "Machine Learning (cs.LG); Databases (cs.DB); Machine Learning (stat.ML)", "abstract": "We present PyTorch Frame, a PyTorch-based framework for deep learning over multi-modal tabular data. PyTorch Frame makes tabular deep learning easy by providing a PyTorch-based data structure to handle complex tabular data, introducing a model abstraction to enable modular implementation of tabular models, and allowing external foundation models to be incorporated to handle complex columns (e.g., LLMs for text columns). We demonstrate the usefulness of PyTorch Frame by implementing diverse tabular models in a modular way, successfully applying these models to complex multi-modal tabular data, and integrating our framework with PyTorch Geometric, a PyTorch library for Graph Neural Networks (GNNs), to perform end-to-end learning over relational databases."}
{"main_page": "https://arxiv.org/abs/2404.00777", "pdf": "https://arxiv.org/pdf/2404.00777", "title": "Privacy-preserving Optics for Enhancing Protection in Face  De-identification", "authors": "Jhon Lopez, Carlos Hinojosa, Henry Arguello, Bernard Ghanem", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Image and Video Processing (eess.IV)", "abstract": "The modern surge in camera usage alongside widespread computer vision technology applications poses significant privacy and security concerns. Current artificial intelligence (AI) technologies aid in recognizing relevant events and assisting in daily tasks in homes, offices, hospitals, etc. The need to access or process personal information for these purposes raises privacy concerns. While software-level solutions like face de-identification provide a good privacy/utility trade-off, they present vulnerabilities to sniffing attacks. In this paper, we propose a hardware-level face de-identification method to solve this vulnerability. Specifically, our approach first learns an optical encoder along with a regression model to obtain a face heatmap while hiding the face identity from the source image. We also propose an anonymization framework that generates a new face using the privacy-preserving image, face heatmap, and a reference face image from a public dataset as input. We validate our approach with extensive simulations and hardware experiments."}
{"main_page": "https://arxiv.org/abs/2404.00781", "pdf": "https://arxiv.org/pdf/2404.00781", "title": "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual  Learning", "authors": "Mohamed Elsayed, A. Rupam Mahmood", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues."}
{"main_page": "https://arxiv.org/abs/2404.00783", "pdf": "https://arxiv.org/pdf/2404.00783", "title": "Potentials of the Metaverse for Robotized Applications in Industry 4.0  and Industry 5.0", "authors": "Eric Guiffo Kaigom", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "As a digital environment of interconnected virtual ecosystems driven by measured and synthesized data, the Metaverse has so far been mostly considered from its gaming perspective that closely aligns with online edutainment. Although it is still in its infancy and more research as well as standardization efforts remain to be done, the Metaverse could provide considerable advantages for smart robotized applications in the industry.Workflow efficiency, collective decision enrichment even for executives, as well as a natural, resilient, and sustainable robotized assistance for the workforce are potential advantages. Hence, the Metaverse could consolidate the connection between Industry 4.0 and Industry 5.0. This paper identifies and puts forward potential advantages of the Metaverse for robotized applications and highlights how these advantages support goals pursued by the Industry 4.0 and Industry 5.0 visions."}
{"main_page": "https://arxiv.org/abs/2404.00785", "pdf": "https://arxiv.org/pdf/2404.00785", "title": "Disentangling Hippocampal Shape Variations: A Study of Neurological  Disorders Using Graph Variational Autoencoder with Contrastive Learning", "authors": "Jakaria Rabbi, Johannes Kiechle, Christian Beaulieu, Nilanjan Ray, Dana Cobzas", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)", "abstract": "This paper presents a comprehensive study focused on disentangling hippocampal shape variations from diffusion tensor imaging (DTI) datasets within the context of neurological disorders. Leveraging a Graph Variational Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach aims to improve interpretability by disentangling two distinct latent variables corresponding to age and the presence of diseases. In our ablation study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SOTA) methods like attribute and guided VAEs in terms of disentanglement scores. Our model distinguishes between age groups and disease status in patients with Multiple Sclerosis (MS) using the hippocampus data. Our Graph VAE with Supervised Contrastive Learning shows the volume changes of the hippocampus of MS populations at different ages, and the result is consistent with the current neuroimaging literature. This research provides valuable insights into the relationship between neurological disorder and hippocampal shape changes in different age groups of MS populations using a Graph VAE with Supervised Contrastive loss."}
{"main_page": "https://arxiv.org/abs/2404.00786", "pdf": "https://arxiv.org/pdf/2404.00786", "title": "There and Back Again: A Netlist's Tale with Much Egraphin'", "authors": "Gus Henry Smith, Zachary D. Sisco, Thanawat Techaumnuaiwit, Jingtao Xia, Vishal Canumalla, Andrew Cheung, Zachary Tatlock, Chandrakana Nandi, Jonathan Balkind", "subjects": "Hardware Architecture (cs.AR); Programming Languages (cs.PL)", "abstract": "EDA toolchains are notoriously unpredictable, incomplete, and error-prone; the generally-accepted remedy has been to re-imagine EDA tasks as compilation problems. However, any compiler framework we apply must be prepared to handle the wide range of EDA tasks, including not only compilation tasks like technology mapping and optimization (the \"there\"} in our title), but also decompilation tasks like loop rerolling (the \"back again\"). In this paper, we advocate for equality saturation -- a term rewriting framework -- as the framework of choice when building hardware toolchains. Through a series of case studies, we show how the needs of EDA tasks line up conspicuously well with the features equality saturation provides."}
{"main_page": "https://arxiv.org/abs/2404.00789", "pdf": "https://arxiv.org/pdf/2404.00789", "title": "A Comparative Analysis of Poetry Reading Audio: Singing, Narrating, or  Somewhere In Between?", "authors": "Kahyun Choi, Minje Kim", "subjects": "Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "This paper provides a computational analysis of poetry reading audio signals at a large scale to unveil the musicality within professionally-read poems. Although the acoustic characteristics of other types of spoken language have been extensively studied, most of the literature is limited to narrative speech or singing voice, discussing how different they are from each other. In this work, we develop signal processing methods, which are tailored to capture the unique acoustic characteristics of poetry reading based on their silence patterns, temporal variations of local pitch, and beat stability. Our large-scale statistical analyses on three big corpora, each of which consists of narration (LibriSpeech), singing voice (Intonation), and poetry reading (from The Poetry Foundation), discover that poetry reading does share some musical characteristics with singing voice, although it may also resemble narrative speech."}
{"main_page": "https://arxiv.org/abs/2404.00790", "pdf": "https://arxiv.org/pdf/2404.00790", "title": "Rehearsal-Free Modular and Compositional Continual Learning for Language  Models", "authors": "Mingyang Wang, Heike Adel, Lukas Lange, Jannik Str\u00f6tgen, Hinrich Sch\u00fctze", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Continual learning aims at incrementally acquiring new knowledge while not forgetting existing knowledge. To overcome catastrophic forgetting, methods are either rehearsal-based, i.e., store data examples from previous tasks for data replay, or isolate parameters dedicated to each task. However, rehearsal-based methods raise privacy and memory issues, and parameter-isolation continual learning does not consider interaction between tasks, thus hindering knowledge transfer. In this work, we propose MoCL, a rehearsal-free Modular and Compositional Continual Learning framework which continually adds new modules to language models and composes them with existing modules. Experiments on various benchmarks show that MoCL outperforms state of the art and effectively facilitates knowledge transfer."}
{"main_page": "https://arxiv.org/abs/2404.00791", "pdf": "https://arxiv.org/pdf/2404.00791", "title": "Personalized Neural Speech Codec", "authors": "Inseon Jang, Haici Yang, Wootaek Lim, Seungkwon Beack, Minje Kim", "subjects": "Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "In this paper, we propose a personalized neural speech codec, envisioning that personalization can reduce the model complexity or improve perceptual speech quality. Despite the common usage of speech codecs where only a single talker is involved on each side of the communication, personalizing a codec for the specific user has rarely been explored in the literature. First, we assume speakers can be grouped into smaller subsets based on their perceptual similarity. Then, we also postulate that a group-specific codec can focus on the group's speech characteristics to improve its perceptual quality and computational efficiency. To this end, we first develop a Siamese network that learns the speaker embeddings from the LibriSpeech dataset, which are then grouped into underlying speaker clusters. Finally, we retrain the LPCNet-based speech codec baselines on each of the speaker clusters. Subjective listening tests show that the proposed personalization scheme introduces model compression while maintaining speech quality. In other words, with the same model complexity, personalized codecs produce better speech quality."}
{"main_page": "https://arxiv.org/abs/2404.00793", "pdf": "https://arxiv.org/pdf/2404.00793", "title": "Learning the mechanisms of network growth", "authors": "Lourens Touwen, Doina Bucur, Remco van der Hofstad, Alessandro Garavaglia, Nelly Litvak", "subjects": "Social and Information Networks (cs.SI); Probability (math.PR); Machine Learning (stat.ML)", "abstract": "We propose a novel model-selection method for dynamic real-life networks. Our approach involves training a classifier on a large body of synthetic network data. The data is generated by simulating nine state-of-the-art random graph models for dynamic networks, with parameter range chosen to ensure exponential growth of the network size in time. We design a conceptually novel type of dynamic features that count new links received by a group of vertices in a particular time interval. The proposed features are easy to compute, analytically tractable, and interpretable. Our approach achieves a near-perfect classification of synthetic networks, exceeding the state-of-the-art by a large margin. Applying our classification method to real-world citation networks gives credibility to the claims in the literature that models with preferential attachment, fitness and aging fit real-world citation networks best, although sometimes, the predicted model does not involve vertex fitness."}
{"main_page": "https://arxiv.org/abs/2404.00795", "pdf": "https://arxiv.org/pdf/2404.00795", "title": "Towards Practical Requirement Analysis and Verification: A Case Study on  Software IP Components in Aerospace Embedded Systems", "authors": "Zhi Ma, Cheng Wen, Jie Su, Ming Zhao, Bin Yu, Xu Lu, Cong Tian", "subjects": "Software Engineering (cs.SE)", "abstract": "IP-based software design is a crucial research field that aims to improve efficiency and reliability by reusing complex software components known as intellectual property (IP) components. To ensure the reusability of these components, particularly in security-sensitive software systems, it is necessary to analyze the requirements and perform formal verification for each IP component. However, converting the requirements of IP components from natural language descriptions to temporal logic and subsequently conducting formal verification demands domain expertise and non-trivial manpower. This paper presents a case study on software IP components derived from aerospace embedded systems, with the objective of automating the requirement analysis and verification process. The study begins by employing Large Language Models to convert unstructured natural language into formal specifications. Subsequently, three distinct verification techniques are employed to ascertain whether the source code meets the extracted temporal logic properties. By doing so, five real-world IP components from the China Academy of Space Technology (CAST) have been successfully verified."}
{"main_page": "https://arxiv.org/abs/2404.00796", "pdf": "https://arxiv.org/pdf/2404.00796", "title": "CARL: Congestion-Aware Reinforcement Learning for Imitation-based  Perturbations in Mixed Traffic Control", "authors": "Bibek Poudel, Weizi Li", "subjects": "Robotics (cs.RO)", "abstract": "Human-driven vehicles (HVs) exhibit complex and diverse behaviors. Accurately modeling such behavior is crucial for validating Robot Vehicles (RVs) in simulation and realizing the potential of mixed traffic control. However, existing approaches like parameterized models and data-driven techniques struggle to capture the full complexity and diversity. To address this, in this work, we introduce CARL, a hybrid technique combining imitation learning for close proximity car-following and probabilistic sampling for larger headways. We also propose two classes of RL-based RVs: a safety RV focused on maximizing safety and an efficiency RV focused on maximizing efficiency. Our experiments show that the safety RV increases Time-to-Collision above the critical 4 second threshold and reduces Deceleration Rate to Avoid a Crash by up to 80%, while the efficiency RV achieves improvements in throughput of up to 49%. These results demonstrate the effectiveness of CARL in enhancing both safety and efficiency in mixed traffic."}
{"main_page": "https://arxiv.org/abs/2404.00797", "pdf": "https://arxiv.org/pdf/2404.00797", "title": "Metarobotics for Industry and Society: Vision, Technologies, and  Opportunities", "authors": "Eric Guiffo Kaigom", "subjects": "Robotics (cs.RO); Computers and Society (cs.CY); Machine Learning (cs.LG); Systems and Control (eess.SY)", "abstract": "Metarobotics aims to combine next generation wireless communication, multi-sense immersion, and collective intelligence to provide a pervasive, itinerant, and non-invasive access and interaction with distant robotized applications. Industry and society are expected to benefit from these functionalities. For instance, robot programmers will no longer travel worldwide to plan and test robot motions, even collaboratively. Instead, they will have a personalized access to robots and their environments from anywhere, thus spending more time with family and friends. Students enrolled in robotics courses will be taught under authentic industrial conditions in real-time. This paper describes objectives of Metarobotics in society, industry, and in-between. It identifies and surveys technologies likely to enable their completion and provides an architecture to put forward the interplay of key components of Metarobotics. Potentials for self-determination, self-efficacy, and work-life-flexibility in robotics-related applications in Society 5.0, Industry 4.0, and Industry 5.0 are outlined."}
{"main_page": "https://arxiv.org/abs/2404.00798", "pdf": "https://arxiv.org/pdf/2404.00798", "title": "On Difficulties of Attention Factorization through Shared Memory", "authors": "Uladzislau Yorsh, Martin Hole\u0148a, Ond\u0159ej Bojar, David Herel", "subjects": "Machine Learning (cs.LG)", "abstract": "Transformers have revolutionized deep learning in numerous fields, including natural language processing, computer vision, and audio processing. Their strength lies in their attention mechanism, which allows for the discovering of complex input relationships. However, this mechanism's quadratic time and memory complexity pose challenges for larger inputs. Researchers are now investigating models like Linear Unified Nested Attention (Luna) or Memory Augmented Transformer, which leverage external learnable memory to either reduce the attention computation complexity down to linear, or to propagate information between chunks in chunk-wise processing. Our findings challenge the conventional thinking on these models, revealing that interfacing with the memory directly through an attention operation is suboptimal, and that the performance may be considerably improved by filtering the input signal before communicating with memory."}
{"main_page": "https://arxiv.org/abs/2404.00801", "pdf": "https://arxiv.org/pdf/2404.00801", "title": "$R^2$-Tuning: Efficient Image-to-Video Transfer Learning for Video  Temporal Grounding", "authors": "Ye Liu, Jixuan He, Wanhua Li, Junsik Kim, Donglai Wei, Hanspeter Pfister, Chang Wen Chen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Video temporal grounding (VTG) is a fine-grained video understanding problem that aims to ground relevant clips in untrimmed videos given natural language queries. Most existing VTG models are built upon frame-wise final-layer CLIP features, aided by additional temporal backbones (e.g., SlowFast) with sophisticated temporal reasoning mechanisms. In this work, we claim that CLIP itself already shows great potential for fine-grained spatial-temporal modeling, as each layer offers distinct yet useful information under different granularity levels. Motivated by this, we propose Reversed Recurrent Tuning ($R^2$-Tuning), a parameter- and memory-efficient transfer learning framework for video temporal grounding. Our method learns a lightweight $R^2$ Block containing only 1.5% of the total parameters to perform progressive spatial-temporal modeling. Starting from the last layer of CLIP, $R^2$ Block recurrently aggregates spatial features from earlier layers, then refines temporal correlation conditioning on the given query, resulting in a coarse-to-fine scheme. $R^2$-Tuning achieves state-of-the-art performance across three VTG tasks (i.e., moment retrieval, highlight detection, and video summarization) on six public benchmarks (i.e., QVHighlights, Charades-STA, Ego4D-NLQ, TACoS, YouTube Highlights, and TVSum) even without the additional backbone, demonstrating the significance and effectiveness of the proposed scheme. Our code is available at https://github.com/yeliudev/R2-Tuning."}
{"main_page": "https://arxiv.org/abs/2404.00807", "pdf": "https://arxiv.org/pdf/2404.00807", "title": "GAMA-IR: Global Additive Multidimensional Averaging for Fast Image  Restoration", "authors": "Youssef Mansour, Reinhard Heckel", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Deep learning-based methods have shown remarkable success for various image restoration tasks such as denoising and deblurring. The current state-of-the-art networks are relatively deep and utilize (variants of) self attention mechanisms. Those networks are significantly slower than shallow convolutional networks, which however perform worse. In this paper, we introduce an image restoration network that is both fast and yields excellent image quality. The network is designed to minimize the latency and memory consumption when executed on a standard GPU, while maintaining state-of-the-art performance. The network is a simple shallow network with an efficient block that implements global additive multidimensional averaging operations. This block can capture global information and enable a large receptive field even when used in shallow networks with minimal computational overhead. Through extensive experiments and evaluations on diverse tasks, we demonstrate that our network achieves comparable or even superior results to existing state-of-the-art image restoration networks with less latency. For instance, we exceed the state-of-the-art result on real-world SIDD denoising by 0.11dB, while being 2 to 10 times faster."}
{"main_page": "https://arxiv.org/abs/2404.00808", "pdf": "https://arxiv.org/pdf/2404.00808", "title": "Using Explainable AI and Hierarchical Planning for Outreach with Robots", "authors": "Daksh Dobhal, Jayesh Nagpal, Rushang Karia, Pulkit Verma, Rashmeet Kaur Nayyar, Naman Shah, Siddharth Srivastava", "subjects": "Robotics (cs.RO)", "abstract": "Understanding how robots plan and execute tasks is crucial in today's world, where they are becoming more prevalent in our daily lives. However, teaching non-experts the complexities of robot planning can be challenging. This work presents an open-source platform that simplifies the process using a visual interface that completely abstracts the complex internals of hierarchical planning that robots use for performing task and motion planning. Using the principles developed in the field of explainable AI, this intuitive platform enables users to create plans for robots to complete tasks, and provides helpful hints and natural language explanations for errors. The platform also has a built-in simulator to demonstrate how robots execute submitted plans. This platform's efficacy was tested in a user study on university students with little to no computer science background. Our results show that this platform is highly effective in teaching novice users the intuitions of robot task planning."}
{"main_page": "https://arxiv.org/abs/2404.00810", "pdf": "https://arxiv.org/pdf/2404.00810", "title": "Off-the-grid regularisation for Poisson inverse problems", "authors": "Marta Lazzaretti, Claudio Estatico, Alejandro Melero Carrillo, Luca Calatroni", "subjects": "Numerical Analysis (math.NA); Optimization and Control (math.OC)", "abstract": "Off-the-grid regularisation has been extensively employed over the last decade in the context of ill-posed inverse problems formulated in the continuous setting of the space of Radon measures $\\mathcal{M}(\\mathcal{X})$. These approaches enjoy convexity and counteract the discretisation biases as well the numerical instabilities typical of their discrete counterparts. In the framework of sparse reconstruction of discrete point measures (sum of weighted Diracs), a Total Variation regularisation norm in $\\mathcal{M}(\\mathcal{X})$ is typically combined with an $L^2$ data term modelling additive Gaussian noise. To asses the framework of off-the-grid regularisation in the presence of signal-dependent Poisson noise, we consider in this work a variational model coupling the Total Variation regularisation with a Kullback-Leibler data term under a non-negativity constraint. Analytically, we study the optimality conditions of the composite functional and analyse its dual problem. Then, we consider an homotopy strategy to select an optimal regularisation parameter and use it within a Sliding Frank-Wolfe algorithm. Several numerical experiments on both 1D/2D simulated and real 3D fluorescent microscopy data are reported."}
{"main_page": "https://arxiv.org/abs/2404.00812", "pdf": "https://arxiv.org/pdf/2404.00812", "title": "No Complete Problem for Constant-Cost Randomized Communication", "authors": "Yuting Fang, Lianna Hambardzumyan, Nathaniel Harms, Pooya Hatami", "subjects": "Computational Complexity (cs.CC)", "abstract": "We prove that the class of communication problems with public-coin randomized constant-cost protocols, called $BPP^0$, does not contain a complete problem. In other words, there is no randomized constant-cost problem $Q \\in BPP^0$, such that all other problems $P \\in BPP^0$ can be computed by a constant-cost deterministic protocol with access to an oracle for $Q$. We also show that the $k$-Hamming Distance problems form an infinite hierarchy within $BPP^0$. Previously, it was known only that Equality is not complete for $BPP^0$. We introduce a new technique, using Ramsey theory, that can prove lower bounds against arbitrary oracles in $BPP^0$, and more generally, we show that $k$-Hamming Distance matrices cannot be expressed as a Boolean combination of any constant number of matrices which forbid large Greater-Than subproblems."}
{"main_page": "https://arxiv.org/abs/2404.00814", "pdf": "https://arxiv.org/pdf/2404.00814", "title": "Imposing Exact Safety Specifications in Neural Reachable Tubes", "authors": "Aditya Singh, Zeyuan Feng, Somil Bansal", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "Hamilton-Jacobi (HJ) reachability analysis is a verification tool that provides safety and performance guarantees for autonomous systems. It is widely adopted because of its ability to handle nonlinear dynamical systems with bounded adversarial disturbances and constraints on states and inputs. However, it involves solving a PDE to compute a safety value function, whose computational and memory complexity scales exponentially with the state dimension, making its direct usage in large-scale systems intractable. Recently, a learning-based approach called DeepReach, has been proposed to approximate high-dimensional reachable tubes using neural networks. While DeepReach has been shown to be effective, the accuracy of the learned solution decreases with the increase in system complexity. One of the reasons for this degradation is the inexact imposition of safety constraints during the learning process, which corresponds to the PDE's boundary conditions. Specifically, DeepReach imposes boundary conditions as soft constraints in the loss function, which leaves room for error during the value function learning. Moreover, one needs to carefully adjust the relative contributions from the imposition of boundary conditions and the imposition of the PDE in the loss function. This, in turn, induces errors in the overall learned solution. In this work, we propose a variant of DeepReach that exactly imposes safety constraints during the learning process by restructuring the overall value function as a weighted sum of the boundary condition and neural network output. This eliminates the need for a boundary loss during training, thus bypassing the need for loss adjustment. We demonstrate the efficacy of the proposed approach in significantly improving the accuracy of learned solutions for challenging high-dimensional reachability tasks, such as rocket-landing and multivehicle collision-avoidance problems."}
{"main_page": "https://arxiv.org/abs/2404.00815", "pdf": "https://arxiv.org/pdf/2404.00815", "title": "Towards Realistic Scene Generation with LiDAR Diffusion Models", "authors": "Haoxi Ran, Vitor Guizilini, Yue Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "abstract": "Diffusion models (DMs) excel in photo-realistic image synthesis, but their adaptation to LiDAR scene generation poses a substantial hurdle. This is primarily because DMs operating in the point space struggle to preserve the curve-like patterns and 3D geometry of LiDAR scenes, which consumes much of their representation power. In this paper, we propose LiDAR Diffusion Models (LiDMs) to generate LiDAR-realistic scenes from a latent space tailored to capture the realism of LiDAR scenes by incorporating geometric priors into the learning pipeline. Our method targets three major desiderata: pattern realism, geometry realism, and object realism. Specifically, we introduce curve-wise compression to simulate real-world LiDAR patterns, point-wise coordinate supervision to learn scene geometry, and patch-wise encoding for a full 3D object context. With these three core designs, our method achieves competitive performance on unconditional LiDAR generation in 64-beam scenario and state of the art on conditional LiDAR generation, while maintaining high efficiency compared to point-based DMs (up to 107$\\times$ faster). Furthermore, by compressing LiDAR scenes into a latent space, we enable the controllability of DMs with various conditions such as semantic maps, camera views, and text prompts. Our code and pretrained weights are available at https://github.com/hancyran/LiDAR-Diffusion."}
{"main_page": "https://arxiv.org/abs/2404.00816", "pdf": "https://arxiv.org/pdf/2404.00816", "title": "HeteroMILE: a Multi-Level Graph Representation Learning Framework for  Heterogeneous Graphs", "authors": "Yue Zhang, Yuntian He, Saket Gurukar, Srinivasan Parthasarathy", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Heterogeneous graphs are ubiquitous in real-world applications because they can represent various relationships between different types of entities. Therefore, learning embeddings in such graphs is a critical problem in graph machine learning. However, existing solutions for this problem fail to scale to large heterogeneous graphs due to their high computational complexity. To address this issue, we propose a Multi-Level Embedding framework of nodes on a heterogeneous graph (HeteroMILE) - a generic methodology that allows contemporary graph embedding methods to scale to large graphs. HeteroMILE repeatedly coarsens the large sized graph into a smaller size while preserving the backbone structure of the graph before embedding it, effectively reducing the computational cost by avoiding time-consuming processing operations. It then refines the coarsened embedding to the original graph using a heterogeneous graph convolution neural network. We evaluate our approach using several popular heterogeneous graph datasets. The experimental results show that HeteroMILE can substantially reduce computational time (approximately 20x speedup) and generate an embedding of better quality for link prediction and node classification."}
{"main_page": "https://arxiv.org/abs/2404.00826", "pdf": "https://arxiv.org/pdf/2404.00826", "title": "Extracting Social Determinants of Health from Pediatric Patient Notes  Using Large Language Models: Novel Corpus and Methods", "authors": "Yujuan Fu, Giridhar Kaushik Ramachandran, Nicholas J Dobbins, Namu Park, Michael Leu, Abby R. Rosenberg, Kevin Lybarger, Fei Xia, Ozlem Uzuner, Meliha Yetisgen", "subjects": "Computation and Language (cs.CL)", "abstract": "Social determinants of health (SDoH) play a critical role in shaping health outcomes, particularly in pediatric populations where interventions can have long-term implications. SDoH are frequently studied in the Electronic Health Record (EHR), which provides a rich repository for diverse patient data. In this work, we present a novel annotated corpus, the Pediatric Social History Annotation Corpus (PedSHAC), and evaluate the automatic extraction of detailed SDoH representations using fine-tuned and in-context learning methods with Large Language Models (LLMs). PedSHAC comprises annotated social history sections from 1,260 clinical notes obtained from pediatric patients within the University of Washington (UW) hospital system. Employing an event-based annotation scheme, PedSHAC captures ten distinct health determinants to encompass living and economic stability, prior trauma, education access, substance use history, and mental health with an overall annotator agreement of 81.9 F1. Our proposed fine-tuning LLM-based extractors achieve high performance at 78.4 F1 for event arguments. In-context learning approaches with GPT-4 demonstrate promise for reliable SDoH extraction with limited annotated examples, with extraction performance at 82.3 F1 for event triggers."}
{"main_page": "https://arxiv.org/abs/2404.00828", "pdf": "https://arxiv.org/pdf/2404.00828", "title": "PID Control-Based Self-Healing to Improve the Robustness of Large  Language Models", "authors": "Zhuotong Chen, Zihu Wang, Yifan Yang, Qianxiao Li, Zheng Zhang", "subjects": "Computation and Language (cs.CL)", "abstract": "Despite the effectiveness of deep neural networks in numerous natural language processing applications, recent findings have exposed the vulnerability of these language models when minor perturbations are introduced. While appearing semantically indistinguishable to humans, these perturbations can significantly reduce the performance of well-trained language models, raising concerns about the reliability of deploying them in safe-critical situations. In this work, we construct a computationally efficient self-healing process to correct undesired model behavior during online inference when perturbations are applied to input data. This is formulated as a trajectory optimization problem in which the internal states of the neural network layers are automatically corrected using a PID (Proportional-Integral-Derivative) control mechanism. The P controller targets immediate state adjustments, while the I and D controllers consider past states and future dynamical trends, respectively. We leverage the geometrical properties of the training data to design effective linear PID controllers. This approach reduces the computational cost to that of using just the P controller, instead of the full PID control. Further, we introduce an analytical method for approximating the optimal control solutions, enhancing the real-time inference capabilities of this controlled system. Moreover, we conduct a theoretical error analysis of the analytic solution in a simplified setting. The proposed PID control-based self-healing is a low cost framework that improves the robustness of pre-trained large language models, whether standard or robustly trained, against a wide range of perturbations. A detailed implementation can be found in:https://github.com/zhuotongchen/PID-Control-Based-Self-Healing-to-Improve-the-Robustness-of-Large-Language-Models."}
{"main_page": "https://arxiv.org/abs/2404.00829", "pdf": "https://arxiv.org/pdf/2404.00829", "title": "Returning to the Start: Generating Narratives with Related Endpoints", "authors": "Anneliese Brei, Chao Zhao, Snigdha Chaturvedi", "subjects": "Computation and Language (cs.CL)", "abstract": "Human writers often bookend their writing with ending sentences that relate back to the beginning sentences in order to compose a satisfying narrative that \"closes the loop.\" Motivated by this observation, we propose RENarGen, a controllable story-generation paradigm that generates narratives by ensuring the first and last sentences are related and then infilling the middle sentences. Our contributions include an initial exploration of how various methods of bookending from Narratology affect language modeling for stories. Automatic and human evaluations indicate RENarGen produces better stories with more narrative closure than current autoregressive models."}
{"main_page": "https://arxiv.org/abs/2404.00830", "pdf": "https://arxiv.org/pdf/2404.00830", "title": "2D Ego-Motion with Yaw Estimation using Only mmWave Radars via Two-Way  weighted ICP", "authors": "Hojune Kim, Hyesu Jang, Ayoung Kim", "subjects": "Robotics (cs.RO)", "abstract": "The interest in single-chip mmWave Radar is driven by their compact form factor, cost-effectiveness, and robustness under harsh environmental conditions. Despite its promising attributes, the principal limitation of mmWave radar lies in its capacity for autonomous yaw rate estimation. Conventional solutions have often resorted to integrating inertial measurement unit (IMU) or deploying multiple radar units to circumvent this shortcoming. This paper introduces an innovative methodology for two-dimensional ego-motion estimation, focusing on yaw rate deduction, utilizing solely mmWave radar sensors. By applying a weighted Iterated Closest Point (ICP) algorithm to register processed points derived from heatmap data, our method facilitates 2D ego-motion estimation devoid of prior information. Through experimental validation, we verified the effectiveness and promise of our technique for ego-motion estimation using exclusively radar data."}
{"main_page": "https://arxiv.org/abs/2404.00831", "pdf": "https://arxiv.org/pdf/2404.00831", "title": "Settling the Communication Complexity of VCG-based Mechanisms for all  Approximation Guarantees", "authors": "Frederick V. Qiu, S. Matthew Weinberg", "subjects": "Computer Science and Game Theory (cs.GT)", "abstract": "We consider truthful combinatorial auctions with items $M = [m]$ for sale to $n$ bidders, where each bidder $i$ has a private monotone valuation $v_i : 2^M \\to R_+$. Among truthful mechanisms, maximal-in-range (MIR) mechanisms achieve the best-known approximation guarantees among all poly-communication deterministic truthful mechanisms in all previously-studied settings. Our work settles the communication necessary to achieve any approximation guarantee via an MIR mechanism. Specifically: Let MIRsubmod$(m,k)$ denote the best approximation guarantee achievable by an MIR mechanism using $2^k$ communication between bidders with submodular valuations over $m$ items. Then for all $k = \\Omega(\\log(m))$, MIRsubmod$(m,k) = \\Omega(\\sqrt{m/(k\\log(m/k))})$. When $k = \\Theta(\\log(m))$, this improves the previous best lower bound for poly-comm. MIR mechanisms from $\\Omega(m^{1/3}/\\log^{2/3}(m))$ to $\\Omega(\\sqrt{m}/\\log(m))$. We also have MIRsubmod$(m,k) = O(\\sqrt{m/k})$. Moreover, our mechanism is optimal w.r.t. the value query and succinct representation models. When $k = \\Theta(\\log(m))$, this improves the previous best approximation guarantee for poly-comm. MIR mechanisms from $O(\\sqrt{m})$ to $O(\\sqrt{m/\\log(m)})$. Let also MIRgen$(m,k)$ denote the best approximation guarantee achievable by an MIR mechanism using $2^k$ communication between bidders with general valuations over $m$ items. Then for all $k = \\Omega(\\log(m))$, MIRgen$(m,k) = \\Omega(m/k)$. When $k = \\Theta(\\log(m))$, this improves the previous best lower bound for poly-comm. MIR mechanisms from $\\Omega(m/\\log^2(m))$ to $\\Omega(m/\\log(m))$. We also have MIRgen$(m,k) = O(m/k)$. Moreover, our mechanism is optimal w.r.t. the value query and succinct representation models. When $k = \\Theta(\\log(m))$, this improves the previous best approximation guarantee for poly-comm. MIR mechanisms from $O(m/\\sqrt{\\log(m)})$ to $O(m/\\log(m))$."}
{"main_page": "https://arxiv.org/abs/2404.00834", "pdf": "https://arxiv.org/pdf/2404.00834", "title": "Towards Robust Event-guided Low-Light Image Enhancement: A Large-Scale  Real-World Event-Image Dataset and Novel Approach", "authors": "Guoqiang Liang, Kanghao Chen, Hangyu Li, Yunfan Lu, Lin Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Event camera has recently received much attention for low-light image enhancement (LIE) thanks to their distinct advantages, such as high dynamic range. However, current research is prohibitively restricted by the lack of large-scale, real-world, and spatial-temporally aligned event-image datasets. To this end, we propose a real-world (indoor and outdoor) dataset comprising over 30K pairs of images and events under both low and normal illumination conditions. To achieve this, we utilize a robotic arm that traces a consistent non-linear trajectory to curate the dataset with spatial alignment precision under 0.03mm. We then introduce a matching alignment strategy, rendering 90% of our dataset with errors less than 0.01s. Based on the dataset, we propose a novel event-guided LIE approach, called EvLight, towards robust performance in real-world low-light scenes. Specifically, we first design the multi-scale holistic fusion branch to extract holistic structural and textural information from both events and images. To ensure robustness against variations in the regional illumination and noise, we then introduce a Signal-to-Noise-Ratio (SNR)-guided regional feature selection to selectively fuse features of images from regions with high SNR and enhance those with low SNR by extracting regional structure information from events. Extensive experiments on our dataset and the synthetic SDSD dataset demonstrate our EvLight significantly surpasses the frame-based methods. Code and datasets are available at https://vlislab22.github.io/eg-lowlight/."}
{"main_page": "https://arxiv.org/abs/2404.00836", "pdf": "https://arxiv.org/pdf/2404.00836", "title": "Rethinking Resource Management in Edge Learning: A Joint Pre-training  and Fine-tuning Design Paradigm", "authors": "Zhonghao Lyu, Yuchen Li, Guangxu Zhu, Jie Xu, H. Vincent Poor, Shuguang Cui", "subjects": "Information Theory (cs.IT); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "abstract": "In some applications, edge learning is experiencing a shift in focusing from conventional learning from scratch to new two-stage learning unifying pre-training and task-specific fine-tuning. This paper considers the problem of joint communication and computation resource management in a two-stage edge learning system. In this system, model pre-training is first conducted at an edge server via centralized learning on local pre-stored general data, and then task-specific fine-tuning is performed at edge devices based on the pre-trained model via federated edge learning. For the two-stage learning model, we first analyze the convergence behavior (in terms of the average squared gradient norm bound), which characterizes the impacts of various system parameters such as the number of learning rounds and batch sizes in the two stages on the convergence rate. Based on our analytical results, we then propose a joint communication and computation resource management design to minimize an average squared gradient norm bound, subject to constraints on the transmit power, overall system energy consumption, and training delay. The decision variables include the number of learning rounds, batch sizes, clock frequencies, and transmit power control for both pre-training and fine-tuning stages. Finally, numerical results are provided to evaluate the effectiveness of our proposed design. It is shown that the proposed joint resource management over the pre-training and fine-tuning stages well balances the system performance trade-off among the training accuracy, delay, and energy consumption. The proposed design is also shown to effectively leverage the inherent trade-off between pre-training and fine-tuning, which arises from the differences in data distribution between pre-stored general data versus real-time task-specific data, thus efficiently optimizing overall system performance."}
{"main_page": "https://arxiv.org/abs/2404.00838", "pdf": "https://arxiv.org/pdf/2404.00838", "title": "3MOS: Multi-sources, Multi-resolutions, and Multi-scenes dataset for  Optical-SAR image matching", "authors": "Yibin Ye, Xichao Teng, Shuo Chen, Yijie Bian, Tao Tan, Zhang Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Optical-SAR image matching is a fundamental task for image fusion and visual navigation. However, all large-scale open SAR dataset for methods development are collected from single platform, resulting in limited satellite types and spatial resolutions. Since images captured by different sensors vary significantly in both geometric and radiometric appearance, existing methods may fail to match corresponding regions containing the same content. Besides, most of existing datasets have not been categorized based on the characteristics of different scenes. To encourage the design of more general multi-modal image matching methods, we introduce a large-scale Multi-sources,Multi-resolutions, and Multi-scenes dataset for Optical-SAR image matching(3MOS). It consists of 155K optical-SAR image pairs, including SAR data from six commercial satellites, with resolutions ranging from 1.25m to 12.5m. The data has been classified into eight scenes including urban, rural, plains, hills, mountains, water, desert, and frozen earth. Extensively experiments show that none of state-of-the-art methods achieve consistently superior performance across different sources, resolutions and scenes. In addition, the distribution of data has a substantial impact on the matching capability of deep learning models, this proposes the domain adaptation challenge in optical-SAR image matching. Our data and code will be available at:https://github.com/3M-OS/3MOS."}
{"main_page": "https://arxiv.org/abs/2404.00842", "pdf": "https://arxiv.org/pdf/2404.00842", "title": "An N-Point Linear Solver for Line and Motion Estimation with Event  Cameras", "authors": "Ling Gao, Daniel Gehrig, Hang Su, Davide Scaramuzza, Laurent Kneip", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Event cameras respond primarily to edges--formed by strong gradients--and are thus particularly well-suited for line-based motion estimation. Recent work has shown that events generated by a single line each satisfy a polynomial constraint which describes a manifold in the space-time volume. Multiple such constraints can be solved simultaneously to recover the partial linear velocity and line parameters. In this work, we show that, with a suitable line parametrization, this system of constraints is actually linear in the unknowns, which allows us to design a novel linear solver. Unlike existing solvers, our linear solver (i) is fast and numerically stable since it does not rely on expensive root finding, (ii) can solve both minimal and overdetermined systems with more than 5 events, and (iii) admits the characterization of all degenerate cases and multiple solutions. The found line parameters are singularity-free and have a fixed scale, which eliminates the need for auxiliary constraints typically encountered in previous work. To recover the full linear camera velocity we fuse observations from multiple lines with a novel velocity averaging scheme that relies on a geometrically-motivated residual, and thus solves the problem more efficiently than previous schemes which minimize an algebraic residual. Extensive experiments in synthetic and real-world settings demonstrate that our method surpasses the previous work in numerical stability, and operates over 600 times faster."}
{"main_page": "https://arxiv.org/abs/2404.00846", "pdf": "https://arxiv.org/pdf/2404.00846", "title": "Transfer Learning with Point Transformers", "authors": "Kartik Gupta, Rahul Vippala, Sahima Srivastava", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Point Transformers are near state-of-the-art models for classification, segmentation, and detection tasks on Point Cloud data. They utilize a self attention based mechanism to model large range spatial dependencies between multiple point sets. In this project we explore two things: classification performance of these attention based networks on ModelNet10 dataset and then, we use the trained model to classify 3D MNIST dataset after finetuning. We also train the model from scratch on 3D MNIST dataset to compare the performance of finetuned and from-scratch model on the MNIST dataset. We observe that since the two datasets have a large difference in the degree of the distributions, transfer learned models do not outperform the from-scratch models in this case. Although we do expect transfer learned models to converge faster since they already know the lower level edges, corners, etc features from the ModelNet10 dataset."}
{"main_page": "https://arxiv.org/abs/2404.00847", "pdf": "https://arxiv.org/pdf/2404.00847", "title": "Collaborative Learning of Anomalies with Privacy (CLAP) for Unsupervised  Video Anomaly Detection: A New Baseline", "authors": "Anas Al-lahham, Muhammad Zaigham Zaheer, Nurbek Tastan, Karthik Nandakumar", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Unsupervised (US) video anomaly detection (VAD) in surveillance applications is gaining more popularity recently due to its practical real-world applications. As surveillance videos are privacy sensitive and the availability of large-scale video data may enable better US-VAD systems, collaborative learning can be highly rewarding in this setting. However, due to the extremely challenging nature of the US-VAD task, where learning is carried out without any annotations, privacy-preserving collaborative learning of US-VAD systems has not been studied yet. In this paper, we propose a new baseline for anomaly detection capable of localizing anomalous events in complex surveillance videos in a fully unsupervised fashion without any labels on a privacy-preserving participant-based distributed training configuration. Additionally, we propose three new evaluation protocols to benchmark anomaly detection approaches on various scenarios of collaborations and data availability. Based on these protocols, we modify existing VAD datasets to extensively evaluate our approach as well as existing US SOTA methods on two large-scale datasets including UCF-Crime and XD-Violence. All proposed evaluation protocols, dataset splits, and codes are available here: https://github.com/AnasEmad11/CLAP"}
{"main_page": "https://arxiv.org/abs/2404.00848", "pdf": "https://arxiv.org/pdf/2404.00848", "title": "Predictive Performance Comparison of Decision Policies Under Confounding", "authors": "Luke Guerdan, Amanda Coston, Kenneth Holstein, Zhiwei Steven Wu", "subjects": "Machine Learning (cs.LG); Computers and Society (cs.CY); Methodology (stat.ME)", "abstract": "Predictive models are often introduced to decision-making tasks under the rationale that they improve performance over an existing decision-making policy. However, it is challenging to compare predictive performance against an existing decision-making policy that is generally under-specified and dependent on unobservable factors. These sources of uncertainty are often addressed in practice by making strong assumptions about the data-generating mechanism. In this work, we propose a method to compare the predictive performance of decision policies under a variety of modern identification approaches from the causal inference and off-policy evaluation literatures (e.g., instrumental variable, marginal sensitivity model, proximal variable). Key to our method is the insight that there are regions of uncertainty that we can safely ignore in the policy comparison. We develop a practical approach for finite-sample estimation of regret intervals under no assumptions on the parametric form of the status quo policy. We verify our framework theoretically and via synthetic data experiments. We conclude with a real-world application using our framework to support a pre-deployment evaluation of a proposed modification to a healthcare enrollment policy."}
{"main_page": "https://arxiv.org/abs/2404.00849", "pdf": "https://arxiv.org/pdf/2404.00849", "title": "Generating Content for HDR Deghosting from Frequency View", "authors": "Tao Hu, Qingsen Yan, Yuankai Qi, Yanning Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recovering ghost-free High Dynamic Range (HDR) images from multiple Low Dynamic Range (LDR) images becomes challenging when the LDR images exhibit saturation and significant motion. Recent Diffusion Models (DMs) have been introduced in HDR imaging field, demonstrating promising performance, particularly in achieving visually perceptible results compared to previous DNN-based methods. However, DMs require extensive iterations with large models to estimate entire images, resulting in inefficiency that hinders their practical application. To address this challenge, we propose the Low-Frequency aware Diffusion (LF-Diff) model for ghost-free HDR imaging. The key idea of LF-Diff is implementing the DMs in a highly compacted latent space and integrating it into a regression-based model to enhance the details of reconstructed images. Specifically, as low-frequency information is closely related to human visual perception we propose to utilize DMs to create compact low-frequency priors for the reconstruction process. In addition, to take full advantage of the above low-frequency priors, the Dynamic HDR Reconstruction Network (DHRNet) is carried out in a regression-based manner to obtain final HDR images. Extensive experiments conducted on synthetic and real-world benchmark datasets demonstrate that our LF-Diff performs favorably against several state-of-the-art methods and is 10$\\times$ faster than previous DM-based methods."}
{"main_page": "https://arxiv.org/abs/2404.00850", "pdf": "https://arxiv.org/pdf/2404.00850", "title": "Delay-Induced Watermarking for Detection of Replay Attacks in Linear  Systems", "authors": "Christoforos Somarakis, Raman Goyal, Erfaun Noorani, Shantanu Rane", "subjects": "Systems and Control (eess.SY); Cryptography and Security (cs.CR)", "abstract": "A state-feedback watermarking signal design for the detection of replay attacks in linear systems is proposed. The control input is augmented with a random time-delayed term of the system state estimate, in order to secure the system against attacks of replay type. We outline the basic analysis of the closed-loop response of the state-feedback watermarking in a LQG controlled system. Our theoretical results are applied on a temperature process control example. While the proposed secure control scheme requires very involved analysis, it, nevertheless, holds promise of being superior to conventional, feed-forward, watermarking schemes, in both its ability to detect attacks as well as the secured system performance."}
{"main_page": "https://arxiv.org/abs/2404.00851", "pdf": "https://arxiv.org/pdf/2404.00851", "title": "Prompt Learning via Meta-Regularization", "authors": "Jinyoung Park, Juyeon Ko, Hyunwoo J. Kim", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Pre-trained vision-language models have shown impressive success on various computer vision tasks with their zero-shot generalizability. Recently, prompt learning approaches have been explored to efficiently and effectively adapt the vision-language models to a variety of downstream tasks. However, most existing prompt learning methods suffer from task overfitting since the general knowledge of the pre-trained vision language models is forgotten while the prompts are finetuned on a small data set from a specific target task. To address this issue, we propose a Prompt Meta-Regularization (ProMetaR) to improve the generalizability of prompt learning for vision-language models. Specifically, ProMetaR meta-learns both the regularizer and the soft prompts to harness the task-specific knowledge from the downstream tasks and task-agnostic general knowledge from the vision-language models. Further, ProMetaR augments the task to generate multiple virtual tasks to alleviate the meta-overfitting. In addition, we provide the analysis to comprehend how ProMetaR improves the generalizability of prompt tuning in the perspective of the gradient alignment. Our extensive experiments demonstrate that our ProMetaR improves the generalizability of conventional prompt learning methods under base-to-base/base-to-new and domain generalization settings. The code of ProMetaR is available at https://github.com/mlvlab/ProMetaR."}
{"main_page": "https://arxiv.org/abs/2404.00852", "pdf": "https://arxiv.org/pdf/2404.00852", "title": "Ensemble Learning for Vietnamese Scene Text Spotting in Urban  Environments", "authors": "Hieu Nguyen, Cong-Hoang Ta, Phuong-Thuy Le-Nguyen, Minh-Triet Tran, Trung-Nghia Le", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "This paper presents a simple yet efficient ensemble learning framework for Vietnamese scene text spotting. Leveraging the power of ensemble learning, which combines multiple models to yield more accurate predictions, our approach aims to significantly enhance the performance of scene text spotting in challenging urban settings. Through experimental evaluations on the VinText dataset, our proposed method achieves a significant improvement in accuracy compared to existing methods with an impressive accuracy of 5%. These results unequivocally demonstrate the efficacy of ensemble learning in the context of Vietnamese scene text spotting in urban environments, highlighting its potential for real world applications, such as text detection and recognition in urban signage, advertisements, and various text-rich urban scenes."}
{"main_page": "https://arxiv.org/abs/2404.00855", "pdf": "https://arxiv.org/pdf/2404.00855", "title": "TSOM: Small Object Motion Detection Neural Network Inspired by Avian  Visual Circuit", "authors": "Pignge Hu, Xiaoteng Zhang, Mengmeng Li, Yingjie Zhu, Li Shi", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Detecting small moving objects in complex backgrounds from an overhead perspective is a highly challenging task for machine vision systems. As an inspiration from nature, the avian visual system is capable of processing motion information in various complex aerial scenes, and its Retina-OT-Rt visual circuit is highly sensitive to capturing the motion information of small objects from high altitudes. However, more needs to be done on small object motion detection algorithms based on the avian visual system. In this paper, we conducted mathematical modeling based on extensive studies of the biological mechanisms of the Retina-OT-Rt visual circuit. Based on this, we proposed a novel tectum small object motion detection neural network (TSOM). The neural network includes the retina, SGC dendritic, SGC Soma, and Rt layers, each layer corresponding to neurons in the visual pathway. The Retina layer is responsible for accurately projecting input content, the SGC dendritic layer perceives and encodes spatial-temporal information, the SGC Soma layer computes complex motion information and extracts small objects, and the Rt layer integrates and decodes motion information from multiple directions to determine the position of small objects. Extensive experiments on pigeon neurophysiological experiments and image sequence data showed that the TSOM is biologically interpretable and effective in extracting reliable small object motion features from complex high-altitude backgrounds."}
{"main_page": "https://arxiv.org/abs/2404.00856", "pdf": "https://arxiv.org/pdf/2404.00856", "title": "Removing Speaker Information from Speech Representation using  Variable-Length Soft Pooling", "authors": "Injune Hwang, Kyogu Lee", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)", "abstract": "Recently, there have been efforts to encode the linguistic information of speech using a self-supervised framework for speech synthesis. However, predicting representations from surrounding representations can inadvertently entangle speaker information in the speech representation. This paper aims to remove speaker information by exploiting the structured nature of speech, composed of discrete units like phonemes with clear boundaries. A neural network predicts these boundaries, enabling variable-length pooling for event-based representation extraction instead of fixed-rate methods. The boundary predictor outputs a probability for the boundary between 0 and 1, making pooling soft. The model is trained to minimize the difference with the pooled representation of the data augmented by time-stretch and pitch-shift. To confirm that the learned representation includes contents information but is independent of speaker information, the model was evaluated with libri-light's phonetic ABX task and SUPERB's speaker identification task."}
{"main_page": "https://arxiv.org/abs/2404.00857", "pdf": "https://arxiv.org/pdf/2404.00857", "title": "Meta Episodic learning with Dynamic Task Sampling for CLIP-based Point  Cloud Classification", "authors": "Shuvozit Ghose, Yang Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Point cloud classification refers to the process of assigning semantic labels or categories to individual points within a point cloud data structure. Recent works have explored the extension of pre-trained CLIP to 3D recognition. In this direction, CLIP-based point cloud models like PointCLIP, CLIP2Point have become state-of-the-art methods in the few-shot setup. Although these methods show promising performance for some classes like airplanes, desks, guitars, etc, the performance for some classes like the cup, flower pot, sink, nightstand, etc is still far from satisfactory. This is due to the fact that the adapter of CLIP-based models is trained using randomly sampled N-way K-shot data in the standard supervised learning setup. In this paper, we propose a novel meta-episodic learning framework for CLIP-based point cloud classification, addressing the challenges of limited training examples and sampling unknown classes. Additionally, we introduce dynamic task sampling within the episode based on performance memory. This sampling strategy effectively addresses the challenge of sampling unknown classes, ensuring that the model learns from a diverse range of classes and promotes the exploration of underrepresented categories. By dynamically updating the performance memory, we adaptively prioritize the sampling of classes based on their performance, enhancing the model's ability to handle challenging and real-world scenarios. Experiments show an average performance gain of 3-6\\% on ModelNet40 and ScanobjectNN datasets in a few-shot setup."}
{"main_page": "https://arxiv.org/abs/2404.00859", "pdf": "https://arxiv.org/pdf/2404.00859", "title": "Do language models plan ahead for future tokens?", "authors": "Wilson Wu, John X. Morris, Lionel Levine", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Do transformers \"think ahead\" during inference at a given position? It is known transformers prepare information in the hidden states of the forward pass at $t$ that is then used in future forward passes $t+\\tau$. We posit two explanations for this phenomenon: pre-caching, in which off-diagonal gradient terms present in training result in the model computing features at $t$ irrelevant to the present inference task but useful for the future, and breadcrumbs, in which features most relevant to time step $t$ are already the same as those that would most benefit inference at time $t+\\tau$. We test these hypotheses by training language models without propagating gradients to past timesteps, a scheme we formalize as myopic training. In a synthetic data setting, we find clear evidence for pre-caching. In the autoregressive language modeling setting, our experiments are more suggestive of the breadcrumbs hypothesis."}
{"main_page": "https://arxiv.org/abs/2404.00860", "pdf": "https://arxiv.org/pdf/2404.00860", "title": "Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text  Guidance", "authors": "Giung Nam, Byeongho Heo, Juho Lee", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Large-scale contrastive vision-language pre-trained models provide the zero-shot model achieving competitive performance across a range of image classification tasks without requiring training on downstream data. Recent works have confirmed that while additional fine-tuning of the zero-shot model on the reference data results in enhanced downstream performance, it compromises the model's robustness against distribution shifts. Our investigation begins by examining the conditions required to achieve the goals of robust fine-tuning, employing descriptions based on feature distortion theory and joint energy-based models. Subsequently, we propose a novel robust fine-tuning algorithm, Lipsum-FT, that effectively utilizes the language modeling aspect of the vision-language pre-trained models. Extensive experiments conducted on distribution shift scenarios in DomainNet and ImageNet confirm the superiority of our proposed Lipsum-FT approach over existing robust fine-tuning methods."}
{"main_page": "https://arxiv.org/abs/2404.00862", "pdf": "https://arxiv.org/pdf/2404.00862", "title": "Bailong: Bilingual Transfer Learning based on QLoRA and Zip-tie  Embedding", "authors": "Lung-Chuan Chen, Zong-Ru Li", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Large language models (LLMs) have demonstrated exceptional performance in various NLP applications. However, the majority of existing open-source LLMs are pre-trained primarily on English data and little part of other languages. This deficiency in multilingual training data results in suboptimal performance when applied to languages with fewer available resources. Furthermore, enhancing the performance of LLMs on low-resource languages by full-parameter fine-tuning with additional data requires substantial computational resources, posing computational barriers for research organizations and individual researchers. Consequently, several techniques such as parameter-efficient tuning and advanced embedding initialization have been proposed to address these challenges. In this work, we combine them to facilitate cross-lingual transfer on English-dominated open-source LLM. To effectively enhance the model's proficiency in Traditional Chinese, we conduct secondary pre-training on Llama 2 7B with Traditional Chinese data by leveraging QLoRA and our proposed zip-tie embedding initialization. The resulting model called Bailong, which stands for Bilingual trAnsfer learnIng based on qLOra and zip-tie embeddiNG. We present Bailong-instruct 7B, a fine-tuned version of Bailong 7B optimized for multi-turn dialogue scenarios. Recognizing the inadequacy of benchmark datasets in Traditional Chinese, we further introduce Bailong-bench to assess the alignment of models with human preferences and the capability to follow instructions in both Traditional Chinese and English tasks. In our evaluation, Bailong-instruct 7B exhibits competitive performance on Bailong-bench and other benchmark datasets when compared to other open-source models of similar or even larger parameter sizes. Bailong-instruct 7B and Bailong-bench are publicly available with the aim of empowering the community to build upon our efforts."}
{"main_page": "https://arxiv.org/abs/2404.00869", "pdf": "https://arxiv.org/pdf/2404.00869", "title": "Towards Automated Generation of Smart Grid Cyber Range for Cybersecurity  Experiments and Training", "authors": "Daisuke Mashima, Muhammad M. Roomi, Bennet Ng, Zbigniew Kalbarczyk, S.M. Suhail Hussain, Ee-chien Chang", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Assurance of cybersecurity is crucial to ensure dependability and resilience of smart power grid systems. In order to evaluate the impact of potential cyber attacks, to assess deployability and effectiveness of cybersecurity measures, and to enable hands-on exercise and training of personals, an interactive, virtual environment that emulates the behaviour of a smart grid system, namely smart grid cyber range, has been demanded by industry players as well as academia. A smart grid cyber range is typically implemented as a combination of cyber system emulation, which allows interactivity, and physical system (i.e., power grid) simulation that are tightly coupled for consistent cyber and physical behaviours. However, its design and implementation require intensive expertise and efforts in cyber and physical aspects of smart power systems as well as software/system engineering. While many industry players, including power grid operators, device vendors, research and education sectors are interested, availability of the smart grid cyber range is limited to a small number of research labs. To address this challenge, we have developed a framework for modelling a smart grid cyber range using an XML-based language, called SG-ML, and for \"compiling\" the model into an operational cyber range with minimal engineering efforts. The modelling language includes standardized schema from IEC 61850 and IEC 61131, which allows industry players to utilize their existing configurations. The SG-ML framework aims at making a smart grid cyber range available to broader user bases to facilitate cybersecurity R\\&D and hands-on exercises."}
{"main_page": "https://arxiv.org/abs/2404.00872", "pdf": "https://arxiv.org/pdf/2404.00872", "title": "Performance Evaluation of RIS-Assisted Spatial Modulation for Downlink  Transmission", "authors": "Xusheng Zhu, Qingqing Wu, Wen Chen", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "This paper explores the performance of reconfigurable intelligent surface (RIS) assisted spatial modulation (SM) downlink communication systems, focusing on the average bit error probability (ABEP). Notably, in scenarios with a large number of reflecting units, the composite channel can be approximated by a Gaussian distribution using the central limit theorem. The receiver utilizes a maximum likelihood detector to recover information in both spatial and symbol domains. In the proposed RIS-SM system, we analytically derive a closed-form expression for the union tight upper bound of ABEP, employing the Gaussian-Chebyshev quadrature method. The validity of these results is rigorously confirmed through exhaustive Monte Carlo simulations."}
{"main_page": "https://arxiv.org/abs/2404.00874", "pdf": "https://arxiv.org/pdf/2404.00874", "title": "DiSR-NeRF: Diffusion-Guided View-Consistent Super-Resolution NeRF", "authors": "Jie Long Lee, Chen Li, Gim Hee Lee", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present DiSR-NeRF, a diffusion-guided framework for view-consistent super-resolution (SR) NeRF. Unlike prior works, we circumvent the requirement for high-resolution (HR) reference images by leveraging existing powerful 2D super-resolution models. Nonetheless, independent SR 2D images are often inconsistent across different views. We thus propose Iterative 3D Synchronization (I3DS) to mitigate the inconsistency problem via the inherent multi-view consistency property of NeRF. Specifically, our I3DS alternates between upscaling low-resolution (LR) rendered images with diffusion models, and updating the underlying 3D representation with standard NeRF training. We further introduce Renoised Score Distillation (RSD), a novel score-distillation objective for 2D image resolution. Our RSD combines features from ancestral sampling and Score Distillation Sampling (SDS) to generate sharp images that are also LR-consistent. Qualitative and quantitative results on both synthetic and real-world datasets demonstrate that our DiSR-NeRF can achieve better results on NeRF super-resolution compared with existing works. Code and video results available at the project website."}
{"main_page": "https://arxiv.org/abs/2404.00875", "pdf": "https://arxiv.org/pdf/2404.00875", "title": "DPA-Net: Structured 3D Abstraction from Sparse Views via Differentiable  Primitive Assembly", "authors": "Fenggen Yu, Yimin Qian, Xu Zhang, Francisca Gil-Ureta, Brian Jackson, Eric Bennett, Hao Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present a differentiable rendering framework to learn structured 3D abstractions in the form of primitive assemblies from sparse RGB images capturing a 3D object. By leveraging differentiable volume rendering, our method does not require 3D supervision. Architecturally, our network follows the general pipeline of an image-conditioned neural radiance field (NeRF) exemplified by pixelNeRF for color prediction. As our core contribution, we introduce differential primitive assembly (DPA) into NeRF to output a 3D occupancy field in place of density prediction, where the predicted occupancies serve as opacity values for volume rendering. Our network, coined DPA-Net, produces a union of convexes, each as an intersection of convex quadric primitives, to approximate the target 3D object, subject to an abstraction loss and a masking loss, both defined in the image space upon volume rendering. With test-time adaptation and additional sampling and loss designs aimed at improving the accuracy and compactness of the obtained assemblies, our method demonstrates superior performance over state-of-the-art alternatives for 3D primitive abstraction from sparse views."}
{"main_page": "https://arxiv.org/abs/2404.00876", "pdf": "https://arxiv.org/pdf/2404.00876", "title": "MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction", "authors": "Xiaolu Liu, Song Wang, Wentong Li, Ruizi Yang, Junbo Chen, Jianke Zhu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Currently, high-definition (HD) map construction leans towards a lightweight online generation tendency, which aims to preserve timely and reliable road scene information. However, map elements contain strong shape priors. Subtle and sparse annotations make current detection-based frameworks ambiguous in locating relevant feature scopes and cause the loss of detailed structures in prediction. To alleviate these problems, we propose MGMap, a mask-guided approach that effectively highlights the informative regions and achieves precise map element localization by introducing the learned masks. Specifically, MGMap employs learned masks based on the enhanced multi-scale BEV features from two perspectives. At the instance level, we propose the Mask-activated instance (MAI) decoder, which incorporates global instance and structural information into instance queries by the activation of instance masks. At the point level, a novel position-guided mask patch refinement (PG-MPR) module is designed to refine point locations from a finer-grained perspective, enabling the extraction of point-specific patch information. Compared to the baselines, our proposed MGMap achieves a notable improvement of around 10 mAP for different input modalities. Extensive experiments also demonstrate that our approach showcases strong robustness and generalization capabilities. Our code can be found at https://github.com/xiaolul2/MGMap."}
{"main_page": "https://arxiv.org/abs/2404.00878", "pdf": "https://arxiv.org/pdf/2404.00878", "title": "TryOn-Adapter: Efficient Fine-Grained Clothing Identity Adaptation for  High-Fidelity Virtual Try-On", "authors": "Jiazheng Xing, Chao Xu, Yijie Qian, Yang Liu, Guang Dai, Baigui Sun, Yong Liu, Jingdong Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Virtual try-on focuses on adjusting the given clothes to fit a specific person seamlessly while avoiding any distortion of the patterns and textures of the garment. However, the clothing identity uncontrollability and training inefficiency of existing diffusion-based methods, which struggle to maintain the identity even with full parameter training, are significant limitations that hinder the widespread applications. In this work, we propose an effective and efficient framework, termed TryOn-Adapter. Specifically, we first decouple clothing identity into fine-grained factors: style for color and category information, texture for high-frequency details, and structure for smooth spatial adaptive transformation. Our approach utilizes a pre-trained exemplar-based diffusion model as the fundamental network, whose parameters are frozen except for the attention layers. We then customize three lightweight modules (Style Preserving, Texture Highlighting, and Structure Adapting) incorporated with fine-tuning techniques to enable precise and efficient identity control. Meanwhile, we introduce the training-free T-RePaint strategy to further enhance clothing identity preservation while maintaining the realistic try-on effect during the inference. Our experiments demonstrate that our approach achieves state-of-the-art performance on two widely-used benchmarks. Additionally, compared with recent full-tuning diffusion-based methods, we only use about half of their tunable parameters during training. The code will be made publicly available at https://github.com/jiazheng-xing/TryOn-Adapter."}
{"main_page": "https://arxiv.org/abs/2404.00879", "pdf": "https://arxiv.org/pdf/2404.00879", "title": "Model-Agnostic Human Preference Inversion in Diffusion Models", "authors": "Jeeyung Kim, Ze Wang, Qiang Qiu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Efficient text-to-image generation remains a challenging task due to the high computational costs associated with the multi-step sampling in diffusion models. Although distillation of pre-trained diffusion models has been successful in reducing sampling steps, low-step image generation often falls short in terms of quality. In this study, we propose a novel sampling design to achieve high-quality one-step image generation aligning with human preferences, particularly focusing on exploring the impact of the prior noise distribution. Our approach, Prompt Adaptive Human Preference Inversion (PAHI), optimizes the noise distributions for each prompt based on human preferences without the need for fine-tuning diffusion models. Our experiments showcase that the tailored noise distributions significantly improve image quality with only a marginal increase in computational cost. Our findings underscore the importance of noise optimization and pave the way for efficient and high-quality text-to-image synthesis."}
{"main_page": "https://arxiv.org/abs/2404.00880", "pdf": "https://arxiv.org/pdf/2404.00880", "title": "Rethinking the Relationship between Recurrent and Non-Recurrent Neural  Networks: A Study in Sparsity", "authors": "Quincy Hershey, Randy Paffenroth, Harsh Pathak, Simon Tavener", "subjects": "Machine Learning (cs.LG)", "abstract": "Neural networks (NN) can be divided into two broad categories, recurrent and non-recurrent. Both types of neural networks are popular and extensively studied, but they are often treated as distinct families of machine learning algorithms. In this position paper, we argue that there is a closer relationship between these two types of neural networks than is normally appreciated. We show that many common neural network models, such as Recurrent Neural Networks (RNN), Multi-Layer Perceptrons (MLP), and even deep multi-layer transformers, can all be represented as iterative maps. The close relationship between RNNs and other types of NNs should not be surprising. In particular, RNNs are known to be Turing complete, and therefore capable of representing any computable function (such as any other types of NNs), but herein we argue that the relationship runs deeper and is more practical than this. For example, RNNs are often thought to be more difficult to train than other types of NNs, with RNNs being plagued by issues such as vanishing or exploding gradients. However, as we demonstrate in this paper, MLPs, RNNs, and many other NNs lie on a continuum, and this perspective leads to several insights that illuminate both theoretical and practical aspects of NNs."}
{"main_page": "https://arxiv.org/abs/2404.00882", "pdf": "https://arxiv.org/pdf/2404.00882", "title": "Metric Learning to Accelerate Convergence of Operator Splitting Methods  for Differentiable Parametric Programming", "authors": "Ethan King, James Kotary, Ferdinando Fioretto, Jan Drgona", "subjects": "Machine Learning (cs.LG)", "abstract": "Recent work has shown a variety of ways in which machine learning can be used to accelerate the solution of constrained optimization problems. Increasing demand for real-time decision-making capabilities in applications such as artificial intelligence and optimal control has led to a variety of approaches, based on distinct strategies. This work proposes a novel approach to learning optimization, in which the underlying metric space of a proximal operator splitting algorithm is learned so as to maximize its convergence rate. While prior works in optimization theory have derived optimal metrics for limited classes of problems, the results do not extend to many practical problem forms including general Quadratic Programming (QP). This paper shows how differentiable optimization can enable the end-to-end learning of proximal metrics, enhancing the convergence of proximal algorithms for QP problems beyond what is possible based on known theory. Additionally, the results illustrate a strong connection between the learned proximal metrics and active constraints at the optima, leading to an interpretation in which the learning of proximal metrics can be viewed as a form of active set learning."}
{"main_page": "https://arxiv.org/abs/2404.00883", "pdf": "https://arxiv.org/pdf/2404.00883", "title": "Interpretable Multi-View Clustering Based on Anchor Graph Tensor  Factorization", "authors": "Jing Li, Quanxue Gao, Cheng Deng, Qianqian Wang, Ming Yang", "subjects": "Machine Learning (cs.LG)", "abstract": "The clustering method based on the anchor graph has gained significant attention due to its exceptional clustering performance and ability to process large-scale data. One common approach is to learn bipartite graphs with K-connected components, helping avoid the need for post-processing. However, this method has strict parameter requirements and may not always get K-connected components. To address this issue, an alternative approach is to directly obtain the cluster label matrix by performing non-negative matrix factorization (NMF) on the anchor graph. Nevertheless, existing multi-view clustering methods based on anchor graph factorization lack adequate cluster interpretability for the decomposed matrix and often overlook the inter-view information. We address this limitation by using non-negative tensor factorization to decompose an anchor graph tensor that combines anchor graphs from multiple views. This approach allows us to consider inter-view information comprehensively. The decomposed tensors, namely the sample indicator tensor and the anchor indicator tensor, enhance the interpretability of the factorization. Extensive experiments validate the effectiveness of this method."}
{"main_page": "https://arxiv.org/abs/2404.00884", "pdf": "https://arxiv.org/pdf/2404.00884", "title": "Self-Demos: Eliciting Out-of-Demonstration Generalizability in Large  Language Models", "authors": "Wei He, Shichun Liu, Jun Zhao, Yiwen Ding, Yi Lu, Zhiheng Xi, Tao Gui, Qi Zhang, Xuanjing Huang", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Large language models (LLMs) have shown promising abilities of in-context learning (ICL), adapting swiftly to new tasks with only few-shot demonstrations. However, current few-shot methods heavily depend on high-quality, query-specific demos, which are often lacking. When faced with out-of-demonstration (OOD) queries, methods that rely on hand-crafted demos or external retrievers might fail. To bridge the gap between limited demos and OOD queries, we propose Self-Demos, a novel prompting method that elicits the inherent generalizability in LLMs by query-aware demo generation. The generated demos strategically interpolate between existing demos and the given query, transforming the query from OOD to ID. To evaluate the effectiveness of our approach, we manually constructed OOD-Toolset, a dataset in the tool-using scenario with over 300 real-world APIs and 1000 instances, each consisting of three tool-use cases as demos and an OOD query. Thorough experiments on our dataset and two public math benchmarks have shown that our method can outperform state-of-the-art baselines in the OOD setting. Moreover, we conduct a range of analyses to validate Self-Demos's generalization and provide more insights."}
{"main_page": "https://arxiv.org/abs/2404.00885", "pdf": "https://arxiv.org/pdf/2404.00885", "title": "Modeling Output-Level Task Relatedness in Multi-Task Learning with  Feedback Mechanism", "authors": "Xiangming Xi, Feng Gao, Jun Xu, Fangtai Guo, Tianlei Jin", "subjects": "Machine Learning (cs.LG)", "abstract": "Multi-task learning (MTL) is a paradigm that simultaneously learns multiple tasks by sharing information at different levels, enhancing the performance of each individual task. While previous research has primarily focused on feature-level or parameter-level task relatedness, and proposed various model architectures and learning algorithms to improve learning performance, we aim to explore output-level task relatedness. This approach introduces a posteriori information into the model, considering that different tasks may produce correlated outputs with mutual influences. We achieve this by incorporating a feedback mechanism into MTL models, where the output of one task serves as a hidden feature for another task, thereby transforming a static MTL model into a dynamic one. To ensure the training process converges, we introduce a convergence loss that measures the trend of a task's outputs during each iteration. Additionally, we propose a Gumbel gating mechanism to determine the optimal projection of feedback signals. We validate the effectiveness of our method and evaluate its performance through experiments conducted on several baseline models in spoken language understanding."}
{"main_page": "https://arxiv.org/abs/2404.00886", "pdf": "https://arxiv.org/pdf/2404.00886", "title": "MTLight: Efficient Multi-Task Reinforcement Learning for Traffic Signal  Control", "authors": "Liwen Zhu, Peixi Peng, Zongqing Lu, Yonghong Tian", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Traffic signal control has a great impact on alleviating traffic congestion in modern cities. Deep reinforcement learning (RL) has been widely used for this task in recent years, demonstrating promising performance but also facing many challenges such as limited performances and sample inefficiency. To handle these challenges, MTLight is proposed to enhance the agent observation with a latent state, which is learned from numerous traffic indicators. Meanwhile, multiple auxiliary and supervisory tasks are constructed to learn the latent state, and two types of embedding latent features, the task-specific feature and task-shared feature, are used to make the latent state more abundant. Extensive experiments conducted on CityFlow demonstrate that MTLight has leading convergence speed and asymptotic performance. We further simulate under peak-hour pattern in all scenarios with increasing control difficulty and the results indicate that MTLight is highly adaptable."}
{"main_page": "https://arxiv.org/abs/2404.00890", "pdf": "https://arxiv.org/pdf/2404.00890", "title": "Development of Musculoskeletal Legs with Planar Interskeletal Structures  to Realize Human Comparable Moving Function", "authors": "Moritaka Onitsuka, Manabu Nishiura, Kento Kawaharazuka, Kei Tsuzuki, Yasunori Toshimitsu, Yusuke Omura, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba", "subjects": "Robotics (cs.RO)", "abstract": "Musculoskeletal humanoids have been developed by imitating humans and expected to perform natural and dynamic motions as well as humans. To achieve desired motions stably in current musculoskeletal humanoids is not easy because they cannot maintain the sufficient moment arm of muscles in various postures. In this research, we discuss planar structures that spread across joint structures such as ligament and planar muscles and the application of planar interskeletal structures to humanoid robots. Next, we develop MusashiOLegs, a musculoskeletal legs which has planar interskeletal structures and conducts several experiments to verify the importance of planar interskeletal structures."}
{"main_page": "https://arxiv.org/abs/2404.00891", "pdf": "https://arxiv.org/pdf/2404.00891", "title": "Marrying NeRF with Feature Matching for One-step Pose Estimation", "authors": "Ronghan Chen, Yang Cong, Yu Ren", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Given the image collection of an object, we aim at building a real-time image-based pose estimation method, which requires neither its CAD model nor hours of object-specific training. Recent NeRF-based methods provide a promising solution by directly optimizing the pose from pixel loss between rendered and target images. However, during inference, they require long converging time, and suffer from local minima, making them impractical for real-time robot applications. We aim at solving this problem by marrying image matching with NeRF. With 2D matches and depth rendered by NeRF, we directly solve the pose in one step by building 2D-3D correspondences between target and initial view, thus allowing for real-time prediction. Moreover, to improve the accuracy of 2D-3D correspondences, we propose a 3D consistent point mining strategy, which effectively discards unfaithful points reconstruted by NeRF. Moreover, current NeRF-based methods naively optimizing pixel loss fail at occluded images. Thus, we further propose a 2D matches based sampling strategy to preclude the occluded area. Experimental results on representative datasets prove that our method outperforms state-of-the-art methods, and improves inference efficiency by 90x, achieving real-time prediction at 6 FPS."}
{"main_page": "https://arxiv.org/abs/2404.00892", "pdf": "https://arxiv.org/pdf/2404.00892", "title": "Realization of Seated Walk by a Musculoskeletal Humanoid with  Buttock-Contact Sensors From Human Constrained Teaching", "authors": "Kento Kawaharazuka, Kei Okada, Masayuki Inaba", "subjects": "Robotics (cs.RO)", "abstract": "In this study, seated walk, a movement of walking while sitting on a chair with casters, is realized on a musculoskeletal humanoid from human teaching. The body is balanced by using buttock-contact sensors implemented on the planar interskeletal structure of the human mimetic musculoskeletal robot. Also, we develop a constrained teaching method in which one-dimensional control command, its transition, and a transition condition are described for each state in advance, and a threshold value for each transition condition such as joint angles and foot contact sensor values is determined based on human teaching. Complex behaviors can be easily generated from simple inputs. In the musculoskeletal humanoid MusashiOLegs, forward, backward, and rotational movements of seated walk are realized."}
{"main_page": "https://arxiv.org/abs/2404.00893", "pdf": "https://arxiv.org/pdf/2404.00893", "title": "An Integrating Comprehensive Trajectory Prediction with Risk Potential  Field Method for Autonomous Driving", "authors": "Kailu Wu, Xing Liu, Feiyu Bian, Yizhai Zhang, Panfeng Huang", "subjects": "Robotics (cs.RO)", "abstract": "Due to the uncertainty of traffic participants' intentions, generating safe but not overly cautious behavior in interactive driving scenarios remains a formidable challenge for autonomous driving. In this paper, we address this issue by combining a deep learning-based trajectory prediction model with risk potential field-based motion planning. In order to comprehensively predict the possible future trajectories of other vehicles, we propose a target-region based trajectory prediction model(TRTP) which considers every region a vehicle may arrive in the future. After that, we construct a risk potential field at each future time step based on the prediction results of TRTP, and integrate risk value to the objective function of Model Predictive Contouring Control(MPCC). This enables the uncertainty of other vehicles to be taken into account during the planning process. Balancing between risk and progress along the reference path can achieve both driving safety and efficiency at the same time. We also demonstrate the security and effectiveness performance of our method in the CARLA simulator."}
{"main_page": "https://arxiv.org/abs/2404.00897", "pdf": "https://arxiv.org/pdf/2404.00897", "title": "Machine Learning Robustness: A Primer", "authors": "Houssem Ben Braiek, Foutse Khomh", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "abstract": "This chapter explores the foundational concept of robustness in Machine Learning (ML) and its integral role in establishing trustworthiness in Artificial Intelligence (AI) systems. The discussion begins with a detailed definition of robustness, portraying it as the ability of ML models to maintain stable performance across varied and unexpected environmental conditions. ML robustness is dissected through several lenses: its complementarity with generalizability; its status as a requirement for trustworthy AI; its adversarial vs non-adversarial aspects; its quantitative metrics; and its indicators such as reproducibility and explainability. The chapter delves into the factors that impede robustness, such as data bias, model complexity, and the pitfalls of underspecified ML pipelines. It surveys key techniques for robustness assessment from a broad perspective, including adversarial attacks, encompassing both digital and physical realms. It covers non-adversarial data shifts and nuances of Deep Learning (DL) software testing methodologies. The discussion progresses to explore amelioration strategies for bolstering robustness, starting with data-centric approaches like debiasing and augmentation. Further examination includes a variety of model-centric methods such as transfer learning, adversarial training, and randomized smoothing. Lastly, post-training methods are discussed, including ensemble techniques, pruning, and model repairs, emerging as cost-effective strategies to make models more resilient against the unpredictable. This chapter underscores the ongoing challenges and limitations in estimating and achieving ML robustness by existing approaches. It offers insights and directions for future research on this crucial concept, as a prerequisite for trustworthy AI systems."}
{"main_page": "https://arxiv.org/abs/2404.00898", "pdf": "https://arxiv.org/pdf/2404.00898", "title": "CAAP: Class-Dependent Automatic Data Augmentation Based On Adaptive  Policies For Time Series", "authors": "Tien-Yu Chang, Hao Dai, Vincent S. Tseng", "subjects": "Machine Learning (cs.LG)", "abstract": "Data Augmentation is a common technique used to enhance the performance of deep learning models by expanding the training dataset. Automatic Data Augmentation (ADA) methods are getting popular because of their capacity to generate policies for various datasets. However, existing ADA methods primarily focused on overall performance improvement, neglecting the problem of class-dependent bias that leads to performance reduction in specific classes. This bias poses significant challenges when deploying models in real-world applications. Furthermore, ADA for time series remains an underexplored domain, highlighting the need for advancements in this field. In particular, applying ADA techniques to vital signals like an electrocardiogram (ECG) is a compelling example due to its potential in medical domains such as heart disease diagnostics. We propose a novel deep learning-based approach called Class-dependent Automatic Adaptive Policies (CAAP) framework to overcome the notable class-dependent bias problem while maintaining the overall improvement in time-series data augmentation. Specifically, we utilize the policy network to generate effective sample-wise policies with balanced difficulty through class and feature information extraction. Second, we design the augmentation probability regulation method to minimize class-dependent bias. Third, we introduce the information region concepts into the ADA framework to preserve essential regions in the sample. Through a series of experiments on real-world ECG datasets, we demonstrate that CAAP outperforms representative methods in achieving lower class-dependent bias combined with superior overall performance. These results highlight the reliability of CAAP as a promising ADA method for time series modeling that fits for the demands of real-world applications."}
{"main_page": "https://arxiv.org/abs/2404.00899", "pdf": "https://arxiv.org/pdf/2404.00899", "title": "TM-TREK at SemEval-2024 Task 8: Towards LLM-Based Automatic Boundary  Detection for Human-Machine Mixed Text", "authors": "Xiaoyan Qu, Xiangfeng Meng", "subjects": "Computation and Language (cs.CL)", "abstract": "With the increasing prevalence of text generated by large language models (LLMs), there is a growing concern about distinguishing between LLM-generated and human-written texts in order to prevent the misuse of LLMs, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content. This paper explores LLMs' ability to identify boundaries in human-written and machine-generated mixed texts. We approach this task by transforming it into a token classification problem and regard the label turning point as the boundary. Notably, our ensemble model of LLMs achieved first place in the 'Human-Machine Mixed Text Detection' sub-task of the SemEval'24 Competition Task 8. Additionally, we investigate factors that influence the capability of LLMs in detecting boundaries within mixed texts, including the incorporation of extra layers on top of LLMs, combination of segmentation loss, and the impact of pretraining. Our findings aim to provide valuable insights for future research in this area."}
{"main_page": "https://arxiv.org/abs/2404.00901", "pdf": "https://arxiv.org/pdf/2404.00901", "title": "Slightly Shift New Classes to Remember Old Classes for Video  Class-Incremental Learning", "authors": "Jian Jiao, Yu Dai, Hefei Mei, Heqian Qiu, Chuanyang Gong, Shiyuan Tang, Xinpeng Hao, Hongliang Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent video class-incremental learning usually excessively pursues the accuracy of the newly seen classes and relies on memory sets to mitigate catastrophic forgetting of the old classes. However, limited storage only allows storing a few representative videos. So we propose SNRO, which slightly shifts the features of new classes to remember old classes. Specifically, SNRO contains Examples Sparse(ES) and Early Break(EB). ES decimates at a lower sample rate to build memory sets and uses interpolation to align those sparse frames in the future. By this, SNRO stores more examples under the same memory consumption and forces the model to focus on low-semantic features which are harder to be forgotten. EB terminates the training at a small epoch, preventing the model from overstretching into the high-semantic space of the current task. Experiments on UCF101, HMDB51, and UESTC-MMEA-CL datasets show that SNRO performs better than other approaches while consuming the same memory consumption."}
{"main_page": "https://arxiv.org/abs/2404.00902", "pdf": "https://arxiv.org/pdf/2404.00902", "title": "Data Analytics for Improving Energy Efficiency in Short Sea Shipping", "authors": "Mohamed Abuella, Hadi Fanaee, M. Amine Atou, Slawomir Nowaczyk, Simon Johansson, Ethan Faghani", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "abstract": "To meet the urgent requirements for the climate change mitigation, several proactive measures of energy efficiency have been implemented in maritime industry. Many of these practices depend highly on the onboard data of vessel's operation and environmental conditions. In this paper, a high resolution onboard data from passenger vessels in short-sea shipping (SSS) have been collected and preprocessed. We first investigated the available data to deploy it effectively to model the physics of the vessel, and hence the vessel performance. Since in SSS, the weather measurements and forecasts might have not been in temporal and spatial resolutions that accurately representing the actual environmental conditions. Then, We proposed a data-driven modeling approach for vessel energy efficiency. This approach addresses the challenges of data representation and energy modeling by combining and aggregating data from multiple sources and seamlessly integrates explainable artificial intelligence (XAI) to attain clear insights about the energy efficiency for a vessel in SSS. After that, the developed model of energy efficiency has been utilized in developing a framework for optimizing the vessel voyage to minimize the fuel consumption and meeting the constraint of arrival time. Moreover, we developed a spatial clustering approach for labeling the vessel paths to detect the paths for vessels with operating routes of repeatable and semi-repeatable paths."}
{"main_page": "https://arxiv.org/abs/2404.00903", "pdf": "https://arxiv.org/pdf/2404.00903", "title": "Maximizing User Experience with LLMOps-Driven Personalized  Recommendation Systems", "authors": "Chenxi Shi, Penghao Liang, Yichao Wu, Tong Zhan, Zhengyu Jin", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "abstract": "The integration of LLMOps into personalized recommendation systems marks a significant advancement in managing LLM-driven applications. This innovation presents both opportunities and challenges for enterprises, requiring specialized teams to navigate the complexity of engineering technology while prioritizing data security and model interpretability. By leveraging LLMOps, enterprises can enhance the efficiency and reliability of large-scale machine learning models, driving personalized recommendations aligned with user preferences. Despite ethical considerations, LLMOps is poised for widespread adoption, promising more efficient and secure machine learning services that elevate user experience and shape the future of personalized recommendation systems."}
{"main_page": "https://arxiv.org/abs/2404.00904", "pdf": "https://arxiv.org/pdf/2404.00904", "title": "A Fast Percolation-Dijkstra Routing Method for Mega-Constellation  Backbone Network", "authors": "Shenshen Luan, Luyuan Wang, Yepeng Liu, Ninghan Sun", "subjects": "Networking and Internet Architecture (cs.NI)", "abstract": "The real-time routing for satellite communication of the mega-constellations is being challenged due to the large-scale of network nodes, especially on devices with limited computation such as onboard embedded systems. In this paper, a fast routing method is proposed for mega-constellation backbone networks. Firstly, inspired by the regularity and sparse characteristics of mega-constellations, the 4-degree percolation theory is proposed to describe the node search process. Then, dynamic minimum search and mapping methods are used to narrow down the traversal range. The proposed method performs as well as the heap-optimized Dijkstra algorithm with less memory space and dynamic access. The experimental results show that the method proposed in this paper can significantly reduce routing computation time, especially on the onboard, edge-computing or other computation-limited devices."}
{"main_page": "https://arxiv.org/abs/2404.00906", "pdf": "https://arxiv.org/pdf/2404.00906", "title": "From Pixels to Graphs: Open-Vocabulary Scene Graph Generation with  Vision-Language Models", "authors": "Rongjie Li, Songyang Zhang, Dahua Lin, Kai Chen, Xuming He", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Scene graph generation (SGG) aims to parse a visual scene into an intermediate graph representation for downstream reasoning tasks. Despite recent advancements, existing methods struggle to generate scene graphs with novel visual relation concepts. To address this challenge, we introduce a new open-vocabulary SGG framework based on sequence generation. Our framework leverages vision-language pre-trained models (VLM) by incorporating an image-to-graph generation paradigm. Specifically, we generate scene graph sequences via image-to-text generation with VLM and then construct scene graphs from these sequences. By doing so, we harness the strong capabilities of VLM for open-vocabulary SGG and seamlessly integrate explicit relational modeling for enhancing the VL tasks. Experimental results demonstrate that our design not only achieves superior performance with an open vocabulary but also enhances downstream vision-language task performance through explicit relation modeling knowledge."}
{"main_page": "https://arxiv.org/abs/2404.00909", "pdf": "https://arxiv.org/pdf/2404.00909", "title": "Learning by Correction: Efficient Tuning Task for Zero-Shot Generative  Vision-Language Reasoning", "authors": "Rongjie Li, Yu Wu, Xuming He", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Generative vision-language models (VLMs) have shown impressive performance in zero-shot vision-language tasks like image captioning and visual question answering. However, improving their zero-shot reasoning typically requires second-stage instruction tuning, which relies heavily on human-labeled or large language model-generated annotation, incurring high labeling costs. To tackle this challenge, we introduce Image-Conditioned Caption Correction (ICCC), a novel pre-training task designed to enhance VLMs' zero-shot performance without the need for labeled task-aware data. The ICCC task compels VLMs to rectify mismatches between visual and language concepts, thereby enhancing instruction following and text generation conditioned on visual inputs. Leveraging language structure and a lightweight dependency parser, we construct data samples of ICCC task from image-text datasets with low labeling and computation costs. Experimental results on BLIP-2 and InstructBLIP demonstrate significant improvements in zero-shot image-text generation-based VL tasks through ICCC instruction tuning."}
{"main_page": "https://arxiv.org/abs/2404.00913", "pdf": "https://arxiv.org/pdf/2404.00913", "title": "LLaMA-Excitor: General Instruction Tuning via Indirect Feature  Interaction", "authors": "Bo Zou, Chao Yang, Yu Qiao, Chengbin Quan, Youjian Zhao", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Existing methods to fine-tune LLMs, like Adapter, Prefix-tuning, and LoRA, which introduce extra modules or additional input sequences to inject new skills or knowledge, may compromise the innate abilities of LLMs. In this paper, we propose LLaMA-Excitor, a lightweight method that stimulates the LLMs' potential to better follow instructions by gradually paying more attention to worthwhile information. Specifically, the LLaMA-Excitor does not directly change the intermediate hidden state during the self-attention calculation of the transformer structure. We designed the Excitor block as a bypass module for the similarity score computation in LLMs' self-attention to reconstruct keys and change the importance of values by learnable prompts. LLaMA-Excitor ensures a self-adaptive allocation of additional attention to input instructions, thus effectively preserving LLMs' pre-trained knowledge when fine-tuning LLMs on low-quality instruction-following datasets. Furthermore, we unify the modeling of multi-modal tuning and language-only tuning, extending LLaMA-Excitor to a powerful visual instruction follower without the need for complex multi-modal alignment. Our proposed approach is evaluated in language-only and multi-modal tuning experimental scenarios. Notably, LLaMA-Excitor is the only method that maintains basic capabilities while achieving a significant improvement (+6%) on the MMLU benchmark. In the visual instruction tuning, we achieve a new state-of-the-art image captioning performance of 157.5 CIDEr on MSCOCO, and a comparable performance (88.39%) on ScienceQA to cutting-edge models with more parameters and extensive vision-language pertaining."}
{"main_page": "https://arxiv.org/abs/2404.00914", "pdf": "https://arxiv.org/pdf/2404.00914", "title": "Token-Efficient Leverage Learning in Large Language Models", "authors": "Yuanhao Zeng, Min Wang, Yihang Wang, Yingxia Shao", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Large Language Models (LLMs) have excelled in various tasks but perform better in high-resource scenarios, which presents challenges in low-resource scenarios. Data scarcity and the inherent difficulty of adapting LLMs to specific tasks compound the challenge. To address the twin hurdles, we introduce \\textbf{Leverage Learning}. We present a streamlined implement of this methodology called Token-Efficient Leverage Learning (TELL). TELL showcases the potential of Leverage Learning, demonstrating effectiveness across various LLMs and low-resource tasks, ranging from $10^4$ to $10^6$ tokens. It reduces task data requirements by up to nearly an order of magnitude compared to conventional Supervised Fine-Tuning (SFT) while delivering competitive performance. With the same amount of task data, TELL leads in improving task performance compared to SFT. We discuss the mechanism of Leverage Learning, suggesting it aligns with quantization hypothesis and explore its promising potential through empirical testing."}
{"main_page": "https://arxiv.org/abs/2404.00915", "pdf": "https://arxiv.org/pdf/2404.00915", "title": "Scalable 3D Registration via Truncated Entry-wise Absolute Residuals", "authors": "Tianyu Huang, Liangzu Peng, Ren\u00e9 Vidal, Yun-Hui Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Given an input set of $3$D point pairs, the goal of outlier-robust $3$D registration is to compute some rotation and translation that align as many point pairs as possible. This is an important problem in computer vision, for which many highly accurate approaches have been recently proposed. Despite their impressive performance, these approaches lack scalability, often overflowing the $16$GB of memory of a standard laptop to handle roughly $30,000$ point pairs. In this paper, we propose a $3$D registration approach that can process more than ten million ($10^7$) point pairs with over $99\\%$ random outliers. Moreover, our method is efficient, entails low memory costs, and maintains high accuracy at the same time. We call our method TEAR, as it involves minimizing an outlier-robust loss that computes Truncated Entry-wise Absolute Residuals. To minimize this loss, we decompose the original $6$-dimensional problem into two subproblems of dimensions $3$ and $2$, respectively, solved in succession to global optimality via a customized branch-and-bound method. While branch-and-bound is often slow and unscalable, this does not apply to TEAR as we propose novel bounding functions that are tight and computationally efficient. Experiments on various datasets are conducted to validate the scalability and efficiency of our method."}
{"main_page": "https://arxiv.org/abs/2404.00916", "pdf": "https://arxiv.org/pdf/2404.00916", "title": "Gyro-based Neural Single Image Deblurring", "authors": "Heemin Yang, Jaesung Rim, Seung-Hwan Baek, Sunghyun Cho", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "In this paper, we present GyroDeblurNet, a novel single image deblurring method that utilizes a gyro sensor to effectively resolve the ill-posedness of image deblurring. The gyro sensor provides valuable information about camera motion during exposure time that can significantly improve deblurring quality. However, effectively exploiting real-world gyro data is challenging due to significant errors from various sources including sensor noise, the disparity between the positions of a camera module and a gyro sensor, the absence of translational motion information, and moving objects whose motions cannot be captured by a gyro sensor. To handle gyro error, GyroDeblurNet is equipped with two novel neural network blocks: a gyro refinement block and a gyro deblurring block. The gyro refinement block refines the error-ridden gyro data using the blur information from the input image. On the other hand, the gyro deblurring block removes blur from the input image using the refined gyro data and further compensates for gyro error by leveraging the blur information from the input image. For training a neural network with erroneous gyro data, we propose a training strategy based on the curriculum learning. We also introduce a novel gyro data embedding scheme to represent real-world intricate camera shakes. Finally, we present a synthetic dataset and a real dataset for the training and evaluation of gyro-based single image deblurring. Our experiments demonstrate that our approach achieves state-of-the-art deblurring quality by effectively utilizing erroneous gyro data."}
{"main_page": "https://arxiv.org/abs/2404.00918", "pdf": "https://arxiv.org/pdf/2404.00918", "title": "Rethinking Saliency-Guided Weakly-Supervised Semantic Segmentation", "authors": "Beomyoung Kim, Donghyeon Kim, Sung Ju Hwang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper presents a fresh perspective on the role of saliency maps in weakly-supervised semantic segmentation (WSSS) and offers new insights and research directions based on our empirical findings. We conduct comprehensive experiments and observe that the quality of the saliency map is a critical factor in saliency-guided WSSS approaches. Nonetheless, we find that the saliency maps used in previous works are often arbitrarily chosen, despite their significant impact on WSSS. Additionally, we observe that the choice of the threshold, which has received less attention before, is non-trivial in WSSS. To facilitate more meaningful and rigorous research for saliency-guided WSSS, we introduce \\texttt{WSSS-BED}, a standardized framework for conducting research under unified conditions. \\texttt{WSSS-BED} provides various saliency maps and activation maps for seven WSSS methods, as well as saliency maps from unsupervised salient object detection models."}
{"main_page": "https://arxiv.org/abs/2404.00921", "pdf": "https://arxiv.org/pdf/2404.00921", "title": "Towards Label-Efficient Human Matting: A Simple Baseline for Weakly  Semi-Supervised Trimap-Free Human Matting", "authors": "Beomyoung Kim, Myeong Yeon Yi, Joonsang Yu, Young Joon Yoo, Sung Ju Hwang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper presents a new practical training method for human matting, which demands delicate pixel-level human region identification and significantly laborious annotations. To reduce the annotation cost, most existing matting approaches often rely on image synthesis to augment the dataset. However, the unnaturalness of synthesized training images brings in a new domain generalization challenge for natural images. To address this challenge, we introduce a new learning paradigm, weakly semi-supervised human matting (WSSHM), which leverages a small amount of expensive matte labels and a large amount of budget-friendly segmentation labels, to save the annotation cost and resolve the domain generalization problem. To achieve the goal of WSSHM, we propose a simple and effective training method, named Matte Label Blending (MLB), that selectively guides only the beneficial knowledge of the segmentation and matte data to the matting model. Extensive experiments with our detailed analysis demonstrate our method can substantially improve the robustness of the matting model using a few matte data and numerous segmentation data. Our training method is also easily applicable to real-time models, achieving competitive accuracy with breakneck inference speed (328 FPS on NVIDIA V100 GPU). The implementation code is available at \\url{https://github.com/clovaai/WSSHM}."}
{"main_page": "https://arxiv.org/abs/2404.00922", "pdf": "https://arxiv.org/pdf/2404.00922", "title": "Towards Memorization-Free Diffusion Models", "authors": "Chen Chen, Daochang Liu, Chang Xu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Pretrained diffusion models and their outputs are widely accessible due to their exceptional capacity for synthesizing high-quality images and their open-source nature. The users, however, may face litigation risks owing to the models' tendency to memorize and regurgitate training data during inference. To address this, we introduce Anti-Memorization Guidance (AMG), a novel framework employing three targeted guidance strategies for the main causes of memorization: image and caption duplication, and highly specific user prompts. Consequently, AMG ensures memorization-free outputs while maintaining high image quality and text alignment, leveraging the synergy of its guidance methods, each indispensable in its own right. AMG also features an innovative automatic detection system for potential memorization during each step of inference process, allows selective application of guidance strategies, minimally interfering with the original sampling process to preserve output utility. We applied AMG to pretrained Denoising Diffusion Probabilistic Models (DDPM) and Stable Diffusion across various generation tasks. The results demonstrate that AMG is the first approach to successfully eradicates all instances of memorization with no or marginal impacts on image quality and text-alignment, as evidenced by FID and CLIP scores."}
{"main_page": "https://arxiv.org/abs/2404.00923", "pdf": "https://arxiv.org/pdf/2404.00923", "title": "MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision,  Depth, and Inertial Measurements", "authors": "Lisong C. Sun, Neel P. Bhatt, Jonathan C. Liu, Zhiwen Fan, Zhangyang Wang, Todd E. Humphreys, Ufuk Topcu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "abstract": "Simultaneous localization and mapping is essential for position tracking and scene understanding. 3D Gaussian-based map representations enable photorealistic reconstruction and real-time rendering of scenes using multiple posed cameras. We show for the first time that using 3D Gaussians for map representation with unposed camera images and inertial measurements can enable accurate SLAM. Our method, MM3DGS, addresses the limitations of prior neural radiance field-based representations by enabling faster rendering, scale awareness, and improved trajectory tracking. Our framework enables keyframe-based mapping and tracking utilizing loss functions that incorporate relative pose transformations from pre-integrated inertial measurements, depth estimates, and measures of photometric rendering quality. We also release a multi-modal dataset, UT-MM, collected from a mobile robot equipped with a camera and an inertial measurement unit. Experimental evaluation on several scenes from the dataset shows that MM3DGS achieves 3x improvement in tracking and 5% improvement in photometric rendering quality compared to the current 3DGS SLAM state-of-the-art, while allowing real-time rendering of a high-resolution dense 3D map. Project Webpage: https://vita-group.github.io/MM3DGS-SLAM"}
{"main_page": "https://arxiv.org/abs/2404.00924", "pdf": "https://arxiv.org/pdf/2404.00924", "title": "BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise  Regression Tasks", "authors": "Zhiyuan Cheng, Zhaoyi Liu, Tengda Guo, Shiwei Feng, Dongfang Liu, Mingjie Tang, Xiangyu Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Pixel-wise regression tasks (e.g., monocular depth estimation (MDE) and optical flow estimation (OFE)) have been widely involved in our daily life in applications like autonomous driving, augmented reality and video composition. Although certain applications are security-critical or bear societal significance, the adversarial robustness of such models are not sufficiently studied, especially in the black-box scenario. In this work, we introduce the first unified black-box adversarial patch attack framework against pixel-wise regression tasks, aiming to identify the vulnerabilities of these models under query-based black-box attacks. We propose a novel square-based adversarial patch optimization framework and employ probabilistic square sampling and score-based gradient estimation techniques to generate the patch effectively and efficiently, overcoming the scalability problem of previous black-box patch attacks. Our attack prototype, named BadPart, is evaluated on both MDE and OFE tasks, utilizing a total of 7 models. BadPart surpasses 3 baseline methods in terms of both attack performance and efficiency. We also apply BadPart on the Google online service for portrait depth estimation, causing 43.5% relative distance error with 50K queries. State-of-the-art (SOTA) countermeasures cannot defend our attack effectively."}
{"main_page": "https://arxiv.org/abs/2404.00925", "pdf": "https://arxiv.org/pdf/2404.00925", "title": "LLMs are Good Sign Language Translators", "authors": "Jia Gong, Lin Geng Foo, Yixuan He, Hossein Rahmani, Jun Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Sign Language Translation (SLT) is a challenging task that aims to translate sign videos into spoken language. Inspired by the strong translation capabilities of large language models (LLMs) that are trained on extensive multilingual text corpora, we aim to harness off-the-shelf LLMs to handle SLT. In this paper, we regularize the sign videos to embody linguistic characteristics of spoken language, and propose a novel SignLLM framework to transform sign videos into a language-like representation for improved readability by off-the-shelf LLMs. SignLLM comprises two key modules: (1) The Vector-Quantized Visual Sign module converts sign videos into a sequence of discrete character-level sign tokens, and (2) the Codebook Reconstruction and Alignment module converts these character-level tokens into word-level sign representations using an optimal transport formulation. A sign-text alignment loss further bridges the gap between sign and text tokens, enhancing semantic compatibility. We achieve state-of-the-art gloss-free results on two widely-used SLT benchmarks."}
{"main_page": "https://arxiv.org/abs/2404.00928", "pdf": "https://arxiv.org/pdf/2404.00928", "title": "Instance-Aware Group Quantization for Vision Transformers", "authors": "Jaehyeon Moon, Dohyung Kim, Junyong Cheon, Bumsub Ham", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Post-training quantization (PTQ) is an efficient model compression technique that quantizes a pretrained full-precision model using only a small calibration set of unlabeled samples without retraining. PTQ methods for convolutional neural networks (CNNs) provide quantization results comparable to full-precision counterparts. Directly applying them to vision transformers (ViTs), however, incurs severe performance degradation, mainly due to the differences in architectures between CNNs and ViTs. In particular, the distribution of activations for each channel vary drastically according to input instances, making PTQ methods for CNNs inappropriate for ViTs. To address this, we introduce instance-aware group quantization for ViTs (IGQ-ViT). To this end, we propose to split the channels of activation maps into multiple groups dynamically for each input instance, such that activations within each group share similar statistical properties. We also extend our scheme to quantize softmax attentions across tokens. In addition, the number of groups for each layer is adjusted to minimize the discrepancies between predictions from quantized and full-precision models, under a bit-operation (BOP) constraint. We show extensive experimental results on image classification, object detection, and instance segmentation, with various transformer architectures, demonstrating the effectiveness of our approach."}
{"main_page": "https://arxiv.org/abs/2404.00929", "pdf": "https://arxiv.org/pdf/2404.00929", "title": "A Survey on Multilingual Large Language Models: Corpora, Alignment, and  Bias", "authors": "Yuemei Xu, Ling Hu, Jiayi Zhao, Zihan Qiu, Yuqi Ye, Hanwen Gu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Based on the foundation of Large Language Models (LLMs), Multilingual Large Language Models (MLLMs) have been developed to address the challenges of multilingual natural language processing tasks, hoping to achieve knowledge transfer from high-resource to low-resource languages. However, significant limitations and challenges still exist, such as language imbalance, multilingual alignment, and inherent bias. In this paper, we aim to provide a comprehensive analysis of MLLMs, delving deeply into discussions surrounding these critical issues. First of all, we start by presenting an overview of MLLMs, covering their evolution, key techniques, and multilingual capacities. Secondly, we explore widely utilized multilingual corpora for MLLMs' training and multilingual datasets oriented for downstream tasks that are crucial for enhancing the cross-lingual capability of MLLMs. Thirdly, we survey the existing studies on multilingual representations and investigate whether the current MLLMs can learn a universal language representation. Fourthly, we discuss bias on MLLMs including its category and evaluation metrics, and summarize the existing debiasing techniques. Finally, we discuss existing challenges and point out promising research directions. By demonstrating these aspects, this paper aims to facilitate a deeper understanding of MLLMs and their potentiality in various domains."}
{"main_page": "https://arxiv.org/abs/2404.00930", "pdf": "https://arxiv.org/pdf/2404.00930", "title": "PSYDIAL: Personality-based Synthetic Dialogue Generation using Large  Language Models", "authors": "Ji-Eun Han, Jun-Seok Koh, Hyeon-Tae Seo, Du-Seong Chang, Kyung-Ah Sohn", "subjects": "Computation and Language (cs.CL)", "abstract": "We present a novel end-to-end personality-based synthetic dialogue data generation pipeline, specifically designed to elicit responses from large language models via prompting. We design the prompts to generate more human-like dialogues considering real-world scenarios when users engage with chatbots. We introduce PSYDIAL, the first Korean dialogue dataset focused on personality-based dialogues, curated using our proposed pipeline. Notably, we focus on the Extraversion dimension of the Big Five personality model in our research. Experimental results indicate that while pre-trained models and those fine-tuned with a chit-chat dataset struggle to generate responses reflecting personality, models trained with PSYDIAL show significant improvements. The versatility of our pipeline extends beyond dialogue tasks, offering potential for other non-dialogue related applications. This research opens doors for more nuanced, personality-driven conversational AI in Korean and potentially other languages. Our code is publicly available at https://github.com/jiSilverH/psydial."}
{"main_page": "https://arxiv.org/abs/2404.00931", "pdf": "https://arxiv.org/pdf/2404.00931", "title": "GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields", "authors": "Yunsong Wang, Hanlin Chen, Gim Hee Lee", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advancements in vision-language foundation models have significantly enhanced open-vocabulary 3D scene understanding. However, the generalizability of existing methods is constrained due to their framework designs and their reliance on 3D data. We address this limitation by introducing Generalizable Open-Vocabulary Neural Semantic Fields (GOV-NeSF), a novel approach offering a generalizable implicit representation of 3D scenes with open-vocabulary semantics. We aggregate the geometry-aware features using a cost volume, and propose a Multi-view Joint Fusion module to aggregate multi-view features through a cross-view attention mechanism, which effectively predicts view-specific blending weights for both colors and open-vocabulary features. Remarkably, our GOV-NeSF exhibits state-of-the-art performance in both 2D and 3D open-vocabulary semantic segmentation, eliminating the need for ground truth semantic labels or depth priors, and effectively generalize across scenes and datasets without fine-tuning."}
{"main_page": "https://arxiv.org/abs/2404.00934", "pdf": "https://arxiv.org/pdf/2404.00934", "title": "ChatGLM-RLHF: Practices of Aligning Large Language Models with Human  Feedback", "authors": "Zhenyu Hou, Yiin Niu, Zhengxiao Du, Xiaohan Zhang, Xiao Liu, Aohan Zeng, Qinkai Zheng, Minlie Huang, Hongning Wang, Jie Tang, Yuxiao Dong", "subjects": "Computation and Language (cs.CL)", "abstract": "ChatGLM is a free-to-use AI service powered by the ChatGLM family of large language models (LLMs). In this paper, we present the ChatGLM-RLHF pipeline -- a reinforcement learning from human feedback (RLHF) system -- designed to enhance ChatGLM's alignment with human preferences. ChatGLM-RLHF encompasses three major components: the collection of human preference data, the training of the reward model, and the optimization of policies. Throughout the process of integrating ChatGLM-RLHF into production, we encountered and addressed several unprecedented challenges. We introduce the strategies to mitigate reward variance for stabilized large-scale training, implement model parallelism with fused gradient-descent, and design regularization constraints to avoid catastrophic forgetting in LLMs. Experiments show that ChatGLM-RLHF brings significant improvements in alignment tasks compared to the supervised fine-tuned (SFT) version of ChatGLM. For instance, it achieves on average 15\\% more wins against ChatGLM-SFT in Chinese alignment tasks. The work presents our practices of aligning LLMs with human preferences, offering insights into the challenges and solutions in RLHF implementations."}
{"main_page": "https://arxiv.org/abs/2404.00936", "pdf": "https://arxiv.org/pdf/2404.00936", "title": "A Comprehensive Review of Knowledge Distillation in Computer Vision", "authors": "Sheikh Musa Kaleem (1), Tufail Rouf (1), Gousia Habib (2), Tausifa jan Saleem (2), Brejesh Lall (2) ((1) National Institute of Technology Srinagar, (2) Bharti School of Telecommunication Technology and management Indian Institute of Technology New Delhi, India)", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Deep learning techniques have been demonstrated to surpass preceding cutting-edge machine learning techniques in recent years, with computer vision being one of the most prominent examples. However, deep learning models suffer from significant drawbacks when deployed in resource-constrained environments due to their large model size and high complexity. Knowledge Distillation is one of the prominent solutions to overcome this challenge. This review paper examines the current state of research on knowledge distillation, a technique for compressing complex models into smaller and simpler ones. The paper provides an overview of the major principles and techniques associated with knowledge distillation and reviews the applications of knowledge distillation in the domain of computer vision. The review focuses on the benefits of knowledge distillation, as well as the problems that must be overcome to improve its effectiveness."}
{"main_page": "https://arxiv.org/abs/2404.00938", "pdf": "https://arxiv.org/pdf/2404.00938", "title": "How Can Large Language Models Enable Better Socially Assistive  Human-Robot Interaction: A Brief Survey", "authors": "Zhonghao Shi, Ellen Landrum, Amy O' Connell, Mina Kian, Leticia Pinto-Alva, Kaleen Shrestha, Xiaoyuan Zhu, Maja J Matari\u0107", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Socially assistive robots (SARs) have shown great success in providing personalized cognitive-affective support for user populations with special needs such as older adults, children with autism spectrum disorder (ASD), and individuals with mental health challenges. The large body of work on SAR demonstrates its potential to provide at-home support that complements clinic-based interventions delivered by mental health professionals, making these interventions more effective and accessible. However, there are still several major technical challenges that hinder SAR-mediated interactions and interventions from reaching human-level social intelligence and efficacy. With the recent advances in large language models (LLMs), there is an increased potential for novel applications within the field of SAR that can significantly expand the current capabilities of SARs. However, incorporating LLMs introduces new risks and ethical concerns that have not yet been encountered, and must be carefully be addressed to safely deploy these more advanced systems. In this work, we aim to conduct a brief survey on the use of LLMs in SAR technologies, and discuss the potentials and risks of applying LLMs to the following three major technical challenges of SAR: 1) natural language dialog; 2) multimodal understanding; 3) LLMs as robot policies."}
{"main_page": "https://arxiv.org/abs/2404.00942", "pdf": "https://arxiv.org/pdf/2404.00942", "title": "Evaluating the Factuality of Large Language Models using Large-Scale  Knowledge Graphs", "authors": "Xiaoze Liu, Feijie Wu, Tianyang Xu, Zhuo Chen, Yichi Zhang, Xiaoqian Wang, Jing Gao", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "The advent of Large Language Models (LLMs) has significantly transformed the AI landscape, enhancing machine learning and AI capabilities. Factuality issue is a critical concern for LLMs, as they may generate factually incorrect responses. In this paper, we propose GraphEval to evaluate an LLM's performance using a substantially large test dataset. Specifically, the test dataset is retrieved from a large knowledge graph with more than 10 million facts without expensive human efforts. Unlike conventional methods that evaluate LLMs based on generated responses, GraphEval streamlines the evaluation process by creating a judge model to estimate the correctness of the answers given by the LLM. Our experiments demonstrate that the judge model's factuality assessment aligns closely with the correctness of the LLM's generated outputs, while also substantially reducing evaluation costs. Besides, our findings offer valuable insights into LLM performance across different metrics and highlight the potential for future improvements in ensuring the factual integrity of LLM outputs. The code is publicly available at https://github.com/xz-liu/GraphEval."}
{"main_page": "https://arxiv.org/abs/2404.00943", "pdf": "https://arxiv.org/pdf/2404.00943", "title": "Evalverse: Unified and Accessible Library for Large Language Model  Evaluation", "authors": "Jihoo Kim, Wonho Song, Dahyun Kim, Yunsu Kim, Yungi Kim, Chanjun Park", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "This paper introduces Evalverse, a novel library that streamlines the evaluation of Large Language Models (LLMs) by unifying disparate evaluation tools into a single, user-friendly framework. Evalverse enables individuals with limited knowledge of artificial intelligence to easily request LLM evaluations and receive detailed reports, facilitated by an integration with communication platforms like Slack. Thus, Evalverse serves as a powerful tool for the comprehensive assessment of LLMs, offering both researchers and practitioners a centralized and easily accessible evaluation framework. Finally, we also provide a demo video for Evalverse, showcasing its capabilities and implementation in a two-minute format."}
{"main_page": "https://arxiv.org/abs/2404.00946", "pdf": "https://arxiv.org/pdf/2404.00946", "title": "Exploring the Efficacy of Group-Normalization in Deep Learning Models  for Alzheimer's Disease Classification", "authors": "Gousia Habib, Ishfaq Ahmed Malik, Jameel Ahmad, Imtiaz Ahmed, Shaima Qureshi", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Batch Normalization is an important approach to advancing deep learning since it allows multiple networks to train simultaneously. A problem arises when normalizing along the batch dimension because B.N.'s error increases significantly as batch size shrinks because batch statistics estimates are inaccurate. As a result, computer vision tasks like detection, segmentation, and video, which require tiny batches based on memory consumption, aren't suitable for using Batch Normalization for larger model training and feature transfer. Here, we explore Group Normalization as an easy alternative to using Batch Normalization A Group Normalization is a channel normalization method in which each group is divided into different channels, and the corresponding mean and variance are calculated for each group. Group Normalization computations are accurate across a wide range of batch sizes and are independent of batch size. When trained using a large ImageNet database on ResNet-50, GN achieves a very low error rate of 10.6% compared to Batch Normalization. when a smaller batch size of only 2 is used. For usual batch sizes, the performance of G.N. is comparable to that of Batch Normalization, but at the same time, it outperforms other normalization techniques. Implementing Group Normalization as a direct alternative to B.N to combat the serious challenges faced by the Batch Normalization in deep learning models with comparable or improved classification accuracy. Additionally, Group Normalization can be naturally transferred from the pre-training to the fine-tuning phase. ."}
{"main_page": "https://arxiv.org/abs/2404.00947", "pdf": "https://arxiv.org/pdf/2404.00947", "title": "Towards an In-Depth Comprehension of Case Relevance for Better Legal  Retrieval", "authors": "Haitao Li, You Chen, Zhekai Ge, Qingyao Ai, Yiqun Liu, Quan Zhou, Shuai Huo", "subjects": "Information Retrieval (cs.IR)", "abstract": "Legal retrieval techniques play an important role in preserving the fairness and equality of the judicial system. As an annually well-known international competition, COLIEE aims to advance the development of state-of-the-art retrieval models for legal texts. This paper elaborates on the methodology employed by the TQM team in COLIEE2024.Specifically, we explored various lexical matching and semantic retrieval models, with a focus on enhancing the understanding of case relevance. Additionally, we endeavor to integrate various features using the learning-to-rank technique. Furthermore, fine heuristic pre-processing and post-processing methods have been proposed to mitigate irrelevant information. Consequently, our methodology achieved remarkable performance in COLIEE2024, securing first place in Task 1 and third place in Task 3. We anticipate that our proposed approach can contribute valuable insights to the advancement of legal retrieval technology."}
{"main_page": "https://arxiv.org/abs/2404.00949", "pdf": "https://arxiv.org/pdf/2404.00949", "title": "Harnessing The Power of Attention For Patch-Based Biomedical Image  Classification", "authors": "Gousia Habib, Shaima Qureshi, Malik ishfaq", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Biomedical image analysis can be facilitated by an innovative architecture rooted in self-attention mechanisms. The traditional convolutional neural network (CNN), characterized by fixed-sized windows, needs help capturing intricate spatial and temporal relations at the pixel level. The immutability of CNN filter weights post-training further restricts input fluctuations. Recognizing these limitations, we propose a new paradigm of attention-based models instead of convolutions. As an alternative to traditional CNNs, these models demonstrate robust modelling capabilities and the ability to grasp comprehensive long-range contextual information efficiently. Providing a solution to critical challenges faced by attention-based vision models such as inductive bias, weight sharing, receptive field limitations, and data handling in high resolution, our work combines non-overlapping (vanilla patching) with novel overlapped Shifted Patching Techniques (S.P.T.s) to induce local context that enhances model generalization. Moreover, we examine the novel Lancoz5 interpolation technique, which adapts variable image sizes to higher resolutions. Experimental evidence validates our model's generalization effectiveness, comparing favourably with existing approaches. Attention-based methods are particularly effective with ample data, especially when advanced data augmentation methodologies are integrated to strengthen their robustness."}
{"main_page": "https://arxiv.org/abs/2404.00950", "pdf": "https://arxiv.org/pdf/2404.00950", "title": "AISPACE at SemEval-2024 task 8: A Class-balanced Soft-voting System for  Detecting Multi-generator Machine-generated Text", "authors": "Renhua Gu, Xiangfeng Meng", "subjects": "Computation and Language (cs.CL)", "abstract": "SemEval-2024 Task 8 provides a challenge to detect human-written and machine-generated text. There are 3 subtasks for different detection scenarios. This paper proposes a system that mainly deals with Subtask B. It aims to detect if given full text is written by human or is generated by a specific Large Language Model (LLM), which is actually a multi-class text classification task. Our team AISPACE conducted a systematic study of fine-tuning transformer-based models, including encoderonly, decoder-only and encoder-decoder models. We compared their performance on this task and identified that encoder-only models performed exceptionally well. We also applied a weighted Cross Entropy loss function to address the issue of data imbalance of different class samples. Additionally, we employed softvoting strategy over multi-models ensemble to enhance the reliability of our predictions. Our system ranked top 1 in Subtask B, which sets a state-of-the-art benchmark for this new challenge."}
{"main_page": "https://arxiv.org/abs/2404.00953", "pdf": "https://arxiv.org/pdf/2404.00953", "title": "Movable Antenna-Aided Hybrid Beamforming for Multi-User Communications", "authors": "Yichi Zhang, Yuchen Zhang, Lipeng Zhu, Sa Xiao, Wanbin Tang, Yonina C. Eldar, Rui Zhang", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "In this correspondence, we propose a movable antenna (MA)-aided multi-user hybrid beamforming scheme with a sub-connected structure, where multiple movable sub-arrays can independently change their positions within different local regions. To maximize the system sum rate, we jointly optimize the digital beamformer, analog beamformer, and positions of subarrays, under the constraints of unit modulus, finite movable regions, and power budget. Due to the non-concave/non-convex objective function/constraints, as well as the highly coupled variables, the formulated problem is challenging to solve. By employing fractional programming, we develop an alternating optimization framework to solve the problem via a combination of Lagrange multipliers, penalty method, and gradient descent. Numerical results reveal that the proposed MA-aided hybrid beamforming scheme significantly improves the sum rate compared to its fixed-position antenna (FPA) counterpart. Moreover, with sufficiently large movable regions, the proposed scheme with sub-connected MA arrays even outperforms the fully-connected FPA array."}
{"main_page": "https://arxiv.org/abs/2404.00959", "pdf": "https://arxiv.org/pdf/2404.00959", "title": "Equivariant Local Reference Frames for Unsupervised Non-rigid Point  Cloud Shape Correspondence", "authors": "Ling Wang, Runfa Chen, Yikai Wang, Fuchun Sun, Xinzhou Wang, Sun Kai, Guangyuan Fu, Jianwei Zhang, Wenbing Huang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Unsupervised non-rigid point cloud shape correspondence underpins a multitude of 3D vision tasks, yet itself is non-trivial given the exponential complexity stemming from inter-point degree-of-freedom, i.e., pose transformations. Based on the assumption of local rigidity, one solution for reducing complexity is to decompose the overall shape into independent local regions using Local Reference Frames (LRFs) that are invariant to SE(3) transformations. However, the focus solely on local structure neglects global geometric contexts, resulting in less distinctive LRFs that lack crucial semantic information necessary for effective matching. Furthermore, such complexity introduces out-of-distribution geometric contexts during inference, thus complicating generalization. To this end, we introduce 1) EquiShape, a novel structure tailored to learn pair-wise LRFs with global structural cues for both spatial and semantic consistency, and 2) LRF-Refine, an optimization strategy generally applicable to LRF-based methods, aimed at addressing the generalization challenges. Specifically, for EquiShape, we employ cross-talk within separate equivariant graph neural networks (Cross-GVP) to build long-range dependencies to compensate for the lack of semantic information in local structure modeling, deducing pair-wise independent SE(3)-equivariant LRF vectors for each point. For LRF-Refine, the optimization adjusts LRFs within specific contexts and knowledge, enhancing the geometric and semantic generalizability of point features. Our overall framework surpasses the state-of-the-art methods by a large margin on three benchmarks. Code and models will be publicly available."}
{"main_page": "https://arxiv.org/abs/2404.00960", "pdf": "https://arxiv.org/pdf/2404.00960", "title": "Randomized Nystr\u00f6m approximation of non-negative self-adjoint  operators", "authors": "David Persson, Nicolas Boull\u00e9, Daniel Kressner", "subjects": "Numerical Analysis (math.NA)", "abstract": "The randomized singular value decomposition (SVD) has become a popular approach to computing cheap, yet accurate, low-rank approximations to matrices due to its efficiency and strong theoretical guarantees. Recent work by Boull\\'e and Townsend (FoCM, 2023) presents an infinite-dimensional analog of the randomized SVD to approximate Hilbert-Schmidt operators. However, many applications involve computing low-rank approximations to symmetric positive semi-definite matrices. In this setting, it is well-established that the randomized Nystr{\\\"o}m approximation is usually preferred over the randomized SVD. This paper explores an infinite-dimensional analog of the Nystr{\\\"o}m approximation to compute low-rank approximations to non-negative self-adjoint trace-class operators. We present an analysis of the method and, along the way, improve the existing infinite-dimensional bounds for the randomized SVD. Our analysis yields bounds on the expected value and tail bounds for the Nystr{\\\"o}m approximation error in the operator, trace, and Hilbert-Schmidt norms. Numerical experiments for simple integral operators validate the proposed framework."}
{"main_page": "https://arxiv.org/abs/2404.00961", "pdf": "https://arxiv.org/pdf/2404.00961", "title": "Orchestrating UAVs for Prioritized Data Harvesting: A Cross-Layer  Optimization Perspective", "authors": "Bharath Keshavamurthy, Nicolo Michelusi", "subjects": "Systems and Control (eess.SY)", "abstract": "This work describes the orchestration of a fleet of rotary-wing Unmanned Aerial Vehicles (UAVs) for harvesting prioritized traffic from random distributions of heterogeneous users with Multiple Input Multiple Output (MIMO) capabilities. In a finite-horizon offline setting, the goal is to optimize the beam-forming design, the 3D UAV positioning and trajectory solution, and the user association/scheduling policy, to maximize the cumulative fleet-wide reward obtained by satisfying the quality-of-service mandates imposed on each user uplink request, subject to an average per-UAV mobility power constraint. With a probabilistic air-to-ground channel model, a multi-user MIMO uplink communication model with prioritized traffic, and a novel 3D mobility model for rotary-wing UAVs, the fleet-wide reward maximization problem is solved via a cross-layer optimization framework: first, K-means clustering is employed to obtain user clusters; then, equipped with a zero-forcing beam-forming design, the positions of the UAVs are optimized via two-stage grid search; next, treating these optimal positions as the graph vertices of a fully-connected mesh, the 3D UAV trajectories (i.e., graph edges) are designed via a learning based competitive swarm optimization algorithm, under an average UAV power consumption constraint, coupled with projected subgradient ascent for dual optimization; consequently, the user association/scheduling strategy is solved via a graphical branch-and-bound method on the underlying multiple traveling salesman problem. Numerical evaluations demonstrate that the proposed solution outperforms static UAV deployments, adaptive Voronoi decomposition techniques, and state-of-the-art iterative fleet control algorithms, with respect to user quality-of-service and per-UAV average power consumption."}
{"main_page": "https://arxiv.org/abs/2404.00962", "pdf": "https://arxiv.org/pdf/2404.00962", "title": "Diffusion-Driven Domain Adaptation for Generating 3D Molecules", "authors": "Haokai Hong, Wanyu Lin, Kay Chen Tan", "subjects": "Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Biomolecules (q-bio.BM)", "abstract": "Can we train a molecule generator that can generate 3D molecules from a new domain, circumventing the need to collect data? This problem can be cast as the problem of domain adaptive molecule generation. This work presents a novel and principled diffusion-based approach, called GADM, that allows shifting a generative model to desired new domains without the need to collect even a single molecule. As the domain shift is typically caused by the structure variations of molecules, e.g., scaffold variations, we leverage a designated equivariant masked autoencoder (MAE) along with various masking strategies to capture the structural-grained representations of the in-domain varieties. In particular, with an asymmetric encoder-decoder module, the MAE can generalize to unseen structure variations from the target domains. These structure variations are encoded with an equivariant encoder and treated as domain supervisors to control denoising. We show that, with these encoded structural-grained domain supervisors, GADM can generate effective molecules within the desired new domains. We conduct extensive experiments across various domain adaptation tasks over benchmarking datasets. We show that our approach can improve up to 65.6% in terms of success rate defined based on molecular validity, uniqueness, and novelty compared to alternative baselines."}
{"main_page": "https://arxiv.org/abs/2404.00964", "pdf": "https://arxiv.org/pdf/2404.00964", "title": "S2RC-GCN: A Spatial-Spectral Reliable Contrastive Graph Convolutional  Network for Complex Land Cover Classification Using Hyperspectral Images", "authors": "Renxiang Guan, Zihao Li, Chujia Song, Guo Yu, Xianju Li, Ruyi Feng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Spatial correlations between different ground objects are an important feature of mining land cover research. Graph Convolutional Networks (GCNs) can effectively capture such spatial feature representations and have demonstrated promising results in performing hyperspectral imagery (HSI) classification tasks of complex land. However, the existing GCN-based HSI classification methods are prone to interference from redundant information when extracting complex features. To classify complex scenes more effectively, this study proposes a novel spatial-spectral reliable contrastive graph convolutional classification framework named S2RC-GCN. Specifically, we fused the spectral and spatial features extracted by the 1D- and 2D-encoder, and the 2D-encoder includes an attention model to automatically extract important information. We then leveraged the fused high-level features to construct graphs and fed the resulting graphs into the GCNs to determine more effective graph representations. Furthermore, a novel reliable contrastive graph convolution was proposed for reliable contrastive learning to learn and fuse robust features. Finally, to test the performance of the model on complex object classification, we used imagery taken by Gaofen-5 in the Jiang Xia area to construct complex land cover datasets. The test results show that compared with other models, our model achieved the best results and effectively improved the classification performance of complex remote sensing imagery."}
{"main_page": "https://arxiv.org/abs/2404.00966", "pdf": "https://arxiv.org/pdf/2404.00966", "title": "GTS: GPU-based Tree Index for Fast Similarity Search", "authors": "Yifan Zhu, Ruiyao Ma, Baihua Zheng, Xiangyu Ke, Lu Chen, Yunjun Gao", "subjects": "Databases (cs.DB)", "abstract": "Similarity search, the task of identifying objects most similar to a given query object under a specific metric, has gathered significant attention due to its practical applications. However, the absence of coordinate information to accelerate similarity search and the high computational cost of measuring object similarity hinder the efficiency of existing CPU-based methods. Additionally, these methods struggle to meet the demand for high throughput data management. To address these challenges, we propose GTS, a GPU-based tree index designed for the parallel processing of similarity search in general metric spaces, where only the distance metric for measuring object similarity is known. The GTS index utilizes a pivot-based tree structure to efficiently prune objects and employs list tables to facilitate GPU computing. To efficiently manage concurrent similarity queries with limited GPU memory, we have developed a two-stage search method that combines batch processing and sequential strategies to optimize memory usage. The paper also introduces an effective update strategy for the proposed GPU-based index, encompassing streaming data updates and batch data updates. Additionally, we present a cost model to evaluate search performance. Extensive experiments on five real-life datasets demonstrate that GTS achieves efficiency gains of up to two orders of magnitude over existing CPU baselines and up to 20x efficiency improvements compared to state-of-the-art GPU-based methods."}
{"main_page": "https://arxiv.org/abs/2404.00968", "pdf": "https://arxiv.org/pdf/2404.00968", "title": "Optimal Bidding Strategies in Network-Constrained Demand Response: A  Distributed Aggregative Game Theoretic Approach", "authors": "Xiupeng Chen, Jacquelien M. A. Scherpen, Nima Monshizadeh", "subjects": "Systems and Control (eess.SY)", "abstract": "Demand response has been a promising solution for accommodating renewable energy in power systems. In this study, we consider a demand response scheme within a distribution network facing an energy supply deficit. The utility company incentivizes load aggregators to adjust their pre-scheduled energy consumption and generation to match the supply. Each aggregator, which represents a group of prosumers, aims to maximize its revenue by bidding strategically in the demand response scheme. Since aggregators act in their own self-interest and their revenues and feasible bids influence one another, we model their competition as a network-constrained aggregative game. This model incorporates power flow constraints to prevent potential line congestion. Given that there are no coordinators and aggregators can only communicate with their neighbours, we introduce a fully distributed generalized Nash equilibrium seeking algorithm to determine the optimal bidding strategies for aggregators in this game. Within this algorithm, only estimates of the aggregate and certain auxiliary variables are communicated among neighbouring aggregators. We demonstrate the convergence of this algorithm by constructing an equivalent iteration using the forward-backward splitting technique."}
{"main_page": "https://arxiv.org/abs/2404.00971", "pdf": "https://arxiv.org/pdf/2404.00971", "title": "Exploring and Evaluating Hallucinations in LLM-Powered Code Generation", "authors": "Fang Liu, Yang Liu, Lin Shi, Houkun Huang, Ruifeng Wang, Zhen Yang, Li Zhang", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "abstract": "The rise of Large Language Models (LLMs) has significantly advanced many applications on software engineering tasks, particularly in code generation. Despite the promising performance, LLMs are prone to generate hallucinations, which means LLMs might produce outputs that deviate from users' intent, exhibit internal inconsistencies, or misalign with the factual knowledge, making the deployment of LLMs potentially risky in a wide range of applications. Existing work mainly focuses on investing the hallucination in the domain of natural language generation (NLG), leaving a gap in understanding the types and extent of hallucinations in the context of code generation. To bridge the gap, we conducted a thematic analysis of the LLM-generated code to summarize and categorize the hallucinations present in it. Our study established a comprehensive taxonomy of hallucinations in LLM-generated code, encompassing 5 primary categories of hallucinations depending on the conflicting objectives and varying degrees of deviation observed in code generation. Furthermore, we systematically analyzed the distribution of hallucinations, exploring variations among different LLMs and their correlation with code correctness. Based on the results, we proposed HalluCode, a benchmark for evaluating the performance of code LLMs in recognizing hallucinations. Hallucination recognition and mitigation experiments with HalluCode and HumanEval show existing LLMs face great challenges in recognizing hallucinations, particularly in identifying their types, and are hardly able to mitigate hallucinations. We believe our findings will shed light on future research about hallucination evaluation, detection, and mitigation, ultimately paving the way for building more effective and reliable code LLMs in the future."}
{"main_page": "https://arxiv.org/abs/2404.00972", "pdf": "https://arxiv.org/pdf/2404.00972", "title": "Cross-channel Recommendation for Multi-channel Retail", "authors": "Yijin Choi, Jongkyung Shin, Chiehyeon Lim", "subjects": "Information Retrieval (cs.IR)", "abstract": "An increasing number of brick-and-mortar retailers are expanding their channels to the online domain, transforming them into multi-channel retailers. This transition emphasizes the need for cross-channel recommender systems, aiming to enhance revenue across both offline and online channels. Given that each retail channel represents a separate domain with a unique context, this can be regarded as a cross-domain recommendation (CDR). However, the existing studies on CDR did not address the scenarios where both users and items partially overlap across multi-retail channels which we define as \"cross-channel retail recommendation (CCRR)\". This paper introduces our original work on CCRR using real-world datasets from a multi-channel retail store. Specifically, (1) we present significant challenges in integrating user preferences across both channels. (2) Accordingly, we propose a novel model for CCRR using a channel-wise attention mechanism to capture different user preferences for the same item on each channel. We empirically validate our model's superiority in addressing CCRR over existing models. (3) Finally, we offer implications for future research on CCRR, delving into our experiment results."}
{"main_page": "https://arxiv.org/abs/2404.00973", "pdf": "https://arxiv.org/pdf/2404.00973", "title": "VideoDistill: Language-aware Vision Distillation for Video Question  Answering", "authors": "Bo Zou, Chao Yang, Yu Qiao, Chengbin Quan, Youjian Zhao", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Significant advancements in video question answering (VideoQA) have been made thanks to thriving large image-language pretraining frameworks. Although these image-language models can efficiently represent both video and language branches, they typically employ a goal-free vision perception process and do not interact vision with language well during the answer generation, thus omitting crucial visual cues. In this paper, we are inspired by the human recognition and learning pattern and propose VideoDistill, a framework with language-aware (i.e., goal-driven) behavior in both vision perception and answer generation process. VideoDistill generates answers only from question-related visual embeddings and follows a thinking-observing-answering approach that closely resembles human behavior, distinguishing it from previous research. Specifically, we develop a language-aware gating mechanism to replace the standard cross-attention, avoiding language's direct fusion into visual representations. We incorporate this mechanism into two key components of the entire framework. The first component is a differentiable sparse sampling module, which selects frames containing the necessary dynamics and semantics relevant to the questions. The second component is a vision refinement module that merges existing spatial-temporal attention layers to ensure the extraction of multi-grained visual semantics associated with the questions. We conduct experimental evaluations on various challenging video question-answering benchmarks, and VideoDistill achieves state-of-the-art performance in both general and long-form VideoQA datasets. In Addition, we verify that VideoDistill can effectively alleviate the utilization of language shortcut solutions in the EgoTaskQA dataset."}
{"main_page": "https://arxiv.org/abs/2404.00974", "pdf": "https://arxiv.org/pdf/2404.00974", "title": "Improving Visual Recognition with Hyperbolical Visual Hierarchy Mapping", "authors": "Hyeongjun Kwon, Jinhyun Jang, Jin Kim, Kwonyoung Kim, Kwanghoon Sohn", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Visual scenes are naturally organized in a hierarchy, where a coarse semantic is recursively comprised of several fine details. Exploring such a visual hierarchy is crucial to recognize the complex relations of visual elements, leading to a comprehensive scene understanding. In this paper, we propose a Visual Hierarchy Mapper (Hi-Mapper), a novel approach for enhancing the structured understanding of the pre-trained Deep Neural Networks (DNNs). Hi-Mapper investigates the hierarchical organization of the visual scene by 1) pre-defining a hierarchy tree through the encapsulation of probability densities; and 2) learning the hierarchical relations in hyperbolic space with a novel hierarchical contrastive loss. The pre-defined hierarchy tree recursively interacts with the visual features of the pre-trained DNNs through hierarchy decomposition and encoding procedures, thereby effectively identifying the visual hierarchy and enhancing the recognition of an entire scene. Extensive experiments demonstrate that Hi-Mapper significantly enhances the representation capability of DNNs, leading to an improved performance on various tasks, including image classification and dense prediction tasks."}
{"main_page": "https://arxiv.org/abs/2404.00978", "pdf": "https://arxiv.org/pdf/2404.00978", "title": "Prior Constraints-based Reward Model Training for Aligning Large  Language Models", "authors": "Hang Zhou, Chenglong Wang, Yimin Hu, Tong Xiao, Chunliang Zhang, Jingbo Zhu", "subjects": "Computation and Language (cs.CL)", "abstract": "Reinforcement learning with human feedback for aligning large language models (LLMs) trains a reward model typically using ranking loss with comparison pairs.However, the training procedure suffers from an inherent problem: the uncontrolled scaling of reward scores during reinforcement learning due to the lack of constraints while training the reward model.This paper proposes a Prior Constraints-based Reward Model (namely PCRM) training method to mitigate this problem. PCRM incorporates prior constraints, specifically, length ratio and cosine similarity between outputs of each comparison pair, during reward model training to regulate optimization magnitude and control score margins. We comprehensively evaluate PCRM by examining its rank correlation with human preferences and its effectiveness in aligning LLMs via RL. Experimental results demonstrate that PCRM significantly improves alignment performance by effectively constraining reward score scaling. As another bonus, our method is easily integrated into arbitrary rank-based alignment methods, such as direct preference optimization, and can yield consistent improvement."}
{"main_page": "https://arxiv.org/abs/2404.00979", "pdf": "https://arxiv.org/pdf/2404.00979", "title": "PDF: A Probability-Driven Framework for Open World 3D Point Cloud  Semantic Segmentation", "authors": "Jinfeng Xu, Siyuan Yang, Xianzhi Li, Yuan Tang, Yixue Hao, Long Hu, Min Chen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Existing point cloud semantic segmentation networks cannot identify unknown classes and update their knowledge, due to a closed-set and static perspective of the real world, which would induce the intelligent agent to make bad decisions. To address this problem, we propose a Probability-Driven Framework (PDF) for open world semantic segmentation that includes (i) a lightweight U-decoder branch to identify unknown classes by estimating the uncertainties, (ii) a flexible pseudo-labeling scheme to supply geometry features along with probability distribution features of unknown classes by generating pseudo labels, and (iii) an incremental knowledge distillation strategy to incorporate novel classes into the existing knowledge base gradually. Our framework enables the model to behave like human beings, which could recognize unknown objects and incrementally learn them with the corresponding knowledge. Experimental results on the S3DIS and ScanNetv2 datasets demonstrate that the proposed PDF outperforms other methods by a large margin in both important tasks of open world semantic segmentation."}
{"main_page": "https://arxiv.org/abs/2404.00980", "pdf": "https://arxiv.org/pdf/2404.00980", "title": "CAMO: Correlation-Aware Mask Optimization with Modulated Reinforcement  Learning", "authors": "Xiaoxiao Liang, Haoyu Yang, Kang Liu, Bei Yu, Yuzhe Ma", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Hardware Architecture (cs.AR)", "abstract": "Optical proximity correction (OPC) is a vital step to ensure printability in modern VLSI manufacturing. Various OPC approaches based on machine learning have been proposed to pursue performance and efficiency, which are typically data-driven and hardly involve any particular considerations of the OPC problem, leading to potential performance or efficiency bottlenecks. In this paper, we propose CAMO, a reinforcement learning-based OPC system that specifically integrates important principles of the OPC problem. CAMO explicitly involves the spatial correlation among the movements of neighboring segments and an OPC-inspired modulation for movement action selection. Experiments are conducted on both via layer patterns and metal layer patterns. The results demonstrate that CAMO outperforms state-of-the-art OPC engines from both academia and industry."}
{"main_page": "https://arxiv.org/abs/2404.00983", "pdf": "https://arxiv.org/pdf/2404.00983", "title": "Continual Learning for Smart City: A Survey", "authors": "Li Yang, Zhipeng Luo, Shiming Zhang, Fei Teng, Tianrui Li", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "With the digitization of modern cities, large data volumes and powerful computational resources facilitate the rapid update of intelligent models deployed in smart cities. Continual learning (CL) is a novel machine learning paradigm that constantly updates models to adapt to changing environments, where the learning tasks, data, and distributions can vary over time. Our survey provides a comprehensive review of continual learning methods that are widely used in smart city development. The content consists of three parts: 1) Methodology-wise. We categorize a large number of basic CL methods and advanced CL frameworks in combination with other learning paradigms including graph learning, spatial-temporal learning, multi-modal learning, and federated learning. 2) Application-wise. We present numerous CL applications covering transportation, environment, public health, safety, networks, and associated datasets related to urban computing. 3) Challenges. We discuss current problems and challenges and envision several promising research directions. We believe this survey can help relevant researchers quickly familiarize themselves with the current state of continual learning research used in smart city development and direct them to future research trends."}
{"main_page": "https://arxiv.org/abs/2404.00986", "pdf": "https://arxiv.org/pdf/2404.00986", "title": "Make Continual Learning Stronger via C-Flat", "authors": "Ang Bian, Wei Li, Hangjie Yuan, Chengrong Yu, Zixiang Zhao, Mang Wang, Aojun Lu, Tao Feng", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Model generalization ability upon incrementally acquiring dynamically updating knowledge from sequentially arriving tasks is crucial to tackle the sensitivity-stability dilemma in Continual Learning (CL). Weight loss landscape sharpness minimization seeking for flat minima lying in neighborhoods with uniform low loss or smooth gradient is proven to be a strong training regime improving model generalization compared with loss minimization based optimizer like SGD. Yet only a few works have discussed this training regime for CL, proving that dedicated designed zeroth-order sharpness optimizer can improve CL performance. In this work, we propose a Continual Flatness (C-Flat) method featuring a flatter loss landscape tailored for CL. C-Flat could be easily called with only one line of code and is plug-and-play to any CL methods. A general framework of C-Flat applied to all CL categories and a thorough comparison with loss minima optimizer and flat minima based CL approaches is presented in this paper, showing that our method can boost CL performance in almost all cases. Code will be publicly available upon publication."}
{"main_page": "https://arxiv.org/abs/2404.00987", "pdf": "https://arxiv.org/pdf/2404.00987", "title": "FlexiDreamer: Single Image-to-3D Generation with FlexiCubes", "authors": "Ruowen Zhao, Zhengyi Wang, Yikai Wang, Zihan Zhou, Jun Zhu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "3D content generation from text prompts or single images has made remarkable progress in quality and speed recently. One of its dominant paradigms involves generating consistent multi-view images followed by a sparse-view reconstruction. However, due to the challenge of directly deforming the mesh representation to approach the target topology, most methodologies learn an implicit representation (such as NeRF) during the sparse-view reconstruction and acquire the target mesh by a post-processing extraction. Although the implicit representation can effectively model rich 3D information, its training typically entails a long convergence time. In addition, the post-extraction operation from the implicit field also leads to undesirable visual artifacts. In this paper, we propose FlexiDreamer, a novel single image-to-3d generation framework that reconstructs the target mesh in an end-to-end manner. By leveraging a flexible gradient-based extraction known as FlexiCubes, our method circumvents the defects brought by the post-processing and facilitates a direct acquisition of the target mesh. Furthermore, we incorporate a multi-resolution hash grid encoding scheme that progressively activates the encoding levels into the implicit field in FlexiCubes to help capture geometric details for per-step optimization. Notably, FlexiDreamer recovers a dense 3D structure from a single-view image in approximately 1 minute on a single NVIDIA A100 GPU, outperforming previous methodologies by a large margin."}
{"main_page": "https://arxiv.org/abs/2404.00988", "pdf": "https://arxiv.org/pdf/2404.00988", "title": "Distributed Satellite-Terrestrial Cooperative Routing Strategy Based on  Minimum Hop-Count Analysis in Mega LEO Satellite Constellation", "authors": "Xin'ao Feng, Yaohua Sun, Mugen Peng", "subjects": "Networking and Internet Architecture (cs.NI)", "abstract": "Mega low earth orbit (LEO) satellite constellation is promising in achieving global coverage with high capacity. However, forwarding packets in mega constellation faces long end-to-end delay caused by multi-hop routing and high-complexity routing table construction, which will detrimentally impair the network transmission efficiency. To overcome this issue, a distributed low-complexity satellite-terrestrial cooperative routing approach is proposed in this paper, and its core idea is that each node forwards packets to next-hop node under the constraints of minimum end-to-end hop-count and queuing delay. Particularly, to achieve an accurate and low-complexity minimum end-to-end hop-count estimation in satellite-terrestrial cooperative routing scenario, we first introduce a satellite real-time position based graph (RTPG) to simplify the description of three-dimensional constellation, and further abstract RTPG into a key node based graph (KNBG). Considering the frequent regeneration of KNBG due to satellite movement, a low complexity generation method of KNBG is studied as well. Finally, utilizing KNBG as input, we design the minimum end-to-end hop-count estimation method (KNBG-MHCE). Meanwhile, the computational complexity, routing path survival probability and practical implementation of our proposal are all deeply discussed. Extensive simulations are also conducted in systems with Ka and laser band inter-satellite links to verify the superiority of our proposal."}
{"main_page": "https://arxiv.org/abs/2404.00989", "pdf": "https://arxiv.org/pdf/2404.00989", "title": "360+x: A Panoptic Multi-modal Scene Understanding Dataset", "authors": "Hao Chen, Yuqi Hou, Chenyuan Qu, Irene Testini, Xiaohan Hong, Jianbo Jiao", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "Human perception of the world is shaped by a multitude of viewpoints and modalities. While many existing datasets focus on scene understanding from a certain perspective (e.g. egocentric or third-person views), our dataset offers a panoptic perspective (i.e. multiple viewpoints with multiple data modalities). Specifically, we encapsulate third-person panoramic and front views, as well as egocentric monocular/binocular views with rich modalities including video, multi-channel audio, directional binaural delay, location data and textual scene descriptions within each scene captured, presenting comprehensive observation of the world. Figure 1 offers a glimpse of all 28 scene categories of our 360+x dataset. To the best of our knowledge, this is the first database that covers multiple viewpoints with multiple data modalities to mimic how daily information is accessed in the real world. Through our benchmark analysis, we presented 5 different scene understanding tasks on the proposed 360+x dataset to evaluate the impact and benefit of each data modality and perspective in panoptic scene understanding. We hope this unique dataset could broaden the scope of comprehensive scene understanding and encourage the community to approach these problems from more diverse perspectives."}
{"main_page": "https://arxiv.org/abs/2404.00990", "pdf": "https://arxiv.org/pdf/2404.00990", "title": "Exploring the Nexus of Large Language Models and Legal Systems: A Short  Survey", "authors": "Weicong Qin, Zhongxiang Sun", "subjects": "Computation and Language (cs.CL)", "abstract": "With the advancement of Artificial Intelligence (AI) and Large Language Models (LLMs), there is a profound transformation occurring in the realm of natural language processing tasks within the legal domain. The capabilities of LLMs are increasingly demonstrating unique roles in the legal sector, bringing both distinctive benefits and various challenges. This survey delves into the synergy between LLMs and the legal system, such as their applications in tasks like legal text comprehension, case retrieval, and analysis. Furthermore, this survey highlights key challenges faced by LLMs in the legal domain, including bias, interpretability, and ethical considerations, as well as how researchers are addressing these issues. The survey showcases the latest advancements in fine-tuned legal LLMs tailored for various legal systems, along with legal datasets available for fine-tuning LLMs in various languages. Additionally, it proposes directions for future research and development."}
{"main_page": "https://arxiv.org/abs/2404.00992", "pdf": "https://arxiv.org/pdf/2404.00992", "title": "SGCNeRF: Few-Shot Neural Rendering via Sparse Geometric Consistency  Guidance", "authors": "Yuru Xiao, Xianming Liu, Deming Zhai, Kui Jiang, Junjun Jiang, Xiangyang Ji", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Neural Radiance Field (NeRF) technology has made significant strides in creating novel viewpoints. However, its effectiveness is hampered when working with sparsely available views, often leading to performance dips due to overfitting. FreeNeRF attempts to overcome this limitation by integrating implicit geometry regularization, which incrementally improves both geometry and textures. Nonetheless, an initial low positional encoding bandwidth results in the exclusion of high-frequency elements. The quest for a holistic approach that simultaneously addresses overfitting and the preservation of high-frequency details remains ongoing. This study introduces a novel feature matching based sparse geometry regularization module. This module excels in pinpointing high-frequency keypoints, thereby safeguarding the integrity of fine details. Through progressive refinement of geometry and textures across NeRF iterations, we unveil an effective few-shot neural rendering architecture, designated as SGCNeRF, for enhanced novel view synthesis. Our experiments demonstrate that SGCNeRF not only achieves superior geometry-consistent outcomes but also surpasses FreeNeRF, with improvements of 0.7 dB and 0.6 dB in PSNR on the LLFF and DTU datasets, respectively."}
{"main_page": "https://arxiv.org/abs/2404.00994", "pdf": "https://arxiv.org/pdf/2404.00994", "title": "AMOR: Ambiguous Authorship Order", "authors": "Maximilian Weiherer, Andreea Dogaru, Shreya Kapoor, Hannah Schieber, Bernhard Egger", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "As we all know, writing scientific papers together with our beloved colleagues is a truly remarkable experience (partially): endless discussions about the same useless paragraph over and over again, followed by long days and long nights -- both at the same time. What a wonderful ride it is! What a beautiful life we have. But wait, there's one tiny little problem that utterly shatters the peace, turning even renowned scientists into bloodthirsty monsters: author order. The reason is that, contrary to widespread opinion, it's not the font size that matters, but the way things are ordered. Of course, this is a fairly well-known fact among scientists all across the planet (and beyond) and explains clearly why we regularly have to read about yet another escalated paper submission in local police reports. In this paper, we take an important step backwards to tackle this issue by solving the so-called author ordering problem (AOP) once and for all. Specifically, we propose AMOR, a system that replaces silly constructs like co-first or co-middle authorship with a simple yet easy probabilistic approach based on random shuffling of the author list at viewing time. In addition to AOP, we also solve the ambiguous author ordering citation problem} (AAOCP) on the fly. Stop author violence, be human."}
{"main_page": "https://arxiv.org/abs/2404.00995", "pdf": "https://arxiv.org/pdf/2404.00995", "title": "PosterLlama: Bridging Design Ability of Langauge Model to Contents-Aware  Layout Generation", "authors": "Jaejung Seol, Seojun Kim, Jaejun Yoo", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Visual layout plays a critical role in graphic design fields such as advertising, posters, and web UI design. The recent trend towards content-aware layout generation through generative models has shown promise, yet it often overlooks the semantic intricacies of layout design by treating it as a simple numerical optimization. To bridge this gap, we introduce PosterLlama, a network designed for generating visually and textually coherent layouts by reformatting layout elements into HTML code and leveraging the rich design knowledge embedded within language models. Furthermore, we enhance the robustness of our model with a unique depth-based poster augmentation strategy. This ensures our generated layouts remain semantically rich but also visually appealing, even with limited data. Our extensive evaluations across several benchmarks demonstrate that PosterLlama outperforms existing methods in producing authentic and content-aware layouts. It supports an unparalleled range of conditions, including but not limited to unconditional layout generation, element conditional layout generation, layout completion, among others, serving as a highly versatile user manipulation tool."}
{"main_page": "https://arxiv.org/abs/2404.00998", "pdf": "https://arxiv.org/pdf/2404.00998", "title": "LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report  Generation", "authors": "Zilong Wang, Xufang Luo, Xinyang Jiang, Dongsheng Li, Lili Qiu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Evaluating generated radiology reports is crucial for the development of radiology AI, but existing metrics fail to reflect the task's clinical requirements. This study proposes a novel evaluation framework using large language models (LLMs) to compare radiology reports for assessment. We compare the performance of various LLMs and demonstrate that, when using GPT-4, our proposed metric achieves evaluation consistency close to that of radiologists. Furthermore, to reduce costs and improve accessibility, making this method practical, we construct a dataset using LLM evaluation results and perform knowledge distillation to train a smaller model. The distilled model achieves evaluation capabilities comparable to GPT-4. Our framework and distilled model offer an accessible and efficient evaluation method for radiology report generation, facilitating the development of more clinically relevant models. The model will be further open-sourced and accessible."}
{"main_page": "https://arxiv.org/abs/2404.00999", "pdf": "https://arxiv.org/pdf/2404.00999", "title": "What Causes the Failure of Explicit to Implicit Discourse Relation  Recognition?", "authors": "Wei Liu, Stephen Wan, Michael Strube", "subjects": "Computation and Language (cs.CL)", "abstract": "We consider an unanswered question in the discourse processing community: why do relation classifiers trained on explicit examples (with connectives removed) perform poorly in real implicit scenarios? Prior work claimed this is due to linguistic dissimilarity between explicit and implicit examples but provided no empirical evidence. In this study, we show that one cause for such failure is a label shift after connectives are eliminated. Specifically, we find that the discourse relations expressed by some explicit instances will change when connectives disappear. Unlike previous work manually analyzing a few examples, we present empirical evidence at the corpus level to prove the existence of such shift. Then, we analyze why label shift occurs by considering factors such as the syntactic role played by connectives, ambiguity of connectives, and more. Finally, we investigate two strategies to mitigate the label shift: filtering out noisy data and joint learning with connectives. Experiments on PDTB 2.0, PDTB 3.0, and the GUM dataset demonstrate that classifiers trained with our strategies outperform strong baselines."}
{"main_page": "https://arxiv.org/abs/2404.01007", "pdf": "https://arxiv.org/pdf/2404.01007", "title": "Extraction of Singular Patterns from a Vector Field via Persistent Path  Homology", "authors": "Yu Chen, Hongwei Lin", "subjects": "Computational Geometry (cs.CG); Algebraic Topology (math.AT)", "abstract": "The extraction of singular patterns is a fundamental problem in theoretical and practical domains due to the ability of such patterns to detect the intrinsic characteristics of vector fields. In this study, we propose an approach for extracting singular patterns from discrete planar vector fields. Our method involves converting the planar discrete vector field into a specialized digraph and computing its one-dimensional persistent path homology. By analyzing the persistence diagram, we can determine the location of singularity and segment a region of the singular pattern, which is referred to as a singular polygon. Experimental results demonstrate the efficacy of our method in analyzing the centers and impact areas of tropical cyclones."}
{"main_page": "https://arxiv.org/abs/2404.01008", "pdf": "https://arxiv.org/pdf/2404.01008", "title": "EEG-SVRec: An EEG Dataset with User Multidimensional Affective  Engagement Labels in Short Video Recommendation", "authors": "Shaorun Zhang, Zhiyu He, Ziyi Ye, Peijie Sun, Qingyao Ai, Min Zhang, Yiqun Liu", "subjects": "Information Retrieval (cs.IR)", "abstract": "In recent years, short video platforms have gained widespread popularity, making the quality of video recommendations crucial for retaining users. Existing recommendation systems primarily rely on behavioral data, which faces limitations when inferring user preferences due to issues such as data sparsity and noise from accidental interactions or personal habits. To address these challenges and provide a more comprehensive understanding of user affective experience and cognitive activity, we propose EEG-SVRec, the first EEG dataset with User Multidimensional Affective Engagement Labels in Short Video Recommendation. The study involves 30 participants and collects 3,657 interactions, offering a rich dataset that can be used for a deeper exploration of user preference and cognitive activity. By incorporating selfassessment techniques and real-time, low-cost EEG signals, we offer a more detailed understanding user affective experiences (valence, arousal, immersion, interest, visual and auditory) and the cognitive mechanisms behind their behavior. We establish benchmarks for rating prediction by the recommendation algorithm, showing significant improvement with the inclusion of EEG signals. Furthermore, we demonstrate the potential of this dataset in gaining insights into the affective experience and cognitive activity behind user behaviors in recommender systems. This work presents a novel perspective for enhancing short video recommendation by leveraging the rich information contained in EEG signals and multidimensional affective engagement scores, paving the way for future research in short video recommendation systems."}
{"main_page": "https://arxiv.org/abs/2404.01009", "pdf": "https://arxiv.org/pdf/2404.01009", "title": "Constructing and Expanding Low-Resource and Underrepresented Parallel  Datasets for Indonesian Local Languages", "authors": "Joanito Agili Lopo, Radius Tanone", "subjects": "Computation and Language (cs.CL)", "abstract": "In Indonesia, local languages play an integral role in the culture. However, the available Indonesian language resources still fall into the category of limited data in the Natural Language Processing (NLP) field. This is become problematic when build NLP model for these languages. To address this gap, we introduce Bhinneka Korpus, a multilingual parallel corpus featuring five Indonesian local languages. Our goal is to enhance access and utilization of these resources, extending their reach within the country. We explained in a detail the dataset collection process and associated challenges. Additionally, we experimented with translation task using the IBM Model 1 due to data constraints. The result showed that the performance of each language already shows good indications for further development. Challenges such as lexical variation, smoothing effects, and cross-linguistic variability are discussed. We intend to evaluate the corpus using advanced NLP techniques for low-resource languages, paving the way for multilingual translation models."}
{"main_page": "https://arxiv.org/abs/2404.01012", "pdf": "https://arxiv.org/pdf/2404.01012", "title": "Query Performance Prediction using Relevance Judgments Generated by  Large Language Models", "authors": "Chuan Meng, Negar Arabzadeh, Arian Askari, Mohammad Aliannejadi, Maarten de Rijke", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Query performance prediction (QPP) aims to estimate the retrieval quality of a search system for a query without human relevance judgments. Previous QPP methods typically return a single scalar value and do not require the predicted values to approximate a specific information retrieval (IR) evaluation measure, leading to certain drawbacks: (i) a single scalar is insufficient to accurately represent different IR evaluation measures, especially when metrics do not highly correlate, and (ii) a single scalar limits the interpretability of QPP methods because solely using a scalar is insufficient to explain QPP results. To address these issues, we propose a QPP framework using automatically generated relevance judgments (QPP-GenRE), which decomposes QPP into independent subtasks of judging the relevance of each item in a ranked list to a given query. This allows us to predict any IR evaluation measure using the generated relevance judgments as pseudo-labels; Also, this allows us to interpret predicted IR evaluation measures, and identify, track and rectify errors in generated relevance judgments to improve QPP quality. We judge relevance by leveraging a leading open-source large language model (LLM), LLaMA, to ensure scientific reproducibility. In doing so, we address two main challenges: (i) excessive computational costs of judging the entire corpus for predicting a recall-based metric, and (ii) poor performance in prompting LLaMA in a zero-/few-shot manner. We devise an approximation strategy to predict a recall-oriented IR measure and propose to fine-tune LLaMA using human-labeled relevance judgments. Experiments on the TREC 2019-2022 deep learning tracks show that QPP-GenRE achieves state-of-the-art QPP accuracy for both lexical and neural rankers in both precision- and recall-oriented metrics."}
{"main_page": "https://arxiv.org/abs/2404.01013", "pdf": "https://arxiv.org/pdf/2404.01013", "title": "Teeth-SEG: An Efficient Instance Segmentation Framework for Orthodontic  Treatment based on Anthropic Prior Knowledge", "authors": "Bo Zou, Shaofeng Wang, Hao Liu, Gaoyue Sun, Yajie Wang, FeiFei Zuo, Chengbin Quan, Youjian Zhao", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Teeth localization, segmentation, and labeling in 2D images have great potential in modern dentistry to enhance dental diagnostics, treatment planning, and population-based studies on oral health. However, general instance segmentation frameworks are incompetent due to 1) the subtle differences between some teeth' shapes (e.g., maxillary first premolar and second premolar), 2) the teeth's position and shape variation across subjects, and 3) the presence of abnormalities in the dentition (e.g., caries and edentulism). To address these problems, we propose a ViT-based framework named TeethSEG, which consists of stacked Multi-Scale Aggregation (MSA) blocks and an Anthropic Prior Knowledge (APK) layer. Specifically, to compose the two modules, we design 1) a unique permutation-based upscaler to ensure high efficiency while establishing clear segmentation boundaries with 2) multi-head self/cross-gating layers to emphasize particular semantics meanwhile maintaining the divergence between token embeddings. Besides, we collect 3) the first open-sourced intraoral image dataset IO150K, which comprises over 150k intraoral photos, and all photos are annotated by orthodontists using a human-machine hybrid algorithm. Experiments on IO150K demonstrate that our TeethSEG outperforms the state-of-the-art segmentation models on dental image segmentation."}
{"main_page": "https://arxiv.org/abs/2404.01014", "pdf": "https://arxiv.org/pdf/2404.01014", "title": "Harnessing Large Language Models for Training-free Video Anomaly  Detection", "authors": "Luca Zanella, Willi Menapace, Massimiliano Mancini, Yiming Wang, Elisa Ricci", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Video anomaly detection (VAD) aims to temporally locate abnormal events in a video. Existing works mostly rely on training deep models to learn the distribution of normality with either video-level supervision, one-class supervision, or in an unsupervised setting. Training-based methods are prone to be domain-specific, thus being costly for practical deployment as any domain change will involve data collection and model training. In this paper, we radically depart from previous efforts and propose LAnguage-based VAD (LAVAD), a method tackling VAD in a novel, training-free paradigm, exploiting the capabilities of pre-trained large language models (LLMs) and existing vision-language models (VLMs). We leverage VLM-based captioning models to generate textual descriptions for each frame of any test video. With the textual scene description, we then devise a prompting mechanism to unlock the capability of LLMs in terms of temporal aggregation and anomaly score estimation, turning LLMs into an effective video anomaly detector. We further leverage modality-aligned VLMs and propose effective techniques based on cross-modal similarity for cleaning noisy captions and refining the LLM-based anomaly scores. We evaluate LAVAD on two large datasets featuring real-world surveillance scenarios (UCF-Crime and XD-Violence), showing that it outperforms both unsupervised and one-class methods without requiring any training or data collection."}
{"main_page": "https://arxiv.org/abs/2404.01015", "pdf": "https://arxiv.org/pdf/2404.01015", "title": "PairEval: Open-domain Dialogue Evaluation with Pairwise Comparison", "authors": "ChaeHun Park, Minseok Choi, Dohyun Lee, Jaegul Choo", "subjects": "Computation and Language (cs.CL)", "abstract": "Building a reliable and automated evaluation metric is a necessary but challenging problem for open-domain dialogue systems. Recent studies proposed evaluation metrics that assess generated responses by considering their relevance to previous dialogue histories. Although effective, these metrics evaluate individual responses directly rather than considering their relative quality compared to other responses. To handle this, we propose PairEval, a novel dialogue evaluation metric for assessing responses by comparing their quality against responses in different conversations. PairEval is built on top of open-sourced and moderate-size language models, and we make them specialized in pairwise comparison between dialogue responses. Extensive experiments on multiple benchmarks demonstrate that our metric exhibits a higher correlation with human judgments than baseline metrics. We also find that the proposed comparative metric is more robust in detecting common failures from open-domain dialogue systems, including repetition and speaker insensitivity."}
{"main_page": "https://arxiv.org/abs/2404.01019", "pdf": "https://arxiv.org/pdf/2404.01019", "title": "Source-Aware Training Enables Knowledge Attribution in Language Models", "authors": "Muhammad Khalifa, David Wadden, Emma Strubell, Honglak Lee, Lu Wang, Iz Beltagy, Hao Peng", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Large language models (LLMs) learn a vast amount of knowledge during pretraining, but they are often oblivious to the source(s) of such knowledge. We investigate the problem of intrinsic source citation, where LLMs are required to cite the pretraining source supporting a generated response. Intrinsic source citation can enhance LLM transparency, interpretability, and verifiability. To give LLMs such ability, we explore source-aware training -- a post pretraining recipe that involves (i) training the LLM to associate unique source document identifiers with the knowledge in each document, followed by (ii) an instruction-tuning to teach the LLM to cite a supporting pretraining source when prompted. Source-aware training can easily be applied to pretrained LLMs off the shelf, and diverges minimally from existing pretraining/fine-tuning frameworks. Through experiments on carefully curated data, we demonstrate that our training recipe can enable faithful attribution to the pretraining data without a substantial impact on the model's quality compared to standard pretraining. Our results also highlight the importance of data augmentation in achieving attribution."}
{"main_page": "https://arxiv.org/abs/2404.01022", "pdf": "https://arxiv.org/pdf/2404.01022", "title": "On the Complexity of Minimizing Energy Consumption of Partitioning DAG  Tasks", "authors": "Wei Liu, Jian-Jia Chen, Yongjie Yang", "subjects": "Computational Complexity (cs.CC)", "abstract": "We study a graph partition problem where we are given a directed acyclic graph (DAG) whose vertices and arcs can be respectively regarded as tasks and dependencies among tasks. The objective of the problem is to minimize the total energy consumed for completing these tasks by assigning the tasks to k heterogeneous machines. We first show that the problem is NP-hard. Then, we present polynomial-time algorithms for two special cases where there are only two machines and where the input DAG is a directed path. Finally, we study a natural variant where there are only two machines with one of them being capable of executing a limited number of tasks. We show that this special case remains computationally hard."}
{"main_page": "https://arxiv.org/abs/2404.01023", "pdf": "https://arxiv.org/pdf/2404.01023", "title": "Large Language Model Evaluation Via Multi AI Agents: Preliminary results", "authors": "Zeeshan Rasheed, Muhammad Waseem, Kari Syst\u00e4, Pekka Abrahamsson", "subjects": "Software Engineering (cs.SE)", "abstract": "As Large Language Models (LLMs) have become integral to both research and daily operations, rigorous evaluation is crucial. This assessment is important not only for individual tasks but also for understanding their societal impact and potential risks. Despite extensive efforts to examine LLMs from various perspectives, there is a noticeable lack of multi-agent AI models specifically designed to evaluate the performance of different LLMs. To address this gap, we introduce a novel multi-agent AI model that aims to assess and compare the performance of various LLMs. Our model consists of eight distinct AI agents, each responsible for retrieving code based on a common description from different advanced language models, including GPT-3.5, GPT-3.5 Turbo, GPT-4, GPT-4 Turbo, Google Bard, LLAMA, and Hugging Face. Our developed model utilizes the API of each language model to retrieve code for a given high-level description. Additionally, we developed a verification agent, tasked with the critical role of evaluating the code generated by its counterparts. We integrate the HumanEval benchmark into our verification agent to assess the generated code's performance, providing insights into their respective capabilities and efficiencies. Our initial results indicate that the GPT-3.5 Turbo model's performance is comparatively better than the other models. This preliminary analysis serves as a benchmark, comparing their performances side by side. Our future goal is to enhance the evaluation process by incorporating the Massively Multitask Benchmark for Python (MBPP) benchmark, which is expected to further refine our assessment. Additionally, we plan to share our developed model with twenty practitioners from various backgrounds to test our model and collect their feedback for further improvement."}
{"main_page": "https://arxiv.org/abs/2404.01024", "pdf": "https://arxiv.org/pdf/2404.01024", "title": "AIGCOIQA2024: Perceptual Quality Assessment of AI Generated  Omnidirectional Images", "authors": "Liu Yang, Huiyu Duan, Long Teng, Yucheng Zhu, Xiaohong Liu, Menghan Hu, Xiongkuo Min, Guangtao Zhai, Patrick Le Callet", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "In recent years, the rapid advancement of Artificial Intelligence Generated Content (AIGC) has attracted widespread attention. Among the AIGC, AI generated omnidirectional images hold significant potential for Virtual Reality (VR) and Augmented Reality (AR) applications, hence omnidirectional AIGC techniques have also been widely studied. AI-generated omnidirectional images exhibit unique distortions compared to natural omnidirectional images, however, there is no dedicated Image Quality Assessment (IQA) criteria for assessing them. This study addresses this gap by establishing a large-scale AI generated omnidirectional image IQA database named AIGCOIQA2024 and constructing a comprehensive benchmark. We first generate 300 omnidirectional images based on 5 AIGC models utilizing 25 text prompts. A subjective IQA experiment is conducted subsequently to assess human visual preferences from three perspectives including quality, comfortability, and correspondence. Finally, we conduct a benchmark experiment to evaluate the performance of state-of-the-art IQA models on our database. The database will be released to facilitate future research."}
{"main_page": "https://arxiv.org/abs/2404.01029", "pdf": "https://arxiv.org/pdf/2404.01029", "title": "Verifying Claims About Metaphors with Large-Scale Automatic Metaphor  Identification", "authors": "Kotaro Aono, Ryohei Sasano, Koichi Takeda", "subjects": "Computation and Language (cs.CL)", "abstract": "There are several linguistic claims about situations where words are more likely to be used as metaphors. However, few studies have sought to verify such claims with large corpora. This study entails a large-scale, corpus-based analysis of certain existing claims about verb metaphors, by applying metaphor detection to sentences extracted from Common Crawl and using the statistics obtained from the results. The verification results indicate that the direct objects of verbs used as metaphors tend to have lower degrees of concreteness, imageability, and familiarity, and that metaphors are more likely to be used in emotional and subjective sentences."}
{"main_page": "https://arxiv.org/abs/2404.01030", "pdf": "https://arxiv.org/pdf/2404.01030", "title": "Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and  Mitigation", "authors": "Yixin Wan, Arjun Subramonian, Anaelia Ovalle, Zongyu Lin, Ashima Suvarna, Christina Chance, Hritik Bansal, Rebecca Pattichis, Kai-Wei Chang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "The recent advancement of large and powerful models with Text-to-Image (T2I) generation abilities -- such as OpenAI's DALLE-3 and Google's Gemini -- enables users to generate high-quality images from textual prompts. However, it has become increasingly evident that even simple prompts could cause T2I models to exhibit conspicuous social bias in generated images. Such bias might lead to both allocational and representational harms in society, further marginalizing minority groups. Noting this problem, a large body of recent works has been dedicated to investigating different dimensions of bias in T2I systems. However, an extensive review of these studies is lacking, hindering a systematic understanding of current progress and research gaps. We present the first extensive survey on bias in T2I generative models. In this survey, we review prior studies on dimensions of bias: Gender, Skintone, and Geo-Culture. Specifically, we discuss how these works define, evaluate, and mitigate different aspects of bias. We found that: (1) while gender and skintone biases are widely studied, geo-cultural bias remains under-explored; (2) most works on gender and skintone bias investigated occupational association, while other aspects are less frequently studied; (3) almost all gender bias works overlook non-binary identities in their studies; (4) evaluation datasets and metrics are scattered, with no unified framework for measuring biases; and (5) current mitigation methods fail to resolve biases comprehensively. Based on current limitations, we point out future research directions that contribute to human-centric definitions, evaluations, and mitigation of biases. We hope to highlight the importance of studying biases in T2I systems, as well as encourage future efforts to holistically understand and tackle biases, building fair and trustworthy T2I technologies for everyone."}
{"main_page": "https://arxiv.org/abs/2404.01036", "pdf": "https://arxiv.org/pdf/2404.01036", "title": "Higher education assessment practice in the era of generative AI tools", "authors": "Bayode Ogunleye, Kudirat Ibilola Zakariyyah, Oluwaseun Ajao, Olakunle Olayinka, Hemlata Sharma", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "The higher education (HE) sector benefits every nation's economy and society at large. However, their contributions are challenged by advanced technologies like generative artificial intelligence (GenAI) tools. In this paper, we provide a comprehensive assessment of GenAI tools towards assessment and pedagogic practice and, subsequently, discuss the potential impacts. This study experimented using three assessment instruments from data science, data analytics, and construction management disciplines. Our findings are two-fold: first, the findings revealed that GenAI tools exhibit subject knowledge, problem-solving, analytical, critical thinking, and presentation skills and thus can limit learning when used unethically. Secondly, the design of the assessment of certain disciplines revealed the limitations of the GenAI tools. Based on our findings, we made recommendations on how AI tools can be utilised for teaching and learning in HE."}
{"main_page": "https://arxiv.org/abs/2404.01037", "pdf": "https://arxiv.org/pdf/2404.01037", "title": "ARAGOG: Advanced RAG Output Grading", "authors": "Matou\u0161 Eibich, Shivay Nagpal, Alexander Fred-Ojala", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "Retrieval-Augmented Generation (RAG) is essential for integrating external knowledge into Large Language Model (LLM) outputs. While the literature on RAG is growing, it primarily focuses on systematic reviews and comparisons of new state-of-the-art (SoTA) techniques against their predecessors, with a gap in extensive experimental comparisons. This study begins to address this gap by assessing various RAG methods' impacts on retrieval precision and answer similarity. We found that Hypothetical Document Embedding (HyDE) and LLM reranking significantly enhance retrieval precision. However, Maximal Marginal Relevance (MMR) and Cohere rerank did not exhibit notable advantages over a baseline Naive RAG system, and Multi-query approaches underperformed. Sentence Window Retrieval emerged as the most effective for retrieval precision, despite its variable performance on answer similarity. The study confirms the potential of the Document Summary Index as a competent retrieval approach. All resources related to this research are publicly accessible for further investigation through our GitHub repository ARAGOG (https://github.com/predlico/ARAGOG). We welcome the community to further this exploratory study in RAG systems."}
{"main_page": "https://arxiv.org/abs/2404.01039", "pdf": "https://arxiv.org/pdf/2404.01039", "title": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step  Guide", "authors": "Sunwoo Kim, Soo Yong Lee, Yue Gao, Alessia Antelmi, Mirko Polato, Kijung Shin", "subjects": "Machine Learning (cs.LG)", "abstract": "Higher-order interactions (HOIs) are ubiquitous in real-world complex systems and applications, and thus investigation of deep learning for HOIs has become a valuable agenda for the data mining and machine learning communities. As networks of HOIs are expressed mathematically as hypergraphs, hypergraph neural networks (HNNs) have emerged as a powerful tool for representation learning on hypergraphs. Given the emerging trend, we present the first survey dedicated to HNNs, with an in-depth and step-by-step guide. Broadly, the present survey overviews HNN architectures, training strategies, and applications. First, we break existing HNNs down into four design components: (i) input features, (ii) input structures, (iii) message-passing schemes, and (iv) training strategies. Second, we examine how HNNs address and learn HOIs with each of their components. Third, we overview the recent applications of HNNs in recommendation, biological and medical science, time series analysis, and computer vision. Lastly, we conclude with a discussion on limitations and future directions."}
{"main_page": "https://arxiv.org/abs/2404.01041", "pdf": "https://arxiv.org/pdf/2404.01041", "title": "Can LLMs get help from other LLMs without revealing private information?", "authors": "Florian Hartmann, Duc-Hieu Tran, Peter Kairouz, Victor C\u0103rbune, Blaise Aguera y Arcas", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)", "abstract": "Cascades are a common type of machine learning systems in which a large, remote model can be queried if a local model is not able to accurately label a user's data by itself. Serving stacks for large language models (LLMs) increasingly use cascades due to their ability to preserve task performance while dramatically reducing inference costs. However, applying cascade systems in situations where the local model has access to sensitive data constitutes a significant privacy risk for users since such data could be forwarded to the remote model. In this work, we show the feasibility of applying cascade systems in such setups by equipping the local model with privacy-preserving techniques that reduce the risk of leaking private information when querying the remote model. To quantify information leakage in such setups, we introduce two privacy measures. We then propose a system that leverages the recently introduced social learning paradigm in which LLMs collaboratively learn from each other by exchanging natural language. Using this paradigm, we demonstrate on several datasets that our methods minimize the privacy loss while at the same time improving task performance compared to a non-cascade baseline."}
{"main_page": "https://arxiv.org/abs/2404.01050", "pdf": "https://arxiv.org/pdf/2404.01050", "title": "Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic  Propagation", "authors": "Haofeng Liu, Chenshu Xu, Yifei Yang, Lihua Zeng, Shengfeng He", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "abstract": "Point-based interactive editing serves as an essential tool to complement the controllability of existing generative models. A concurrent work, DragDiffusion, updates the diffusion latent map in response to user inputs, causing global latent map alterations. This results in imprecise preservation of the original content and unsuccessful editing due to gradient vanishing. In contrast, we present DragNoise, offering robust and accelerated editing without retracing the latent map. The core rationale of DragNoise lies in utilizing the predicted noise output of each U-Net as a semantic editor. This approach is grounded in two critical observations: firstly, the bottleneck features of U-Net inherently possess semantically rich features ideal for interactive editing; secondly, high-level semantics, established early in the denoising process, show minimal variation in subsequent stages. Leveraging these insights, DragNoise edits diffusion semantics in a single denoising step and efficiently propagates these changes, ensuring stability and efficiency in diffusion editing. Comparative experiments reveal that DragNoise achieves superior control and semantic retention, reducing the optimization time by over 50% compared to DragDiffusion. Our codes are available at https://github.com/haofengl/DragNoise."}
{"main_page": "https://arxiv.org/abs/2404.01051", "pdf": "https://arxiv.org/pdf/2404.01051", "title": "Action Detection via an Image Diffusion Process", "authors": "Lin Geng Foo, Tianjiao Li, Hossein Rahmani, Jun Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Action detection aims to localize the starting and ending points of action instances in untrimmed videos, and predict the classes of those instances. In this paper, we make the observation that the outputs of the action detection task can be formulated as images. Thus, from a novel perspective, we tackle action detection via a three-image generation process to generate starting point, ending point and action-class predictions as images via our proposed Action Detection Image Diffusion (ADI-Diff) framework. Furthermore, since our images differ from natural images and exhibit special properties, we further explore a Discrete Action-Detection Diffusion Process and a Row-Column Transformer design to better handle their processing. Our ADI-Diff framework achieves state-of-the-art results on two widely-used datasets."}
{"main_page": "https://arxiv.org/abs/2404.01053", "pdf": "https://arxiv.org/pdf/2404.01053", "title": "HAHA: Highly Articulated Gaussian Human Avatars with Textured Mesh Prior", "authors": "David Svitov, Pietro Morerio, Lourdes Agapito, Alessio Del Bue", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present HAHA - a novel approach for animatable human avatar generation from monocular input videos. The proposed method relies on learning the trade-off between the use of Gaussian splatting and a textured mesh for efficient and high fidelity rendering. We demonstrate its efficiency to animate and render full-body human avatars controlled via the SMPL-X parametric model. Our model learns to apply Gaussian splatting only in areas of the SMPL-X mesh where it is necessary, like hair and out-of-mesh clothing. This results in a minimal number of Gaussians being used to represent the full avatar, and reduced rendering artifacts. This allows us to handle the animation of small body parts such as fingers that are traditionally disregarded. We demonstrate the effectiveness of our approach on two open datasets: SnapshotPeople and X-Humans. Our method demonstrates on par reconstruction quality to the state-of-the-art on SnapshotPeople, while using less than a third of Gaussians. HAHA outperforms previous state-of-the-art on novel poses from X-Humans both quantitatively and qualitatively."}
{"main_page": "https://arxiv.org/abs/2404.01054", "pdf": "https://arxiv.org/pdf/2404.01054", "title": "Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language  Model Alignment", "authors": "Yuu Jinnai, Tetsuro Morimura, Kaito Ariu, Kenshi Abe", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Best-of-N (BoN) sampling with a reward model has been shown to be an effective strategy for aligning Large Language Models (LLMs) to human preferences at the time of decoding. BoN sampling is susceptible to a problem known as reward hacking. Because the reward model is an imperfect proxy for the true objective, over-optimizing its value can compromise its performance on the true objective. A common solution to prevent reward hacking in preference learning techniques is to optimize a reward using proximity regularization (e.g., KL regularization), which ensures that the language model remains close to the reference model. In this research, we propose Regularized Best-of-N (RBoN), a variant of BoN that aims to mitigate reward hacking by incorporating a proximity term in response selection, similar to preference learning techniques. We evaluate two variants of RBoN on the AlpacaFarm dataset and find that they outperform BoN, especially when the proxy reward model has a low correlation with the true objective."}
{"main_page": "https://arxiv.org/abs/2404.01055", "pdf": "https://arxiv.org/pdf/2404.01055", "title": "Quantum circuit scheduler for QPUs usage optimization", "authors": "Javier Romero-Alvarez, Jaime Alvarado-Valiente, Jorge Casco-Seco, Enrique Moguel, Jose Garcia-Alonso, Javier Berrocal, Juan M. Murillo", "subjects": "Software Engineering (cs.SE)", "abstract": "Progress in the realm of quantum technologies is paving the way for a multitude of potential applications across different sectors. However, the reduced number of available quantum computers, their technical limitations and the high demand for their use are posing some problems for developers and researchers. Mainly, users trying to execute quantum circuits on these devices are usually facing long waiting times in the tasks queues. In this context, this work propose a technique to reduce waiting times and optimize quantum computers usage by scheduling circuits from different users into combined circuits that are executed at the same time. To validate this proposal, different widely known quantum algorithms have been selected and executed in combined circuits. The obtained results are then compared with the results of executing the same algorithms in an isolated way. This allowed us to measure the impact of the use of the scheduler. Among the obtained results, it has been possible to verify that the noise suffered by executing a combination of circuits through the proposed scheduler does not critically affect the outcomes."}
{"main_page": "https://arxiv.org/abs/2404.01058", "pdf": "https://arxiv.org/pdf/2404.01058", "title": "A Novel Audio Representation for Music Genre Identification in MIR", "authors": "Navin Kamuni, Mayank Jindal, Arpita Soni, Sukender Reddy Mallreddy, Sharath Chandra Macha", "subjects": "Sound (cs.SD); Information Retrieval (cs.IR); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)", "abstract": "For Music Information Retrieval downstream tasks, the most common audio representation is time-frequency-based, such as Mel spectrograms. In order to identify musical genres, this study explores the possibilities of a new form of audio representation one of the most usual MIR downstream tasks. Therefore, to discretely encoding music using deep vector quantization; a novel audio representation was created for the innovative generative music model i.e. Jukebox. The effectiveness of Jukebox's audio representation is compared to Mel spectrograms using a dataset that is almost equivalent to State-of-the-Art (SOTA) and an almost same transformer design. The results of this study imply that, at least when the transformers are pretrained using a very modest dataset of 20k tracks, Jukebox's audio representation is not superior to Mel spectrograms. This could be explained by the fact that Jukebox's audio representation does not sufficiently take into account the peculiarities of human hearing perception. On the other hand, Mel spectrograms are specifically created with the human auditory sense in mind."}
{"main_page": "https://arxiv.org/abs/2404.01059", "pdf": "https://arxiv.org/pdf/2404.01059", "title": "STAR-RIS Aided Secure MIMO Communication Systems", "authors": "Xiequn Dong, Zesong Fei, Xinyi Wang, Meng Hua, Qingqing Wu", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "This paper investigates simultaneous transmission and reflection reconfigurable intelligent surface (STAR-RIS) aided physical layer security (PLS) in multiple-input multiple-output (MIMO) systems, where the base station (BS) transmits secrecy information with the aid of STAR-RIS against multiple eavesdroppers equipped with multiple antennas. We aim to maximize the secrecy rate by jointly optimizing the active beamforming at the BS and passive beamforming at the STAR-RIS, subject to the hardware constraint for STAR-RIS. To handle the coupling variables, a minimum mean-square error (MMSE) based alternating optimization (AO) algorithm is applied. In particular, the amplitudes and phases of STAR-RIS are divided into two blocks to simplify the algorithm design. Besides, by applying the Majorization-Minimization (MM) method, we derive a closed-form expression of the STAR-RIS's phase shifts. Numerical results show that the proposed scheme significantly outperforms various benchmark schemes, especially as the number of STAR-RIS elements increases."}
{"main_page": "https://arxiv.org/abs/2404.01060", "pdf": "https://arxiv.org/pdf/2404.01060", "title": "A comparison of Single- and Double-generator formalisms for  Thermodynamics-Informed Neural Networks", "authors": "Pau Urdeitx, Ic\u00edar Alfaro, David Gonz\u00e1lez, Francisco Chinesta, El\u00edas Cueto", "subjects": "Machine Learning (cs.LG)", "abstract": "The development of inductive biases has been shown to be a very effective way to increase the accuracy and robustness of neural networks, particularly when they are used to predict physical phenomena. These biases significantly increase the certainty of predictions, decrease the error made and allow considerably smaller datasets to be used. There are a multitude of methods in the literature to develop these biases. One of the most effective ways, when dealing with physical phenomena, is to introduce physical principles of recognised validity into the network architecture. The problem becomes more complex without knowledge of the physical principles governing the phenomena under study. A very interesting possibility then is to turn to the principles of thermodynamics, which are universally valid, regardless of the level of abstraction of the description sought for the phenomenon under study. To ensure compliance with the principles of thermodynamics, there are formulations that have a long tradition in many branches of science. In the field of rheology, for example, two main types of formalisms are used to ensure compliance with these principles: one-generator and two-generator formalisms. In this paper we study the advantages and disadvantages of each, using classical problems with known solutions and synthetic data."}
{"main_page": "https://arxiv.org/abs/2404.01063", "pdf": "https://arxiv.org/pdf/2404.01063", "title": "Chat Modeling: Natural Language-based Procedural Modeling of Biological  Structures without Training", "authors": "Donggang Jia, Yunhai Wang, Ivan Viola", "subjects": "Human-Computer Interaction (cs.HC); Graphics (cs.GR)", "abstract": "3D modeling of biological structures is an inherently complex process, necessitating both biological and geometric understanding. Additionally, the complexity of user interfaces of 3D modeling tools and the associated steep learning curve further exacerbate the difficulty of authoring a 3D model. In this paper, we introduce a novel framework to address the challenge of using 3D modeling software by converting users' textual inputs into modeling actions within an interactive procedural modeling system. The framework incorporates a code generator of a novel code format and a corresponding code interpreter. The major technical innovation includes the user-refinement mechanism that captures the degree of user dissatisfaction with the modeling outcome, offers an interactive revision, and leverages this feedback for future improved 3D modeling. This entire framework is powered by large language models and eliminates the need for a traditional training process. We develop a prototype tool named Chat Modeling, offering both automatic and step-by-step 3D modeling approaches. Our evaluation of the framework with structural biologists highlights the potential of our approach being utilized in their scientific workflows. All supplemental materials are available at https://osf.io/x4qb7/."}
{"main_page": "https://arxiv.org/abs/2404.01064", "pdf": "https://arxiv.org/pdf/2404.01064", "title": "Roadside Monocular 3D Detection via 2D Detection Prompting", "authors": "Yechi Ma, Shuoquan Wei, Churun Zhang, Wei Hua, Yanan Li, Shu Kong", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The problem of roadside monocular 3D detection requires detecting objects of interested classes in a 2D RGB frame and predicting their 3D information such as locations in bird's-eye-view (BEV). It has broad applications in traffic control, vehicle-vehicle communication, and vehicle-infrastructure cooperative perception. To approach this problem, we present a novel and simple method by prompting the 3D detector using 2D detections. Our method builds on a key insight that, compared with 3D detectors, a 2D detector is much easier to train and performs significantly better w.r.t detections on the 2D image plane. That said, one can exploit 2D detections of a well-trained 2D detector as prompts to a 3D detector, being trained in a way of inflating such 2D detections to 3D towards 3D detection. To construct better prompts using the 2D detector, we explore three techniques: (a) concatenating both 2D and 3D detectors' features, (b) attentively fusing 2D and 3D detectors' features, and (c) encoding predicted 2D boxes x, y, width, height, label and attentively fusing such with the 3D detector's features. Surprisingly, the third performs the best. Moreover, we present a yaw tuning tactic and a class-grouping strategy that merges classes based on their functionality; these techniques improve 3D detection performance further. Comprehensive ablation studies and extensive experiments demonstrate that our method resoundingly outperforms prior works, achieving the state-of-the-art on two large-scale roadside 3D detection benchmarks."}
{"main_page": "https://arxiv.org/abs/2404.01065", "pdf": "https://arxiv.org/pdf/2404.01065", "title": "T-Mamba: Frequency-Enhanced Gated Long-Range Dependency for Tooth 3D  CBCT Segmentation", "authors": "Jing Hao, Lei He, Kuo Feng Hung", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Efficient tooth segmentation in three-dimensional (3D) imaging, critical for orthodontic diagnosis, remains challenging due to noise, low contrast, and artifacts in CBCT images. Both convolutional Neural Networks (CNNs) and transformers have emerged as popular architectures for image segmentation. However, their efficacy in handling long-range dependencies is limited due to inherent locality or computational complexity. To address this issue, we propose T-Mamba, integrating shared positional encoding and frequency-based features into vision mamba, to address limitations in spatial position preservation and feature enhancement in frequency domain. Besides, we also design a gate selection unit to integrate two features in spatial domain and one feature in frequency domain adaptively. T-Mamba is the first work to introduce frequency-based features into vision mamba. Extensive experiments demonstrate that T-Mamba achieves new SOTA results on the public Tooth CBCT dataset and outperforms previous SOTA methods by a large margin, i.e., IoU + 3.63%, SO + 2.43%, DSC +2.30%, HD -4.39mm, and ASSD -0.37mm. The code and models are publicly available at https://github.com/isbrycee/T-Mamba."}
{"main_page": "https://arxiv.org/abs/2404.01066", "pdf": "https://arxiv.org/pdf/2404.01066", "title": "Steering game dynamics towards desired outcomes", "authors": "Ilayda Canyakmaz, Iosif Sakos, Wayne Lin, Antonios Varvitsiotis, Georgios Piliouras", "subjects": "Systems and Control (eess.SY); Computer Science and Game Theory (cs.GT)", "abstract": "The dynamic behavior of agents in games, which captures how their strategies evolve over time based on past interactions, can lead to a spectrum of undesirable behaviors, ranging from non-convergence to Nash equilibria to the emergence of limit cycles and chaos. To mitigate the effects of selfish behavior, central planners can use dynamic payments to guide strategic multi-agent systems toward stability and socially optimal outcomes. However, the effectiveness of such interventions critically relies on accurately predicting agents' responses to incentives and dynamically adjusting payments so that the system is guided towards the desired outcomes. These challenges are further amplified in real-time applications where the dynamics are unknown and only scarce data is available. To tackle this challenge, in this work we introduce the SIAR-MPC method, combining the recently introduced Side Information Assisted Regression (SIAR) method for system identification with Model Predictive Control (MPC). SIAR utilizes side-information constraints inherent to game theoretic applications to model agent responses to payments from scarce data, while MPC uses this model to facilitate dynamic payment adjustments. Our experiments demonstrate the efficiency of SIAR-MPC in guiding the system towards socially optimal equilibria, stabilizing chaotic behaviors, and avoiding specified regions of the state space. Comparative analyses in data-scarce settings show SIAR-MPC's superior performance over pairing MPC with Physics Informed Neural Networks (PINNs), a powerful system identification method that finds models satisfying specific constraints."}
{"main_page": "https://arxiv.org/abs/2404.01067", "pdf": "https://arxiv.org/pdf/2404.01067", "title": "Exploring the Mystery of Influential Data for Mathematical Reasoning", "authors": "Xinzhe Ni, Yeyun Gong, Zhibin Gou, Yelong Shen, Yujiu Yang, Nan Duan, Weizhu Chen", "subjects": "Computation and Language (cs.CL)", "abstract": "Selecting influential data for fine-tuning on downstream tasks is a key factor for both performance and computation efficiency. Recent works have shown that training with only limited data can show a superior performance on general tasks. However, the feasibility on mathematical reasoning tasks has not been validated. To go further, there exist two open questions for mathematical reasoning: how to select influential data and what is an influential data composition. For the former one, we propose a Quality-aware Diverse Selection (QaDS) strategy adaptable for mathematical reasoning. A comparison with other selection strategies validates the superiority of QaDS. For the latter one, we first enlarge our setting and explore the influential data composition. We conduct a series of experiments and highlight: scaling up reasoning data, and training with general data selected by QaDS is helpful. Then, we define our optimal mixture as OpenMathMix, an influential data mixture with open-source data selected by QaDS. With OpenMathMix, we achieve a state-of-the-art 48.8% accuracy on MATH with 7B base model. Additionally, we showcase the use of QaDS in creating efficient fine-tuning mixtures with various selection ratios, and analyze the quality of a wide range of open-source datasets, which can perform as a reference for future works on mathematical reasoning tasks."}
{"main_page": "https://arxiv.org/abs/2404.01070", "pdf": "https://arxiv.org/pdf/2404.01070", "title": "Advancing AI with Integrity: Ethical Challenges and Solutions in Neural  Machine Translation", "authors": "Richard Kimera, Yun-Seon Kim, Heeyoul Choi", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "This paper addresses the ethical challenges of Artificial Intelligence in Neural Machine Translation (NMT) systems, emphasizing the imperative for developers to ensure fairness and cultural sensitivity. We investigate the ethical competence of AI models in NMT, examining the Ethical considerations at each stage of NMT development, including data handling, privacy, data ownership, and consent. We identify and address ethical issues through empirical studies. These include employing Transformer models for Luganda-English translations and enhancing efficiency with sentence mini-batching. And complementary studies that refine data labeling techniques and fine-tune BERT and Longformer models for analyzing Luganda and English social media content. Our second approach is a literature review from databases such as Google Scholar and platforms like GitHub. Additionally, the paper probes the distribution of responsibility between AI systems and humans, underscoring the essential role of human oversight in upholding NMT ethical standards. Incorporating a biblical perspective, we discuss the societal impact of NMT and the broader ethical responsibilities of developers, positing them as stewards accountable for the societal repercussions of their creations."}
{"main_page": "https://arxiv.org/abs/2404.01072", "pdf": "https://arxiv.org/pdf/2404.01072", "title": "How biomedical papers accumulated their clinical citations: A  large-scale retrospective analysis based on PubMed", "authors": "Xin Li, Xuli Tang, Wei Lu", "subjects": "Digital Libraries (cs.DL)", "abstract": "This paper explored the temporal characteristics of clinical citations of biomedical papers, including how long it takes to receive its first clinical citation (the initial stage) and how long it takes to receive two or more clinical citations after its first clinical citation (the build-up stage). Over 23 million biomedical papers in PubMed between 1940 and 2013 and their clinical citations are used as the research data. We divide these biomedical papers into three groups and four categories from clinical citation level and translational science perspectives. We compare the temporal characteristics of biomedical papers of different groups or categories. From the perspective of clinical citation level, the results show that highly clinically cited papers had obvious advantages of receiving clinical citations over medium and lowly clinically cited papers in both the initial and build-up stages. Meanwhile, as the number of clinical citations increased in the build-up stage, the difference in the length of time to receive the corresponding number of clinical citations among the three groups of biomedical papers significantly increased. From the perspective of translational science, the results reveal that biomedical papers closer to clinical science more easily receive clinical citations than papers closer to basic science in both the initial and build-up stages. Moreover, we found that highly clinically cited papers had the desperate advantage of receiving clinical citations over even the clinical guidelines or clinical trials. The robustness analysis of the two aspects demonstrates the reliability of our results."}
{"main_page": "https://arxiv.org/abs/2404.01074", "pdf": "https://arxiv.org/pdf/2404.01074", "title": "Prompt Learning for Oriented Power Transmission Tower Detection in  High-Resolution SAR Images", "authors": "Tianyang Li, Chao Wang, Hong Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Detecting transmission towers from synthetic aperture radar (SAR) images remains a challenging task due to the comparatively small size and side-looking geometry, with background clutter interference frequently hindering tower identification. A large number of interfering signals superimposes the return signal from the tower. We found that localizing or prompting positions of power transmission towers is beneficial to address this obstacle. Based on this revelation, this paper introduces prompt learning into the oriented object detector (P2Det) for multimodal information learning. P2Det contains the sparse prompt coding and cross-attention between the multimodal data. Specifically, the sparse prompt encoder (SPE) is proposed to represent point locations, converting prompts into sparse embeddings. The image embeddings are generated through the Transformer layers. Then a two-way fusion module (TWFM) is proposed to calculate the cross-attention of the two different embeddings. The interaction of image-level and prompt-level features is utilized to address the clutter interference. A shape-adaptive refinement module (SARM) is proposed to reduce the effect of aspect ratio. Extensive experiments demonstrated the effectiveness of the proposed model on high-resolution SAR images. P2Det provides a novel insight for multimodal object detection due to its competitive performance."}
{"main_page": "https://arxiv.org/abs/2404.01077", "pdf": "https://arxiv.org/pdf/2404.01077", "title": "Efficient Prompting Methods for Large Language Models: A Survey", "authors": "Kaiyan Chang, Songcheng Xu, Chenglong Wang, Yingfeng Luo, Tong Xiao, Jingbo Zhu", "subjects": "Computation and Language (cs.CL)", "abstract": "Prompting has become a mainstream paradigm for adapting large language models (LLMs) to specific natural language processing tasks. While this approach opens the door to in-context learning of LLMs, it brings the additional computational burden of model inference and human effort of manual-designed prompts, particularly when using lengthy and complex prompts to guide and control the behavior of LLMs. As a result, the LLM field has seen a remarkable surge in efficient prompting methods. In this paper, we present a comprehensive overview of these methods. At a high level, efficient prompting methods can broadly be categorized into two approaches: prompting with efficient computation and prompting with efficient design. The former involves various ways of compressing prompts, and the latter employs techniques for automatic prompt optimization. We present the basic concepts of prompting, review the advances for efficient prompting, and highlight future research directions."}
{"main_page": "https://arxiv.org/abs/2404.01078", "pdf": "https://arxiv.org/pdf/2404.01078", "title": "Energy Model-based Accurate Shapley Value Estimation for Interpretable  Deep Learning Predictive Modelling", "authors": "Cheng Lu, Jiusun Zeng, Yu Xia, Jinhui Cai, Shihua Luo", "subjects": "Machine Learning (cs.LG)", "abstract": "As a favorable tool for explainable artificial intelligence (XAI), Shapley value has been widely used to interpret deep learning based predictive models. However, accurate and efficient estimation of Shapley value is a difficult task since the computation load grows exponentially with the increase of input features. Most existing accelerated Shapley value estimation methods have to compromise on estimation accuracy with efficiency. In this article, we present EmSHAP(Energy model-based Shapley value estimation), which can effectively approximate the expectation of Shapley contribution function/deep learning model under arbitrary subset of features given the rest. In order to determine the proposal conditional distribution in the energy model, a gated recurrent unit(GRU) is introduced by mapping the input features onto a hidden space, so that the impact of input feature orderings can be eliminated. In addition, a dynamic masking scheme is proposed to improve the generalization ability. It is proved in Theorems 1, 2 and 3 that EmSHAP achieves tighter error bound than state-of-the-art methods like KernelSHAP and VAEAC, leading to higher estimation accuracy. Finally, case studies on a medical application and an industrial application show that the proposed Shapley value-based explainable framework exhibits enhanced estimation accuracy without compromise on efficiency."}
{"main_page": "https://arxiv.org/abs/2404.01079", "pdf": "https://arxiv.org/pdf/2404.01079", "title": "Stale Diffusion: Hyper-realistic 5D Movie Generation Using Old-school  Methods", "authors": "Joao F. Henriques, Dylan Campbell, Tengda Han", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Two years ago, Stable Diffusion achieved super-human performance at generating images with super-human numbers of fingers. Following the steady decline of its technical novelty, we propose Stale Diffusion, a method that solidifies and ossifies Stable Diffusion in a maximum-entropy state. Stable Diffusion works analogously to a barn (the Stable) from which an infinite set of horses have escaped (the Diffusion). As the horses have long left the barn, our proposal may be seen as antiquated and irrelevant. Nevertheless, we vigorously defend our claim of novelty by identifying as early adopters of the Slow Science Movement, which will produce extremely important pearls of wisdom in the future. Our speed of contributions can also be seen as a quasi-static implementation of the recent call to pause AI experiments, which we wholeheartedly support. As a result of a careful archaeological expedition to 18-months-old Git commit histories, we found that naturally-accumulating errors have produced a novel entropy-maximising Stale Diffusion method, that can produce sleep-inducing hyper-realistic 5D video that is as good as one's imagination."}
{"main_page": "https://arxiv.org/abs/2404.01080", "pdf": "https://arxiv.org/pdf/2404.01080", "title": "A simplified proof of the CSP Dichotomy Conjecture and XY-symmetric  operations", "authors": "Dmitriy Zhuk", "subjects": "Computational Complexity (cs.CC); Logic in Computer Science (cs.LO); Rings and Algebras (math.RA)", "abstract": "We develop a new theory of strong subalgebras and linear congruences that are defined globally. Using this theory we provide a new proof of the correctness of Zhuk's algorithm for all tractable CSPs on a finite domain, and therefore a new simplified proof of the CSP Dichotomy Conjecture. Additionally, using the new theory we prove that composing a weak near-unanimity operation of an odd arity $n$ we can derive an $n$-ary operation that is symmetric on all two-element sets. Thus, CSP over a constraint language $\\Gamma$ on a finite domain is tractable if and only if there exist infinitely many polymorphisms of $\\Gamma$ that are symmetric on all two-element sets."}
{"main_page": "https://arxiv.org/abs/2404.01081", "pdf": "https://arxiv.org/pdf/2404.01081", "title": "PhysReaction: Physically Plausible Real-Time Humanoid Reaction Synthesis  via Forward Dynamics Guided 4D Imitation", "authors": "Yunze Liu, Changxi Chen, Chenjing Ding, Li Yi", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Humanoid Reaction Synthesis is pivotal for creating highly interactive and empathetic robots that can seamlessly integrate into human environments, enhancing the way we live, work, and communicate. However, it is difficult to learn the diverse interaction patterns of multiple humans and generate physically plausible reactions. The kinematics-based approaches face challenges, including issues like floating feet, sliding, penetration, and other problems that defy physical plausibility. The existing physics-based method often relies on kinematics-based methods to generate reference states, which struggle with the challenges posed by kinematic noise during action execution. Constrained by their reliance on diffusion models, these methods are unable to achieve real-time inference. In this work, we propose a Forward Dynamics Guided 4D Imitation method to generate physically plausible human-like reactions. The learned policy is capable of generating physically plausible and human-like reactions in real-time, significantly improving the speed(x33) and quality of reactions compared with the existing method. Our experiments on the InterHuman and Chi3D datasets, along with ablation studies, demonstrate the effectiveness of our approach."}
{"main_page": "https://arxiv.org/abs/2404.01084", "pdf": "https://arxiv.org/pdf/2404.01084", "title": "AILS-NTUA at SemEval-2024 Task 9: Cracking Brain Teasers: Transformer  Models for Lateral Thinking Puzzles", "authors": "Ioannis Panagiotopoulos, Giorgos Filandrianos, Maria Lymperaiou, Giorgos Stamou", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "In this paper, we outline our submission for the SemEval-2024 Task 9 competition: 'BRAINTEASER: A Novel Task Defying Common Sense'. We engage in both sub-tasks: Sub-task A-Sentence Puzzle and Sub-task B-Word Puzzle. We evaluate a plethora of pre-trained transformer-based language models of different sizes through fine-tuning. Subsequently, we undertake an analysis of their scores and responses to aid future researchers in understanding and utilizing these models effectively. Our top-performing approaches secured competitive positions on the competition leaderboard across both sub-tasks. In the evaluation phase, our best submission attained an average accuracy score of 81.7% in the Sentence Puzzle, and 85.4% in the Word Puzzle, significantly outperforming the best neural baseline (ChatGPT) by more than 20% and 30% respectively."}
{"main_page": "https://arxiv.org/abs/2404.01089", "pdf": "https://arxiv.org/pdf/2404.01089", "title": "Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On", "authors": "Xu Yang, Changxing Ding, Zhibin Hong, Junhao Huang, Jin Tao, Xiangmin Xu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Image-based virtual try-on is an increasingly important task for online shopping. It aims to synthesize images of a specific person wearing a specified garment. Diffusion model-based approaches have recently become popular, as they are excellent at image synthesis tasks. However, these approaches usually employ additional image encoders and rely on the cross-attention mechanism for texture transfer from the garment to the person image, which affects the try-on's efficiency and fidelity. To address these issues, we propose an Texture-Preserving Diffusion (TPD) model for virtual try-on, which enhances the fidelity of the results and introduces no additional image encoders. Accordingly, we make contributions from two aspects. First, we propose to concatenate the masked person and reference garment images along the spatial dimension and utilize the resulting image as the input for the diffusion model's denoising UNet. This enables the original self-attention layers contained in the diffusion model to achieve efficient and accurate texture transfer. Second, we propose a novel diffusion-based method that predicts a precise inpainting mask based on the person and reference garment images, further enhancing the reliability of the try-on results. In addition, we integrate mask prediction and image synthesis into a single compact model. The experimental results show that our approach can be applied to various try-on tasks, e.g., garment-to-person and person-to-person try-ons, and significantly outperforms state-of-the-art methods on popular VITON, VITON-HD databases."}
{"main_page": "https://arxiv.org/abs/2404.01090", "pdf": "https://arxiv.org/pdf/2404.01090", "title": "Mitigating Transient Bullwhip Effects Under Imperfect Demand Forecasts", "authors": "Sarah H.Q. Li, Florian D\u00f6rfler", "subjects": "Emerging Technologies (cs.ET); Optimization and Control (math.OC)", "abstract": "Motivated by how forecast errors exacerbate order fluctuations in supply chains, we use tools from robust control theory to characterize and compute the worst-case order fluctuation experienced by an individual supply chain vendor under bounded forecast errors and demand fluctuations. Building on existing discrete time, linear time-invariant (LTI) models of supply chains, we separately model forecast error and demand fluctuations as inputs to the inventory dynamics. We then define a transient Bullwhip measure to evaluate the vendor's worst-case order fluctuation and show that for bounded forecast errors and demand fluctuations, this measure is equivalent to the disturbance to control peak gain. To compute the controller that minimizes the worst-case peak gain, we formulate an optimization problem with bilinear matrix inequalities and show that solving this problem is equivalent to minimizing a quasi-convex function on a bounded domain. In contrast to the existing Bullwhip measure in literature, the transient Bullwhip measure has an explicit dependency on the forecast error and does not need the forecast to be a deterministic function of the demand history. This explicit dependency enables us to separately quantify the transient Bullwhip measure's sensitivity to forecast error and demand fluctuations. We empirically verify our model for vendors with non-zero perishable rates and order backlogging rates."}
{"main_page": "https://arxiv.org/abs/2404.01094", "pdf": "https://arxiv.org/pdf/2404.01094", "title": "HairFastGAN: Realistic and Robust Hair Transfer with a Fast  Encoder-Based Approach", "authors": "Maxim Nikolaev, Mikhail Kuznetsov, Dmitry Vetrov, Aibek Alanov", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Our paper addresses the complex task of transferring a hairstyle from a reference image to an input photo for virtual hair try-on. This task is challenging due to the need to adapt to various photo poses, the sensitivity of hairstyles, and the lack of objective metrics. The current state of the art hairstyle transfer methods use an optimization process for different parts of the approach, making them inexcusably slow. At the same time, faster encoder-based models are of very low quality because they either operate in StyleGAN's W+ space or use other low-dimensional image generators. Additionally, both approaches have a problem with hairstyle transfer when the source pose is very different from the target pose, because they either don't consider the pose at all or deal with it inefficiently. In our paper, we present the HairFast model, which uniquely solves these problems and achieves high resolution, near real-time performance, and superior reconstruction compared to optimization problem-based methods. Our solution includes a new architecture operating in the FS latent space of StyleGAN, an enhanced inpainting approach, and improved encoders for better alignment, color transfer, and a new encoder for post-processing. The effectiveness of our approach is demonstrated on realism metrics after random hairstyle transfer and reconstruction when the original hairstyle is transferred. In the most difficult scenario of transferring both shape and color of a hairstyle from different images, our method performs in less than a second on the Nvidia V100. Our code is available at https://github.com/AIRI-Institute/HairFastGAN."}
{"main_page": "https://arxiv.org/abs/2404.01096", "pdf": "https://arxiv.org/pdf/2404.01096", "title": "Enabling Memory Safety of C Programs using LLMs", "authors": "Nausheen Mohammed, Akash Lal, Aseem Rastogi, Subhajit Roy, Rahul Sharma", "subjects": "Software Engineering (cs.SE); Programming Languages (cs.PL)", "abstract": "Memory safety violations in low-level code, written in languages like C, continues to remain one of the major sources of software vulnerabilities. One method of removing such violations by construction is to port C code to a safe C dialect. Such dialects rely on programmer-supplied annotations to guarantee safety with minimal runtime overhead. This porting, however, is a manual process that imposes significant burden on the programmer and, hence, there has been limited adoption of this technique. The task of porting not only requires inferring annotations, but may also need refactoring/rewriting of the code to make it amenable to such annotations. In this paper, we use Large Language Models (LLMs) towards addressing both these concerns. We show how to harness LLM capabilities to do complex code reasoning as well as rewriting of large codebases. We also present a novel framework for whole-program transformations that leverages lightweight static analysis to break the transformation into smaller steps that can be carried out effectively by an LLM. We implement our ideas in a tool called MSA that targets the CheckedC dialect. We evaluate MSA on several micro-benchmarks, as well as real-world code ranging up to 20K lines of code. We showcase superior performance compared to a vanilla LLM baseline, as well as demonstrate improvement over a state-of-the-art symbolic (non-LLM) technique."}
{"main_page": "https://arxiv.org/abs/2404.01099", "pdf": "https://arxiv.org/pdf/2404.01099", "title": "What's in Your \"Safe\" Data?: Identifying Benign Data that Breaks Safety", "authors": "Luxi He, Mengzhou Xia, Peter Henderson", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "abstract": "Current Large Language Models (LLMs), even those tuned for safety and alignment, are susceptible to jailbreaking. Some have found that just further fine-tuning an aligned model with benign data (i.e., data without harmful content) surprisingly leads to substantial degradation in safety. We delve into the data-centric aspects of why benign fine-tuning inadvertently contributes to jailbreaking. First, we represent fine-tuning data through two lenses: representation and gradient spaces. Furthermore, we propose a bi-directional anchoring method that prioritizes data points that are close to harmful examples and distant from benign ones. By doing so, our approach effectively identifies subsets of benign data that are more likely to degrade the model's safety after fine-tuning. Training on just 100 of these seemingly benign datapoints can lead to the fine-tuned model affirmatively responding to > 70% of tested harmful requests, compared to < 20% after fine-tuning on randomly selected data. We further find that selected data are often in the form of lists and bullet points, or math questions."}
{"main_page": "https://arxiv.org/abs/2404.01100", "pdf": "https://arxiv.org/pdf/2404.01100", "title": "Finite Sample Frequency Domain Identification", "authors": "Anastasios Tsiamis, Mohamed Abdalmoaty, Roy S. Smith, John Lygeros", "subjects": "Systems and Control (eess.SY); Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)", "abstract": "We study non-parametric frequency-domain system identification from a finite-sample perspective. We assume an open loop scenario where the excitation input is periodic and consider the Empirical Transfer Function Estimate (ETFE), where the goal is to estimate the frequency response at certain desired (evenly-spaced) frequencies, given input-output samples. We show that under sub-Gaussian colored noise (in time-domain) and stability assumptions, the ETFE estimates are concentrated around the true values. The error rate is of the order of $\\mathcal{O}((d_{\\mathrm{u}}+\\sqrt{d_{\\mathrm{u}}d_{\\mathrm{y}}})\\sqrt{M/N_{\\mathrm{tot}}})$, where $N_{\\mathrm{tot}}$ is the total number of samples, $M$ is the number of desired frequencies, and $d_{\\mathrm{u}},\\,d_{\\mathrm{y}}$ are the dimensions of the input and output signals respectively. This rate remains valid for general irrational transfer functions and does not require a finite order state-space representation. By tuning $M$, we obtain a $N_{\\mathrm{tot}}^{-1/3}$ finite-sample rate for learning the frequency response over all frequencies in the $ \\mathcal{H}_{\\infty}$ norm. Our result draws upon an extension of the Hanson-Wright inequality to semi-infinite matrices. We study the finite-sample behavior of ETFE in simulations."}
{"main_page": "https://arxiv.org/abs/2404.01101", "pdf": "https://arxiv.org/pdf/2404.01101", "title": "UFID: A Unified Framework for Input-level Backdoor Detection on  Diffusion Models", "authors": "Zihan Guan, Mengxuan Hu, Sheng Li, Anil Vullikanti", "subjects": "Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Diffusion Models are vulnerable to backdoor attacks, where malicious attackers inject backdoors by poisoning some parts of the training samples during the training stage. This poses a serious threat to the downstream users, who query the diffusion models through the API or directly download them from the internet. To mitigate the threat of backdoor attacks, there have been a plethora of investigations on backdoor detections. However, none of them designed a specialized backdoor detection method for diffusion models, rendering the area much under-explored. Moreover, these prior methods mainly focus on the traditional neural networks in the classification task, which cannot be adapted to the backdoor detections on the generative task easily. Additionally, most of the prior methods require white-box access to model weights and architectures, or the probability logits as additional information, which are not always practical. In this paper, we propose a Unified Framework for Input-level backdoor Detection (UFID) on the diffusion models, which is motivated by observations in the diffusion models and further validated with a theoretical causality analysis. Extensive experiments across different datasets on both conditional and unconditional diffusion models show that our method achieves a superb performance on detection effectiveness and run-time efficiency. The code is available at https://github.com/GuanZihan/official_UFID."}
{"main_page": "https://arxiv.org/abs/2404.01103", "pdf": "https://arxiv.org/pdf/2404.01103", "title": "Second-Order Newton-Based Extremum Seeking for Multivariable Static Maps", "authors": "Azad Ghaffari, Tiago Roux Oliveira", "subjects": "Systems and Control (eess.SY)", "abstract": "A second-order Newton-based extremum seeking (SONES) algorithm is presented to estimate directional inflection points for multivariable static maps. The design extends the first-order Newton-based extremum seeking algorithm that drives the system toward its peak point. This work provides perturbation matrices to estimate the second- and third-order derivatives necessary for implementation of the SONES. A set of conditions are provided for the probing frequencies that ensure accurate estimation of the derivatives. A differential Riccati filter is used to calculate the inverse of the third-order derivative. The local stability of the new algorithm is proven for general multivariable static maps using averaging analysis. The proposed algorithm ensures uniform convergence toward directional inflection point without requiring information about the curvature of the map and its gradient. Simulation results show the effectiveness of the proposed algorithm."}
{"main_page": "https://arxiv.org/abs/2404.01104", "pdf": "https://arxiv.org/pdf/2404.01104", "title": "SentiCSE: A Sentiment-aware Contrastive Sentence Embedding Framework  with Sentiment-guided Textual Similarity", "authors": "Jaemin Kim, Yohan Na, Kangmin Kim, Sang Rak Lee, Dong-Kyu Chae", "subjects": "Computation and Language (cs.CL)", "abstract": "Recently, sentiment-aware pre-trained language models (PLMs) demonstrate impressive results in downstream sentiment analysis tasks. However, they neglect to evaluate the quality of their constructed sentiment representations; they just focus on improving the fine-tuning performance, which overshadows the representation quality. We argue that without guaranteeing the representation quality, their downstream performance can be highly dependent on the supervision of the fine-tuning data rather than representation quality. This problem would make them difficult to foray into other sentiment-related domains, especially where labeled data is scarce. We first propose Sentiment-guided Textual Similarity (SgTS), a novel metric for evaluating the quality of sentiment representations, which is designed based on the degree of equivalence in sentiment polarity between two sentences. We then propose SentiCSE, a novel Sentiment-aware Contrastive Sentence Embedding framework for constructing sentiment representations via combined word-level and sentence-level objectives, whose quality is guaranteed by SgTS. Qualitative and quantitative comparison with the previous sentiment-aware PLMs shows the superiority of our work. Our code is available at: https://github.com/nayohan/SentiCSE"}
{"main_page": "https://arxiv.org/abs/2404.01106", "pdf": "https://arxiv.org/pdf/2404.01106", "title": "MagLive: Near-Field Magnetic Sensing-Based Voice Liveness Detection on  Smartphones", "authors": "Xiping Sun, Jing Chen, Cong Wu, Kun He, Haozhe Xu, Yebo Feng, Ruiying Du, Xianhao Chen", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Voice authentication has been widely used on smartphones. However, it remains vulnerable to spoofing attacks, where the attacker replays recorded voice samples from authentic humans using loudspeakers to bypass the voice authentication system. In this paper, we present MagLive, a robust voice liveness detection scheme designed for smartphones to mitigate such spoofing attacks. MagLive leverages differences in magnetic field patterns generated by different speakers (i.e., humans or loudspeakers) when speaking for liveness detection. It uses the built-in magnetometer on smartphones to capture these magnetic field changes. Specifically, MagLive utilizes two CNN-based submodels and a self-attention-based feature fusion model to extract effective and robust features. Supervised contrastive learning is then employed to achieve user-irrelevance, device-irrelevance, and content-irrelevance. MagLive imposes no additional burdens on users and does not rely on active sensing or extra devices. We conducted comprehensive experiments with various settings to evaluate the security and robustness of MagLive. Our results demonstrate that MagLive effectively distinguishes between humans and attackers (i.e., loudspeakers), achieving a balanced accuracy of 99.01% and an equal error rate of 0.77%."}
{"main_page": "https://arxiv.org/abs/2404.01109", "pdf": "https://arxiv.org/pdf/2404.01109", "title": "An incremental hybrid adaptive network-based IDS in Software Defined  Networks to detect stealth attacks", "authors": "Abdullah H Alqahtani", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Network attacks have became increasingly more sophisticated and stealthy due to the advances in technologies and the growing sophistication of attackers. Advanced Persistent Threats (APTs) are a type of attack that implement a wide range of strategies to evade detection and be under the defence radar. Software Defined Network (SDN) is a network paradigm that implements dynamic configuration by separating the control plane from the network plane. This approach improves security aspects by facilitating the employment of network intrusion detection systems. Implementing Machine Learning (ML) techniques in Intrusion Detection Systems (IDSs) is widely used to detect such attacks but has a challenge when the data distribution changes. Concept drift is a term that describes the change in the relationship between the input data and the target value (label or class). The model is expected to degrade as certain forms of change occur. In this paper, the primary form of change will be in user behaviour (particularly changes in attacker behaviour). It is essential for a model to adapt itself to deviations in data distribution. SDN can help in monitoring changes in data distribution. This paper discusses changes in stealth attacker behaviour. The work described here investigates various concept drift detection algorithms. An incremental hybrid adaptive Network Intrusion Detection System (NIDS) is proposed to tackle the issue of concept drift in SDN. It can detect known and unknown attacks. The model is evaluated over different datasets showing promising results."}
{"main_page": "https://arxiv.org/abs/2404.01110", "pdf": "https://arxiv.org/pdf/2404.01110", "title": "A Center-of-Mass Shifting Aerial Manipulation Platform for Heavy-Tool  Handling on Non-Horizontal Surfaces", "authors": "Tong Hui, Stefan Rucareanu, Haotian Liu, Matteo Fumagalli", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "Aerial vehicles equipped with manipulators can serve contact-based industrial applications, where fundamental tasks like drilling and grinding often necessitate aerial platforms to handle heavy tools. Industrial environments often involve non-horizontal surfaces. Existing aerial manipulation platforms based on multirotors typically feature a fixed CoM (Center of Mass) within the rotor-defined area, leading to a considerable moment arm between the EE (End-Effector) tip and the CoM for operations on such surfaces. Carrying heavy tools at the EE tip of the manipulator with an extended moment arm can lead to system instability and potential damage to the servo actuators used in the manipulator. To tackle this issue, we present a novel aerial vehicle tailored for handling heavy tools on non-horizontal surfaces. In this work, we provide the platform's system design, modeling, and control strategies. This platform can carry heavy manipulators within the rotor-defined area during free flight. During interactions, the manipulator can shift towards the work surface outside the rotor-defined area, resulting in a displaced CoM location with a significantly shorter moment arm. Furthermore, we propose a method for automatically determining the manipulator's position to reach the maximum CoM displacement towards the work surface. Our proposed concepts are validated through simulations that closely capture the developed physical prototype of the platform."}
{"main_page": "https://arxiv.org/abs/2404.01111", "pdf": "https://arxiv.org/pdf/2404.01111", "title": "The Rate-Distortion-Perception Trade-off: The Role of Private Randomness", "authors": "Yassine Hamdi, Aaron B. Wagner, Deniz G\u00fcnd\u00fcz", "subjects": "Information Theory (cs.IT); Machine Learning (stat.ML)", "abstract": "In image compression, with recent advances in generative modeling, the existence of a trade-off between the rate and the perceptual quality (realism) has been brought to light, where the realism is measured by the closeness of the output distribution to the source. It has been shown that randomized codes can be strictly better under a number of formulations. In particular, the role of common randomness has been well studied. We elucidate the role of private randomness in the compression of a memoryless source $X^n=(X_1,...,X_n)$ under two kinds of realism constraints. The near-perfect realism constraint requires the joint distribution of output symbols $(Y_1,...,Y_n)$ to be arbitrarily close the distribution of the source in total variation distance (TVD). The per-symbol near-perfect realism constraint requires that the TVD between the distribution of output symbol $Y_t$ and the source distribution be arbitrarily small, uniformly in the index $t.$ We characterize the corresponding asymptotic rate-distortion trade-off and show that encoder private randomness is not useful if the compression rate is lower than the entropy of the source, however limited the resources in terms of common randomness and decoder private randomness may be."}
{"main_page": "https://arxiv.org/abs/2404.01112", "pdf": "https://arxiv.org/pdf/2404.01112", "title": "Few shot point cloud reconstruction and denoising via learned Guassian  splats renderings and fine-tuned diffusion features", "authors": "Pietro Bonazzi, Marie-Julie Rakatosaona, Marco Cannici, Federico Tombari, Davide Scaramuzza", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computational Geometry (cs.CG)", "abstract": "Existing deep learning methods for the reconstruction and denoising of point clouds rely on small datasets of 3D shapes. We circumvent the problem by leveraging deep learning methods trained on billions of images. We propose a method to reconstruct point clouds from few images and to denoise point clouds from their rendering by exploiting prior knowledge distilled from image-based deep learning models. To improve reconstruction in constraint settings, we regularize the training of a differentiable renderer with hybrid surface and appearance by introducing semantic consistency supervision. In addition, we propose a pipeline to finetune Stable Diffusion to denoise renderings of noisy point clouds and we demonstrate how these learned filters can be used to remove point cloud noise coming without 3D supervision. We compare our method with DSS and PointRadiance and achieved higher quality 3D reconstruction on the Sketchfab Testset and SCUT Dataset."}
{"main_page": "https://arxiv.org/abs/2404.01114", "pdf": "https://arxiv.org/pdf/2404.01114", "title": "A CRISP-DM-based Methodology for Assessing Agent-based Simulation Models  using Process Mining", "authors": "Rob H. Bemthuis, Ruben R. Govers, Amin Asadi", "subjects": "Multiagent Systems (cs.MA)", "abstract": "Agent-based simulation (ABS) models are potent tools for analyzing complex systems. However, understanding and validating ABS models can be a significant challenge. To address this challenge, cutting-edge data-driven techniques offer sophisticated capabilities for analyzing the outcomes of ABS models. One such technique is process mining, which encompasses a range of methods for discovering, monitoring, and enhancing processes by extracting knowledge from event logs. However, applying process mining to event logs derived from ABSs is not trivial, and deriving meaningful insights from the resulting process models adds an additional layer of complexity. Although process mining is invaluable in extracting insights from ABS models, there is a lack of comprehensive methodological guidance for its application in ABS evaluation in the research landscape. In this paper, we propose a methodology, based on the CRoss-Industry Standard Process for Data Mining (CRISP-DM) methodology, to assess ABS models using process mining techniques. We incorporate process mining techniques into the stages of the CRISP-DM methodology, facilitating the analysis of ABS model behaviors and their underlying processes. We demonstrate our methodology using an established agent-based model, Schelling model of segregation. Our results show that our proposed methodology can effectively assess ABS models through produced event logs, potentially paving the way for enhanced agent-based model validity and more insightful decision-making."}
{"main_page": "https://arxiv.org/abs/2404.01116", "pdf": "https://arxiv.org/pdf/2404.01116", "title": "Intelligent Robotic Control System Based on Computer Vision Technology", "authors": "Chang Che, Haotian Zheng, Zengyi Huang, Wei Jiang, Bo Liu", "subjects": "Robotics (cs.RO)", "abstract": "The article explores the intersection of computer vision technology and robotic control, highlighting its importance in various fields such as industrial automation, healthcare, and environmental protection. Computer vision technology, which simulates human visual observation, plays a crucial role in enabling robots to perceive and understand their surroundings, leading to advancements in tasks like autonomous navigation, object recognition, and waste management. By integrating computer vision with robot control, robots gain the ability to interact intelligently with their environment, improving efficiency."}
{"main_page": "https://arxiv.org/abs/2404.01120", "pdf": "https://arxiv.org/pdf/2404.01120", "title": "Motion Blur Decomposition with Cross-shutter Guidance", "authors": "Xiang Ji, Haiyang Jiang, Yinqiang Zheng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Motion blur is a frequently observed image artifact, especially under insufficient illumination where exposure time has to be prolonged so as to collect more photons for a bright enough image. Rather than simply removing such blurring effects, recent researches have aimed at decomposing a blurry image into multiple sharp images with spatial and temporal coherence. Since motion blur decomposition itself is highly ambiguous, priors from neighbouring frames or human annotation are usually needed for motion disambiguation. In this paper, inspired by the complementary exposure characteristics of a global shutter (GS) camera and a rolling shutter (RS) camera, we propose to utilize the ordered scanline-wise delay in a rolling shutter image to robustify motion decomposition of a single blurry image. To evaluate this novel dual imaging setting, we construct a triaxial system to collect realistic data, as well as a deep network architecture that explicitly addresses temporal and contextual information through reciprocal branches for cross-shutter motion blur decomposition. Experiment results have verified the effectiveness of our proposed algorithm, as well as the validity of our dual imaging setting."}
{"main_page": "https://arxiv.org/abs/2404.01121", "pdf": "https://arxiv.org/pdf/2404.01121", "title": "CMT: Cross Modulation Transformer with Hybrid Loss for Pansharpening", "authors": "Wen-Jie Shu, Hong-Xia Dou, Rui Wen, Xiao Wu, Liang-Jian Deng", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Pansharpening aims to enhance remote sensing image (RSI) quality by merging high-resolution panchromatic (PAN) with multispectral (MS) images. However, prior techniques struggled to optimally fuse PAN and MS images for enhanced spatial and spectral information, due to a lack of a systematic framework capable of effectively coordinating their individual strengths. In response, we present the Cross Modulation Transformer (CMT), a pioneering method that modifies the attention mechanism. This approach utilizes a robust modulation technique from signal processing, integrating it into the attention mechanism's calculations. It dynamically tunes the weights of the carrier's value (V) matrix according to the modulator's features, thus resolving historical challenges and achieving a seamless integration of spatial and spectral attributes. Furthermore, considering that RSI exhibits large-scale features and edge details along with local textures, we crafted a hybrid loss function that combines Fourier and wavelet transforms to effectively capture these characteristics, thereby enhancing both spatial and spectral accuracy in pansharpening. Extensive experiments demonstrate our framework's superior performance over existing state-of-the-art methods. The code will be publicly available to encourage further research."}
{"main_page": "https://arxiv.org/abs/2404.01122", "pdf": "https://arxiv.org/pdf/2404.01122", "title": "Enhanced Precision in Rainfall Forecasting for Mumbai: Utilizing Physics  Informed ConvLSTM2D Models for Finer Spatial and Temporal Resolution", "authors": "Ajay Devda, Akshay Sunil, Murthy R, B Deepthi", "subjects": "Machine Learning (cs.LG)", "abstract": "Forecasting rainfall in tropical areas is challenging due to complex atmospheric behaviour, elevated humidity levels, and the common presence of convective rain events. In the Indian context, the difficulty is further exacerbated because of the monsoon intra seasonal oscillations, which introduce significant variability in rainfall patterns over short periods. Earlier investigations into rainfall prediction leveraged numerical weather prediction methods, along with statistical and deep learning approaches. This study introduces deep learning spatial model aimed at enhancing rainfall prediction accuracy on a finer scale. In this study, we hypothesize that integrating physical understanding improves the precipitation prediction skill of deep learning models with high precision for finer spatial scales, such as cities. To test this hypothesis, we introduce a physics informed ConvLSTM2D model to predict precipitation 6hr and 12hr ahead for Mumbai, India. We utilize ERA5 reanalysis data select predictor variables, across various geopotential levels. The ConvLSTM2D model was trained on the target variable precipitation for 4 different grids representing different spatial grid locations of Mumbai. Thus, the use of the ConvLSTM2D model for rainfall prediction, utilizing physics informed data from specific grids with limited spatial information, reflects current advancements in meteorological research that emphasize both efficiency and localized precision."}
{"main_page": "https://arxiv.org/abs/2404.01123", "pdf": "https://arxiv.org/pdf/2404.01123", "title": "CLIPtone: Unsupervised Learning for Text-based Image Tone Adjustment", "authors": "Hyeongmin Lee, Kyoungkook Kang, Jungseul Ok, Sunghyun Cho", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Image and Video Processing (eess.IV)", "abstract": "Recent image tone adjustment (or enhancement) approaches have predominantly adopted supervised learning for learning human-centric perceptual assessment. However, these approaches are constrained by intrinsic challenges of supervised learning. Primarily, the requirement for expertly-curated or retouched images escalates the data acquisition expenses. Moreover, their coverage of target style is confined to stylistic variants inferred from the training data. To surmount the above challenges, we propose an unsupervised learning-based approach for text-based image tone adjustment method, CLIPtone, that extends an existing image enhancement method to accommodate natural language descriptions. Specifically, we design a hyper-network to adaptively modulate the pretrained parameters of the backbone model based on text description. To assess whether the adjusted image aligns with the text description without ground truth image, we utilize CLIP, which is trained on a vast set of language-image pairs and thus encompasses knowledge of human perception. The major advantages of our approach are three fold: (i) minimal data collection expenses, (ii) support for a range of adjustments, and (iii) the ability to handle novel text descriptions unseen in training. Our approach's efficacy is demonstrated through comprehensive experiments, including a user study."}
{"main_page": "https://arxiv.org/abs/2404.01125", "pdf": "https://arxiv.org/pdf/2404.01125", "title": "Probability-Based Optimal Control Design for Soft Landing of  Short-Stroke Actuators", "authors": "Eduardo Moya-Lasheras (1), Edgar Ramirez-Laboreo (1), Carlos Sagues (1) ((1) Universidad de Zaragoza)", "subjects": "Systems and Control (eess.SY)", "abstract": "The impact forces during switching operations of short-stroke actuators may cause bouncing, audible noise and mechanical wear. The application of soft-landing control strategies to these devices aims at minimizing the impact velocities of their moving components to ultimately improve their lifetime and performance. In this paper, a novel approach for soft-landing trajectory planning, including probability functions, is proposed for optimal control of the actuators. The main contribution of the proposal is that it considers uncertainty in the contact position and hence the obtained trajectories are more robust against system uncertainties. The problem is formulated as an optimal control problem and transformed into a two-point boundary value problem for its numerical resolution. Simulated and experimental tests have been performed using a dynamic model and a commercial short-stroke solenoid valve. The results show a significant improvement in the expected velocities and accelerations at contact with respect to past solutions in which the contact position is assumed to be perfectly known."}
{"main_page": "https://arxiv.org/abs/2404.01127", "pdf": "https://arxiv.org/pdf/2404.01127", "title": "Medical Visual Prompting (MVP): A Unified Framework for Versatile and  High-Quality Medical Image Segmentation", "authors": "Yulin Chen, Guoheng Huang, Kai Huang, Zijin Lin, Guo Zhong, Shenghong Luo, Jie Deng, Jian Zhou", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Accurate segmentation of lesion regions is crucial for clinical diagnosis and treatment across various diseases. While deep convolutional networks have achieved satisfactory results in medical image segmentation, they face challenges such as loss of lesion shape information due to continuous convolution and downsampling, as well as the high cost of manually labeling lesions with varying shapes and sizes. To address these issues, we propose a novel medical visual prompting (MVP) framework that leverages pre-training and prompting concepts from natural language processing (NLP). The framework utilizes three key components: Super-Pixel Guided Prompting (SPGP) for superpixelating the input image, Image Embedding Guided Prompting (IEGP) for freezing patch embedding and merging with superpixels to provide visual prompts, and Adaptive Attention Mechanism Guided Prompting (AAGP) for pinpointing prompt content and efficiently adapting all layers. By integrating SPGP, IEGP, and AAGP, the MVP enables the segmentation network to better learn shape prompting information and facilitates mutual learning across different tasks. Extensive experiments conducted on five datasets demonstrate superior performance of this method in various challenging medical image tasks, while simplifying single-task medical segmentation models. This novel framework offers improved performance with fewer parameters and holds significant potential for accurate segmentation of lesion regions in various medical tasks, making it clinically valuable."}
{"main_page": "https://arxiv.org/abs/2404.01129", "pdf": "https://arxiv.org/pdf/2404.01129", "title": "Structured Information Matters: Incorporating Abstract Meaning  Representation into LLMs for Improved Open-Domain Dialogue Evaluation", "authors": "Bohao Yang, Kun Zhao, Chen Tang, Liang Zhan, Chenghua Lin", "subjects": "Computation and Language (cs.CL)", "abstract": "Automatic open-domain dialogue evaluation has attracted increasing attention. Trainable evaluation metrics are commonly trained with true positive and randomly selected negative responses, resulting in a tendency for them to assign a higher score to the responses that share higher content similarity with a given context. However, adversarial negative responses possess high content similarity with the contexts whilst being semantically different. Therefore, existing evaluation metrics are not robust enough to evaluate such responses, resulting in low correlations with human judgments. While recent studies have shown some efficacy in utilizing Large Language Models (LLMs) for open-domain dialogue evaluation, they still encounter challenges in effectively handling adversarial negative examples. In this paper, we propose a simple yet effective framework for open-domain dialogue evaluation, which combines domain-specific language models (SLMs) with LLMs. The SLMs can explicitly incorporate Abstract Meaning Representation (AMR) graph information of the dialogue through a gating mechanism for enhanced semantic representation learning. The evaluation result of SLMs and AMR graph information are plugged into the prompt of LLM, for the enhanced in-context learning performance. Experimental results on open-domain dialogue evaluation tasks demonstrate the superiority of our method compared to a wide range of state-of-the-art baselines, especially in discriminating adversarial negative responses. Our code is available at https://github.com/Bernard-Yang/SIMAMR."}
{"main_page": "https://arxiv.org/abs/2404.01131", "pdf": "https://arxiv.org/pdf/2404.01131", "title": "GOV-REK: Governed Reward Engineering Kernels for Designing Robust  Multi-Agent Reinforcement Learning Systems", "authors": "Ashish Rana, Michael Oesterle, Jannik Brinkmann", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "abstract": "For multi-agent reinforcement learning systems (MARLS), the problem formulation generally involves investing massive reward engineering effort specific to a given problem. However, this effort often cannot be translated to other problems; worse, it gets wasted when system dynamics change drastically. This problem is further exacerbated in sparse reward scenarios, where a meaningful heuristic can assist in the policy convergence task. We propose GOVerned Reward Engineering Kernels (GOV-REK), which dynamically assign reward distributions to agents in MARLS during its learning stage. We also introduce governance kernels, which exploit the underlying structure in either state or joint action space for assigning meaningful agent reward distributions. During the agent learning stage, it iteratively explores different reward distribution configurations with a Hyperband-like algorithm to learn ideal agent reward models in a problem-agnostic manner. Our experiments demonstrate that our meaningful reward priors robustly jumpstart the learning process for effectively learning different MARL problems."}
{"main_page": "https://arxiv.org/abs/2404.01133", "pdf": "https://arxiv.org/pdf/2404.01133", "title": "CityGaussian: Real-time High-quality Large-Scale Scene Rendering with  Gaussians", "authors": "Yang Liu, He Guan, Chuanchen Luo, Lue Fan, Junran Peng, Zhaoxiang Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The advancement of real-time 3D scene reconstruction and novel view synthesis has been significantly propelled by 3D Gaussian Splatting (3DGS). However, effectively training large-scale 3DGS and rendering it in real-time across various scales remains challenging. This paper introduces CityGaussian (CityGS), which employs a novel divide-and-conquer training approach and Level-of-Detail (LoD) strategy for efficient large-scale 3DGS training and rendering. Specifically, the global scene prior and adaptive training data selection enables efficient training and seamless fusion. Based on fused Gaussian primitives, we generate different detail levels through compression, and realize fast rendering across various scales through the proposed block-wise detail levels selection and aggregation strategy. Extensive experimental results on large-scale scenes demonstrate that our approach attains state-of-theart rendering quality, enabling consistent real-time rendering of largescale scenes across vastly different scales. Our project page is available at https://dekuliutesla.github.io/citygs/."}
{"main_page": "https://arxiv.org/abs/2404.01135", "pdf": "https://arxiv.org/pdf/2404.01135", "title": "Enhancing Reasoning Capacity of SLM using Cognitive Enhancement", "authors": "Jonathan Pan, Swee Liang Wong, Xin Wei Chia, Yidi Yuan", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Large Language Models (LLMs) have been applied to automate cyber security activities and processes including cyber investigation and digital forensics. However, the use of such models for cyber investigation and digital forensics should address accountability and security considerations. Accountability ensures models have the means to provide explainable reasonings and outcomes. This information can be extracted through explicit prompt requests. For security considerations, it is crucial to address privacy and confidentiality of the involved data during data processing as well. One approach to deal with this consideration is to have the data processed locally using a local instance of the model. Due to limitations of locally available resources, namely memory and GPU capacities, a Smaller Large Language Model (SLM) will typically be used. These SLMs have significantly fewer parameters compared to the LLMs. However, such size reductions have notable performance reduction, especially when tasked to provide reasoning explanations. In this paper, we aim to mitigate performance reduction through the integration of cognitive strategies that humans use for problem-solving. We term this as cognitive enhancement through prompts. Our experiments showed significant improvement gains of the SLMs' performances when such enhancements were applied. We believe that our exploration study paves the way for further investigation into the use of cognitive enhancement to optimize SLM for cyber security applications."}
{"main_page": "https://arxiv.org/abs/2404.01136", "pdf": "https://arxiv.org/pdf/2404.01136", "title": "Density Evolution Analysis of Generalized Low-density Parity-check Codes  under a Posteriori Probability Decoder", "authors": "Dongxu Chang, Qingqing Peng, Guanghui Wang, Dawei Yin", "subjects": "Information Theory (cs.IT)", "abstract": "In this study, the performance of generalized low-density parity-check (GLDPC) codes under the a posteriori probability (APP) decoder is analyzed. We explore the concentration, symmetry, and monotonicity properties of GLDPC codes under the APP decoder, extending the applicability of density evolution to GLDPC codes. We demonstrate that with an appropriate proportion of generalized constraint (GC) nodes, GLDPC codes can reduce the original gap to capacity compared to their original LDPC counterparts over the BEC and BI-AWGN channels. Additionally, on the BI-AWGN channel, we adopt Gaussian mixture distributions to approximate the message distributions from variable nodes and Gaussian distributions for those from constraint nodes. This approximation technique significantly enhances the precision of the channel parameter threshold compared to traditional Gaussian approximations while maintaining a low computational complexity similar to that of Gaussian approximations. Our simulation experiments provide empirical evidence that GLDPC codes, when decoded with the APP decoder and equipped with the right fraction of GC nodes, can achieve substantial performance improvements compared to low-density parity-check (LDPC) codes."}
{"main_page": "https://arxiv.org/abs/2404.01139", "pdf": "https://arxiv.org/pdf/2404.01139", "title": "Structured Initialization for Attention in Vision Transformers", "authors": "Jianqiao Zheng, Xueqian Li, Simon Lucey", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The training of vision transformer (ViT) networks on small-scale datasets poses a significant challenge. By contrast, convolutional neural networks (CNNs) have an architectural inductive bias enabling them to perform well on such problems. In this paper, we argue that the architectural bias inherent to CNNs can be reinterpreted as an initialization bias within ViT. This insight is significant as it empowers ViTs to perform equally well on small-scale problems while maintaining their flexibility for large-scale applications. Our inspiration for this ``structured'' initialization stems from our empirical observation that random impulse filters can achieve comparable performance to learned filters within CNNs. Our approach achieves state-of-the-art performance for data-efficient ViT learning across numerous benchmarks including CIFAR-10, CIFAR-100, and SVHN."}
{"main_page": "https://arxiv.org/abs/2404.01140", "pdf": "https://arxiv.org/pdf/2404.01140", "title": "KoCoNovel: Annotated Dataset of Character Coreference in Korean Novels", "authors": "Kyuhee Kim, Surin Lee, Sangah Lee", "subjects": "Computation and Language (cs.CL)", "abstract": "We present KoCoNovel, an novel character coreference dataset derived from Korean literary texts, complete with detailed annotation guidelines. Comprising 178K tokens from 50 modern and contemporary Korean novels, KoCoNovel stands as the second-largest public coreference resolution corpus in Korean, after the NIKL corpus, and the first to be based on literary texts. To broaden its utility, we provide four distinct versions of KoCoNovel, offering options for the perspectives of the omniscient author and readers, and for handling multiple entities as either separate or overlapping. This approach integrates existing discourse surrounding coreference resolution in literary texts, providing a comprehensive dataset for exploration. One of KoCoNovel's distinctive features is that 24% of all character mentions are single common nouns, lacking possessive markers or articles. This feature is particularly influenced by the nuances of Korean address term culture, which favors the use of terms denoting social relationships and kinship over personal names. In experiments with a BERT-based coreference model, we observed notable performance enhancements with KoCoNovel in comparison to the NIKL corpus. Such findings underscore KoCoNovel's potential to significantly enhance coreference resolution models through the integration of Korean cultural and linguistic dynamics."}
{"main_page": "https://arxiv.org/abs/2404.01141", "pdf": "https://arxiv.org/pdf/2404.01141", "title": "SoK: A Review of Differentially Private Linear Models For  High-Dimensional Data", "authors": "Amol Khanna, Edward Raff, Nathan Inkawhich", "subjects": "Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)", "abstract": "Linear models are ubiquitous in data science, but are particularly prone to overfitting and data memorization in high dimensions. To guarantee the privacy of training data, differential privacy can be used. Many papers have proposed optimization techniques for high-dimensional differentially private linear models, but a systematic comparison between these methods does not exist. We close this gap by providing a comprehensive review of optimization methods for private high-dimensional linear models. Empirical tests on all methods demonstrate robust and coordinate-optimized algorithms perform best, which can inform future research. Code for implementing all methods is released online."}
{"main_page": "https://arxiv.org/abs/2404.01143", "pdf": "https://arxiv.org/pdf/2404.01143", "title": "Condition-Aware Neural Network for Controlled Image Generation", "authors": "Han Cai, Muyang Li, Zhuoyang Zhang, Qinsheng Zhang, Ming-Yu Liu, Song Han", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "We present Condition-Aware Neural Network (CAN), a new method for adding control to image generative models. In parallel to prior conditional control methods, CAN controls the image generation process by dynamically manipulating the weight of the neural network. This is achieved by introducing a condition-aware weight generation module that generates conditional weight for convolution/linear layers based on the input condition. We test CAN on class-conditional image generation on ImageNet and text-to-image generation on COCO. CAN consistently delivers significant improvements for diffusion transformer models, including DiT and UViT. In particular, CAN combined with EfficientViT (CaT) achieves 2.78 FID on ImageNet 512x512, surpassing DiT-XL/2 while requiring 52x fewer MACs per sampling step."}
{"main_page": "https://arxiv.org/abs/2404.01145", "pdf": "https://arxiv.org/pdf/2404.01145", "title": "Sequential-in-time training of nonlinear parametrizations for solving  time-dependent partial differential equations", "authors": "Huan Zhang, Yifan Chen, Eric Vanden-Eijnden, Benjamin Peherstorfer", "subjects": "Numerical Analysis (math.NA); Machine Learning (cs.LG)", "abstract": "Sequential-in-time methods solve a sequence of training problems to fit nonlinear parametrizations such as neural networks to approximate solution trajectories of partial differential equations over time. This work shows that sequential-in-time training methods can be understood broadly as either optimize-then-discretize (OtD) or discretize-then-optimize (DtO) schemes, which are well known concepts in numerical analysis. The unifying perspective leads to novel stability and a posteriori error analysis results that provide insights into theoretical and numerical aspects that are inherent to either OtD or DtO schemes such as the tangent space collapse phenomenon, which is a form of over-fitting. Additionally, the unified perspective facilitates establishing connections between variants of sequential-in-time training methods, which is demonstrated by identifying natural gradient descent methods on energy functionals as OtD schemes applied to the corresponding gradient flows."}
{"main_page": "https://arxiv.org/abs/2404.01147", "pdf": "https://arxiv.org/pdf/2404.01147", "title": "Do LLMs Find Human Answers To Fact-Driven Questions Perplexing? A Case  Study on Reddit", "authors": "Parker Seegmiller, Joseph Gatto, Omar Sharif, Madhusudan Basak, Sarah Masud Preum", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Large language models (LLMs) have been shown to be proficient in correctly answering questions in the context of online discourse. However, the study of using LLMs to model human-like answers to fact-driven social media questions is still under-explored. In this work, we investigate how LLMs model the wide variety of human answers to fact-driven questions posed on several topic-specific Reddit communities, or subreddits. We collect and release a dataset of 409 fact-driven questions and 7,534 diverse, human-rated answers from 15 r/Ask{Topic} communities across 3 categories: profession, social identity, and geographic location. We find that LLMs are considerably better at modeling highly-rated human answers to such questions, as opposed to poorly-rated human answers. We present several directions for future research based on our initial findings."}
{"main_page": "https://arxiv.org/abs/2404.01148", "pdf": "https://arxiv.org/pdf/2404.01148", "title": "Joint Beam Scheduling and Beamforming Design for Cooperative Positioning  in Multi-beam LEO Satellite Networks", "authors": "Hongtao Xv, Yaohua Sun, Yafei Zhao, Mugen Peng, Shijie Zhang", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "Cooperative positioning with multiple low earth orbit (LEO) satellites is promising in providing location-based services and enhancing satellite-terrestrial communication. However, positioning accuracy is greatly affected by inter-beam interference and satellite-terrestrial topology geometry. To select the best combination of satellites from visible ones and suppress inter-beam interference, this paper explores the utilization of flexible beam scheduling and beamforming of multi-beam LEO satellites that can adjust beam directions toward the same earth-fixed cell to send positioning signals simultaneously. By leveraging Cram\\'{e}r-Rao lower bound (CRLB) to characterize user Time Difference of Arrival (TDOA) positioning accuracy, the concerned problem is formulated, aiming at optimizing user positioning accuracy under beam scheduling and beam transmission power constraints. To deal with the mixed-integer-nonconvex problem, we decompose it into an inner beamforming design problem and an outer beam scheduling problem. For the former, we first prove the monotonic relationship between user positioning accuracy and its perceived signal-to-interference-plus-noise ratio (SINR) to reformulate the problem, and then semidefinite relaxation (SDR) is adopted for beamforming design. For the outer problem, a heuristic low-complexity beam scheduling scheme is proposed, whose core idea is to schedule users with lower channel correlation to mitigate inter-beam interference while seeking a proper satellite-terrestrial topology geometry. Simulation results verify the superior positioning performance of our proposed positioning-oriented beamforming and beam scheduling scheme, and it is shown that average user positioning accuracy is improved by $17.1\\%$ and $55.9\\%$ when the beam transmission power is 20 dBw, compared to conventional beamforming and beam scheduling schemes, respectively."}
{"main_page": "https://arxiv.org/abs/2404.01150", "pdf": "https://arxiv.org/pdf/2404.01150", "title": "Visual-inertial state estimation based on Chebyshev polynomial  optimization", "authors": "Hongyu Zhang, Maoran Zhu, Qi Cai, Yuanxin Wu", "subjects": "Robotics (cs.RO)", "abstract": "This paper proposes an innovative state estimation method for visual-inertial fusion based on Chebyshev polynomial optimization. Specifically, the pose is modeled as a Chebyshev polynomial of a certain order, and its time derivatives are used to calculate linear acceleration and angular velocity, which, along with inertial measurements, constitute dynamic constraints. This is coupled with a visual measurement model to construct a visual-inertial bundle adjustment formulation. Simulation and public dataset experiments show that the proposed method has better accuracy than the discrete-form preintegration method."}
{"main_page": "https://arxiv.org/abs/2404.01151", "pdf": "https://arxiv.org/pdf/2404.01151", "title": "Detect2Interact: Localizing Object Key Field in Visual Question  Answering (VQA) with LLMs", "authors": "Jialou Wang, Manli Zhu, Yulei Li, Honglei Li, Longzhi Yang, Wai Lok Woo", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Localization plays a crucial role in enhancing the practicality and precision of VQA systems. By enabling fine-grained identification and interaction with specific parts of an object, it significantly improves the system's ability to provide contextually relevant and spatially accurate responses, crucial for applications in dynamic environments like robotics and augmented reality. However, traditional systems face challenges in accurately mapping objects within images to generate nuanced and spatially aware responses. In this work, we introduce \"Detect2Interact\", which addresses these challenges by introducing an advanced approach for fine-grained object visual key field detection. First, we use the segment anything model (SAM) to generate detailed spatial maps of objects in images. Next, we use Vision Studio to extract semantic object descriptions. Third, we employ GPT-4's common sense knowledge, bridging the gap between an object's semantics and its spatial map. As a result, Detect2Interact achieves consistent qualitative results on object key field detection across extensive test cases and outperforms the existing VQA system with object detection by providing a more reasonable and finer visual representation."}
{"main_page": "https://arxiv.org/abs/2404.01154", "pdf": "https://arxiv.org/pdf/2404.01154", "title": "Uncovering the Text Embedding in Text-to-Image Diffusion Models", "authors": "Hu Yu, Hao Luo, Fan Wang, Feng Zhao", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The correspondence between input text and the generated image exhibits opacity, wherein minor textual modifications can induce substantial deviations in the generated image. While, text embedding, as the pivotal intermediary between text and images, remains relatively underexplored. In this paper, we address this research gap by delving into the text embedding space, unleashing its capacity for controllable image editing and explicable semantic direction attributes within a learning-free framework. Specifically, we identify two critical insights regarding the importance of per-word embedding and their contextual correlations within text embedding, providing instructive principles for learning-free image editing. Additionally, we find that text embedding inherently possesses diverse semantic potentials, and further reveal this property through the lens of singular value decomposition (SVD). These uncovered properties offer practical utility for image editing and semantic discovery. More importantly, we expect the in-depth analyses and findings of the text embedding can enhance the understanding of text-to-image diffusion models."}
{"main_page": "https://arxiv.org/abs/2404.01155", "pdf": "https://arxiv.org/pdf/2404.01155", "title": "Research on Mechanism of Voltage Oscillation Caused by Repeated LVRT of  Wind Turbine Based on Switched System Theory", "authors": "Qiping Lai, Chen Shen, Dongsheng Li", "subjects": "Systems and Control (eess.SY)", "abstract": "The electrical distance between the wind power collection sending end grid and the main grid is relatively long, lacking synchronous power supply support, showing the characteristics of weak grid. Therefore, the voltage oscillation phenomenon is easy to happen, threatening the safe and stable operation of the grid. Its dynamic process and evolution mechanism need to be studied urgently. This paper firstly analyzes conditions for voltage oscillations caused by repeated low voltage ride through (LVRT) of wind turbine through steady-state power flow calculation. Then, based on the switched system theory, considering the external connected impedance and internal control dynamics of the wind turbine, the switched system model for the grid-side converter (GSC) of wind turbine is established. After that, the relevant parameters are substituted to analyze the dynamic evolution process of each electrical quantity during the process that wind turbine repeatedly enters and exits LVRT, revealing the evolution mechanism of voltage oscillations. Finally, the voltage oscillation phenomenon of the grid-connected point of wind turbine is reproduced through simulation, verifying the correctness and effectiveness of theoretical analysis results. Furthermore, the main factors which influence characteristics of voltage oscillations are explored as well."}
{"main_page": "https://arxiv.org/abs/2404.01156", "pdf": "https://arxiv.org/pdf/2404.01156", "title": "SyncMask: Synchronized Attentional Masking for Fashion-centric  Vision-Language Pretraining", "authors": "Chull Hwan Song, Taebaek Hwang, Jooyoung Yoon, Shunghyun Choi, Yeong Hyeon Gu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Vision-language models (VLMs) have made significant strides in cross-modal understanding through large-scale paired datasets. However, in fashion domain, datasets often exhibit a disparity between the information conveyed in image and text. This issue stems from datasets containing multiple images of a single fashion item all paired with one text, leading to cases where some textual details are not visible in individual images. This mismatch, particularly when non-co-occurring elements are masked, undermines the training of conventional VLM objectives like Masked Language Modeling and Masked Image Modeling, thereby hindering the model's ability to accurately align fine-grained visual and textual features. Addressing this problem, we propose Synchronized attentional Masking (SyncMask), which generate masks that pinpoint the image patches and word tokens where the information co-occur in both image and text. This synchronization is accomplished by harnessing cross-attentional features obtained from a momentum model, ensuring a precise alignment between the two modalities. Additionally, we enhance grouped batch sampling with semi-hard negatives, effectively mitigating false negative issues in Image-Text Matching and Image-Text Contrastive learning objectives within fashion datasets. Our experiments demonstrate the effectiveness of the proposed approach, outperforming existing methods in three downstream tasks."}
{"main_page": "https://arxiv.org/abs/2404.01157", "pdf": "https://arxiv.org/pdf/2404.01157", "title": "Green AI: Exploring Carbon Footprints, Mitigation Strategies, and Trade  Offs in Large Language Model Training", "authors": "Vivian Liu, Yiqiao Yin", "subjects": "Computation and Language (cs.CL); Performance (cs.PF)", "abstract": "Prominent works in the field of Natural Language Processing have long attempted to create new innovative models by improving upon previous model training approaches, altering model architecture, and developing more in-depth datasets to better their performance. However, with the quickly advancing field of NLP comes increased greenhouse gas emissions, posing concerns over the environmental damage caused by training LLMs. Gaining a comprehensive understanding of the various costs, particularly those pertaining to environmental aspects, that are associated with artificial intelligence serves as the foundational basis for ensuring safe AI models. Currently, investigations into the CO2 emissions of AI models remain an emerging area of research, and as such, in this paper, we evaluate the CO2 emissions of well-known large language models, which have an especially high carbon footprint due to their significant amount of model parameters. We argue for the training of LLMs in a way that is responsible and sustainable by suggesting measures for reducing carbon emissions. Furthermore, we discuss how the choice of hardware affects CO2 emissions by contrasting the CO2 emissions during model training for two widely used GPUs. Based on our results, we present the benefits and drawbacks of our proposed solutions and make the argument for the possibility of training more environmentally safe AI models without sacrificing their robustness and performance."}
{"main_page": "https://arxiv.org/abs/2404.01158", "pdf": "https://arxiv.org/pdf/2404.01158", "title": "Dialogue with Robots: Proposals for Broadening Participation and  Research in the SLIVAR Community", "authors": "Casey Kennington, Malihe Alikhani, Heather Pon-Barry, Katherine Atwell, Yonatan Bisk, Daniel Fried, Felix Gervits, Zhao Han, Mert Inan, Michael Johnston, Raj Korpan, Diane Litman, Matthew Marge, Cynthia Matuszek, Ross Mead, Shiwali Mohan, Raymond Mooney, Natalie Parde, Jivko Sinapov, Angela Stewart, Matthew Stone, Stefanie Tellex, Tom Williams", "subjects": "Computation and Language (cs.CL); Robotics (cs.RO)", "abstract": "The ability to interact with machines using natural human language is becoming not just commonplace, but expected. The next step is not just text interfaces, but speech interfaces and not just with computers, but with all machines including robots. In this paper, we chronicle the recent history of this growing field of spoken dialogue with robots and offer the community three proposals, the first focused on education, the second on benchmarks, and the third on the modeling of language when it comes to spoken interaction with robots. The three proposals should act as white papers for any researcher to take and build upon."}
{"main_page": "https://arxiv.org/abs/2404.01159", "pdf": "https://arxiv.org/pdf/2404.01159", "title": "GPU-accelerated Evolutionary Multiobjective Optimization Using  Tensorized RVEA", "authors": "Zhenyu Liang, Tao Jiang, Kebin Sun, Ran Cheng", "subjects": "Neural and Evolutionary Computing (cs.NE)", "abstract": "Evolutionary multiobjective optimization has witnessed remarkable progress during the past decades. However, existing algorithms often encounter computational challenges in large-scale scenarios, primarily attributed to the absence of hardware acceleration. In response, we introduce a Tensorized Reference Vector Guided Evolutionary Algorithm (TensorRVEA) for harnessing the advancements of GPU acceleration. In TensorRVEA, the key data structures and operators are fully transformed into tensor forms for leveraging GPU-based parallel computing. In numerical benchmark tests involving large-scale populations and problem dimensions, TensorRVEA consistently demonstrates high computational performance, achieving up to over 1000$\\times$ speedups. Then, we applied TensorRVEA to the domain of multiobjective neuroevolution for addressing complex challenges in robotic control tasks. Furthermore, we assessed TensorRVEA's extensibility by altering several tensorized reproduction operators. Experimental results demonstrate promising scalability and robustness of TensorRVEA. Source codes are available at https://github.com/EMI-Group/tensorrvea."}
{"main_page": "https://arxiv.org/abs/2404.01160", "pdf": "https://arxiv.org/pdf/2404.01160", "title": "Diagnosis of Skin Cancer Using VGG16 and VGG19 Based Transfer Learning  Models", "authors": "Amir Faghihi, Mohammadreza Fathollahi, Roozbeh Rajabi", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Today, skin cancer is considered as one of the most dangerous and common cancers in the world which demands special attention. Skin cancer may be developed in different types; including melanoma, actinic keratosis, basal cell carcinoma, squamous cell carcinoma, and Merkel cell carcinoma. Among them, melanoma is more unpredictable. Melanoma cancer can be diagnosed at early stages increasing the possibility of disease treatment. Automatic classification of skin lesions is a challenging task due to diverse forms and grades of the disease, demanding the requirement of novel methods implementation. Deep convolution neural networks (CNN) have shown an excellent potential for data and image classification. In this article, we inspect skin lesion classification problem using CNN techniques. Remarkably, we present that prominent classification accuracy of lesion detection can be obtained by proper designing and applying of transfer learning framework on pre-trained neural networks, without any requirement for data enlargement procedures i.e. merging VGG16 and VGG19 architectures pre-trained by a generic dataset with modified AlexNet network, and then, fine-tuned by a subject-specific dataset containing dermatology images. The convolution neural network was trained using 2541 images and, in particular, dropout was used to prevent the network from overfitting. Finally, the validity of the model was checked by applying the K-fold cross validation method. The proposed model increased classification accuracy by 3% (from 94.2% to 98.18%) in comparison with other methods."}
{"main_page": "https://arxiv.org/abs/2404.01163", "pdf": "https://arxiv.org/pdf/2404.01163", "title": "Capturing Shock Waves by Relaxation Neural Networks", "authors": "Nan Zhou, Zheng Ma", "subjects": "Numerical Analysis (math.NA); Artificial Intelligence (cs.AI)", "abstract": "In this paper, we put forward a neural network framework to solve the nonlinear hyperbolic systems. This framework, named relaxation neural networks(RelaxNN), is a simple and scalable extension of physics-informed neural networks(PINN). It is shown later that a typical PINN framework struggles to handle shock waves that arise in hyperbolic systems' solutions. This ultimately results in the failure of optimization that is based on gradient descent in the training process. Relaxation systems provide a smooth asymptotic to the discontinuity solution, under the expectation that macroscopic problems can be solved from a microscopic perspective. Based on relaxation systems, the RelaxNN framework alleviates the conflict of losses in the training process of the PINN framework. In addition to the remarkable results demonstrated in numerical simulations, most of the acceleration techniques and improvement strategies aimed at the standard PINN framework can also be applied to the RelaxNN framework."}
{"main_page": "https://arxiv.org/abs/2404.01164", "pdf": "https://arxiv.org/pdf/2404.01164", "title": "Unified Predefined-time Stability Conditions of Nonlinear Systems with  Lyapunov Analysis", "authors": "Bing Xiao, Haichao Zhang, Shijie Zhao, Lu Cao", "subjects": "Systems and Control (eess.SY)", "abstract": "This brief gives a set of unified Lyapunov stability conditions to guarantee the predefined-time/finite-time stability of a dynamical systems. The derived Lyapunov theorem for autonomous systems establishes equivalence with existing theorems on predefined-time/finite-time stability. The findings proposed herein develop a nonsingular sliding mode control framework for an Euler-Lagrange system to analyze its stability, and its upper bound for the settling time can be arbitrarily determined a priori through predefined time constant."}
{"main_page": "https://arxiv.org/abs/2404.01165", "pdf": "https://arxiv.org/pdf/2404.01165", "title": "LITE: Modeling Environmental Ecosystems with Multimodal Large Language  Models", "authors": "Haoran Li, Junqi Liu, Zexian Wang, Shiyuan Luo, Xiaowei Jia, Huaxiu Yao", "subjects": "Computation and Language (cs.CL)", "abstract": "The modeling of environmental ecosystems plays a pivotal role in the sustainable management of our planet. Accurate prediction of key environmental variables over space and time can aid in informed policy and decision-making, thus improving people's livelihood. Recently, deep learning-based methods have shown promise in modeling the spatial-temporal relationships for predicting environmental variables. However, these approaches often fall short in handling incomplete features and distribution shifts, which are commonly observed in environmental data due to the substantial cost of data collection and malfunctions in measuring instruments. To address these issues, we propose LITE -- a multimodal large language model for environmental ecosystems modeling. Specifically, LITE unifies different environmental variables by transforming them into natural language descriptions and line graph images. Then, LITE utilizes unified encoders to capture spatial-temporal dynamics and correlations in different modalities. During this step, the incomplete features are imputed by a sparse Mixture-of-Experts framework, and the distribution shift is handled by incorporating multi-granularity information from past observations. Finally, guided by domain instructions, a language model is employed to fuse the multimodal representations for the prediction. Our experiments demonstrate that LITE significantly enhances performance in environmental spatial-temporal prediction across different domains compared to the best baseline, with a 41.25% reduction in prediction error. This justifies its effectiveness. Our data and code are available at https://github.com/hrlics/LITE."}
{"main_page": "https://arxiv.org/abs/2404.01166", "pdf": "https://arxiv.org/pdf/2404.01166", "title": "Scalable Radar-based ITS: Self-localization and Occupancy Heat Map for  Traffic Analysis", "authors": "Longfei Han, Klaus Kefferp\u00fctz, Qiuyu Xu, Ying Lu, Gordon Elger, J\u00fcrgen Beyerer", "subjects": "Robotics (cs.RO)", "abstract": "4D mmWave radar sensors are well suited for city scale Intelligent Transportation Systems (ITS) given their long sensing range, weatherproof functionality, simple mechanical design, and low manufacturing cost. In this paper, we investigate radar-based ITS for scalable traffic analysis. Localization of these radar sensors in a city scale range is a fundamental task in ITS. For mobile ITS setups it requires more endeavor. To address this task, we propose a self-localization approach that matches two descriptions of \"road\": the one from the geometry of the motion trajectories of cumulatively observed vehicles, and the other one from the aerial laser scan. An ICP (iterative closest point) algorithm is used to register the motion trajectory into the road section of the laser scan to estimate the sensor pose. We evaluates the results and show that it outperforms other map-based radar localization methods, especially for the orientation estimation. Beyond the localization result, we project radar sensor data onto city scale laser scan and generate an scalable occupancy heat map as a traffic analysis tool. This is demonstrated using two radar sensors monitoring an urban area in the real world."}
{"main_page": "https://arxiv.org/abs/2404.01168", "pdf": "https://arxiv.org/pdf/2404.01168", "title": "Mirror-3DGS: Incorporating Mirror Reflections into 3D Gaussian Splatting", "authors": "Jiarui Meng, Haijie Li, Yanmin Wu, Qiankun Gao, Shuzhou Yang, Jian Zhang, Siwei Ma", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "3D Gaussian Splatting (3DGS) has marked a significant breakthrough in the realm of 3D scene reconstruction and novel view synthesis. However, 3DGS, much like its predecessor Neural Radiance Fields (NeRF), struggles to accurately model physical reflections, particularly in mirrors that are ubiquitous in real-world scenes. This oversight mistakenly perceives reflections as separate entities that physically exist, resulting in inaccurate reconstructions and inconsistent reflective properties across varied viewpoints. To address this pivotal challenge, we introduce Mirror-3DGS, an innovative rendering framework devised to master the intricacies of mirror geometries and reflections, paving the way for the generation of realistically depicted mirror reflections. By ingeniously incorporating mirror attributes into the 3DGS and leveraging the principle of plane mirror imaging, Mirror-3DGS crafts a mirrored viewpoint to observe from behind the mirror, enriching the realism of scene renderings. Extensive assessments, spanning both synthetic and real-world scenes, showcase our method's ability to render novel views with enhanced fidelity in real-time, surpassing the state-of-the-art Mirror-NeRF specifically within the challenging mirror regions. Our code will be made publicly available for reproducible research."}
{"main_page": "https://arxiv.org/abs/2404.01170", "pdf": "https://arxiv.org/pdf/2404.01170", "title": "Force-EvT: A Closer Look at Robotic Gripper Force Measurement with  Event-based Vision Transformer", "authors": "Qianyu Guo, Ziqing Yu, Jiaming Fu, Yawen Lu, Yahya Zweiri, Dongming Gan", "subjects": "Robotics (cs.RO); Image and Video Processing (eess.IV)", "abstract": "Robotic grippers are receiving increasing attention in various industries as essential components of robots for interacting and manipulating objects. While significant progress has been made in the past, conventional rigid grippers still have limitations in handling irregular objects and can damage fragile objects. We have shown that soft grippers offer deformability to adapt to a variety of object shapes and maximize object protection. At the same time, dynamic vision sensors (e.g., event-based cameras) are capable of capturing small changes in brightness and streaming them asynchronously as events, unlike RGB cameras, which do not perform well in low-light and fast-moving environments. In this paper, a dynamic-vision-based algorithm is proposed to measure the force applied to the gripper. In particular, we first set up a DVXplorer Lite series event camera to capture twenty-five sets of event data. Second, motivated by the impressive performance of the Vision Transformer (ViT) algorithm in dense image prediction tasks, we propose a new approach that demonstrates the potential for real-time force estimation and meets the requirements of real-world scenarios. We extensively evaluate the proposed algorithm on a wide range of scenarios and settings, and show that it consistently outperforms recent approaches."}
{"main_page": "https://arxiv.org/abs/2404.01174", "pdf": "https://arxiv.org/pdf/2404.01174", "title": "SpikeMba: Multi-Modal Spiking Saliency Mamba for Temporal Video  Grounding", "authors": "Wenrui Li, Xiaopeng Hong, Xiaopeng Fan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)", "abstract": "Temporal video grounding (TVG) is a critical task in video content understanding. Despite significant advancements, existing methods often limit in capturing the fine-grained relationships between multimodal inputs and the high computational costs with processing long video sequences. To address these limitations, we introduce a novel SpikeMba: multi-modal spiking saliency mamba for temporal video grounding. In our work, we integrate the Spiking Neural Networks (SNNs) and state space models (SSMs) to capture the fine-grained relationships of multimodal features effectively. Specifically, we introduce the relevant slots to enhance the model's memory capabilities, enabling a deeper contextual understanding of video sequences. The contextual moment reasoner leverages these slots to maintain a balance between contextual information preservation and semantic relevance exploration. Simultaneously, the spiking saliency detector capitalizes on the unique properties of SNNs to accurately locate salient proposals. Our experiments demonstrate the effectiveness of SpikeMba, which consistently outperforms state-of-the-art methods across mainstream benchmarks."}
{"main_page": "https://arxiv.org/abs/2404.01176", "pdf": "https://arxiv.org/pdf/2404.01176", "title": "Using Chao's Estimator as a Stopping Criterion for Technology-Assisted  Review", "authors": "Michiel P. Bron, Peter G. M. van der Heijden, Ad J. Feelders, Arno P. J. M. Siebes", "subjects": "Information Retrieval (cs.IR)", "abstract": "Technology-Assisted Review (TAR) aims to reduce the human effort required for screening processes such as abstract screening for systematic literature reviews. Human reviewers label documents as relevant or irrelevant during this process, while the system incrementally updates a prediction model based on the reviewers' previous decisions. After each model update, the system proposes new documents it deems relevant, to prioritize relevant documentsover irrelevant ones. A stopping criterion is necessary to guide users in stopping the review process to minimize the number of missed relevant documents and the number of read irrelevant documents. In this paper, we propose and evaluate a new ensemble-based Active Learning strategy and a stopping criterion based on Chao's Population Size Estimator that estimates the prevalence of relevant documents in the dataset. Our simulation study demonstrates that this criterion performs well on several datasets and is compared to other methods presented in the literature."}
{"main_page": "https://arxiv.org/abs/2404.01177", "pdf": "https://arxiv.org/pdf/2404.01177", "title": "Poisoning Decentralized Collaborative Recommender System and Its  Countermeasures", "authors": "Ruiqi Zheng, Liang Qu, Tong Chen, Kai Zheng, Yuhui Shi, Hongzhi Yin", "subjects": "Cryptography and Security (cs.CR); Information Retrieval (cs.IR)", "abstract": "To make room for privacy and efficiency, the deployment of many recommender systems is experiencing a shift from central servers to personal devices, where the federated recommender systems (FedRecs) and decentralized collaborative recommender systems (DecRecs) are arguably the two most representative paradigms. While both leverage knowledge (e.g., gradients) sharing to facilitate learning local models, FedRecs rely on a central server to coordinate the optimization process, yet in DecRecs, the knowledge sharing directly happens between clients. Knowledge sharing also opens a backdoor for model poisoning attacks, where adversaries disguise themselves as benign clients and disseminate polluted knowledge to achieve malicious goals like promoting an item's exposure rate. Although research on such poisoning attacks provides valuable insights into finding security loopholes and corresponding countermeasures, existing attacks mostly focus on FedRecs, and are either inapplicable or ineffective for DecRecs. Compared with FedRecs where the tampered information can be universally distributed to all clients once uploaded to the cloud, each adversary in DecRecs can only communicate with neighbor clients of a small size, confining its impact to a limited range. To fill the gap, we present a novel attack method named Poisoning with Adaptive Malicious Neighbors (PAMN). With item promotion in top-K recommendation as the attack objective, PAMN effectively boosts target items' ranks with several adversaries that emulate benign clients and transfers adaptively crafted gradients conditioned on each adversary's neighbors. Moreover, with the vulnerabilities of DecRecs uncovered, a dedicated defensive mechanism based on user-level gradient clipping with sparsified updating is proposed. Extensive experiments demonstrate the effectiveness of the poisoning attack and the robustness of our defensive mechanism."}
{"main_page": "https://arxiv.org/abs/2404.01179", "pdf": "https://arxiv.org/pdf/2404.01179", "title": "BEM: Balanced and Entropy-based Mix for Long-Tailed Semi-Supervised  Learning", "authors": "Hongwei Zheng, Linyuan Zhou, Han Li, Jinming Su, Xiaoming Wei, Xiaoming Xu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Data mixing methods play a crucial role in semi-supervised learning (SSL), but their application is unexplored in long-tailed semi-supervised learning (LTSSL). The primary reason is that the in-batch mixing manner fails to address class imbalance. Furthermore, existing LTSSL methods mainly focus on re-balancing data quantity but ignore class-wise uncertainty, which is also vital for class balance. For instance, some classes with sufficient samples might still exhibit high uncertainty due to indistinguishable features. To this end, this paper introduces the Balanced and Entropy-based Mix (BEM), a pioneering mixing approach to re-balance the class distribution of both data quantity and uncertainty. Specifically, we first propose a class balanced mix bank to store data of each class for mixing. This bank samples data based on the estimated quantity distribution, thus re-balancing data quantity. Then, we present an entropy-based learning approach to re-balance class-wise uncertainty, including entropy-based sampling strategy, entropy-based selection module, and entropy-based class balanced loss. Our BEM first leverages data mixing for improving LTSSL, and it can also serve as a complement to the existing re-balancing methods. Experimental results show that BEM significantly enhances various LTSSL frameworks and achieves state-of-the-art performances across multiple benchmarks."}
{"main_page": "https://arxiv.org/abs/2404.01182", "pdf": "https://arxiv.org/pdf/2404.01182", "title": "A Neuro-Symbolic Approach to Monitoring Salt Content in Food", "authors": "Anuja Tayal, Barbara Di Eugenio, Devika Salunke, Andrew D. Boyd, Carolyn A Dickens, Eulalia P Abril, Olga Garcia-Bedoya, Paula G Allen-Meares", "subjects": "Computation and Language (cs.CL); Symbolic Computation (cs.SC)", "abstract": "We propose a dialogue system that enables heart failure patients to inquire about salt content in foods and help them monitor and reduce salt intake. Addressing the lack of specific datasets for food-based salt content inquiries, we develop a template-based conversational dataset. The dataset is structured to ask clarification questions to identify food items and their salt content. Our findings indicate that while fine-tuning transformer-based models on the dataset yields limited performance, the integration of Neuro-Symbolic Rules significantly enhances the system's performance. Our experiments show that by integrating neuro-symbolic rules, our system achieves an improvement in joint goal accuracy of over 20% across different data sizes compared to naively fine-tuning transformer-based models."}
{"main_page": "https://arxiv.org/abs/2404.01184", "pdf": "https://arxiv.org/pdf/2404.01184", "title": "Efficient Motion Planning for Manipulators with Control Barrier  Function-Induced Neural Controller", "authors": "Mingxin Yu, Chenning Yu, M-Mahdi Naddaf-Sh, Devesh Upadhyay, Sicun Gao, Chuchu Fan", "subjects": "Robotics (cs.RO); Machine Learning (cs.LG)", "abstract": "Sampling-based motion planning methods for manipulators in crowded environments often suffer from expensive collision checking and high sampling complexity, which make them difficult to use in real time. To address this issue, we propose a new generalizable control barrier function (CBF)-based steering controller to reduce the number of samples needed in a sampling-based motion planner RRT. Our method combines the strength of CBF for real-time collision-avoidance control and RRT for long-horizon motion planning, by using CBF-induced neural controller (CBF-INC) to generate control signals that steer the system towards sampled configurations by RRT. CBF-INC is learned as Neural Networks and has two variants handling different inputs, respectively: state (signed distance) input and point-cloud input from LiDAR. In the latter case, we also study two different settings: fully and partially observed environmental information. Compared to manually crafted CBF which suffers from over-approximating robot geometry, CBF-INC can balance safety and goal-reaching better without being over-conservative. Given state-based input, our neural CBF-induced neural controller-enhanced RRT (CBF-INC-RRT) can increase the success rate by 14% while reducing the number of nodes explored by 30%, compared with vanilla RRT on hard test cases. Given LiDAR input where vanilla RRT is not directly applicable, we demonstrate that our CBF-INC-RRT can improve the success rate by 10%, compared with planning with other steering controllers. Our project page with supplementary material is at https://mit-realm.github.io/CBF-INC-RRT-website/."}
{"main_page": "https://arxiv.org/abs/2404.01188", "pdf": "https://arxiv.org/pdf/2404.01188", "title": "MonoBox: Tightness-free Box-supervised Polyp 001 001 Segmentation using  Monotonicity Constraint", "authors": "Qiang Hu, Zhenyu Yi, Ying Zhou, Ting Li, Fan Huang, Mei Liu, Zhiwei Wang, Qiang Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We propose MonoBox, an innovative box-supervised segmentation method constrained by monotonicity to liberate its training from the user-unfriendly box-tightness assumption. In contrast to conventional box-supervised segmentation, where the box edges must precisely touch the target boundaries, MonoBox leverages imprecisely-annotated boxes to achieve robust pixel-wise segmentation. The 'linchpin' is that, within the noisy zones around box edges, MonoBox discards the traditional misguiding multiple-instance learning loss, and instead optimizes a carefully-designed objective, termed monotonicity constraint. Along directions transitioning from the foreground to background, this new constraint steers responses to adhere to a trend of monotonically decreasing values. Consequently, the originally unreliable learning within the noisy zones is transformed into a correct and effective monotonicity optimization. Moreover, an adaptive label correction is introduced, enabling MonoBox to enhance the tightness of box annotations using predicted masks from the previous epoch and dynamically shrink the noisy zones as training progresses. We verify MonoBox in the box-supervised segmentation task of polyps, where satisfying box-tightness is challenging due to the vague boundaries between the polyp and normal tissues. Experiments on both public synthetic and in-house real noisy datasets demonstrate that MonoBox exceeds other anti-noise state-of-the-arts by improving Dice by at least 5.5% and 3.3%, respectively. Codes are at https://github.com/Huster-Hq/MonoBox."}
{"main_page": "https://arxiv.org/abs/2404.01189", "pdf": "https://arxiv.org/pdf/2404.01189", "title": "Generating Faithful and Complete Hospital-Course Summaries from the  Electronic Health Record", "authors": "Griffin Adams", "subjects": "Computation and Language (cs.CL)", "abstract": "The rapid adoption of Electronic Health Records (EHRs) has been instrumental in streamlining administrative tasks, increasing transparency, and enabling continuity of care across providers. An unintended consequence of the increased documentation burden, however, has been reduced face-time with patients and, concomitantly, a dramatic rise in clinician burnout. In this thesis, we pinpoint a particularly time-intensive, yet critical, documentation task: generating a summary of a patient's hospital admissions, and propose and evaluate automated solutions. In Chapter 2, we construct a dataset based on 109,000 hospitalizations (2M source notes) and perform exploratory analyses to motivate future work on modeling and evaluation [NAACL 2021]. In Chapter 3, we address faithfulness from a modeling perspective by revising noisy references [EMNLP 2022] and, to reduce the reliance on references, directly calibrating model outputs to metrics [ACL 2023]. These works relied heavily on automatic metrics as human annotations were limited. To fill this gap, in Chapter 4, we conduct a fine-grained expert annotation of system errors in order to meta-evaluate existing metrics and better understand task-specific issues of domain adaptation and source-summary alignments. To learn a metric less correlated to extractiveness (copy-and-paste), we derive noisy faithfulness labels from an ensemble of existing metrics and train a faithfulness classifier on these pseudo labels [MLHC 2023]. Finally, in Chapter 5, we demonstrate that fine-tuned LLMs (Mistral and Zephyr) are highly prone to entity hallucinations and cover fewer salient entities. We improve both coverage and faithfulness by performing sentence-level entity planning based on a set of pre-computed salient entities from the source text, which extends our work on entity-guided news summarization [ACL, 2023], [EMNLP, 2023]."}
{"main_page": "https://arxiv.org/abs/2404.01194", "pdf": "https://arxiv.org/pdf/2404.01194", "title": "Adaptive Query Prompting for Multi-Domain Landmark Detection", "authors": "Qiusen Wei, Guoheng Huang, Xiaochen Yuan, Xuhang Chen, Guo Zhong, Jianwen Huang, Jiajie Huang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Medical landmark detection is crucial in various medical imaging modalities and procedures. Although deep learning-based methods have achieve promising performance, they are mostly designed for specific anatomical regions or tasks. In this work, we propose a universal model for multi-domain landmark detection by leveraging transformer architecture and developing a prompting component, named as Adaptive Query Prompting (AQP). Instead of embedding additional modules in the backbone network, we design a separate module to generate prompts that can be effectively extended to any other transformer network. In our proposed AQP, prompts are learnable parameters maintained in a memory space called prompt pool. The central idea is to keep the backbone frozen and then optimize prompts to instruct the model inference process. Furthermore, we employ a lightweight decoder to decode landmarks from the extracted features, namely Light-MLD. Thanks to the lightweight nature of the decoder and AQP, we can handle multiple datasets by sharing the backbone encoder and then only perform partial parameter tuning without incurring much additional cost. It has the potential to be extended to more landmark detection tasks. We conduct experiments on three widely used X-ray datasets for different medical landmark detection tasks. Our proposed Light-MLD coupled with AQP achieves SOTA performance on many metrics even without the use of elaborate structural designs or complex frameworks."}
{"main_page": "https://arxiv.org/abs/2404.01196", "pdf": "https://arxiv.org/pdf/2404.01196", "title": "Estimating Lexical Complexity from Document-Level Distributions", "authors": "Sondre Wold, Petter M\u00e6hlum, Oddbj\u00f8rn Hove", "subjects": "Computation and Language (cs.CL)", "abstract": "Existing methods for complexity estimation are typically developed for entire documents. This limitation in scope makes them inapplicable for shorter pieces of text, such as health assessment tools. These typically consist of lists of independent sentences, all of which are too short for existing methods to apply. The choice of wording in these assessment tools is crucial, as both the cognitive capacity and the linguistic competency of the intended patient groups could vary substantially. As a first step towards creating better tools for supporting health practitioners, we develop a two-step approach for estimating lexical complexity that does not rely on any pre-annotated data. We implement our approach for the Norwegian language and verify its effectiveness using statistical testing and a qualitative evaluation of samples from real assessment tools. We also investigate the relationship between our complexity measure and certain features typically associated with complexity in the literature, such as word length, frequency, and the number of syllables."}
{"main_page": "https://arxiv.org/abs/2404.01197", "pdf": "https://arxiv.org/pdf/2404.01197", "title": "Getting it Right: Improving Spatial Consistency in Text-to-Image Models", "authors": "Agneet Chatterjee, Gabriela Ben Melech Stan, Estelle Aflalo, Sayak Paul, Dhruba Ghosh, Tejas Gokhale, Ludwig Schmidt, Hannaneh Hajishirzi, Vasudev Lal, Chitta Baral, Yezhou Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "One of the key shortcomings in current text-to-image (T2I) models is their inability to consistently generate images which faithfully follow the spatial relationships specified in the text prompt. In this paper, we offer a comprehensive investigation of this limitation, while also developing datasets and methods that achieve state-of-the-art performance. First, we find that current vision-language datasets do not represent spatial relationships well enough; to alleviate this bottleneck, we create SPRIGHT, the first spatially-focused, large scale dataset, by re-captioning 6 million images from 4 widely used vision datasets. Through a 3-fold evaluation and analysis pipeline, we find that SPRIGHT largely improves upon existing datasets in capturing spatial relationships. To demonstrate its efficacy, we leverage only ~0.25% of SPRIGHT and achieve a 22% improvement in generating spatially accurate images while also improving the FID and CMMD scores. Secondly, we find that training on images containing a large number of objects results in substantial improvements in spatial consistency. Notably, we attain state-of-the-art on T2I-CompBench with a spatial score of 0.2133, by fine-tuning on <500 images. Finally, through a set of controlled experiments and ablations, we document multiple findings that we believe will enhance the understanding of factors that affect spatial consistency in text-to-image models. We publicly release our dataset and model to foster further research in this area."}
{"main_page": "https://arxiv.org/abs/2404.01198", "pdf": "https://arxiv.org/pdf/2404.01198", "title": "Nearly-tight Approximation Guarantees for the Improving Multi-Armed  Bandits Problem", "authors": "Avrim Blum, Kavya Ravichandran", "subjects": "Machine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)", "abstract": "We give nearly-tight upper and lower bounds for the improving multi-armed bandits problem. An instance of this problem has $k$ arms, each of whose reward function is a concave and increasing function of the number of times that arm has been pulled so far. We show that for any randomized online algorithm, there exists an instance on which it must suffer at least an $\\Omega(\\sqrt{k})$ approximation factor relative to the optimal reward. We then provide a randomized online algorithm that guarantees an $O(\\sqrt{k})$ approximation factor, if it is told the maximum reward achievable by the optimal arm in advance. We then show how to remove this assumption at the cost of an extra $O(\\log k)$ approximation factor, achieving an overall $O(\\sqrt{k} \\log k)$ approximation relative to optimal."}
{"main_page": "https://arxiv.org/abs/2404.01203", "pdf": "https://arxiv.org/pdf/2404.01203", "title": "Video Interpolation with Diffusion Models", "authors": "Siddhant Jain, Daniel Watson, Eric Tabellion, Aleksander Ho\u0142y\u0144ski, Ben Poole, Janne Kontkanen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present VIDIM, a generative model for video interpolation, which creates short videos given a start and end frame. In order to achieve high fidelity and generate motions unseen in the input data, VIDIM uses cascaded diffusion models to first generate the target video at low resolution, and then generate the high-resolution video conditioned on the low-resolution generated video. We compare VIDIM to previous state-of-the-art methods on video interpolation, and demonstrate how such works fail in most settings where the underlying motion is complex, nonlinear, or ambiguous while VIDIM can easily handle such cases. We additionally demonstrate how classifier-free guidance on the start and end frame and conditioning the super-resolution model on the original high-resolution frames without additional parameters unlocks high-fidelity results. VIDIM is fast to sample from as it jointly denoises all the frames to be generated, requires less than a billion parameters per diffusion model to produce compelling results, and still enjoys scalability and improved quality at larger parameter counts."}
{"main_page": "https://arxiv.org/abs/2404.01204", "pdf": "https://arxiv.org/pdf/2404.01204", "title": "The Fine Line: Navigating Large Language Model Pretraining with  Down-streaming Capability Analysis", "authors": "Chen Yang, Junzhuo Li, Xinyao Niu, Xinrun Du, Songyang Gao, Haoran Zhang, Zhaoliang Chen, Xingwei Qu, Ruibin Yuan, Yizhi Li, Jiaheng Liu, Stephen W. Huang, Shawn Yue, Wenhu Chen, Jie Fu, Ge Zhang", "subjects": "Computation and Language (cs.CL)", "abstract": "Uncovering early-stage metrics that reflect final model performance is one core principle for large-scale pretraining. The existing scaling law demonstrates the power-law correlation between pretraining loss and training flops, which serves as an important indicator of the current training state for large language models. However, this principle only focuses on the model's compression properties on the training data, resulting in an inconsistency with the ability improvements on the downstream tasks. Some follow-up works attempted to extend the scaling-law to more complex metrics (such as hyperparameters), but still lacked a comprehensive analysis of the dynamic differences among various capabilities during pretraining. To address the aforementioned limitations, this paper undertakes a comprehensive comparison of model capabilities at various pretraining intermediate checkpoints. Through this analysis, we confirm that specific downstream metrics exhibit similar training dynamics across models of different sizes, up to 67 billion parameters. In addition to our core findings, we've reproduced Amber and OpenLLaMA, releasing their intermediate checkpoints. This initiative offers valuable resources to the research community and facilitates the verification and exploration of LLM pretraining by open-source researchers. Besides, we provide empirical summaries, including performance comparisons of different models and capabilities, and tuition of key metrics for different training phases. Based on these findings, we provide a more user-friendly strategy for evaluating the optimization state, offering guidance for establishing a stable pretraining process."}
{"main_page": "https://arxiv.org/abs/2404.01205", "pdf": "https://arxiv.org/pdf/2404.01205", "title": "Foundations of Cyber Resilience: The Confluence of Game, Control, and  Learning Theories", "authors": "Quanyan Zhu", "subjects": "Systems and Control (eess.SY); Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT)", "abstract": "Cyber resilience is a complementary concept to cybersecurity, focusing on the preparation, response, and recovery from cyber threats that are challenging to prevent. Organizations increasingly face such threats in an evolving cyber threat landscape. Understanding and establishing foundations for cyber resilience provide a quantitative and systematic approach to cyber risk assessment, mitigation policy evaluation, and risk-informed defense design. A systems-scientific view toward cyber risks provides holistic and system-level solutions. This chapter starts with a systemic view toward cyber risks and presents the confluence of game theory, control theory, and learning theories, which are three major pillars for the design of cyber resilience mechanisms to counteract increasingly sophisticated and evolving threats in our networks and organizations. Game and control theoretic methods provide a set of modeling frameworks to capture the strategic and dynamic interactions between defenders and attackers. Control and learning frameworks together provide a feedback-driven mechanism that enables autonomous and adaptive responses to threats. Game and learning frameworks offer a data-driven approach to proactively reason about adversarial behaviors and resilient strategies. The confluence of the three lays the theoretical foundations for the analysis and design of cyber resilience. This chapter presents various theoretical paradigms, including dynamic asymmetric games, moving horizon control, conjectural learning, and meta-learning, as recent advances at the intersection. This chapter concludes with future directions and discussions of the role of neurosymbolic learning and the synergy between foundation models and game models in cyber resilience."}
{"main_page": "https://arxiv.org/abs/2404.01206", "pdf": "https://arxiv.org/pdf/2404.01206", "title": "Machine Unlearning for Traditional Models and Large Language Models: A  Short Survey", "authors": "Yi Xu", "subjects": "Machine Learning (cs.LG); Cryptography and Security (cs.CR)", "abstract": "With the implementation of personal data privacy regulations, the field of machine learning (ML) faces the challenge of the \"right to be forgotten\". Machine unlearning has emerged to address this issue, aiming to delete data and reduce its impact on models according to user requests. Despite the widespread interest in machine unlearning, comprehensive surveys on its latest advancements, especially in the field of Large Language Models (LLMs) is lacking. This survey aims to fill this gap by providing an in-depth exploration of machine unlearning, including the definition, classification and evaluation criteria, as well as challenges in different environments and their solutions. Specifically, this paper categorizes and investigates unlearning on both traditional models and LLMs, and proposes methods for evaluating the effectiveness and efficiency of unlearning, and standards for performance measurement. This paper reveals the limitations of current unlearning techniques and emphasizes the importance of a comprehensive unlearning evaluation to avoid arbitrary forgetting. This survey not only summarizes the key concepts of unlearning technology but also points out its prominent issues and feasible directions for future research, providing valuable guidance for scholars in the field."}
{"main_page": "https://arxiv.org/abs/2404.01207", "pdf": "https://arxiv.org/pdf/2404.01207", "title": "Vision-language models for decoding provider attention during neonatal  resuscitation", "authors": "Felipe Parodi, Jordan Matelsky, Alejandra Regla-Vargas, Elizabeth Foglia, Charis Lim, Danielle Weinberg, Konrad Kording, Heidi Herrick, Michael Platt", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Neonatal resuscitations demand an exceptional level of attentiveness from providers, who must process multiple streams of information simultaneously. Gaze strongly influences decision making; thus, understanding where a provider is looking during neonatal resuscitations could inform provider training, enhance real-time decision support, and improve the design of delivery rooms and neonatal intensive care units (NICUs). Current approaches to quantifying neonatal providers' gaze rely on manual coding or simulations, which limit scalability and utility. Here, we introduce an automated, real-time, deep learning approach capable of decoding provider gaze into semantic classes directly from first-person point-of-view videos recorded during live resuscitations. Combining state-of-the-art, real-time segmentation with vision-language models (CLIP), our low-shot pipeline attains 91\\% classification accuracy in identifying gaze targets without training. Upon fine-tuning, the performance of our gaze-guided vision transformer exceeds 98\\% accuracy in gaze classification, approaching human-level precision. This system, capable of real-time inference, enables objective quantification of provider attention dynamics during live neonatal resuscitation. Our approach offers a scalable solution that seamlessly integrates with existing infrastructure for data-scarce gaze analysis, thereby offering new opportunities for understanding and refining clinical decision making."}
{"main_page": "https://arxiv.org/abs/2404.01210", "pdf": "https://arxiv.org/pdf/2404.01210", "title": "AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for  hallucination detection and analysis", "authors": "Natalia Griogoriadou, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou", "subjects": "Computation and Language (cs.CL)", "abstract": "In this paper, we present our team's submissions for SemEval-2024 Task-6 - SHROOM, a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes. The participants were asked to perform binary classification to identify cases of fluent overgeneration hallucinations. Our experimentation included fine-tuning a pre-trained model on hallucination detection and a Natural Language Inference (NLI) model. The most successful strategy involved creating an ensemble of these models, resulting in accuracy rates of 77.8% and 79.9% on model-agnostic and model-aware datasets respectively, outperforming the organizers' baseline and achieving notable results when contrasted with the top-performing results in the competition, which reported accuracies of 84.7% and 81.3% correspondingly."}
{"main_page": "https://arxiv.org/abs/2404.01216", "pdf": "https://arxiv.org/pdf/2404.01216", "title": "Novel Node Category Detection Under Subpopulation Shift", "authors": "Hsing-Huan Chung, Shravan Chaudhari, Yoav Wald, Xing Han, Joydeep Ghosh", "subjects": "Machine Learning (cs.LG); Social and Information Networks (cs.SI); Machine Learning (stat.ML)", "abstract": "In real-world graph data, distribution shifts can manifest in various ways, such as the emergence of new categories and changes in the relative proportions of existing categories. It is often important to detect nodes of novel categories under such distribution shifts for safety or insight discovery purposes. We introduce a new approach, Recall-Constrained Optimization with Selective Link Prediction (RECO-SLIP), to detect nodes belonging to novel categories in attributed graphs under subpopulation shifts. By integrating a recall-constrained learning framework with a sample-efficient link prediction mechanism, RECO-SLIP addresses the dual challenges of resilience against subpopulation shifts and the effective exploitation of graph structure. Our extensive empirical evaluation across multiple graph datasets demonstrates the superior performance of RECO-SLIP over existing methods."}
{"main_page": "https://arxiv.org/abs/2404.01217", "pdf": "https://arxiv.org/pdf/2404.01217", "title": "Incorporating Domain Differential Equations into Graph Convolutional  Networks to Lower Generalization Discrepancy", "authors": "Yue Sun, Chao Chen, Yuesheng Xu, Sihong Xie, Rick S. Blum, Parv Venkitasubramaniam", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Ensuring both accuracy and robustness in time series prediction is critical to many applications, ranging from urban planning to pandemic management. With sufficient training data where all spatiotemporal patterns are well-represented, existing deep-learning models can make reasonably accurate predictions. However, existing methods fail when the training data are drawn from different circumstances (e.g., traffic patterns on regular days) compared to test data (e.g., traffic patterns after a natural disaster). Such challenges are usually classified under domain generalization. In this work, we show that one way to address this challenge in the context of spatiotemporal prediction is by incorporating domain differential equations into Graph Convolutional Networks (GCNs). We theoretically derive conditions where GCNs incorporating such domain differential equations are robust to mismatched training and testing data compared to baseline domain agnostic models. To support our theory, we propose two domain-differential-equation-informed networks called Reaction-Diffusion Graph Convolutional Network (RDGCN), which incorporates differential equations for traffic speed evolution, and Susceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN), which incorporates a disease propagation model. Both RDGCN and SIRGCN are based on reliable and interpretable domain differential equations that allow the models to generalize to unseen patterns. We experimentally show that RDGCN and SIRGCN are more robust with mismatched testing data than the state-of-the-art deep learning methods."}
{"main_page": "https://arxiv.org/abs/2404.01218", "pdf": "https://arxiv.org/pdf/2404.01218", "title": "Towards System Modelling to Support Diseases Data Extraction from the  Electronic Health Records for Physicians Research Activities", "authors": "Bushra F. Alsaqer, Alaa F. Alsaqer, Amna Asif", "subjects": "Machine Learning (cs.LG); Information Retrieval (cs.IR)", "abstract": "The use of Electronic Health Records (EHRs) has increased dramatically in the past 15 years, as, it is considered an important source of managing data od patients. The EHRs are primary sources of disease diagnosis and demographic data of patients worldwide. Therefore, the data can be utilized for secondary tasks such as research. This paper aims to make such data usable for research activities such as monitoring disease statistics for a specific population. As a result, the researchers can detect the disease causes for the behavior and lifestyle of the target group. One of the limitations of EHRs systems is that the data is not available in the standard format but in various forms. Therefore, it is required to first convert the names of the diseases and demographics data into one standardized form to make it usable for research activities. There is a large amount of EHRs available, and solving the standardizing issues requires some optimized techniques. We used a first-hand EHR dataset extracted from EHR systems. Our application uploads the dataset from the EHRs and converts it to the ICD-10 coding system to solve the standardization problem. So, we first apply the steps of pre-processing, annotation, and transforming the data to convert it into the standard form. The data pre-processing is applied to normalize demographic formats. In the annotation step, a machine learning model is used to recognize the diseases from the text. Furthermore, the transforming step converts the disease name to the ICD-10 coding format. The model was evaluated manually by comparing its performance in terms of disease recognition with an available dictionary-based system (MetaMap). The accuracy of the proposed machine learning model is 81%, that outperformed MetaMap accuracy of 67%. This paper contributed to system modelling for EHR data extraction to support research activities."}
{"main_page": "https://arxiv.org/abs/2404.01219", "pdf": "https://arxiv.org/pdf/2404.01219", "title": "LTL-D*: Incrementally Optimal Replanning for Feasible and Infeasible  Tasks in Linear Temporal Logic Specifications", "authors": "Jiming Ren, Haris Miller, Karen M. Feigh, Samuel Coogan, Ye Zhao", "subjects": "Robotics (cs.RO); Formal Languages and Automata Theory (cs.FL)", "abstract": "This paper presents an incremental replanning algorithm, dubbed LTL-D*, for temporal-logic-based task planning in a dynamically changing environment. Unexpected changes in the environment may lead to failures in satisfying a task specification in the form of a Linear Temporal Logic (LTL). In this study, the considered failures are categorized into two classes: (i) the desired LTL specification can be satisfied via replanning, and (ii) the desired LTL specification is infeasible to meet strictly and can only be satisfied in a \"relaxed\" fashion. To address these failures, the proposed algorithm finds an optimal replanning solution that minimally violates desired task specifications. In particular, our approach leverages the D* Lite algorithm and employs a distance metric within the synthesized automaton to quantify the degree of the task violation and then replan incrementally. This ensures plan optimality and reduces planning time, especially when frequent replanning is required. Our approach is implemented in a robot navigation simulation to demonstrate a significant improvement in the computational efficiency for replanning by two orders of magnitude."}
{"main_page": "https://arxiv.org/abs/2404.01220", "pdf": "https://arxiv.org/pdf/2404.01220", "title": "Entity-Centric Reinforcement Learning for Object Manipulation from  Pixels", "authors": "Dan Haramati, Tal Daniel, Aviv Tamar", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Manipulating objects is a hallmark of human intelligence, and an important task in domains such as robotics. In principle, Reinforcement Learning (RL) offers a general approach to learn object manipulation. In practice, however, domains with more than a few objects are difficult for RL agents due to the curse of dimensionality, especially when learning from raw image observations. In this work we propose a structured approach for visual RL that is suitable for representing multiple objects and their interaction, and use it to learn goal-conditioned manipulation of several objects. Key to our method is the ability to handle goals with dependencies between the objects (e.g., moving objects in a certain order). We further relate our architecture to the generalization capability of the trained agent, based on a theoretical result for compositional generalization, and demonstrate agents that learn with 3 objects but generalize to similar tasks with over 10 objects. Videos and code are available on the project website: https://sites.google.com/view/entity-centric-rl"}
{"main_page": "https://arxiv.org/abs/2404.01223", "pdf": "https://arxiv.org/pdf/2404.01223", "title": "Feature Splatting: Language-Driven Physics-Based Scene Synthesis and  Editing", "authors": "Ri-Zhao Qiu, Ge Yang, Weijia Zeng, Xiaolong Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)", "abstract": "Scene representations using 3D Gaussian primitives have produced excellent results in modeling the appearance of static and dynamic 3D scenes. Many graphics applications, however, demand the ability to manipulate both the appearance and the physical properties of objects. We introduce Feature Splatting, an approach that unifies physics-based dynamic scene synthesis with rich semantics from vision language foundation models that are grounded by natural language. Our first contribution is a way to distill high-quality, object-centric vision-language features into 3D Gaussians, that enables semi-automatic scene decomposition using text queries. Our second contribution is a way to synthesize physics-based dynamics from an otherwise static scene using a particle-based simulator, in which material properties are assigned automatically via text queries. We ablate key techniques used in this pipeline, to illustrate the challenge and opportunities in using feature-carrying 3D Gaussians as a unified format for appearance, geometry, material properties and semantics grounded on natural language. Project website: https://feature-splatting.github.io/"}
{"main_page": "https://arxiv.org/abs/2404.01224", "pdf": "https://arxiv.org/pdf/2404.01224", "title": "Collaborative Pareto Set Learning in Multiple Multi-Objective  Optimization Problems", "authors": "Chikai Shang, Rongguang Ye, Jiaqi Jiang, Fangqing Gu", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC)", "abstract": "Pareto Set Learning (PSL) is an emerging research area in multi-objective optimization, focusing on training neural networks to learn the mapping from preference vectors to Pareto optimal solutions. However, existing PSL methods are limited to addressing a single Multi-objective Optimization Problem (MOP) at a time. When faced with multiple MOPs, this limitation not only leads to significant inefficiencies but also fails to exploit the potential synergies across varying MOPs. In this paper, we propose a Collaborative Pareto Set Learning (CoPSL) framework, which simultaneously learns the Pareto sets of multiple MOPs in a collaborative manner. CoPSL employs an architecture consisting of shared and MOP-specific layers, where shared layers aim to capture common relationships among MOPs collaboratively, and MOP-specific layers process these relationships to generate solution sets for each MOP. This collaborative approach enables CoPSL to efficiently learn the Pareto sets of multiple MOPs in a single run while leveraging the relationships among various MOPs. To further understand these relationships, we experimentally demonstrate that there exist shareable representations among MOPs. Leveraging these collaboratively shared representations can effectively improve the capability to approximate Pareto sets. Extensive experiments underscore the superior efficiency and robustness of CoPSL in approximating Pareto sets compared to state-of-the-art approaches on a variety of synthetic and real-world MOPs. Code is available at https://github.com/ckshang/CoPSL."}
{"main_page": "https://arxiv.org/abs/2404.01225", "pdf": "https://arxiv.org/pdf/2404.01225", "title": "SurMo: Surface-based 4D Motion Modeling for Dynamic Human Rendering", "authors": "Tao Hu, Fangzhou Hong, Ziwei Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Dynamic human rendering from video sequences has achieved remarkable progress by formulating the rendering as a mapping from static poses to human images. However, existing methods focus on the human appearance reconstruction of every single frame while the temporal motion relations are not fully explored. In this paper, we propose a new 4D motion modeling paradigm, SurMo, that jointly models the temporal dynamics and human appearances in a unified framework with three key designs: 1) Surface-based motion encoding that models 4D human motions with an efficient compact surface-based triplane. It encodes both spatial and temporal motion relations on the dense surface manifold of a statistical body template, which inherits body topology priors for generalizable novel view synthesis with sparse training observations. 2) Physical motion decoding that is designed to encourage physical motion learning by decoding the motion triplane features at timestep t to predict both spatial derivatives and temporal derivatives at the next timestep t+1 in the training stage. 3) 4D appearance decoding that renders the motion triplanes into images by an efficient volumetric surface-conditioned renderer that focuses on the rendering of body surfaces with motion learning conditioning. Extensive experiments validate the state-of-the-art performance of our new paradigm and illustrate the expressiveness of surface-based motion triplanes for rendering high-fidelity view-consistent humans with fast motions and even motion-dependent shadows. Our project page is at: https://taohuumd.github.io/projects/SurMo/"}
{"main_page": "https://arxiv.org/abs/2404.01226", "pdf": "https://arxiv.org/pdf/2404.01226", "title": "Stable Code Technical Report", "authors": "Nikhil Pinnaparaju, Reshinth Adithyan, Duy Phung, Jonathan Tow, James Baicoianu, Ashish Datta, Maksym Zhuravinskyi, Dakota Mahan, Marco Bellagente, Carlos Riquelme, Nathan Cooper", "subjects": "Computation and Language (cs.CL)", "abstract": "We introduce Stable Code, the first in our new-generation of code language models series, which serves as a general-purpose base code language model targeting code completion, reasoning, math, and other software engineering-based tasks. Additionally, we introduce an instruction variant named Stable Code Instruct that allows conversing with the model in a natural chat interface for performing question-answering and instruction-based tasks. In this technical report, we detail the data and training procedure leading to both models. Their weights are available via Hugging Face for anyone to download and use at https://huggingface.co/stabilityai/stable-code-3b and https://huggingface.co/stabilityai/stable-code-instruct-3b. This report contains thorough evaluations of the models, including multilingual programming benchmarks, and the MT benchmark focusing on multi-turn dialogues. At the time of its release, Stable Code is the state-of-the-art open model under 3B parameters and even performs comparably to larger models of sizes 7 billion and 15 billion parameters on the popular Multi-PL benchmark. Stable Code Instruct also exhibits state-of-the-art performance on the MT-Bench coding tasks and on Multi-PL completion compared to other instruction tuned models. Given its appealing small size, we also provide throughput measurements on a number of edge devices. In addition, we open source several quantized checkpoints and provide their performance metrics compared to the original model."}
{"main_page": "https://arxiv.org/abs/2404.01228", "pdf": "https://arxiv.org/pdf/2404.01228", "title": "Adaptive hybrid high-order method for guaranteed lower eigenvalue bounds", "authors": "Carsten Carstensen, Benedikt Gr\u00e4\u00dfle, Ngoc Tien Tran", "subjects": "Numerical Analysis (math.NA)", "abstract": "The higher-order guaranteed lower eigenvalue bounds of the Laplacian in the recent work by Carstensen, Ern, and Puttkammer [Numer. Math. 149, 2021] require a parameter $C_{\\mathrm{st},1}$ that is found $\\textit{not}$ robust as the polynomial degree $p$ increases. This is related to the $H^1$ stability bound of the $L^2$ projection onto polynomials of degree at most $p$ and its growth $C_{\\rm st, 1}\\propto (p+1)^{1/2}$ as $p \\to \\infty$. A similar estimate for the Galerkin projection holds with a $p$-robust constant $C_{\\mathrm{st},2}$ and $C_{\\mathrm{st},2} \\le 2$ for right-isosceles triangles. This paper utilizes the new inequality with the constant $C_{\\mathrm{st},2}$ to design a modified hybrid high-order (HHO) eigensolver that directly computes guaranteed lower eigenvalue bounds under the idealized hypothesis of exact solve of the generalized algebraic eigenvalue problem and a mild explicit condition on the maximal mesh-size in the simplicial mesh. A key advance is a $p$-robust parameter selection. The analysis of the new method with a different fine-tuned volume stabilization allows for a priori quasi-best approximation and improved $L^2$ error estimates as well as a stabilization-free reliable and efficient a posteriori error control. The associated adaptive mesh-refining algorithm performs superior in computer benchmarks with striking numerical evidence for optimal higher empirical convergence rates."}
{"main_page": "https://arxiv.org/abs/2404.01229", "pdf": "https://arxiv.org/pdf/2404.01229", "title": "Age of Information in a Single-Source Generate-at-Will Dual-Server  Status Update System", "authors": "Nail Akar, Sennur Ulukus", "subjects": "Information Theory (cs.IT); Networking and Internet Architecture (cs.NI); Performance (cs.PF)", "abstract": "We study age of information (AoI) in a single-source dual-server status update system for the generate at will (GAW) scenario, consisting of an information source, dual servers, and a monitor. For this system, the method of stochastic hybrid systems (SHS) was used to obtain the mean AoI for the work-conserving ZW (zero wait) policy with out-of-order packet discarding at the monitor. In this paper, we propose a non-work-conserving F/P (freeze/preempt) policy for which the sampling and transmission process is frozen for an Erlang distributed amount of time upon each transmission, and out-of-order packets are preempted immediately at the source, rather than being discarded at the monitor upon reception. We use the absorbing Markov chain (AMC) method to obtain the exact distributions of AoI and also the peak AoI (PAoI) processes, for both ZW and F/P policies. Numerical results are presented for the validation of the proposed analytical model and a comparative evaluation of ZW and F/P policies."}
{"main_page": "https://arxiv.org/abs/2404.01230", "pdf": "https://arxiv.org/pdf/2404.01230", "title": "LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language  Models", "authors": "Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Adrian de Wynter, Yan Xia, Wenshan Wu, Ting Song, Man Lan, Furu Wei", "subjects": "Computation and Language (cs.CL)", "abstract": "This paper presents a comprehensive survey of the current status and opportunities for Large Language Models (LLMs) in strategic reasoning, a sophisticated form of reasoning that necessitates understanding and predicting adversary actions in multi-agent settings while adjusting strategies accordingly. Strategic reasoning is distinguished by its focus on the dynamic and uncertain nature of interactions among multi-agents, where comprehending the environment and anticipating the behavior of others is crucial. We explore the scopes, applications, methodologies, and evaluation metrics related to strategic reasoning with LLMs, highlighting the burgeoning development in this area and the interdisciplinary approaches enhancing their decision-making performance. It aims to systematize and clarify the scattered literature on this subject, providing a systematic review that underscores the importance of strategic reasoning as a critical cognitive capability and offers insights into future research directions and potential improvements."}
{"main_page": "https://arxiv.org/abs/2404.01231", "pdf": "https://arxiv.org/pdf/2404.01231", "title": "Privacy Backdoors: Enhancing Membership Inference through Poisoning  Pre-trained Models", "authors": "Yuxin Wen, Leo Marchyok, Sanghyun Hong, Jonas Geiping, Tom Goldstein, Nicholas Carlini", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "It is commonplace to produce application-specific models by fine-tuning large pre-trained models using a small bespoke dataset. The widespread availability of foundation model checkpoints on the web poses considerable risks, including the vulnerability to backdoor attacks. In this paper, we unveil a new vulnerability: the privacy backdoor attack. This black-box privacy attack aims to amplify the privacy leakage that arises when fine-tuning a model: when a victim fine-tunes a backdoored model, their training data will be leaked at a significantly higher rate than if they had fine-tuned a typical model. We conduct extensive experiments on various datasets and models, including both vision-language models (CLIP) and large language models, demonstrating the broad applicability and effectiveness of such an attack. Additionally, we carry out multiple ablation studies with different fine-tuning methods and inference strategies to thoroughly analyze this new threat. Our findings highlight a critical privacy concern within the machine learning community and call for a reevaluation of safety protocols in the use of open-source pre-trained models."}
{"main_page": "https://arxiv.org/abs/2404.01232", "pdf": "https://arxiv.org/pdf/2404.01232", "title": "Open-Vocabulary Federated Learning with Multimodal Prototyping", "authors": "Huimin Zeng, Zhenrui Yue, Dong Wang", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Existing federated learning (FL) studies usually assume the training label space and test label space are identical. However, in real-world applications, this assumption is too ideal to be true. A new user could come up with queries that involve data from unseen classes, and such open-vocabulary queries would directly defect such FL systems. Therefore, in this work, we explicitly focus on the under-explored open-vocabulary challenge in FL. That is, for a new user, the global server shall understand her/his query that involves arbitrary unknown classes. To address this problem, we leverage the pre-trained vision-language models (VLMs). In particular, we present a novel adaptation framework tailored for VLMs in the context of FL, named as Federated Multimodal Prototyping (Fed-MP). Fed-MP adaptively aggregates the local model weights based on light-weight client residuals, and makes predictions based on a novel multimodal prototyping mechanism. Fed-MP exploits the knowledge learned from the seen classes, and robustifies the adapted VLM to unseen categories. Our empirical evaluation on various datasets validates the effectiveness of Fed-MP."}
{"main_page": "https://arxiv.org/abs/2404.01234", "pdf": "https://arxiv.org/pdf/2404.01234", "title": "GFLean: An Autoformalisation Framework for Lean via GF", "authors": "Shashank Pathak", "subjects": "Computation and Language (cs.CL); Logic (math.LO)", "abstract": "We present an autoformalisation framework for the Lean theorem prover, called GFLean. GFLean uses a high-level grammar writing tool called Grammatical Framework (GF) for parsing and linearisation. GFLean is implemented in Haskell. We explain the functionalities of GFLean, its inner working and discuss its limitations. We also discuss how we can use neural network based translation programs and rule based translation programs together complimenting each other to build robust autoformalisation frameworks."}
{"main_page": "https://arxiv.org/abs/2404.01237", "pdf": "https://arxiv.org/pdf/2404.01237", "title": "FPGA-Accelerated Correspondence-free Point Cloud Registration with  PointNet Features", "authors": "Keisuke Sugiura, Hiroki Matsutani", "subjects": "Robotics (cs.RO); Hardware Architecture (cs.AR)", "abstract": "Point cloud registration serves as a basis for vision and robotic applications including 3D reconstruction and mapping. Despite significant improvements on the quality of results, recent deep learning approaches are computationally expensive and power-hungry, making them difficult to deploy on resource-constrained edge devices. To tackle this problem, in this paper, we propose a fast, accurate, and robust registration for low-cost embedded FPGAs. Based on a parallel and pipelined PointNet feature extractor, we develop custom accelerator cores namely PointLKCore and ReAgentCore, for two different learning-based methods. They are both correspondence-free and computationally efficient as they avoid the costly feature matching step involving nearest-neighbor search. The proposed cores are implemented on the Xilinx ZCU104 board and evaluated using both synthetic and real-world datasets, showing the substantial improvements in the trade-offs between runtime and registration quality. They run 44.08-45.75x faster than ARM Cortex-A53 CPU and offer 1.98-11.13x speedups over Intel Xeon CPU and Nvidia Jetson boards, while consuming less than 1W and achieving 163.11-213.58x energy-efficiency compared to Nvidia GeForce GPU. The proposed cores are more robust to noise and large initial misalignments than the classical methods and quickly find reasonable solutions in less than 15ms, demonstrating the real-time performance."}
{"main_page": "https://arxiv.org/abs/2404.01240", "pdf": "https://arxiv.org/pdf/2404.01240", "title": "AURORA: Navigating UI Tarpits via Automated Neural Screen Understanding", "authors": "Safwat Ali Khan, Wenyu Wang, Yiran Ren, Bin Zhu, Jiangfan Shi, Alyssa McGowan, Wing Lam, Kevin Moran", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)", "abstract": "Nearly a decade of research in software engineering has focused on automating mobile app testing to help engineers in overcoming the unique challenges associated with the software platform. Much of this work has come in the form of Automated Input Generation tools (AIG tools) that dynamically explore app screens. However, such tools have repeatedly been demonstrated to achieve lower-than-expected code coverage - particularly on sophisticated proprietary apps. Prior work has illustrated that a primary cause of these coverage deficiencies is related to so-called tarpits, or complex screens that are difficult to navigate. In this paper, we take a critical step toward enabling AIG tools to effectively navigate tarpits during app exploration through a new form of automated semantic screen understanding. We introduce AURORA, a technique that learns from the visual and textual patterns that exist in mobile app UIs to automatically detect common screen designs and navigate them accordingly. The key idea of AURORA is that there are a finite number of mobile app screen designs, albeit with subtle variations, such that the general patterns of different categories of UI designs can be learned. As such, AURORA employs a multi-modal, neural screen classifier that is able to recognize the most common types of UI screen designs. After recognizing a given screen, it then applies a set of flexible and generalizable heuristics to properly navigate the screen. We evaluated AURORA both on a set of 12 apps with known tarpits from prior work, and on a new set of five of the most popular apps from the Google Play store. Our results indicate that AURORA is able to effectively navigate tarpit screens, outperforming prior approaches that avoid tarpits by 19.6% in terms of method coverage. The improvements can be attributed to AURORA's UI design classification and heuristic navigation techniques."}
{"main_page": "https://arxiv.org/abs/2404.01241", "pdf": "https://arxiv.org/pdf/2404.01241", "title": "StructLDM: Structured Latent Diffusion for 3D Human Generation", "authors": "Tao Hu, Fangzhou Hong, Ziwei Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent 3D human generative models have achieved remarkable progress by learning 3D-aware GANs from 2D images. However, existing 3D human generative methods model humans in a compact 1D latent space, ignoring the articulated structure and semantics of human body topology. In this paper, we explore more expressive and higher-dimensional latent space for 3D human modeling and propose StructLDM, a diffusion-based unconditional 3D human generative model, which is learned from 2D images. StructLDM solves the challenges imposed due to the high-dimensional growth of latent space with three key designs: 1) A semantic structured latent space defined on the dense surface manifold of a statistical human body template. 2) A structured 3D-aware auto-decoder that factorizes the global latent space into several semantic body parts parameterized by a set of conditional structured local NeRFs anchored to the body template, which embeds the properties learned from the 2D training data and can be decoded to render view-consistent humans under different poses and clothing styles. 3) A structured latent diffusion model for generative human appearance sampling. Extensive experiments validate StructLDM's state-of-the-art generation performance and illustrate the expressiveness of the structured latent space over the well-adopted 1D latent space. Notably, StructLDM enables different levels of controllable 3D human generation and editing, including pose/view/shape control, and high-level tasks including compositional generations, part-aware clothing editing, 3D virtual try-on, etc. Our project page is at: https://taohuumd.github.io/projects/StructLDM/."}
{"main_page": "https://arxiv.org/abs/2404.01242", "pdf": "https://arxiv.org/pdf/2404.01242", "title": "Effectively Prompting Small-sized Language Models for Cross-lingual  Tasks via Winning Tickets", "authors": "Mingqi Li, Feng Luo", "subjects": "Computation and Language (cs.CL)", "abstract": "Current soft prompt methods yield limited performance when applied to small-sized models (fewer than a billion parameters). Deep prompt-tuning, which entails prepending parameters in each layer for enhanced efficacy, presents a solution for prompting small-sized models, albeit requiring carefully designed implementation. In this paper, we introduce the Lottery Ticket Prompt-learning (LTP) framework that integrates winning tickets with soft prompts. The LTP offers a simpler implementation and requires only a one-time execution. We demonstrate LTP on cross-lingual tasks, where prior works rely on external tools like human-designed multilingual templates and bilingual dictionaries, which may not be feasible in a low-resource regime. Specifically, we select a subset of parameters that have been changed the most during the fine-tuning with the Masked Language Modeling objective. Then, we prepend soft prompts to the original pre-trained language model and only update the selected parameters together with prompt-related parameters when adapting to the downstream tasks. We verify the effectiveness of our LTP framework on cross-lingual tasks, specifically targeting low-resource languages. Our approach outperforms the baselines by only updating 20\\% of the original parameters."}
{"main_page": "https://arxiv.org/abs/2404.01243", "pdf": "https://arxiv.org/pdf/2404.01243", "title": "A Unified and Interpretable Emotion Representation and Expression  Generation", "authors": "Reni Paskaleva, Mykyta Holubakha, Andela Ilic, Saman Motamed, Luc Van Gool, Danda Paudel", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Canonical emotions, such as happy, sad, and fearful, are easy to understand and annotate. However, emotions are often compound, e.g. happily surprised, and can be mapped to the action units (AUs) used for expressing emotions, and trivially to the canonical ones. Intuitively, emotions are continuous as represented by the arousal-valence (AV) model. An interpretable unification of these four modalities - namely, Canonical, Compound, AUs, and AV - is highly desirable, for a better representation and understanding of emotions. However, such unification remains to be unknown in the current literature. In this work, we propose an interpretable and unified emotion model, referred as C2A2. We also develop a method that leverages labels of the non-unified models to annotate the novel unified one. Finally, we modify the text-conditional diffusion models to understand continuous numbers, which are then used to generate continuous expressions using our unified emotion model. Through quantitative and qualitative experiments, we show that our generated images are rich and capture subtle expressions. Our work allows a fine-grained generation of expressions in conjunction with other textual inputs and offers a new label space for emotions at the same time."}
{"main_page": "https://arxiv.org/abs/2404.01247", "pdf": "https://arxiv.org/pdf/2404.01247", "title": "An image speaks a thousand words, but can everyone listen? On  translating images for cultural relevance", "authors": "Simran Khanuja, Sathyanarayanan Ramamoorthy, Yueqi Song, Graham Neubig", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Given the rise of multimedia content, human translators increasingly focus on culturally adapting not only words but also other modalities such as images to convey the same meaning. While several applications stand to benefit from this, machine translation systems remain confined to dealing with language in speech and text. In this work, we take a first step towards translating images to make them culturally relevant. First, we build three pipelines comprising state-of-the-art generative models to do the task. Next, we build a two-part evaluation dataset: i) concept: comprising 600 images that are cross-culturally coherent, focusing on a single concept per image, and ii) application: comprising 100 images curated from real-world applications. We conduct a multi-faceted human evaluation of translated images to assess for cultural relevance and meaning preservation. We find that as of today, image-editing models fail at this task, but can be improved by leveraging LLMs and retrievers in the loop. Best pipelines can only translate 5% of images for some countries in the easier concept dataset and no translation is successful for some countries in the application dataset, highlighting the challenging nature of the task. Our code and data is released here: https://github.com/simran-khanuja/image-transcreation."}
{"main_page": "https://arxiv.org/abs/2404.01248", "pdf": "https://arxiv.org/pdf/2404.01248", "title": "Scalable Scene Modeling from Perspective Imaging: Physics-based  Appearance and Geometry Inference", "authors": "Shuang Song", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "3D scene modeling techniques serve as the bedrocks in the geospatial engineering and computer science, which drives many applications ranging from automated driving, terrain mapping, navigation, virtual, augmented, mixed, and extended reality (for gaming and movie industry etc.). This dissertation presents a fraction of contributions that advances 3D scene modeling to its state of the art, in the aspects of both appearance and geometry modeling. In contrast to the prevailing deep learning methods, as a core contribution, this thesis aims to develop algorithms that follow first principles, where sophisticated physic-based models are introduced alongside with simpler learning and inference tasks. The outcomes of these algorithms yield processes that can consume much larger volume of data for highly accurate reconstructing 3D scenes at a scale without losing methodological generality, which are not possible by contemporary complex-model based deep learning methods. Specifically, the dissertation introduces three novel methodologies that address the challenges of inferring appearance and geometry through physics-based modeling. Overall, the research encapsulated in this dissertation marks a series of methodological triumphs in the processing of complex datasets. By navigating the confluence of deep learning, computational geometry, and photogrammetry, this work lays down a robust framework for future exploration and practical application in the rapidly evolving field of 3D scene reconstruction. The outcomes of these studies are evidenced through rigorous experiments and comparisons with existing state-of-the-art methods, demonstrating the efficacy and scalability of the proposed approaches."}
{"main_page": "https://arxiv.org/abs/2404.01249", "pdf": "https://arxiv.org/pdf/2404.01249", "title": "FireANTs: Adaptive Riemannian Optimization for Multi-Scale Diffeomorphic  Registration", "authors": "Rohit Jena, Pratik Chaudhari, James C. Gee", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Diffeomorphic Image Registration is a critical part of the analysis in various imaging modalities and downstream tasks like image translation, segmentation, and atlas building. Registration algorithms based on optimization have stood the test of time in terms of accuracy, reliability, and robustness across a wide spectrum of modalities and acquisition settings. However, these algorithms converge slowly, are prohibitively expensive to run, and their usage requires a steep learning curve, limiting their scalability to larger clinical and scientific studies. In this paper, we develop multi-scale Adaptive Riemannian Optimization algorithms for diffeomorphic image registration. We demonstrate compelling improvements on image registration across a spectrum of modalities and anatomies by measuring structural and landmark overlap of the registered image volumes. Our proposed framework leads to a consistent improvement in performance, and from 300x up to 2000x speedup over existing algorithms. Our modular library design makes it easy to use and allows customization via user-defined cost functions."}
{"main_page": "https://arxiv.org/abs/2404.01251", "pdf": "https://arxiv.org/pdf/2404.01251", "title": "Duality based error control for the Signorini problem", "authors": "Ben S. Ashby, Tristan Pryer", "subjects": "Numerical Analysis (math.NA)", "abstract": "In this paper we study the a posteriori bounds for a conforming piecewise linear finite element approximation of the Signorini problem. We prove new rigorous a posteriori estimates of residual type in $L^{p}$, for $p \\in (4,\\infty)$ in two spatial dimensions. This new analysis treats the positive and negative parts of the discretisation error separately, requiring a novel sign- and bound-preserving interpolant, which is shown to have optimal approximation properties. The estimates rely on the sharp dual stability results on the problem in $W^{2,(4 - \\varepsilon)/3}$ for any $\\varepsilon \\ll 1$. We summarise extensive numerical experiments aimed at testing the robustness of the estimator to validate the theory."}
{"main_page": "https://arxiv.org/abs/2404.01253", "pdf": "https://arxiv.org/pdf/2404.01253", "title": "UniArk: Improving Generalisation and Consistency for Factual Knowledge  Extraction through Debiasing", "authors": "Yijun Yang, Jie He, Pinzhen Chen, V\u00edctor Guti\u00e9rrez-Basulto, Jeff Z. Pan", "subjects": "Computation and Language (cs.CL)", "abstract": "Several recent papers have investigated the potential of language models as knowledge bases as well as the existence of severe biases when extracting factual knowledge. In this work, we focus on the factual probing performance over unseen prompts from tuning, and using a probabilistic view we show the inherent misalignment between pre-training and downstream tuning objectives in language models for probing knowledge. We hypothesize that simultaneously debiasing these objectives can be the key to generalisation over unseen prompts. We propose an adapter-based framework, UniArk, for generalised and consistent factual knowledge extraction through simple methods without introducing extra parameters. Extensive experiments show that UniArk can significantly improve the model's out-of-domain generalisation as well as consistency under various prompts. Additionally, we construct ParaTrex, a large-scale and diverse dataset for measuring the inconsistency and out-of-domain generation of models. Further, ParaTrex offers a reference method for constructing paraphrased datasets using large language models."}
{"main_page": "https://arxiv.org/abs/2404.01257", "pdf": "https://arxiv.org/pdf/2404.01257", "title": "New logarithmic step size for stochastic gradient descent", "authors": "M. Soheil Shamaee, S. Fathi Hafshejani, Z. Saeidian", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC)", "abstract": "In this paper, we propose a novel warm restart technique using a new logarithmic step size for the stochastic gradient descent (SGD) approach. For smooth and non-convex functions, we establish an $O(\\frac{1}{\\sqrt{T}})$ convergence rate for the SGD. We conduct a comprehensive implementation to demonstrate the efficiency of the newly proposed step size on the ~FashionMinst,~ CIFAR10, and CIFAR100 datasets. Moreover, we compare our results with nine other existing approaches and demonstrate that the new logarithmic step size improves test accuracy by $0.9\\%$ for the CIFAR100 dataset when we utilize a convolutional neural network (CNN) model."}
{"main_page": "https://arxiv.org/abs/2404.01258", "pdf": "https://arxiv.org/pdf/2404.01258", "title": "Direct Preference Optimization of Video Large Multimodal Models from  Language Model Reward", "authors": "Ruohong Zhang, Liangke Gui, Zhiqing Sun, Yihao Feng, Keyang Xu, Yuanhan Zhang, Di Fu, Chunyuan Li, Alexander Hauptmann, Yonatan Bisk, Yiming Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Preference modeling techniques, such as direct preference optimization (DPO), has shown effective in enhancing the generalization abilities of large language model (LLM). However, in tasks involving video instruction-following, providing informative feedback, especially for detecting hallucinations in generated responses, remains a significant challenge. Previous studies have explored using large large multimodal models (LMMs) as reward models to guide preference modeling, but their ability to accurately assess the factuality of generated responses compared to corresponding videos has not been conclusively established. This paper introduces a novel framework that utilizes detailed video captions as a proxy of video content, enabling language models to incorporate this information as supporting evidence for scoring video Question Answering (QA) predictions. Our approach demonstrates robust alignment with OpenAI GPT-4V model's reward mechanism, which directly takes video frames as input. Furthermore, we show that applying this tailored reward through DPO significantly improves the performance of video LMMs on video QA tasks."}
{"main_page": "https://arxiv.org/abs/2404.01260", "pdf": "https://arxiv.org/pdf/2404.01260", "title": "Bridging Remote Sensors with Multisensor Geospatial Foundation Models", "authors": "Boran Han, Shuai Zhang, Xingjian Shi, Markus Reichstein", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "In the realm of geospatial analysis, the diversity of remote sensors, encompassing both optical and microwave technologies, offers a wealth of distinct observational capabilities. Recognizing this, we present msGFM, a multisensor geospatial foundation model that effectively unifies data from four key sensor modalities. This integration spans an expansive dataset of two million multisensor images. msGFM is uniquely adept at handling both paired and unpaired sensor data. For data originating from identical geolocations, our model employs an innovative cross-sensor pretraining approach in masked image modeling, enabling the synthesis of joint representations from diverse sensors. msGFM, incorporating four remote sensors, upholds strong performance, forming a comprehensive model adaptable to various sensor types. msGFM has demonstrated enhanced proficiency in a range of both single-sensor and multisensor downstream tasks. These include scene classification, segmentation, cloud removal, and pan-sharpening. A key discovery of our research is that representations derived from natural images are not always compatible with the distinct characteristics of geospatial remote sensors, underscoring the limitations of existing representations in this field. Our work can serve as a guide for developing multisensor geospatial pretraining models, paving the way for more advanced geospatial capabilities."}
{"main_page": "https://arxiv.org/abs/2404.01261", "pdf": "https://arxiv.org/pdf/2404.01261", "title": "FABLES: Evaluating faithfulness and content selection in book-length  summarization", "authors": "Yekyung Kim, Yapei Chang, Marzena Karpinska, Aparna Garimella, Varun Manjunatha, Kyle Lo, Tanya Goyal, Mohit Iyyer", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "While long-context large language models (LLMs) can technically summarize book-length documents (>100K tokens), the length and complexity of the documents have so far prohibited evaluations of input-dependent aspects like faithfulness. In this paper, we conduct the first large-scale human evaluation of faithfulness and content selection on LLM-generated summaries of fictional books. Our study mitigates the issue of data contamination by focusing on summaries of books published in 2023 or 2024, and we hire annotators who have fully read each book prior to the annotation task to minimize cost and cognitive burden. We collect FABLES, a dataset of annotations on 3,158 claims made in LLM-generated summaries of 26 books, at a cost of $5.2K USD, which allows us to rank LLM summarizers based on faithfulness: Claude-3-Opus significantly outperforms all closed-source LLMs, while the open-source Mixtral is on par with GPT-3.5-Turbo. An analysis of the annotations reveals that most unfaithful claims relate to events and character states, and they generally require indirect reasoning over the narrative to invalidate. While LLM-based auto-raters have proven reliable for factuality and coherence in other settings, we implement several LLM raters of faithfulness and find that none correlates strongly with human annotations, especially with regard to detecting unfaithful claims. Our experiments suggest that detecting unfaithful claims is an important future direction not only for summarization evaluation but also as a testbed for long-context understanding. Finally, we move beyond faithfulness by exploring content selection errors in book-length summarization: we develop a typology of omission errors related to crucial narrative elements and also identify a systematic over-emphasis on events occurring towards the end of the book."}
{"main_page": "https://arxiv.org/abs/2404.01263", "pdf": "https://arxiv.org/pdf/2404.01263", "title": "Artificial Intelligence and the Spatial Documentation of Languages", "authors": "Hakam Ghanim", "subjects": "Computation and Language (cs.CL)", "abstract": "The advancement in technology has made interdisciplinary research more accessible. Particularly the breakthrough in Artificial Intelligence AI has given huge advantages to researchers working in interdisciplinary and multidisciplinary fields. This study investigates the ability of AI models, particularly GPT4 and GPT Data Analyst in creating language maps for language documentation. The study Integrates documentary linguistics linguistic geography and AI by showcasing how AI models facilitate the spatial documentation of languages through the creation of language maps with minimal cartographic expertise. The study is conducted using a CSV file and a GeoJSON file both obtained from HDX and from the researchers fieldwork. The study data is then applied in realtime conversations with the AI models in order to generate the language distribution maps. The study highlights the two AI models capabilities in generating highquality static and interactive web maps and streamlining the mapmaking process, despite facing challenges like inconsistencies and difficulties in adding legends. The findings suggest a promising future for AI in generating language maps and enhancing the work of documentary linguists as they collect their data in the field pointing towards the need for further development to fully harness AI potential in this field."}
{"main_page": "https://arxiv.org/abs/2404.01266", "pdf": "https://arxiv.org/pdf/2404.01266", "title": "IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic  Representations", "authors": "Deqing Fu, Ghazal Khalighinejad, Ollie Liu, Bhuwan Dhingra, Dani Yogatama, Robin Jia, Willie Neiswanger", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Current foundation models exhibit impressive capabilities when prompted either with text only or with both image and text inputs. But do their capabilities change depending on the input modality? In this work, we propose $\\textbf{IsoBench}$, a benchmark dataset containing problems from four major areas: math, science, algorithms, and games. Each example is presented with multiple $\\textbf{isomorphic representations}$ of inputs, such as visual, textual, and mathematical presentations. IsoBench provides fine-grained feedback to diagnose performance gaps caused by the form of the representation. Across various foundation models, we observe that on the same problem, models have a consistent preference towards textual representations. Most prominently, when evaluated on all IsoBench problems, Claude-3 Opus performs 28.7 points worse when provided with images instead of text; similarly, GPT-4 Turbo is 18.7 points worse and Gemini Pro is 14.9 points worse. Finally, we present two prompting techniques, $\\textit{IsoCombination}$ and $\\textit{IsoScratchPad}$, which improve model performance by considering combinations of, and translations between, different input representations."}
{"main_page": "https://arxiv.org/abs/2404.01268", "pdf": "https://arxiv.org/pdf/2404.01268", "title": "Mapping the Increasing Use of LLMs in Scientific Papers", "authors": "Weixin Liang, Yaohui Zhang, Zhengxuan Wu, Haley Lepp, Wenlong Ji, Xuandong Zhao, Hancheng Cao, Sheng Liu, Siyu He, Zhi Huang, Diyi Yang, Christopher Potts, Christopher D Manning, James Y. Zou", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Machine Learning (cs.LG); Social and Information Networks (cs.SI)", "abstract": "Scientific publishing lays the foundation of science by disseminating research findings, fostering collaboration, encouraging reproducibility, and ensuring that scientific knowledge is accessible, verifiable, and built upon over time. Recently, there has been immense speculation about how many people are using large language models (LLMs) like ChatGPT in their academic writing, and to what extent this tool might have an effect on global scientific practices. However, we lack a precise measure of the proportion of academic writing substantially modified or produced by LLMs. To address this gap, we conduct the first systematic, large-scale analysis across 950,965 papers published between January 2020 and February 2024 on the arXiv, bioRxiv, and Nature portfolio journals, using a population-level statistical framework to measure the prevalence of LLM-modified content over time. Our statistical estimation operates on the corpus level and is more robust than inference on individual instances. Our findings reveal a steady increase in LLM usage, with the largest and fastest growth observed in Computer Science papers (up to 17.5%). In comparison, Mathematics papers and the Nature portfolio showed the least LLM modification (up to 6.3%). Moreover, at an aggregate level, our analysis reveals that higher levels of LLM-modification are associated with papers whose first authors post preprints more frequently, papers in more crowded research areas, and papers of shorter lengths. Our findings suggests that LLMs are being broadly used in scientific writings."}
{"main_page": "https://arxiv.org/abs/2404.01270", "pdf": "https://arxiv.org/pdf/2404.01270", "title": "Decentralized Collaborative Learning Framework with External Privacy  Leakage Analysis", "authors": "Tsuyoshi Id\u00e9, Dzung T. Phan, Rudy Raymond", "subjects": "Machine Learning (cs.LG); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "This paper presents two methodological advancements in decentralized multi-task learning under privacy constraints, aiming to pave the way for future developments in next-generation Blockchain platforms. First, we expand the existing framework for collaborative dictionary learning (CollabDict), which has previously been limited to Gaussian mixture models, by incorporating deep variational autoencoders (VAEs) into the framework, with a particular focus on anomaly detection. We demonstrate that the VAE-based anomaly score function shares the same mathematical structure as the non-deep model, and provide comprehensive qualitative comparison. Second, considering the widespread use of \"pre-trained models,\" we provide a mathematical analysis on data privacy leakage when models trained with CollabDict are shared externally. We show that the CollabDict approach, when applied to Gaussian mixtures, adheres to a Renyi differential privacy criterion. Additionally, we propose a practical metric for monitoring internal privacy breaches during the learning process."}
{"main_page": "https://arxiv.org/abs/2404.01272", "pdf": "https://arxiv.org/pdf/2404.01272", "title": "Language Guided Domain Generalized Medical Image Segmentation", "authors": "Shahina Kunhimon, Muzammal Naseer, Salman Khan, Fahad Shahbaz Khan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Single source domain generalization (SDG) holds promise for more reliable and consistent image segmentation across real-world clinical settings particularly in the medical domain, where data privacy and acquisition cost constraints often limit the availability of diverse datasets. Depending solely on visual features hampers the model's capacity to adapt effectively to various domains, primarily because of the presence of spurious correlations and domain-specific characteristics embedded within the image features. Incorporating text features alongside visual features is a potential solution to enhance the model's understanding of the data, as it goes beyond pixel-level information to provide valuable context. Textual cues describing the anatomical structures, their appearances, and variations across various imaging modalities can guide the model in domain adaptation, ultimately contributing to more robust and consistent segmentation. In this paper, we propose an approach that explicitly leverages textual information by incorporating a contrastive learning mechanism guided by the text encoder features to learn a more robust feature representation. We assess the effectiveness of our text-guided contrastive feature alignment technique in various scenarios, including cross-modality, cross-sequence, and cross-site settings for different segmentation tasks. Our approach achieves favorable performance against existing methods in literature. Our code and model weights are available at https://github.com/ShahinaKK/LG_SDG.git."}
{"main_page": "https://arxiv.org/abs/2404.01273", "pdf": "https://arxiv.org/pdf/2404.01273", "title": "TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model", "authors": "Yue Wang, Yingzhou Lu, Yinlong Xu, Zihan Ma, Hongxia Xu, Bang Du, Honghao Gao, Jian Wu", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Methodology (stat.ME)", "abstract": "Recently, there has been a burgeoning interest in virtual clinical trials, which simulate real-world scenarios and hold the potential to significantly enhance patient safety, expedite development, reduce costs, and contribute to the broader scientific knowledge in healthcare. Existing research often focuses on leveraging electronic health records (EHRs) to support clinical trial outcome prediction. Yet, trained with limited clinical trial outcome data, existing approaches frequently struggle to perform accurate predictions. Some research has attempted to generate EHRs to augment model development but has fallen short in personalizing the generation for individual patient profiles. Recently, the emergence of large language models has illuminated new possibilities, as their embedded comprehensive clinical knowledge has proven beneficial in addressing medical issues. In this paper, we propose a large language model-based digital twin creation approach, called TWIN-GPT. TWIN-GPT can establish cross-dataset associations of medical information given limited data, generating unique personalized digital twins for different patients, thereby preserving individual patient characteristics. Comprehensive experiments show that using digital twins created by TWIN-GPT can boost clinical trial outcome prediction, exceeding various previous prediction approaches. Besides, we also demonstrate that TWIN-GPT can generate high-fidelity trial data that closely approximate specific patients, aiding in more accurate result predictions in data-scarce situations. Moreover, our study provides practical evidence for the application of digital twins in healthcare, highlighting its potential significance."}
{"main_page": "https://arxiv.org/abs/2404.01276", "pdf": "https://arxiv.org/pdf/2404.01276", "title": "Variable-Length Stop-Feedback Coding for Minimum Age of Incorrect  Information", "authors": "Konstantinos Bountrogiannis, Ioannis Papoutsidakis, Anthony Ephremides, Panagiotis Tsakalides, George Tzagkarakis", "subjects": "Information Theory (cs.IT)", "abstract": "We study the average Age of Incorrect Information (AoII) in the context of remote monitoring of a symmetric Markov source using variable-length stop-feedback (VLSF) coding. We consider sources with small cardinality, where feedback is non-instantaneous, as the transmitted information and feedback may have comparable lengths. We leverage recent results on the non-asymptotic achievable channel coding rate to derive optimal feedback sequences, i.e. the times of feedback transmissions, in terms of either AoII or delay. Our results showcase the impact of the feedback sequence and SNR on the AoII, revealing that a lower average delay does not necessarily correspond to a lower average AoII. We discuss implications and suggest directions for efficient coding scheme design."}
{"main_page": "https://arxiv.org/abs/2404.01278", "pdf": "https://arxiv.org/pdf/2404.01278", "title": "BiPer: Binary Neural Networks using a Periodic Function", "authors": "Edwin Vargas, Claudia Correa, Carlos Hinojosa, Henry Arguello", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Quantized neural networks employ reduced precision representations for both weights and activations. This quantization process significantly reduces the memory requirements and computational complexity of the network. Binary Neural Networks (BNNs) are the extreme quantization case, representing values with just one bit. Since the sign function is typically used to map real values to binary values, smooth approximations are introduced to mimic the gradients during error backpropagation. Thus, the mismatch between the forward and backward models corrupts the direction of the gradient, causing training inconsistency problems and performance degradation. In contrast to current BNN approaches, we propose to employ a binary periodic (BiPer) function during binarization. Specifically, we use a square wave for the forward pass to obtain the binary values and employ the trigonometric sine function with the same period of the square wave as a differentiable surrogate during the backward pass. We demonstrate that this approach can control the quantization error by using the frequency of the periodic function and improves network performance. Extensive experiments validate the effectiveness of BiPer in benchmark datasets and network architectures, with improvements of up to 1% and 0.69% with respect to state-of-the-art methods in the classification task over CIFAR-10 and ImageNet, respectively. Our code is publicly available at https://github.com/edmav4/BiPer."}
{"main_page": "https://arxiv.org/abs/2404.01282", "pdf": "https://arxiv.org/pdf/2404.01282", "title": "LoSA: Long-Short-range Adapter for Scaling End-to-End Temporal Action  Localization", "authors": "Akshita Gupta, Gaurav Mittal, Ahmed Magooda, Ye Yu, Graham W. Taylor, Mei Chen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Temporal Action Localization (TAL) involves localizing and classifying action snippets in an untrimmed video. The emergence of large video foundation models has led RGB-only video backbones to outperform previous methods needing both RGB and optical flow modalities. Leveraging these large models is often limited to training only the TAL head due to the prohibitively large GPU memory required to adapt the video backbone for TAL. To overcome this limitation, we introduce LoSA, the first memory-and-parameter-efficient backbone adapter designed specifically for TAL to handle untrimmed videos. LoSA specializes for TAL by introducing Long-Short-range Adapters that adapt the intermediate layers of the video backbone over different temporal ranges. These adapters run parallel to the video backbone to significantly reduce memory footprint. LoSA also includes Long-Short-range Fusion that strategically combines the output of these adapters from the video backbone layers to enhance the video features provided to the TAL head. Experiments show that LoSA significantly outperforms all existing methods on standard TAL benchmarks, THUMOS-14 and ActivityNet-v1.3, by scaling end-to-end backbone adaptation to billion-parameter-plus models like VideoMAEv2~(ViT-g) and leveraging them beyond head-only transfer learning."}
{"main_page": "https://arxiv.org/abs/2404.01283", "pdf": "https://arxiv.org/pdf/2404.01283", "title": "Evaluating Privacy Perceptions, Experience, and Behavior of Software  Development Teams", "authors": "Maxwell Prybylo, Sara Haghighi, Sai Teja Peddinti, Sepideh Ghanavati", "subjects": "Software Engineering (cs.SE); Human-Computer Interaction (cs.HC)", "abstract": "With the increase in the number of privacy regulations, small development teams are forced to make privacy decisions on their own. In this paper, we conduct a mixed-method survey study, including statistical and qualitative analysis, to evaluate the privacy perceptions, practices, and knowledge of members involved in various phases of software development (SDLC). Our survey includes 362 participants from 23 countries, encompassing roles such as product managers, developers, and testers. Our results show diverse definitions of privacy across SDLC roles, emphasizing the need for a holistic privacy approach throughout SDLC. We find that software teams, regardless of their region, are less familiar with privacy concepts (such as anonymization), relying on self-teaching and forums. Most participants are more familiar with GDPR and HIPAA than other regulations, with multi-jurisdictional compliance being their primary concern. Our results advocate the need for role-dependent solutions to address the privacy challenges, and we highlight research directions and educational takeaways to help improve privacy-aware software development."}
{"main_page": "https://arxiv.org/abs/2404.01284", "pdf": "https://arxiv.org/pdf/2404.01284", "title": "Large Motion Model for Unified Multi-Modal Motion Generation", "authors": "Mingyuan Zhang, Daisheng Jin, Chenyang Gu, Fangzhou Hong, Zhongang Cai, Jingfang Huang, Chongzhi Zhang, Xinying Guo, Lei Yang, Ying He, Ziwei Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Human motion generation, a cornerstone technique in animation and video production, has widespread applications in various tasks like text-to-motion and music-to-dance. Previous works focus on developing specialist models tailored for each task without scalability. In this work, we present Large Motion Model (LMM), a motion-centric, multi-modal framework that unifies mainstream motion generation tasks into a generalist model. A unified motion model is appealing since it can leverage a wide range of motion data to achieve broad generalization beyond a single task. However, it is also challenging due to the heterogeneous nature of substantially different motion data and tasks. LMM tackles these challenges from three principled aspects: 1) Data: We consolidate datasets with different modalities, formats and tasks into a comprehensive yet unified motion generation dataset, MotionVerse, comprising 10 tasks, 16 datasets, a total of 320k sequences, and 100 million frames. 2) Architecture: We design an articulated attention mechanism ArtAttention that incorporates body part-aware modeling into Diffusion Transformer backbone. 3) Pre-Training: We propose a novel pre-training strategy for LMM, which employs variable frame rates and masking forms, to better exploit knowledge from diverse training data. Extensive experiments demonstrate that our generalist LMM achieves competitive performance across various standard motion generation tasks over state-of-the-art specialist models. Notably, LMM exhibits strong generalization capabilities and emerging properties across many unseen tasks. Additionally, our ablation studies reveal valuable insights about training and scaling up large motion models for future research."}
{"main_page": "https://arxiv.org/abs/2404.01288", "pdf": "https://arxiv.org/pdf/2404.01288", "title": "Large Language Models are Capable of Offering Cognitive Reappraisal, if  Guided", "authors": "Hongli Zhan, Allen Zheng, Yoon Kyung Lee, Jina Suh, Junyi Jessy Li, Desmond C. Ong", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) have offered new opportunities for emotional support, and recent work has shown that they can produce empathic responses to people in distress. However, long-term mental well-being requires emotional self-regulation, where a one-time empathic response falls short. This work takes a first step by engaging with cognitive reappraisals, a strategy from psychology practitioners that uses language to targetedly change negative appraisals that an individual makes of the situation; such appraisals is known to sit at the root of human emotional experience. We hypothesize that psychologically grounded principles could enable such advanced psychology capabilities in LLMs, and design RESORT which consists of a series of reappraisal constitutions across multiple dimensions that can be used as LLM instructions. We conduct a first-of-its-kind expert evaluation (by clinical psychologists with M.S. or Ph.D. degrees) of an LLM's zero-shot ability to generate cognitive reappraisal responses to medium-length social media messages asking for support. This fine-grained evaluation showed that even LLMs at the 7B scale guided by RESORT are capable of generating empathic responses that can help users reappraise their situations."}
{"main_page": "https://arxiv.org/abs/2404.01291", "pdf": "https://arxiv.org/pdf/2404.01291", "title": "Evaluating Text-to-Visual Generation with Image-to-Text Generation", "authors": "Zhiqiu Lin, Deepak Pathak, Baiqi Li, Jiayao Li, Xide Xia, Graham Neubig, Pengchuan Zhang, Deva Ramanan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)", "abstract": "Despite significant progress in generative AI, comprehensive evaluation remains challenging because of the lack of effective metrics and standardized benchmarks. For instance, the widely-used CLIPScore measures the alignment between a (generated) image and text prompt, but it fails to produce reliable scores for complex prompts involving compositions of objects, attributes, and relations. One reason is that text encoders of CLIP can notoriously act as a \"bag of words\", conflating prompts such as \"the horse is eating the grass\" with \"the grass is eating the horse\". To address this, we introduce the VQAScore, which uses a visual-question-answering (VQA) model to produce an alignment score by computing the probability of a \"Yes\" answer to a simple \"Does this figure show '{text}'?\" question. Though simpler than prior art, VQAScore computed with off-the-shelf models produces state-of-the-art results across many (8) image-text alignment benchmarks. We also compute VQAScore with an in-house model that follows best practices in the literature. For example, we use a bidirectional image-question encoder that allows image embeddings to depend on the question being asked (and vice versa). Our in-house model, CLIP-FlanT5, outperforms even the strongest baselines that make use of the proprietary GPT-4V. Interestingly, although we train with only images, VQAScore can also align text with video and 3D models. VQAScore allows researchers to benchmark text-to-visual generation using complex texts that capture the compositional structure of real-world prompts. We introduce GenAI-Bench, a more challenging benchmark with 1,600 compositional text prompts that require parsing scenes, objects, attributes, relationships, and high-order reasoning like comparison and logic. GenAI-Bench also offers over 15,000 human ratings for leading image and video generation models such as Stable Diffusion, DALL-E 3, and Gen2."}
{"main_page": "https://arxiv.org/abs/2404.01292", "pdf": "https://arxiv.org/pdf/2404.01292", "title": "Measuring Style Similarity in Diffusion Models", "authors": "Gowthami Somepalli, Anubhav Gupta, Kamal Gupta, Shramay Palta, Micah Goldblum, Jonas Geiping, Abhinav Shrivastava, Tom Goldstein", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Generative models are now widely used by graphic designers and artists. Prior works have shown that these models remember and often replicate content from their training data during generation. Hence as their proliferation increases, it has become important to perform a database search to determine whether the properties of the image are attributable to specific training data, every time before a generated image is used for professional purposes. Existing tools for this purpose focus on retrieving images of similar semantic content. Meanwhile, many artists are concerned with style replication in text-to-image models. We present a framework for understanding and extracting style descriptors from images. Our framework comprises a new dataset curated using the insight that style is a subjective property of an image that captures complex yet meaningful interactions of factors including but not limited to colors, textures, shapes, etc. We also propose a method to extract style descriptors that can be used to attribute style of a generated image to the images used in the training dataset of a text-to-image model. We showcase promising results in various style retrieval tasks. We also quantitatively and qualitatively analyze style attribution and matching in the Stable Diffusion model. Code and artifacts are available at https://github.com/learn2phoenix/CSD."}
{"main_page": "https://arxiv.org/abs/2404.01294", "pdf": "https://arxiv.org/pdf/2404.01294", "title": "CosmicMan: A Text-to-Image Foundation Model for Humans", "authors": "Shikai Li, Jianglin Fu, Kaiyuan Liu, Wentao Wang, Kwan-Yee Lin, Wayne Wu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present CosmicMan, a text-to-image foundation model specialized for generating high-fidelity human images. Unlike current general-purpose foundation models that are stuck in the dilemma of inferior quality and text-image misalignment for humans, CosmicMan enables generating photo-realistic human images with meticulous appearance, reasonable structure, and precise text-image alignment with detailed dense descriptions. At the heart of CosmicMan's success are the new reflections and perspectives on data and models: (1) We found that data quality and a scalable data production flow are essential for the final results from trained models. Hence, we propose a new data production paradigm, Annotate Anyone, which serves as a perpetual data flywheel to produce high-quality data with accurate yet cost-effective annotations over time. Based on this, we constructed a large-scale dataset, CosmicMan-HQ 1.0, with 6 Million high-quality real-world human images in a mean resolution of 1488x1255, and attached with precise text annotations deriving from 115 Million attributes in diverse granularities. (2) We argue that a text-to-image foundation model specialized for humans must be pragmatic -- easy to integrate into down-streaming tasks while effective in producing high-quality human images. Hence, we propose to model the relationship between dense text descriptions and image pixels in a decomposed manner, and present Decomposed-Attention-Refocusing (Daring) training framework. It seamlessly decomposes the cross-attention features in existing text-to-image diffusion model, and enforces attention refocusing without adding extra modules. Through Daring, we show that explicitly discretizing continuous text space into several basic groups that align with human body structure is the key to tackling the misalignment problem in a breeze."}
{"main_page": "https://arxiv.org/abs/2404.01295", "pdf": "https://arxiv.org/pdf/2404.01295", "title": "Towards Safety and Helpfulness Balanced Responses via Controllable Large  Language Models", "authors": "Yi-Lin Tuan, Xilun Chen, Eric Michael Smith, Louis Martin, Soumya Batra, Asli Celikyilmaz, William Yang Wang, Daniel M. Bikel", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "As large language models (LLMs) become easily accessible nowadays, the trade-off between safety and helpfulness can significantly impact user experience. A model that prioritizes safety will cause users to feel less engaged and assisted while prioritizing helpfulness will potentially cause harm. Possible harms include teaching people how to build a bomb, exposing youth to inappropriate content, and hurting users' mental health. In this work, we propose to balance safety and helpfulness in diverse use cases by controlling both attributes in LLM. We explore training-free and fine-tuning methods that do not require extra human annotations and analyze the challenges of controlling safety and helpfulness in LLMs. Our experiments demonstrate that our method can rewind a learned model and unlock its controllability."}
{"main_page": "https://arxiv.org/abs/2404.01296", "pdf": "https://arxiv.org/pdf/2404.01296", "title": "MagicMirror: Fast and High-Quality Avatar Generation with a Constrained  Search Space", "authors": "Armand Comas-Massagu\u00e9, Di Qiu, Menglei Chai, Marcel B\u00fchler, Amit Raj, Ruiqi Gao, Qiangeng Xu, Mark Matthews, Paulo Gotardo, Octavia Camps, Sergio Orts-Escolano, Thabo Beeler", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We introduce a novel framework for 3D human avatar generation and personalization, leveraging text prompts to enhance user engagement and customization. Central to our approach are key innovations aimed at overcoming the challenges in photo-realistic avatar synthesis. Firstly, we utilize a conditional Neural Radiance Fields (NeRF) model, trained on a large-scale unannotated multi-view dataset, to create a versatile initial solution space that accelerates and diversifies avatar generation. Secondly, we develop a geometric prior, leveraging the capabilities of Text-to-Image Diffusion Models, to ensure superior view invariance and enable direct optimization of avatar geometry. These foundational ideas are complemented by our optimization pipeline built on Variational Score Distillation (VSD), which mitigates texture loss and over-saturation issues. As supported by our extensive experiments, these strategies collectively enable the creation of custom avatars with unparalleled visual quality and better adherence to input text prompts. You can find more results and videos in our website: https://syntec-research.github.io/MagicMirror"}
{"main_page": "https://arxiv.org/abs/2404.01297", "pdf": "https://arxiv.org/pdf/2404.01297", "title": "Streaming Dense Video Captioning", "authors": "Xingyi Zhou, Anurag Arnab, Shyamal Buch, Shen Yan, Austin Myers, Xuehan Xiong, Arsha Nagrani, Cordelia Schmid", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "An ideal model for dense video captioning -- predicting captions localized temporally in a video -- should be able to handle long input videos, predict rich, detailed textual descriptions, and be able to produce outputs before processing the entire video. Current state-of-the-art models, however, process a fixed number of downsampled frames, and make a single full prediction after seeing the whole video. We propose a streaming dense video captioning model that consists of two novel components: First, we propose a new memory module, based on clustering incoming tokens, which can handle arbitrarily long videos as the memory is of a fixed size. Second, we develop a streaming decoding algorithm that enables our model to make predictions before the entire video has been processed. Our model achieves this streaming ability, and significantly improves the state-of-the-art on three dense video captioning benchmarks: ActivityNet, YouCook2 and ViTT. Our code is released at https://github.com/google-research/scenic."}
{"main_page": "https://arxiv.org/abs/2404.01298", "pdf": "https://arxiv.org/pdf/2404.01298", "title": "Noise2Image: Noise-Enabled Static Scene Recovery for Event Cameras", "authors": "Ruiming Cao, Dekel Galor, Amit Kohli, Jacob L Yates, Laura Waller", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Event cameras capture changes of intensity over time as a stream of 'events' and generally cannot measure intensity itself; hence, they are only used for imaging dynamic scenes. However, fluctuations due to random photon arrival inevitably trigger noise events, even for static scenes. While previous efforts have been focused on filtering out these undesirable noise events to improve signal quality, we find that, in the photon-noise regime, these noise events are correlated with the static scene intensity. We analyze the noise event generation and model its relationship to illuminance. Based on this understanding, we propose a method, called Noise2Image, to leverage the illuminance-dependent noise characteristics to recover the static parts of a scene, which are otherwise invisible to event cameras. We experimentally collect a dataset of noise events on static scenes to train and validate Noise2Image. Our results show that Noise2Image can robustly recover intensity images solely from noise events, providing a novel approach for capturing static scenes in event cameras, without additional hardware."}
{"main_page": "https://arxiv.org/abs/2404.01299", "pdf": "https://arxiv.org/pdf/2404.01299", "title": "CausalChaos! Dataset for Comprehensive Causal Action Question Answering  Over Longer Causal Chains Grounded in Dynamic Visual Scenes", "authors": "Ting En Lam, Yuhan Chen, Elston Tan, Eric Peh, Ruirui Chen, Paritosh Parmar, Basura Fernando", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Causal video question answering (QA) has garnered increasing interest, yet existing datasets often lack depth in causal reasoning analysis. To address this gap, we capitalize on the unique properties of cartoons and construct CausalChaos!, a novel, challenging causal Why-QA dataset built upon the iconic \"Tom and Jerry\" cartoon series. With thoughtful questions and multi-level answers, our dataset contains much longer causal chains embedded in dynamic interactions and visuals, at the same time principles of animation allows animators to create well-defined, unambiguous causal relationships. These factors allow models to solve more challenging, yet well-defined causal relationships. We also introduce hard negative mining, including CausalConfusion version. While models perform well, there is much room for improvement, especially, on open-ended answers. We identify more advanced/explicit causal relationship modeling and joint modeling of vision and language as the immediate areas for future efforts to focus upon. Along with the other complementary datasets, our new challenging dataset will pave the way for these developments in the field. We will release our dataset, codes, and models to help future efforts in this domain."}
{"main_page": "https://arxiv.org/abs/2404.01300", "pdf": "https://arxiv.org/pdf/2404.01300", "title": "NeRF-MAE : Masked AutoEncoders for Self Supervised 3D representation  Learning for Neural Radiance Fields", "authors": "Muhammad Zubair Irshad, Sergey Zakahrov, Vitor Guizilini, Adrien Gaidon, Zsolt Kira, Rares Ambrus", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Neural fields excel in computer vision and robotics due to their ability to understand the 3D visual world such as inferring semantics, geometry, and dynamics. Given the capabilities of neural fields in densely representing a 3D scene from 2D images, we ask the question: Can we scale their self-supervised pretraining, specifically using masked autoencoders, to generate effective 3D representations from posed RGB images. Owing to the astounding success of extending transformers to novel data modalities, we employ standard 3D Vision Transformers to suit the unique formulation of NeRFs. We leverage NeRF's volumetric grid as a dense input to the transformer, contrasting it with other 3D representations such as pointclouds where the information density can be uneven, and the representation is irregular. Due to the difficulty of applying masked autoencoders to an implicit representation, such as NeRF, we opt for extracting an explicit representation that canonicalizes scenes across domains by employing the camera trajectory for sampling. Our goal is made possible by masking random patches from NeRF's radiance and density grid and employing a standard 3D Swin Transformer to reconstruct the masked patches. In doing so, the model can learn the semantic and spatial structure of complete scenes. We pretrain this representation at scale on our proposed curated posed-RGB data, totaling over 1.6 million images. Once pretrained, the encoder is used for effective 3D transfer learning. Our novel self-supervised pretraining for NeRFs, NeRF-MAE, scales remarkably well and improves performance on various challenging 3D tasks. Utilizing unlabeled posed 2D data for pretraining, NeRF-MAE significantly outperforms self-supervised 3D pretraining and NeRF scene understanding baselines on Front3D and ScanNet datasets with an absolute performance improvement of over 20% AP50 and 8% AP25 for 3D object detection."}
